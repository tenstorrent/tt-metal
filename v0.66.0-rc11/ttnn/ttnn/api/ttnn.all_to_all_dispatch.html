<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>ttnn.all_to_all_dispatch &mdash; TT-NN  documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/tt_theme.css" type="text/css" />
    <link rel="shortcut icon" href="../../_static/favicon.png"/>
    <link rel="canonical" href="/tt-metal/latest/ttnn/ttnn/api/ttnn.all_to_all_dispatch.html" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js?v=b3ba4146"></script>
        <script src="../../_static/doctools.js?v=888ff710"></script>
        <script src="../../_static/sphinx_highlight.js?v=4825356b"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script src="../../_static/posthog.js?v=aa5946f9"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="ttnn.broadcast" href="ttnn.broadcast.html" />
    <link rel="prev" title="ttnn.all_to_all_combine" href="ttnn.all_to_all_combine.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >



<a href="https://docs.tenstorrent.com/">
    <img src="../../_static/tt_logo.svg" class="logo" alt="Logo"/>
</a>

<a href="../../index.html">
    TT-NN
</a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">TTNN</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../about.html">What is TT-NN?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../get_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installing.html">Install</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/tutorials/ttnn_intro.html">TT-NN Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tensor.html">Tensor</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../api.html">APIs</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../api.html#device">Device</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#memory-config">Memory Config</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../api.html#operations">Operations</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../api.html#core">Core</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api.html#tensor-creation">Tensor Creation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api.html#matrix-multiplication">Matrix Multiplication</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api.html#pointwise-unary">Pointwise Unary</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api.html#pointwise-binary">Pointwise Binary</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api.html#pointwise-ternary">Pointwise Ternary</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api.html#quantization">Quantization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api.html#losses">Losses</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api.html#reduction">Reduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api.html#data-movement">Data Movement</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api.html#normalization">Normalization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api.html#normalization-program-configs">Normalization Program Configs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api.html#transformer">Transformer</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="../api.html#ccl">CCL</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="ttnn.all_broadcast.html">ttnn.all_broadcast</a></li>
<li class="toctree-l4"><a class="reference internal" href="ttnn.all_gather.html">ttnn.all_gather</a></li>
<li class="toctree-l4"><a class="reference internal" href="ttnn.all_reduce.html">ttnn.all_reduce</a></li>
<li class="toctree-l4"><a class="reference internal" href="ttnn.all_to_all_combine.html">ttnn.all_to_all_combine</a></li>
<li class="toctree-l4 current"><a class="current reference internal" href="#">ttnn.all_to_all_dispatch</a></li>
<li class="toctree-l4"><a class="reference internal" href="ttnn.broadcast.html">ttnn.broadcast</a></li>
<li class="toctree-l4"><a class="reference internal" href="ttnn.mesh_partition.html">ttnn.mesh_partition</a></li>
<li class="toctree-l4"><a class="reference internal" href="ttnn.point_to_point.html">ttnn.point_to_point</a></li>
<li class="toctree-l4"><a class="reference internal" href="ttnn.reduce_scatter.html">ttnn.reduce_scatter</a></li>
<li class="toctree-l4"><a class="reference internal" href="ttnn.reduce_to_root.html">ttnn.reduce_to_root</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api.html#embedding">Embedding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api.html#convolution">Convolution</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api.html#pooling">Pooling</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api.html#prefetcher">Prefetcher</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api.html#vision">Vision</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api.html#generic">Generic</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api.html#kv-cache">KV Cache</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api.html#backward-operations">Backward operations</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#model-conversion">Model Conversion</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#reports">Reports</a></li>
<li class="toctree-l2"><a class="reference internal" href="../api.html#operation-hooks">Operation Hooks</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials.html">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onboarding.html">Onboarding New Functionality</a></li>
<li class="toctree-l1"><a class="reference internal" href="../converting_torch_model_to_ttnn.html">Converting PyTorch Model to TT-NN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../adding_new_ttnn_operation.html">Adding New TT-NN Operation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../profiling_ttnn_operations.html">Profiling TT-NN Operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../demos.html">Building and Uplifting Demos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tools/index.html">Tools</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Resources</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../resources/support.html">Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../resources/contributing.html">Contributing as a developer</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">TT-NN</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../api.html">APIs</a></li>
      <li class="breadcrumb-item active">ttnn.all_to_all_dispatch</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/ttnn/api/ttnn.all_to_all_dispatch.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="ttnn-all-to-all-dispatch">
<h1>ttnn.all_to_all_dispatch<a class="headerlink" href="#ttnn-all-to-all-dispatch" title="Permalink to this heading"></a>
</h1>
<span class="target" id="id1"></span><dl class="py function">
<dt class="sig sig-object py" id="ttnn.all_to_all_dispatch">
<span class="sig-prename descclassname"><span class="pre">ttnn.</span></span><span class="sig-name descname"><span class="pre">all_to_all_dispatch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_tensor:</span> <span class="pre">ttnn.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">expert_indices_tensor:</span> <span class="pre">ttnn.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">expert_mapping_tensor:</span> <span class="pre">ttnn.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cluster_axis:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_links:</span> <span class="pre">number</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">topology:</span> <span class="pre">ttnn.Topology</span> <span class="pre">=</span> <span class="pre">what</span> <span class="pre">the</span> <span class="pre">mesh</span> <span class="pre">topology</span> <span class="pre">is</span> <span class="pre">initialized</span> <span class="pre">with</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">memory_config:</span> <span class="pre">ttnn.MemoryConfig</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subdevice_id:</span> <span class="pre">ttnn.SubDeviceId</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_concat_dim:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_tensors:</span> <span class="pre">Tuple[ttnn.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ttnn.Tensor]</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">→</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">ttnn.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">ttnn.Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#ttnn.all_to_all_dispatch" title="Permalink to this definition"></a>
</dt>
<dd>
<p>All to all dispatch operation for dispatching the input tokens to devices with the selected experts, based on the expert indices and expert mapping tensors. If cluster axis is specified then we dispatch the tokens to the experts only on that axis. This operation sends tokens to their selected experts, with empty rows for tokens that did not select any experts on that device.
B = local batch size/batch size per device
S = local sequence length/sequence length per device
H = hidden size
K = selected experts per token
D = total number of devices
A = cluster axis to dispatch along
D[A] = number of devices along the cluster axis, just D if cluster axis is not specified.
E = local experts/experts per device
T = total number of tokens per device = B * S</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span>
</dt>
<dd class="field-odd">
<ul class="simple">
<li><p><strong>input_tensor</strong> (<em>ttnn.Tensor</em>) – The input tensor containing the tokens to dispatch. The tensor is expected to be [B, S, 1, H] per device, sharded along either the batch dimension or the sequence dimension, such that the global shape is either [B*D[A], S, 1, H] or [B, S*D[A], 1, H]. Each row is a token. The tensor is expected to be in Row Major, Interleaved format. It is duplicated on the non-cluster axis.</p></li>
<li><p><strong>expert_indices_tensor</strong> (<em>ttnn.Tensor</em>) – The expert indices tensor containing the ranking of the experts for each token. The tensor is expected to be [B, S, 1, K] per device, sharded identically to the input_tensor. Each value in the row is an expert index, which corresponds to a row index in the expert mapping tensor. This tensor only contains the expert ranking for the tokens local to that device. The tensor is expected to be in Row Major, Interleaved format. It is duplicated on the non-cluster axis.</p></li>
<li><p><strong>expert_mapping_tensor</strong> (<em>ttnn.Tensor</em>) – The one-hot encoded expert to device mapping tensor containing the location of the experts among each device and each mesh. The tensor is expected to be [1, 1, E, D] per device, fully replicated across all devices. Each row corresponds to an expert, and the value in each corresponding column is 1 if the expert is on the device, 0 otherwise. The tensor is expected to be in Row Major, Interleaved format. This tensor is expected to be the same across all devices.</p></li>
</ul>
</dd>
<dt class="field-even">Keyword Arguments<span class="colon">:</span>
</dt>
<dd class="field-even">
<ul class="simple">
<li><p><strong>cluster_axis</strong> (<em>int</em><em>, </em><em>optional</em>) – the cluster axis to dispatch along. Defaults to <cite>None</cite> though we assert out when it is not specified.</p></li>
<li><p><strong>num_links</strong> (<em>number</em><em>, </em><em>optional</em>) – the number of cross-device links to use for dispatching the tokens. Defaults to <cite>None</cite>, for which the number of links is determined automatically.</p></li>
<li><p><strong>topology</strong> (<em>ttnn.Topology</em><em>, </em><em>optional</em>) – the topology to use when dispatching the tokens. Defaults to what the mesh topology is initialized with. CAREFUL: no guarantees that the topology is valid for the given Fabric Init unless it matches the topology of the mesh.</p></li>
<li><p><strong>memory_config</strong> (<em>ttnn.MemoryConfig</em><em>, </em><em>optional</em>) – Output memory configuration for the output tensors. Defaults to <cite>None</cite>.</p></li>
<li><p><strong>subdevice_id</strong> (<em>ttnn.SubDeviceId</em><em>, </em><em>optional</em>) – the subdevice id for the subdevice on which we allocate the worker cores. Defaults to <cite>None</cite>.</p></li>
<li><p><strong>output_concat_dim</strong> (<em>int</em><em>, </em><em>optional</em>) – the dimension to concat the output tokens along. Defaults to <cite>1</cite>, which is the batch dimension.</p></li>
<li><p><strong>output_tensors</strong> (<em>Tuple</em><em>[</em><em>ttnn.Tensor</em><em>, </em><em>ttnn.Tensor</em><em>]</em><em>, </em><em>optional</em>) – the optional output tensors to use for the dispatched tokens and the metadata. Defaults to <cite>None</cite>.</p></li>
</ul>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span>
</dt>
<dd class="field-odd">
<p></p>
<p><em>Tuple[ttnn.Tensor, ttnn.Tensor]</em> – The sparse output tokens tensor and the metadata tensor. The output tensor on each device is sparsely populated with all the tokens that are dispatched to that device. The non-dispatched tokens have placeholder rows populated with garbage. The metadata tensor is used to track the expert indices.</p>
<p>output_tensor: The output tensor is expected to be [1, B*D[A], S, H] per device if output_concat_dim is 1 or [1, B, S*D[A], H] per device if output_concat_dim is 2, sharded fully such that we have [D, B*D[A], S, H] or [D, B, S*D[A], H] total when gathered along dimension 0. Each row is either a token if that token was dispatched to that device, or a placeholder row if that token was not dispatched to that device. The tensor is expected to be in Row Major, Interleaved format.
expert_metadata_tensor: The metadata tensor is expected to be [1, B*D[A], S, K] per device if output_concat_dim is 1 or [1, B, S*D[A], K] per device if output_concat_dim is 2, replicated across all devices. Each row contains the all the expert indices selected for each token on the mesh. This is equivalent to an all-gather of the expert indices. The tensor is expected to be in Row Major, Interleaved format.</p>

</dd>
</dl>
<div class="admonition-example admonition">
<p class="admonition-title">Example</p>
<div class="doctest highlight-default notranslate">
<div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">output_tensor</span><span class="p">,</span> <span class="n">metadata_tensor</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">all_to_all_dispatch</span><span class="p">(</span>
<span class="go">                input_tensor,</span>
<span class="go">                expert_indices_tensor,</span>
<span class="go">                expert_mapping_tensor,</span>
<span class="go">                cluster_axis=cluster_axis,</span>
<span class="go">                num_links=num_links,</span>
<span class="go">                topology=topology,</span>
<span class="go">                memory_config=memory_config,</span>
<span class="go">                subdevice_id=subdevice_id,</span>
<span class="go">                output_concat_dim=output_concat_dim)</span>
</pre></div>
</div>
</div>
</dd>
</dl>

</section>



           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="ttnn.all_to_all_combine.html" class="btn btn-neutral float-left" title="ttnn.all_to_all_combine" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="ttnn.broadcast.html" class="btn btn-neutral float-right" title="ttnn.broadcast" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright Tenstorrent.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
        Version: <span id="current-version">latest</span>
        <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
        <dl id="version-list">
            <dt>Versions</dt>
        </dl>
        <br>
        </dl>
    </div>
</div>

<script>
const VERSIONS_URL = 'https://raw.githubusercontent.com/tenstorrent/tt-metal/refs/heads/main/docs/published_versions.json';

async function loadVersions() {
    try {
        const response = await fetch(VERSIONS_URL);
        const data = await response.json();
        const versionList = document.getElementById('version-list');
        const projectCode = location.pathname.split('/')[3];

        data.versions.forEach(version => {
            const dd = document.createElement('dd');
            const link = document.createElement('a');
            link.href = `https://docs.tenstorrent.com/tt-metal/${version}/${projectCode}/index.html`;
            link.textContent = version;
            dd.appendChild(link);
            versionList.appendChild(dd);
        });
    } catch (error) {
        console.error('Error loading versions:', error);
    }
}

loadVersions();

function getCurrentVersion() {
    return window.location.pathname.split('/')[2];
}
document.getElementById('current-version').textContent = getCurrentVersion();

const versionEl = document.createElement("span");
versionEl.innerText = getCurrentVersion();
versionEl.className = "project-versions";
const wySideSearchEl = document.getElementsByClassName("wy-side-nav-search").item(0);
if (wySideSearchEl) {
    const projectNameEl = wySideSearchEl.children.item(1);
    if (projectNameEl) projectNameEl.appendChild(versionEl);
}

</script><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>