{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f292ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "from models.common.utility_functions import ulp\n",
    "import os\n",
    "os.environ[\"TT_METAL_CACHE\"] = \"/localdev/astancov/tt-metal/built\" \n",
    "from loguru import logger\n",
    "\n",
    "# Disable TT logging\n",
    "os.environ['TT_LOGGER_LEVEL'] = 'off'\n",
    "logger.disable('ttnn')\n",
    "\n",
    "default_fig_size = (6, 4)\n",
    "\n",
    "def plot_abs_err_histogram(res: torch.Tensor, ref: torch.Tensor, n_bins: int = 100):\n",
    "    \"\"\"\n",
    "    Plot histogram of absolute differences (res - ref).\n",
    "    \n",
    "    Args:\n",
    "        res: Result tensor\n",
    "        ref: Reference tensor\n",
    "        n_bins: Number of bins for histogram\n",
    "    \"\"\"\n",
    "    abs_err = (res - ref).detach().cpu().numpy()\n",
    "    abs_err_flat = abs_err.flatten()\n",
    "    \n",
    "    plt.figure(figsize=default_fig_size)\n",
    "    plt.hist(abs_err_flat, bins=n_bins, edgecolor='black', alpha=0.7)\n",
    "    plt.xlabel('Absolute Error')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Absolute Errors')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Mean absolute error: {abs_err_flat.mean():.6e}\")\n",
    "    print(f\"Max absolute error: {abs_err_flat.max():.6e}\")\n",
    "    print(f\"Min absolute error: {abs_err_flat.min():.6e}\")\n",
    "\n",
    "\n",
    "def plot_rel_err_histogram(res: torch.Tensor, ref: torch.Tensor, n_bins: int = 100):\n",
    "    \"\"\"\n",
    "    Plot histogram of relative errors (res - ref) / ref.\n",
    "    \n",
    "    Args:\n",
    "        res: Result tensor\n",
    "        ref: Reference tensor\n",
    "        n_bins: Number of bins for histogram\n",
    "    \"\"\"\n",
    "    abs_err = (res - ref).abs().detach().cpu()\n",
    "    ref_abs = ref.abs().detach().cpu()\n",
    "    \n",
    "    # Avoid division by zero - set zeros in ref to 1 (or use mask)\n",
    "    rel_err = abs_err / torch.where(ref_abs > 0, ref_abs, torch.ones_like(ref_abs))\n",
    "    rel_err_np = rel_err.numpy().flatten()\n",
    "    \n",
    "    # Filter out inf/nan values\n",
    "    rel_err_np = rel_err_np[np.isfinite(rel_err_np)]\n",
    "    \n",
    "    plt.figure(figsize=default_fig_size)\n",
    "    plt.hist(rel_err_np, bins=n_bins, edgecolor='black', alpha=0.7)\n",
    "    plt.xlabel('Relative Error')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Relative Errors')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Mean relative error: {rel_err_np.mean():.6e}\")\n",
    "    print(f\"Max relative error: {rel_err_np.max():.6e}\")\n",
    "    print(f\"Median relative error: {np.median(rel_err_np):.6e}\")\n",
    "\n",
    "\n",
    "def rel_fro_error(res, ref):\n",
    "        res_np = res.to(torch.float64).detach().cpu().numpy() if isinstance(res, torch.Tensor) else np.asarray(res).astype(np.float64)\n",
    "        ref_np = ref.to(torch.float64).detach().cpu().numpy() if isinstance(ref, torch.Tensor) else np.asarray(ref).astype(np.float64)\n",
    "        # flatten scalars for np.linalg.norm\n",
    "        if np.isscalar(res_np) or (hasattr(res_np, \"shape\") and res_np.shape == ()):\n",
    "            res_np = np.array([res_np])\n",
    "        if np.isscalar(ref_np) or (hasattr(ref_np, \"shape\") and ref_np.shape == ()):\n",
    "            ref_np = np.array([ref_np])\n",
    "        num = np.linalg.norm(res_np - ref_np)\n",
    "        denom = np.linalg.norm(ref_np)\n",
    "        if denom == 0:\n",
    "            return float(\"inf\") if num > 0 else 0.0\n",
    "        return float(num) / float(denom)\n",
    "\n",
    "def plot_rel_fro_error_vs_magnitude(\n",
    "    res_list: list, \n",
    "    names: list, \n",
    "    ref_list: list, \n",
    "    title_suffix=\"\"\n",
    "):\n",
    "    \"\"\"\n",
    "    For each method (entry in res_list), plot the relative Frobenius error vs reference range.\n",
    "    Each entry in res_list should be a list of result tensors corresponding to ref_list.\n",
    "    Args:\n",
    "        res_list: List of lists. Each sublist is a list of result tensors for one method.\n",
    "                 Each tensor can be a torch.Tensor or a numpy array.\n",
    "        ref_list: List of reference tensors (torch.Tensor or numpy arrays).\n",
    "        names: List of legend entries, one for each sublist in res_list.\n",
    "        title_suffix: String to append to the plot title.\n",
    "    \"\"\"\n",
    "    if not isinstance(res_list, list) or not isinstance(ref_list, list) or not isinstance(names, list):\n",
    "        raise ValueError(\"res_list, ref_list, and names must all be lists.\")\n",
    "    if len(res_list) != len(names):\n",
    "        raise ValueError(\"res_list and names must have the same length\")\n",
    "    n_refs = len(ref_list)\n",
    "    for r in res_list:\n",
    "        if len(r) != n_refs:\n",
    "            raise ValueError(\"Each inner list in res_list must have the same length as ref_list.\")\n",
    "\n",
    "    def to_numpy(x):\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            return x.detach().cpu().numpy()\n",
    "        return np.asarray(x)\n",
    "\n",
    "    ranges = []\n",
    "    for ref in ref_list:\n",
    "        ref_np = to_numpy(ref)\n",
    "        ref_range = ref_np.max() - ref_np.min()\n",
    "        ranges.append(ref_range)\n",
    "\n",
    "    plt.figure(figsize=default_fig_size)\n",
    "    for results, label in zip(res_list, names):\n",
    "        rel_errors = [rel_fro_error(res, ref) for res, ref in zip(results, ref_list)]\n",
    "        marker = '.' if 'unfold' in label.lower() else 'x'\n",
    "        plt.plot(ranges, rel_errors, marker=marker, linestyle=\"-\", markersize=10 if marker == 'x' else 8, label=label, linewidth=2, alpha=0.7)\n",
    "\n",
    "    plt.xlabel('Reference Range (max - min)')\n",
    "    plt.ylabel('Relative Frobenius Error (||res-ref|| / ||ref||)')\n",
    "    plt.title('Relative Frobenius Error vs Reference Magnitude Range' + (f\" {title_suffix}\" if title_suffix else \"\"))\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_rel_error_vs_param(\n",
    "    tensors, names, refs, norm_type=\"fro\", param_vals=None, param_name=\"K\", logy=False, title_suffix=\"\", fig_size=default_fig_size\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots relative norm error (||res-ref|| / ||ref|| using specified norm) vs a parameter for multiple sets of tensors.\n",
    "\n",
    "    Args:\n",
    "        tensors: list of lists of tensors. Each element of the outer list corresponds to a group/method/etc,\n",
    "                 and should be a list of tensors (length n_params), one for each parameter value.\n",
    "        names:   list of names (length = len(tensors)), one per outer list.\n",
    "        refs:    list of reference tensors (length n_params), one for each parameter value.\n",
    "        norm_type: str, one of [\"fro\", \"1\", \"inf\", \"spectral\"] (required).\n",
    "        param_vals: optional list of parameter values (length n_params); otherwise [0, ..., n_params-1].\n",
    "        param_name: string for parameter name in x-axis label.\n",
    "        logy:     whether to plot y-axis in log scale.\n",
    "    \"\"\"\n",
    "\n",
    "    if norm_type not in [\"fro\", \"1\", \"inf\", \"spectral\"]:\n",
    "        raise ValueError(f\"norm_type must be one of ['fro', '1', 'inf', 'spectral'], got '{norm_type}'\")\n",
    "\n",
    "    if not isinstance(tensors, list) or not isinstance(names, list) or not isinstance(refs, list):\n",
    "        raise ValueError(\"tensors, names, and refs must all be lists.\")\n",
    "    if len(tensors) != len(names):\n",
    "        raise ValueError(\"tensors and names must have the same length.\")\n",
    "    if len(tensors) == 0:\n",
    "        raise ValueError(\"tensors list must not be empty.\")\n",
    "    n_params = [len(row) for row in tensors]\n",
    "    n_refs = len(refs)\n",
    "    if any(n != n_refs for n in n_params):\n",
    "        raise ValueError(\"Each inner list in tensors and refs must all have the same length (len(refs)).\")\n",
    "    xvals = list(range(n_refs)) if param_vals is None else param_vals\n",
    "    if len(xvals) != n_refs:\n",
    "        raise ValueError(\"Mismatch between param_vals and number of reference tensors.\")\n",
    "\n",
    "    def to_numpy(x):\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            return x.to(torch.float64).detach().cpu().numpy()\n",
    "        return np.asarray(x).astype(np.float64)\n",
    "\n",
    "    def rel_norm_error(res, ref, norm):\n",
    "        # norm can be \"fro\", 1, np.inf, \"spectral\"\n",
    "        # Flatten to 1D for consistent norm computation\n",
    "        res_np = to_numpy(res).flatten()\n",
    "        ref_np = to_numpy(ref).flatten()\n",
    "        \n",
    "        # For 1D arrays, Frobenius norm is equivalent to L2 norm\n",
    "        if norm == \"fro\":\n",
    "            err = np.linalg.norm(res_np - ref_np, ord=2) / np.linalg.norm(ref_np, ord=2)\n",
    "        elif norm == \"1\":\n",
    "            err = np.linalg.norm(res_np - ref_np, ord=1) / np.linalg.norm(ref_np, ord=1)\n",
    "        elif norm == \"inf\":\n",
    "            err = np.linalg.norm(res_np - ref_np, ord=np.inf) / np.linalg.norm(ref_np, ord=np.inf)\n",
    "        elif norm == \"spectral\":\n",
    "            # For 1D arrays, spectral norm is the same as L2 norm\n",
    "            err = np.linalg.norm(res_np - ref_np, ord=2) / np.linalg.norm(ref_np, ord=2)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported norm type: {norm}\")\n",
    "        return err\n",
    "\n",
    "    norm_label = {\n",
    "        \"fro\": \"Frobenius-Norm\",\n",
    "        \"1\": \"1-Norm\",\n",
    "        \"inf\": \"Infinity-Norm\",\n",
    "        \"spectral\": \"Spectral-Norm\"\n",
    "    }[norm_type]\n",
    "\n",
    "    plt.figure(figsize=fig_size)\n",
    "    for idx, (tensor_list, label) in enumerate(zip(tensors, names)):\n",
    "        errors = [rel_norm_error(out, ref, norm_type) for out, ref in zip(tensor_list, refs)]\n",
    "        marker_style = \"x\" if \"torch\" in str(label) else \"o\"\n",
    "        plt.plot(xvals, errors, marker=marker_style, linestyle=\"-\", markersize=10 if marker_style == \"x\" else 8, label=str(label), linewidth=2)\n",
    "\n",
    "    plt.xlabel(f\"{param_name}\")\n",
    "    plt.ylabel(f\"Relative {norm_label} Error (||res-ref|| / ||ref||\") \n",
    "    plt.title(\n",
    "        f\"Relative {norm_label} Error vs {param_name}\"\n",
    "        + (f\" {title_suffix}\" if title_suffix else \"\")\n",
    "    )\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    # Avoid duplicate labels in legend\n",
    "    handles, all_labels = plt.gca().get_legend_handles_labels()\n",
    "    unique = dict(zip(all_labels, handles))\n",
    "    plt.legend(unique.values(), unique.keys())\n",
    "    if logy:\n",
    "        plt.yscale(\"log\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def ulp_error(res, ref):\n",
    "    \"\"\"\n",
    "    Compute the ULP error (in res ULPs)between two tensors.\n",
    "    \n",
    "    Args:\n",
    "        res: Result tensor\n",
    "        ref: Reference tensor\n",
    "        \n",
    "    Returns:\n",
    "        ULP error between res and ref (in ULPs of res)\n",
    "    \"\"\"\n",
    "    res_ulp = ulp(res)\n",
    "    ref_as_res_dtype = ref.to(res.dtype)\n",
    "    return torch.abs((res.to(torch.float64) - ref_as_res_dtype.to(torch.float64)) / res_ulp.to(torch.float64))\n",
    "\n",
    "def plot_ulp_error_histogram(res, ref, n_bins=100):\n",
    "    \"\"\"\n",
    "    Plot the ULP error histogram for two tensors.\n",
    "\n",
    "    Args:\n",
    "        res: Result tensor\n",
    "        ref: Reference tensor\n",
    "        n_bins: Number of bins for the histogram\n",
    "    \"\"\"\n",
    "    ulp_errors = ulp_error(res, ref)\n",
    "    ulp_vals = ulp_errors.detach().cpu().numpy().flatten()\n",
    "    plt.figure(figsize=default_fig_size)\n",
    "    plt.hist(ulp_vals, bins=n_bins, alpha=0.7, linewidth=2, edgecolor='black')\n",
    "    plt.xlabel('ULP Error')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('ULP Error Histogram')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_ulp_error_cdf(res, ref):\n",
    "    \"\"\"\n",
    "    Plot the ULP error CDF for two tensors.\n",
    "\n",
    "    Args:\n",
    "        res: Result tensor\n",
    "        ref: Reference tensor\n",
    "    \"\"\"\n",
    "    ulp_errors = ulp_error(res, ref)\n",
    "    ulp_vals = ulp_errors.detach().cpu().numpy().flatten()\n",
    "    sorted_vals = np.sort(ulp_vals)\n",
    "    cdf = np.arange(1, len(sorted_vals) + 1) / len(sorted_vals)\n",
    "\n",
    "    plt.figure(figsize=default_fig_size)\n",
    "    plt.plot(sorted_vals, cdf, linewidth=2)\n",
    "    plt.xlabel('ULP Error')\n",
    "    plt.ylabel('Cumulative Probability')\n",
    "    plt.title('ULP Error CDF')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9f6673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ttnn\n",
    "from ttnn.operations.conv2d import conv2d_unfold_matmul\n",
    "\n",
    "def generate_torch_conv_tensors(batch, in_channels, out_channels, height, width, kernel_h, kernel_w, dtype, scaler=1.0, rand_func=torch.rand,seed=None):\n",
    "    \"\"\"\n",
    "    Generate random input and weight tensors for a conv2d\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "    input_tensor = rand_func((batch, in_channels, height, width), dtype=dtype) * scaler\n",
    "    weight_tensor = rand_func((out_channels, in_channels, kernel_h, kernel_w), dtype=dtype) * scaler\n",
    "    bias_tensor = rand_func((1, 1, 1, out_channels), dtype=dtype) * scaler\n",
    "    return input_tensor, weight_tensor, bias_tensor\n",
    "\n",
    "def run_torch_conv2d(input, weight, bias, stride=1, padding=0):\n",
    "    \"\"\"\n",
    "    Run a single conv2d in torch using the input tensors\n",
    "    \"\"\"\n",
    "    return torch.nn.functional.conv2d(input, weight, bias.reshape(-1) if bias is not None else None, stride=stride, padding=padding)\n",
    "\n",
    "def run_conv2d_unfold_matmul(input, weight, bias, stride=1, padding=0, matmul_precision=\"highest\"):\n",
    "    \"\"\"\n",
    "    Run conv2d using unfold+matmul decomposition\n",
    "    \"\"\"\n",
    "    return conv2d_unfold_matmul(input, weight, bias, stride=stride, padding=padding, matmul_precision=matmul_precision)\n",
    "\n",
    "def run_np_conv2d(input, weight, bias, stride=1, padding=0):\n",
    "    \"\"\"\n",
    "    Run a single conv2d using numpy float64 (via torch for conv2d operation)\n",
    "    Input tensors are numpy arrays in NCHW format\n",
    "    \"\"\"\n",
    "    # Convert numpy arrays to torch tensors\n",
    "    input_torch = torch.from_numpy(input)\n",
    "    weight_torch = torch.from_numpy(weight)\n",
    "    bias_torch = torch.from_numpy(bias) if bias is not None else None\n",
    "    \n",
    "    # Run conv2d\n",
    "    output = torch.nn.functional.conv2d(input_torch, weight_torch, bias_torch.reshape(-1) if bias_torch is not None else None, stride=stride, padding=padding)\n",
    "    \n",
    "    # Convert back to numpy\n",
    "    return output.numpy()\n",
    "\n",
    "def run_ttnn_conv2d(input, weight, bias, device, stride=1, padding=0, dtype=ttnn.bfloat16, \n",
    "                    fp32_accum=False, math_fidelity=ttnn.MathFidelity.HiFi4):\n",
    "    \"\"\"\n",
    "    Run a single conv2d in ttnn and return the result.\n",
    "    Input: input is NCHW torch tensor, weight is OIHW, bias is (1,1,1,C) or None\n",
    "    Args:\n",
    "        device: ttnn device (required, like in test_conv2d.py)\n",
    "        dtype: ttnn dtype for activations, weights, and bias (ttnn.bfloat16, ttnn.float32, etc.)\n",
    "        fp32_accum: whether to use FP32 dest accumulation in compute kernel\n",
    "        math_fidelity: math fidelity setting (LoFi, HiFi2, HiFi3, HiFi4)\n",
    "    \"\"\"\n",
    "    create_local_device = device is None\n",
    "    if create_local_device:\n",
    "        device = ttnn.CreateDevice(0,l1_small_size = 16384)\n",
    "    # Extract dimensions\n",
    "    batch, in_channels, height, width = input.shape\n",
    "    out_channels = weight.shape[0]\n",
    "    kernel_h, kernel_w = weight.shape[2], weight.shape[3]\n",
    "    \n",
    "    # Handle padding and stride\n",
    "    if isinstance(padding, int):\n",
    "        pad_h, pad_w = padding, padding\n",
    "    elif len(padding) == 2:\n",
    "        pad_h, pad_w = padding[0], padding[1]\n",
    "    elif len(padding) == 4:\n",
    "        pad_h, pad_w = padding[0], padding[2]  # Use top and left\n",
    "    else:\n",
    "        pad_h = pad_w = padding\n",
    "        \n",
    "    if isinstance(stride, int):\n",
    "        str_h, str_w = stride, stride\n",
    "    elif len(stride) == 2:\n",
    "        str_h, str_w = stride[0], stride[1]\n",
    "    else:\n",
    "        str_h = str_w = stride\n",
    "    \n",
    "    # Convert input to NHWC format\n",
    "    input_nhwc = input.permute(0, 2, 3, 1).contiguous()\n",
    "    \n",
    "    # Convert to ttnn tensors with specified dtype\n",
    "    tt_input = ttnn.from_torch(input_nhwc, dtype=dtype, layout=ttnn.ROW_MAJOR_LAYOUT, device=device)\n",
    "    tt_weight = ttnn.from_torch(weight, dtype=dtype)\n",
    "    tt_bias = ttnn.from_torch(bias, dtype=dtype) if bias is not None else None\n",
    "    \n",
    "    compute_config = ttnn.init_device_compute_kernel_config(\n",
    "        device.arch(),\n",
    "        math_fidelity=math_fidelity,\n",
    "        math_approx_mode=False,\n",
    "        fp32_dest_acc_en=fp32_accum,\n",
    "        packer_l1_acc=True,  # Always enabled\n",
    "    )\n",
    "    \n",
    "    # Run conv2d (it handles weight preparation internally)\n",
    "    [tt_output, out_dims, _] = ttnn.conv2d(\n",
    "        input_tensor=tt_input,\n",
    "        weight_tensor=tt_weight,\n",
    "        bias_tensor=tt_bias,\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        device=device,\n",
    "        kernel_size=(kernel_h, kernel_w),\n",
    "        stride=(str_h, str_w),\n",
    "        padding=(pad_h, pad_h, pad_w, pad_w),\n",
    "        dilation=(1, 1),\n",
    "        batch_size=batch,\n",
    "        input_height=height,\n",
    "        input_width=width,\n",
    "        compute_config=compute_config,\n",
    "        groups=1,\n",
    "        return_output_dim=True,\n",
    "        return_weights_and_bias=True,\n",
    "    )\n",
    "    \n",
    "    # Convert back to torch\n",
    "    output_torch = ttnn.to_torch(tt_output)\n",
    "    \n",
    "    # Reshape from (1, 1, N*H*W, C) to (N, C, H, W)\n",
    "    out_height, out_width = out_dims\n",
    "    output_nchw = output_torch.reshape(batch, out_height, out_width, out_channels).permute(0, 3, 1, 2)\n",
    "    \n",
    "    if create_local_device:\n",
    "        ttnn.close_device(device)\n",
    "\n",
    "    return output_nchw\n",
    "\n",
    "def single_conv2d_analysis(res, ref):\n",
    "    \"\"\"Run all analysis plots comparing result against reference\"\"\"\n",
    "    plot_abs_err_histogram(res, ref)\n",
    "    plot_rel_err_histogram(res, ref)\n",
    "    plot_ulp_error_histogram(res, ref)\n",
    "    plot_ulp_error_cdf(res, ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc4d097",
   "metadata": {},
   "source": [
    "## Run a single-conv2d analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3467c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do single conv2d, compare ttnn.conv2d (various configs) and conv2d_unfold_matmul to numpy float64 reference\n",
    "batch, in_ch, out_ch = 1, 3, 64\n",
    "height, width = 32, 32\n",
    "kernel_h, kernel_w = 3, 3\n",
    "stride, padding = 1, 1\n",
    "\n",
    "# Create device (like conftest provides in test_conv2d.py)\n",
    "device = None\n",
    "\n",
    "# Generate tensors in float64\n",
    "input_64, weight_64, bias_64 = generate_torch_conv_tensors(batch, in_ch, out_ch, height, width, kernel_h, kernel_w, torch.float64)\n",
    "input_bf16, weight_bf16, bias_bf16 = input_64.to(torch.bfloat16), weight_64.to(torch.bfloat16), bias_64.to(torch.bfloat16)\n",
    "input_f32, weight_f32, bias_f32 = input_64.to(torch.float32), weight_64.to(torch.float32), bias_64.to(torch.float32)\n",
    "\n",
    "# Compute numpy float64 reference\n",
    "input_64_np = input_64.numpy()\n",
    "weight_64_np = weight_64.numpy()\n",
    "bias_64_np = bias_64.numpy()\n",
    "np64_ref = run_np_conv2d(input_64_np, weight_64_np, bias_64_np, stride=stride, padding=padding)\n",
    "\n",
    "# Test implementations - vary dtype, fp32_accum, and math_fidelity\n",
    "ttnn_bf16_hifi4 = run_ttnn_conv2d(input_bf16, weight_bf16, bias_bf16, device, stride=stride, padding=padding, \n",
    "                                  dtype=ttnn.bfloat16, fp32_accum=False, math_fidelity=ttnn.MathFidelity.HiFi4)\n",
    "ttnn_bf16_hifi4_fp32acc = run_ttnn_conv2d(input_bf16, weight_bf16, bias_bf16, device, stride=stride, padding=padding, \n",
    "                                          dtype=ttnn.bfloat16, fp32_accum=True, math_fidelity=ttnn.MathFidelity.HiFi4)\n",
    "ttnn_bf16_lofi = run_ttnn_conv2d(input_bf16, weight_bf16, bias_bf16, device, stride=stride, padding=padding, \n",
    "                                 dtype=ttnn.bfloat16, fp32_accum=False, math_fidelity=ttnn.MathFidelity.LoFi)\n",
    "unfold_bf16 = run_conv2d_unfold_matmul(input_bf16, weight_bf16, bias_bf16, stride=stride, padding=padding)\n",
    "unfold_f32 = run_conv2d_unfold_matmul(input_f32, weight_f32, bias_f32, stride=stride, padding=padding)\n",
    "\n",
    "print(\"\\n=== TTNN Conv2d (bf16, HiFi4) vs NumPy Float64 Reference ===\")\n",
    "single_conv2d_analysis(ttnn_bf16_hifi4, torch.from_numpy(np64_ref))\n",
    "\n",
    "print(\"\\n=== TTNN Conv2d (bf16, HiFi4, FP32 accum) vs NumPy Float64 Reference ===\")\n",
    "single_conv2d_analysis(ttnn_bf16_hifi4_fp32acc, torch.from_numpy(np64_ref))\n",
    "\n",
    "print(\"\\n=== TTNN Conv2d (bf16, LoFi) vs NumPy Float64 Reference ===\")\n",
    "single_conv2d_analysis(ttnn_bf16_lofi, torch.from_numpy(np64_ref))\n",
    "\n",
    "print(\"\\n=== Conv2d Unfold+Matmul (bf16) vs NumPy Float64 Reference ===\")\n",
    "single_conv2d_analysis(unfold_bf16, torch.from_numpy(np64_ref))\n",
    "\n",
    "print(\"\\n=== Conv2d Unfold+Matmul (f32) vs NumPy Float64 Reference ===\")\n",
    "single_conv2d_analysis(unfold_f32, torch.from_numpy(np64_ref))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae43c0c5",
   "metadata": {},
   "source": [
    "## Run a sweep over input magnitudes, compare dtypes, fp32 accum, and math fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a153b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "batch, in_ch, out_ch = 1, 64, 128\n",
    "height, width = 32, 32\n",
    "kernel_h, kernel_w = 3, 3\n",
    "stride, padding = 1, 1\n",
    "\n",
    "\n",
    "# Results for different configurations\n",
    "results_bf16_hifi4 = []\n",
    "results_bf16_hifi4_fp32acc = []\n",
    "results_bf16_hifi2 = []\n",
    "results_bf16_lofi = []\n",
    "results_f32_hifi4 = []\n",
    "results_f32_hifi4_fp32acc = []\n",
    "results_unfold_bf16 = []\n",
    "results_unfold_f32 = []\n",
    "ref_tensors = []\n",
    "\n",
    "for scaler in scalers:\n",
    "    # Generate float64 tensors\n",
    "    input_64, weight_64, bias_64 = generate_torch_conv_tensors(\n",
    "        batch, in_ch, out_ch, height, width, kernel_h, kernel_w, torch.float64, scaler=scaler\n",
    "    )\n",
    "    input_bf16, weight_bf16, bias_bf16 = input_64.to(torch.bfloat16), weight_64.to(torch.bfloat16), bias_64.to(torch.bfloat16)\n",
    "    input_f32, weight_f32, bias_f32 = input_64.to(torch.float32), weight_64.to(torch.float32), bias_64.to(torch.float32)\n",
    "    \n",
    "    # Compute numpy float64 reference\n",
    "    input_64_np = input_64.numpy()\n",
    "    weight_64_np = weight_64.numpy()\n",
    "    bias_64_np = bias_64.numpy()\n",
    "    np64_ref = run_np_conv2d(input_64_np, weight_64_np, bias_64_np, stride=stride, padding=padding)\n",
    "    ref_tensors.append(np64_ref)\n",
    "    \n",
    "    # Results with different configurations (pass device to each call)\n",
    "    results_bf16_hifi4.append(run_ttnn_conv2d(input_bf16, weight_bf16, bias_bf16, device, stride=stride, padding=padding, \n",
    "                                              dtype=ttnn.bfloat16, fp32_accum=False, math_fidelity=ttnn.MathFidelity.HiFi4))\n",
    "    results_bf16_hifi4_fp32acc.append(run_ttnn_conv2d(input_bf16, weight_bf16, bias_bf16, device, stride=stride, padding=padding, \n",
    "                                                       dtype=ttnn.bfloat16, fp32_accum=True, math_fidelity=ttnn.MathFidelity.HiFi4))\n",
    "    results_bf16_hifi2.append(run_ttnn_conv2d(input_bf16, weight_bf16, bias_bf16, device, stride=stride, padding=padding, \n",
    "                                              dtype=ttnn.bfloat16, fp32_accum=False, math_fidelity=ttnn.MathFidelity.HiFi2))\n",
    "    results_bf16_lofi.append(run_ttnn_conv2d(input_bf16, weight_bf16, bias_bf16, device, stride=stride, padding=padding, \n",
    "                                             dtype=ttnn.bfloat16, fp32_accum=False, math_fidelity=ttnn.MathFidelity.LoFi))\n",
    "    results_f32_hifi4.append(run_ttnn_conv2d(input_f32, weight_f32, bias_f32, device, stride=stride, padding=padding, \n",
    "                                             dtype=ttnn.float32, fp32_accum=False, math_fidelity=ttnn.MathFidelity.HiFi4))\n",
    "    results_f32_hifi4_fp32acc.append(run_ttnn_conv2d(input_f32, weight_f32, bias_f32, device, stride=stride, padding=padding, \n",
    "                                                      dtype=ttnn.float32, fp32_accum=True, math_fidelity=ttnn.MathFidelity.HiFi4))\n",
    "    results_unfold_bf16.append(run_conv2d_unfold_matmul(input_bf16, weight_bf16, bias_bf16, stride=stride, padding=padding))\n",
    "    results_unfold_f32.append(run_conv2d_unfold_matmul(input_f32, weight_f32, bias_f32, stride=stride, padding=padding))\n",
    "\n",
    "\n",
    "results = [results_bf16_hifi4, results_bf16_hifi4_fp32acc, results_bf16_hifi2, results_bf16_lofi, \n",
    "           results_f32_hifi4, results_f32_hifi4_fp32acc, results_unfold_bf16, results_unfold_f32]\n",
    "names = [\n",
    "    \"ttnn (bf16, HiFi4)\",\n",
    "    \"ttnn (bf16, HiFi4, fp32acc)\",\n",
    "    \"ttnn (bf16, HiFi2)\",\n",
    "    \"ttnn (bf16, LoFi)\",\n",
    "    \"ttnn (f32, HiFi4)\",\n",
    "    \"ttnn (f32, HiFi4, fp32acc)\",\n",
    "    \"unfold_matmul (bf16)\",\n",
    "    \"unfold_matmul (f32)\"\n",
    "]\n",
    "plot_rel_fro_error_vs_magnitude(\n",
    "    results,\n",
    "    names, \n",
    "    ref_tensors,\n",
    "    title_suffix=\"\\nReference=np64\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d78a4c",
   "metadata": {},
   "source": [
    "## Run a sweep over number of channels, compare dtypes and fp32 accum settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b806a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels_list = [32, 64, 128, 256, 512, 1024, 2048, 2560, 3072, 3584, 4096, 5120, 6144, 7168, 8192, 10240, 12288, 14336, 16384]\n",
    "out_ch = 128  # Fixed output channels\n",
    "batch = 1\n",
    "height, width = 32, 32\n",
    "kernel_h, kernel_w = 3, 3\n",
    "stride, padding = 1, 1\n",
    "\n",
    "tensor_lists = []\n",
    "names_lists = []\n",
    "ref_list = []\n",
    "\n",
    "# Results for different configurations\n",
    "bf16_hifi4_results = []\n",
    "bf16_hifi4_fp32acc_results = []\n",
    "bf16_hifi2_results = []\n",
    "bf16_lofi_results = []\n",
    "f32_hifi4_results = []\n",
    "f32_hifi4_fp32acc_results = []\n",
    "unfold_bf16_results = []\n",
    "unfold_f32_results = []\n",
    "\n",
    "device = None\n",
    "for in_ch in in_channels_list:\n",
    "    # Generate float64 tensors\n",
    "    input_64, weight_64, bias_64 = generate_torch_conv_tensors(\n",
    "        batch, in_ch, out_ch, height, width, kernel_h, kernel_w, torch.float64\n",
    "    )\n",
    "    input_bf16, weight_bf16, bias_bf16 = input_64.to(torch.bfloat16), weight_64.to(torch.bfloat16), bias_64.to(torch.bfloat16)\n",
    "    input_f32, weight_f32, bias_f32 = input_64.to(torch.float32), weight_64.to(torch.float32), bias_64.to(torch.float32)\n",
    "    \n",
    "    # Compute numpy float64 reference\n",
    "    input_64_np = input_64.numpy()\n",
    "    weight_64_np = weight_64.numpy()\n",
    "    bias_64_np = bias_64.numpy()\n",
    "    np64_ref = run_np_conv2d(input_64_np, weight_64_np, bias_64_np, stride=stride, padding=padding)\n",
    "    ref_list.append(np64_ref)\n",
    "    \n",
    "    # Results with different configurations (pass device to each call)\n",
    "    bf16_hifi4_results.append(run_ttnn_conv2d(input_bf16, weight_bf16, bias_bf16, device, stride=stride, padding=padding, \n",
    "                                              dtype=ttnn.bfloat16, fp32_accum=False, math_fidelity=ttnn.MathFidelity.HiFi4))\n",
    "    bf16_hifi4_fp32acc_results.append(run_ttnn_conv2d(input_bf16, weight_bf16, bias_bf16, device, stride=stride, padding=padding, \n",
    "                                                       dtype=ttnn.bfloat16, fp32_accum=True, math_fidelity=ttnn.MathFidelity.HiFi4))\n",
    "    bf16_hifi2_results.append(run_ttnn_conv2d(input_bf16, weight_bf16, bias_bf16, device, stride=stride, padding=padding, \n",
    "                                              dtype=ttnn.bfloat16, fp32_accum=False, math_fidelity=ttnn.MathFidelity.HiFi2))\n",
    "    bf16_lofi_results.append(run_ttnn_conv2d(input_bf16, weight_bf16, bias_bf16, device, stride=stride, padding=padding, \n",
    "                                             dtype=ttnn.bfloat16, fp32_accum=False, math_fidelity=ttnn.MathFidelity.LoFi))\n",
    "    f32_hifi4_results.append(run_ttnn_conv2d(input_f32, weight_f32, bias_f32, device, stride=stride, padding=padding, \n",
    "                                             dtype=ttnn.float32, fp32_accum=False, math_fidelity=ttnn.MathFidelity.HiFi4))\n",
    "    f32_hifi4_fp32acc_results.append(run_ttnn_conv2d(input_f32, weight_f32, bias_f32, device, stride=stride, padding=padding, \n",
    "                                                      dtype=ttnn.float32, fp32_accum=True, math_fidelity=ttnn.MathFidelity.HiFi4))\n",
    "    unfold_bf16_results.append(run_conv2d_unfold_matmul(input_bf16, weight_bf16, bias_bf16, stride=stride, padding=padding))\n",
    "    unfold_f32_results.append(run_conv2d_unfold_matmul(input_f32, weight_f32, bias_f32, stride=stride, padding=padding))\n",
    "\n",
    "\n",
    "# Calculate K = in_channels * kernel_h * kernel_w for x-axis\n",
    "k_vals = [ic * kernel_h * kernel_w for ic in in_channels_list]\n",
    "\n",
    "tensor_lists.extend([bf16_hifi4_results, bf16_hifi4_fp32acc_results, bf16_hifi2_results, bf16_lofi_results,\n",
    "                     f32_hifi4_results, f32_hifi4_fp32acc_results, unfold_bf16_results, unfold_f32_results])\n",
    "names_lists.extend([\n",
    "    \"ttnn (bf16, HiFi4)\",\n",
    "    \"ttnn (bf16, HiFi4, fp32acc)\",\n",
    "    \"ttnn (bf16, HiFi2)\",\n",
    "    \"ttnn (bf16, LoFi)\",\n",
    "    \"ttnn (f32, HiFi4)\",\n",
    "    \"ttnn (f32, HiFi4, fp32acc)\",\n",
    "    \"unfold_matmul (bf16)\",\n",
    "    \"unfold_matmul (f32)\"\n",
    "])\n",
    "\n",
    "for norm_type in [\"fro\", \"1\", \"inf\", \"spectral\"]:\n",
    "    plot_rel_error_vs_param(\n",
    "        tensors=tensor_lists,\n",
    "        names=names_lists,\n",
    "        refs=ref_list,\n",
    "        norm_type=norm_type,\n",
    "        param_vals=k_vals,\n",
    "        param_name=\"K (In_Channels × Kh × Kw)\",\n",
    "        logy=True,\n",
    "        title_suffix=f\"\\nh={height}, w={width}, k={kernel_h}x{kernel_w}, Reference=np64\",\n",
    "        fig_size=(12, 7)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "v0kuq2gsm0r",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense sampling for K <= 10k (where K = in_channels × kernel_h × kernel_w)\n",
    "# With kernel 3x3, K <= 10k means in_channels <= ~1111\n",
    "in_channels_list = [9 * i for i in range(32, 1056, 64)]  # All multiples of 32 from 32 to 1024\n",
    "out_ch = 128  # Fixed output channels\n",
    "batch = 1\n",
    "height, width = 32, 32\n",
    "kernel_h, kernel_w = 1, 1\n",
    "stride, padding = 1, 0\n",
    "\n",
    "tensor_lists = []\n",
    "names_lists = []\n",
    "ref_list = []\n",
    "\n",
    "# Results for different configurations\n",
    "bf16_hifi4_results = []\n",
    "bf16_hifi4_fp32acc_results = []\n",
    "bf16_hifi2_results = []\n",
    "bf16_lofi_results = []\n",
    "f32_hifi4_results = []\n",
    "f32_hifi4_fp32acc_results = []\n",
    "unfold_bf16_results = []\n",
    "unfold_f32_results = []\n",
    "\n",
    "device = None\n",
    "for in_ch in in_channels_list:\n",
    "    # Generate float64 tensors\n",
    "    input_64, weight_64, bias_64 = generate_torch_conv_tensors(\n",
    "        batch, in_ch, out_ch, height, width, kernel_h, kernel_w, torch.float64\n",
    "    )\n",
    "    input_bf16, weight_bf16, bias_bf16 = input_64.to(torch.bfloat16), weight_64.to(torch.bfloat16), bias_64.to(torch.bfloat16)\n",
    "    input_f32, weight_f32, bias_f32 = input_64.to(torch.float32), weight_64.to(torch.float32), bias_64.to(torch.float32)\n",
    "    \n",
    "    # Compute numpy float64 reference\n",
    "    input_64_np = input_64.numpy()\n",
    "    weight_64_np = weight_64.numpy()\n",
    "    bias_64_np = bias_64.numpy()\n",
    "    np64_ref = run_np_conv2d(input_64_np, weight_64_np, bias_64_np, stride=stride, padding=padding)\n",
    "    ref_list.append(np64_ref)\n",
    "    \n",
    "    # Results with different configurations (pass device to each call)\n",
    "    bf16_hifi4_results.append(run_ttnn_conv2d(input_bf16, weight_bf16, bias_bf16, device, stride=stride, padding=padding, \n",
    "                                              dtype=ttnn.bfloat16, fp32_accum=False, math_fidelity=ttnn.MathFidelity.HiFi4))\n",
    "    bf16_hifi4_fp32acc_results.append(run_ttnn_conv2d(input_bf16, weight_bf16, bias_bf16, device, stride=stride, padding=padding, \n",
    "                                                       dtype=ttnn.bfloat16, fp32_accum=True, math_fidelity=ttnn.MathFidelity.HiFi4))\n",
    "    # bf16_hifi2_results.append(run_ttnn_conv2d(input_bf16, weight_bf16, bias_bf16, device, stride=stride, padding=padding, \n",
    "    #                                           dtype=ttnn.bfloat16, fp32_accum=False, math_fidelity=ttnn.MathFidelity.HiFi2))\n",
    "    # bf16_lofi_results.append(run_ttnn_conv2d(input_bf16, weight_bf16, bias_bf16, device, stride=stride, padding=padding, \n",
    "    #                                          dtype=ttnn.bfloat16, fp32_accum=False, math_fidelity=ttnn.MathFidelity.LoFi))\n",
    "    f32_hifi4_results.append(run_ttnn_conv2d(input_f32, weight_f32, bias_f32, device, stride=stride, padding=padding, \n",
    "                                             dtype=ttnn.float32, fp32_accum=False, math_fidelity=ttnn.MathFidelity.HiFi4))\n",
    "    f32_hifi4_fp32acc_results.append(run_ttnn_conv2d(input_f32, weight_f32, bias_f32, device, stride=stride, padding=padding, \n",
    "                                                      dtype=ttnn.float32, fp32_accum=True, math_fidelity=ttnn.MathFidelity.HiFi4))\n",
    "    unfold_bf16_results.append(run_conv2d_unfold_matmul(input_bf16, weight_bf16, bias_bf16, stride=stride, padding=padding))\n",
    "    unfold_f32_results.append(run_conv2d_unfold_matmul(input_f32, weight_f32, bias_f32, stride=stride, padding=padding))\n",
    "\n",
    "\n",
    "# Calculate K = in_channels * kernel_h * kernel_w for x-axis\n",
    "k_vals = [ic * kernel_h * kernel_w for ic in in_channels_list]\n",
    "print(f\"K range: {min(k_vals)} to {max(k_vals)}\")\n",
    "print(f\"Number of points: {len(k_vals)}\")\n",
    "\n",
    "# tensor_lists.extend([bf16_hifi4_results, bf16_hifi4_fp32acc_results, bf16_hifi2_results, bf16_lofi_results,\n",
    "                    #  f32_hifi4_results, f32_hifi4_fp32acc_results, unfold_bf16_results, unfold_f32_results])\n",
    "tensor_lists.extend([bf16_hifi4_results, bf16_hifi4_fp32acc_results,\n",
    "                     f32_hifi4_results, f32_hifi4_fp32acc_results, unfold_bf16_results, unfold_f32_results])\n",
    "names_lists.extend([\n",
    "    \"ttnn (bf16, HiFi4)\",\n",
    "    \"ttnn (bf16, HiFi4, fp32acc)\",\n",
    "    # \"ttnn (bf16, HiFi2)\",\n",
    "    # \"ttnn (bf16, LoFi)\",\n",
    "    \"ttnn (f32, HiFi4)\",\n",
    "    \"ttnn (f32, HiFi4, fp32acc)\",\n",
    "    \"unfold_matmul (bf16)\",\n",
    "    \"unfold_matmul (f32)\"\n",
    "])\n",
    "\n",
    "for norm_type in [\"fro\", \"1\", \"inf\", \"spectral\"]:\n",
    "    plot_rel_error_vs_param(\n",
    "        tensors=tensor_lists,\n",
    "        names=names_lists,\n",
    "        refs=ref_list,\n",
    "        norm_type=norm_type,\n",
    "        param_vals=k_vals,\n",
    "        param_name=\"K (In_Channels × Kh × Kw)\",\n",
    "        logy=True,\n",
    "        title_suffix=f\"\\nh={height}, w={width}, k={kernel_h}x{kernel_w}, Reference=np64\",\n",
    "        fig_size=(12, 7)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833f7a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense sampling for K <= 10k (where K = in_channels × kernel_h × kernel_w)\n",
    "# With kernel 3x3, K <= 10k means in_channels <= ~1111\n",
    "in_channels_list = [1024]  # All multiples of 32 from 32 to 1024\n",
    "out_ch = 32  # Fixed output channels\n",
    "batch = 1\n",
    "height, width = 32, 32\n",
    "kernel_h, kernel_w = 3,3\n",
    "stride, padding = 1, 1\n",
    "\n",
    "tensor_lists = []\n",
    "names_lists = []\n",
    "ref_list = []\n",
    "\n",
    "# Results for different configurations\n",
    "bf16_hifi4_results = []\n",
    "bf16_hifi4_fp32acc_results = []\n",
    "bf16_hifi2_results = []\n",
    "bf16_lofi_results = []\n",
    "f32_hifi4_results = []\n",
    "f32_hifi4_fp32acc_results = []\n",
    "unfold_bf16_results = []\n",
    "unfold_f32_results = []\n",
    "\n",
    "device = None\n",
    "for in_ch in in_channels_list:\n",
    "    # Generate float64 tensors\n",
    "    input_64, weight_64, bias_64 = generate_torch_conv_tensors(\n",
    "        batch, in_ch, out_ch, height, width, kernel_h, kernel_w, torch.float64\n",
    "    )\n",
    "    input_bf16, weight_bf16, bias_bf16 = input_64.to(torch.bfloat16), weight_64.to(torch.bfloat16), bias_64.to(torch.bfloat16)\n",
    "    input_f32, weight_f32, bias_f32 = input_64.to(torch.float32), weight_64.to(torch.float32), bias_64.to(torch.float32)\n",
    "    \n",
    "    # Compute numpy float64 reference\n",
    "    input_64_np = input_64.numpy()\n",
    "    weight_64_np = weight_64.numpy()\n",
    "    bias_64_np = bias_64.numpy()\n",
    "    np64_ref = run_np_conv2d(input_64_np, weight_64_np, bias_64_np, stride=stride, padding=padding)\n",
    "    ref_list.append(np64_ref)\n",
    "    \n",
    "    # Results with different configurations (pass device to each call)\n",
    "    f32_hifi4_results.append(run_ttnn_conv2d(input_f32, weight_f32, bias_f32, device, stride=stride, padding=padding, \n",
    "                                             dtype=ttnn.float32, fp32_accum=False, math_fidelity=ttnn.MathFidelity.HiFi4))\n",
    "    unfold_bf16_results.append(run_conv2d_unfold_matmul(input_bf16, weight_bf16, bias_bf16, stride=stride, padding=padding))\n",
    "    unfold_f32_results.append(run_conv2d_unfold_matmul(input_f32, weight_f32, bias_f32, stride=stride, padding=padding))\n",
    "\n",
    "\n",
    "# Calculate K = in_channels * kernel_h * kernel_w for x-axis\n",
    "k_vals = [ic * kernel_h * kernel_w for ic in in_channels_list]\n",
    "print(f\"K range: {min(k_vals)} to {max(k_vals)}\")\n",
    "print(f\"Number of points: {len(k_vals)}\")\n",
    "\n",
    "tensor_lists.extend([\n",
    "                     f32_hifi4_results, unfold_bf16_results, unfold_f32_results])\n",
    "names_lists.extend([\n",
    "    \"ttnn (f32, HiFi4)\",\n",
    "    \"unfold_matmul (bf16)\",\n",
    "    \"unfold_matmul (f32)\"\n",
    "])\n",
    "\n",
    "for norm_type in [\"fro\", \"1\", \"inf\", \"spectral\"]:\n",
    "    plot_rel_error_vs_param(\n",
    "        tensors=tensor_lists,\n",
    "        names=names_lists,\n",
    "        refs=ref_list,\n",
    "        norm_type=norm_type,\n",
    "        param_vals=k_vals,\n",
    "        param_name=\"K (In_Channels × Kh × Kw)\",\n",
    "        logy=True,\n",
    "        title_suffix=f\"\\nh={height}, w={width}, k={kernel_h}x{kernel_w}, Reference=np64\",\n",
    "        fig_size=(12, 7)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498ba41f",
   "metadata": {},
   "source": [
    "## Run a sweep over kernel sizes, compare dtypes, fp32 accum, and matmul precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e7f491",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_sizes = [(1, 1), (3, 3), (5, 5), (7, 7)]\n",
    "matmul_precisions = [\"high\"]\n",
    "batch, in_ch, out_ch = 1, 64, 128\n",
    "height, width = 32, 32\n",
    "stride, padding = 1, 1\n",
    "\n",
    "# Create device once (like conftest provides in test_conv2d.py)\n",
    "device = None\n",
    "\n",
    "tensor_lists = []\n",
    "names_lists = []\n",
    "ref_list = []\n",
    "\n",
    "# Results for different configurations\n",
    "bf16_hifi4_results = []\n",
    "bf16_hifi4_fp32acc_results = []\n",
    "bf16_hifi2_results = []\n",
    "bf16_lofi_results = []\n",
    "f32_hifi4_results = []\n",
    "f32_hifi4_fp32acc_results = []\n",
    "unfold_bf16_results_by_precision = {prec: [] for prec in matmul_precisions}\n",
    "unfold_f32_results_by_precision = {prec: [] for prec in matmul_precisions}\n",
    "\n",
    "for kernel_h, kernel_w in kernel_sizes:\n",
    "    pad_h = kernel_h // 2 if padding == 1 else padding\n",
    "    pad_w = kernel_w // 2 if padding == 1 else padding\n",
    "    \n",
    "    # Generate float64 tensors\n",
    "    input_64, weight_64, bias_64 = generate_torch_conv_tensors(\n",
    "        batch, in_ch, out_ch, height, width, kernel_h, kernel_w, torch.float64\n",
    "    )\n",
    "    input_bf16, weight_bf16, bias_bf16 = input_64.to(torch.bfloat16), weight_64.to(torch.bfloat16), bias_64.to(torch.bfloat16)\n",
    "    input_f32, weight_f32, bias_f32 = input_64.to(torch.float32), weight_64.to(torch.float32), bias_64.to(torch.float32)\n",
    "    \n",
    "    # Compute numpy float64 reference\n",
    "    input_64_np = input_64.numpy()\n",
    "    weight_64_np = weight_64.numpy()\n",
    "    bias_64_np = bias_64.numpy()\n",
    "    np64_ref = run_np_conv2d(input_64_np, weight_64_np, bias_64_np, stride=stride, padding=(pad_h, pad_w))\n",
    "    ref_list.append(np64_ref)\n",
    "    \n",
    "    # TTNN results with different dtypes, fp32 accum, and math fidelity (pass device to each call)\n",
    "    bf16_hifi4_results.append(run_ttnn_conv2d(input_bf16, weight_bf16, bias_bf16, device, stride=stride, padding=(pad_h, pad_w), \n",
    "                                              dtype=ttnn.bfloat16, fp32_accum=False, math_fidelity=ttnn.MathFidelity.HiFi4))\n",
    "    bf16_hifi4_fp32acc_results.append(run_ttnn_conv2d(input_bf16, weight_bf16, bias_bf16, device, stride=stride, padding=(pad_h, pad_w), \n",
    "                                                       dtype=ttnn.bfloat16, fp32_accum=True, math_fidelity=ttnn.MathFidelity.HiFi4))\n",
    "    bf16_hifi2_results.append(run_ttnn_conv2d(input_bf16, weight_bf16, bias_bf16, device, stride=stride, padding=(pad_h, pad_w), \n",
    "                                              dtype=ttnn.bfloat16, fp32_accum=False, math_fidelity=ttnn.MathFidelity.HiFi2))\n",
    "    bf16_lofi_results.append(run_ttnn_conv2d(input_bf16, weight_bf16, bias_bf16, device, stride=stride, padding=(pad_h, pad_w), \n",
    "                                             dtype=ttnn.bfloat16, fp32_accum=False, math_fidelity=ttnn.MathFidelity.LoFi))\n",
    "    f32_hifi4_results.append(run_ttnn_conv2d(input_f32, weight_f32, bias_f32, device, stride=stride, padding=(pad_h, pad_w), \n",
    "                                             dtype=ttnn.float32, fp32_accum=False, math_fidelity=ttnn.MathFidelity.HiFi4))\n",
    "    f32_hifi4_fp32acc_results.append(run_ttnn_conv2d(input_f32, weight_f32, bias_f32, device, stride=stride, padding=(pad_h, pad_w), \n",
    "                                                      dtype=ttnn.float32, fp32_accum=True, math_fidelity=ttnn.MathFidelity.HiFi4))\n",
    "    \n",
    "    # Unfold results for different precisions and dtypes\n",
    "    for prec in matmul_precisions:\n",
    "        unfold_bf16_results_by_precision[prec].append(\n",
    "            run_conv2d_unfold_matmul(input_bf16, weight_bf16, bias_bf16, stride=stride, padding=(pad_h, pad_w), matmul_precision=prec)\n",
    "        )\n",
    "        unfold_f32_results_by_precision[prec].append(\n",
    "            run_conv2d_unfold_matmul(input_f32, weight_f32, bias_f32, stride=stride, padding=(pad_h, pad_w), matmul_precision=prec)\n",
    "        )\n",
    "\n",
    "\n",
    "# Add TTNN results\n",
    "tensor_lists.extend([bf16_hifi4_results, bf16_hifi4_fp32acc_results, bf16_hifi2_results, bf16_lofi_results,\n",
    "                     f32_hifi4_results, f32_hifi4_fp32acc_results])\n",
    "names_lists.extend([\n",
    "    \"ttnn (bf16, HiFi4)\",\n",
    "    \"ttnn (bf16, HiFi4, fp32acc)\",\n",
    "    \"ttnn (bf16, HiFi2)\",\n",
    "    \"ttnn (bf16, LoFi)\",\n",
    "    \"ttnn (f32, HiFi4)\",\n",
    "    \"ttnn (f32, HiFi4, fp32acc)\"\n",
    "])\n",
    "\n",
    "# Add unfold results for different precisions and dtypes\n",
    "for prec in matmul_precisions:\n",
    "    tensor_lists.append(unfold_bf16_results_by_precision[prec])\n",
    "    names_lists.append(f\"unfold_matmul (bf16, {prec})\")\n",
    "for prec in matmul_precisions:\n",
    "    tensor_lists.append(unfold_f32_results_by_precision[prec])\n",
    "    names_lists.append(f\"unfold_matmul (f32, {prec})\")\n",
    "\n",
    "for norm_type in [\"fro\", \"1\", \"inf\", \"spectral\"]:\n",
    "    plot_rel_error_vs_param(\n",
    "        tensors=tensor_lists,\n",
    "        names=names_lists,\n",
    "        refs=ref_list,\n",
    "        norm_type=norm_type,\n",
    "        param_vals=[f\"{kh}x{kw}\" for kh, kw in kernel_sizes],\n",
    "        param_name=\"Kernel Size\",\n",
    "        logy=True,\n",
    "        title_suffix=f\"\\nbatch={batch}, in_ch={in_ch}, out_ch={out_ch}, h={height}, w={width}, Reference=np64\",\n",
    "        fig_size=(14, 8)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zpgny6i9xf",
   "metadata": {},
   "source": [
    "## ULP Analysis: ttnn.conv2d vs unfold+matmul across Inner Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b997ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clamped_randn(*args, **kwargs):\n",
    "    return torch.clamp(torch.randn(*args, **kwargs), 0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6tgc6icngb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sweep over inner dimensions (K = in_channels × kernel_h × kernel_w)\n",
    "# Target: K from ~288 to ~100,000\n",
    "# With kernel 3x3 (K=9 per channel), need in_channels from 32 to ~11,104 to reach K=100k\n",
    "\n",
    "# Generate input channels list (multiples of 32) to reach inner_dim ~100k\n",
    "kernel_h, kernel_w = 3, 3\n",
    "\n",
    "# Dense sampling with multiples of 32\n",
    "in_channels_list = [32,64,128,256,512,1024,2048,4096,6144,8192,10240]\n",
    "# in_channels_list = [32,64,128,256,512,1024] + [1024*i for i in range(2,16)]\n",
    "\n",
    "print(f\"Input channels range: {min(in_channels_list)} to {max(in_channels_list)}\")\n",
    "print(f\"Number of test points: {len(in_channels_list)}\")\n",
    "\n",
    "# Fixed parameters\n",
    "out_ch = 32\n",
    "batch = 1\n",
    "height, width = 32, 32\n",
    "stride, padding = 1, 1\n",
    "num_iterations = 40  # Number of iterations per configuration to reduce flakiness\n",
    "use_bias = False  # Set to True to include bias, False to exclude bias\n",
    "\n",
    "# Storage for results\n",
    "inner_dims = []\n",
    "mean_ulp_bf16 = []\n",
    "max_ulp_bf16 = []\n",
    "mean_ulp_bf16_fp32acc = []\n",
    "max_ulp_bf16_fp32acc = []\n",
    "# mean_ulp_f32_fp32acc = []\n",
    "# max_ulp_f32_fp32acc = []\n",
    "\n",
    "device = None\n",
    "\n",
    "bias_str = \"with bias\" if use_bias else \"without bias\"\n",
    "print(f\"\\nRunning ULP analysis {bias_str} with {num_iterations} iterations per configuration...\")\n",
    "\n",
    "import sys\n",
    "\n",
    "for idx, in_ch in enumerate(in_channels_list):\n",
    "    inner_dim = in_ch * kernel_h * kernel_w\n",
    "    inner_dims.append(inner_dim)\n",
    "    \n",
    "    # Collect ULP statistics across multiple iterations\n",
    "    iter_mean_ulp_bf16 = []\n",
    "    iter_max_ulp_bf16 = []\n",
    "    iter_mean_ulp_bf16_fp32acc = []\n",
    "    iter_max_ulp_bf16_fp32acc = []\n",
    "    # iter_mean_ulp_f32_fp32acc = []\n",
    "    #   iter_max_ulp_f32_fp32acc = []\n",
    "    \n",
    "    for iteration in range(num_iterations):\n",
    "        print(f\"Progress: {iteration + 1}/{num_iterations} - K={inner_dim}\",flush=True)\n",
    "        # Generate test tensors (new random tensors for each iteration)\n",
    "        input_f32, weight_f32, bias_f32 = generate_torch_conv_tensors(\n",
    "            batch, in_ch, out_ch, height, width, kernel_h, kernel_w, torch.float32,1, torch.rand\n",
    "        )\n",
    "        input_bf16 = input_f32.to(torch.bfloat16)\n",
    "        weight_bf16 = weight_f32.to(torch.bfloat16)\n",
    "        bias_bf16 = bias_f32.to(torch.bfloat16) if use_bias else None\n",
    "        bias_f32 = bias_f32 if use_bias else None\n",
    "        \n",
    "        # Compute reference using conv2d_unfold_matmul (torch implementation with medium precision for bf16)\n",
    "        ref_unfold_matmul = run_conv2d_unfold_matmul(\n",
    "            input_bf16, weight_bf16, bias_bf16.reshape(-1) if use_bias else None, \n",
    "            stride=stride, padding=padding\n",
    "        )\n",
    "        # # For f32, need f32 reference\n",
    "        # ref_unfold_matmul_f32 = run_conv2d_unfold_matmul(\n",
    "        #     input_f32, weight_f32, bias_f32.reshape(-1) if use_bias else None, \n",
    "        #     stride=stride, padding=padding, \n",
    "        #     matmul_precision=\"highest\"\n",
    "        # )\n",
    "        \n",
    "        # Run ttnn.conv2d with different configurations\n",
    "        # 1. bf16, HiFi4, no fp32_accum\n",
    "        ttnn_bf16 = run_ttnn_conv2d(\n",
    "            input_bf16, weight_bf16, bias_bf16, device, \n",
    "            stride=stride, padding=padding, \n",
    "            dtype=ttnn.bfloat16, fp32_accum=False, math_fidelity=ttnn.MathFidelity.HiFi4\n",
    "        )\n",
    "        \n",
    "        # 2. bf16, HiFi4, with fp32_accum\n",
    "        ttnn_bf16_fp32acc = run_ttnn_conv2d(\n",
    "            input_bf16, weight_bf16, bias_bf16, device, \n",
    "            stride=stride, padding=padding, \n",
    "            dtype=ttnn.bfloat16, fp32_accum=True, math_fidelity=ttnn.MathFidelity.HiFi4\n",
    "        )\n",
    "        \n",
    "        # # 3. f32, HiFi4, with fp32_accum\n",
    "        # ttnn_f32_fp32acc = run_ttnn_conv2d(\n",
    "        #     input_f32, weight_f32, bias_f32, device, \n",
    "        #     stride=stride, padding=padding, \n",
    "        #     dtype=ttnn.float32, fp32_accum=True, math_fidelity=ttnn.MathFidelity.HiFi4\n",
    "        # )\n",
    "        \n",
    "        # Compute ULP errors (comparing ttnn.conv2d to unfold+matmul reference)\n",
    "        ulp_bf16 = ulp_error(ttnn_bf16, ref_unfold_matmul)\n",
    "        ulp_bf16_fp32acc = ulp_error(ttnn_bf16_fp32acc, ref_unfold_matmul)\n",
    "        \n",
    "        # ulp_f32_fp32acc = ulp_error(ttnn_f32_fp32acc, ref_unfold_matmul_f32)\n",
    "        \n",
    "        # Store this iteration's ULP statistics\n",
    "        iter_mean_ulp_bf16.append(ulp_bf16.mean().item())\n",
    "        iter_max_ulp_bf16.append(ulp_bf16.max().item())\n",
    "        iter_mean_ulp_bf16_fp32acc.append(ulp_bf16_fp32acc.mean().item())\n",
    "        iter_max_ulp_bf16_fp32acc.append(ulp_bf16_fp32acc.max().item())\n",
    "        # iter_mean_ulp_f32_fp32acc.append(ulp_f32_fp32acc.mean().item())\n",
    "        # iter_max_ulp_f32_fp32acc.append(ulp_f32_fp32acc.max().item())\n",
    "    \n",
    "    # Average ULP statistics across all iterations\n",
    "    mean_ulp_bf16.append(np.mean(iter_mean_ulp_bf16))\n",
    "    max_ulp_bf16.append(np.mean(iter_max_ulp_bf16))\n",
    "    mean_ulp_bf16_fp32acc.append(np.mean(iter_mean_ulp_bf16_fp32acc))\n",
    "    max_ulp_bf16_fp32acc.append(np.mean(iter_max_ulp_bf16_fp32acc))\n",
    "    # mean_ulp_f32_fp32acc.append(np.mean(iter_mean_ulp_f32_fp32acc))\n",
    "    # max_ulp_f32_fp32acc.append(np.mean(iter_max_ulp_f32_fp32acc))\n",
    "\n",
    "print(\"\\nULP analysis complete!\")\n",
    "\n",
    "# Plot Mean ULP vs Inner Dimension\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(inner_dims, mean_ulp_bf16, 'o-', label='bf16, HiFi4', linewidth=2, markersize=4)\n",
    "plt.plot(inner_dims, mean_ulp_bf16_fp32acc, 's-', label='bf16, HiFi4, fp32acc', linewidth=2, markersize=4)\n",
    "# plt.plot(inner_dims, mean_ulp_f32_fp32acc, '^-', label='f32, HiFi4, fp32acc', linewidth=2, markersize=4)\n",
    "plt.xlabel('Inner Dimension K (in_channels × kH × kW)', fontsize=12)\n",
    "plt.ylabel(f'Mean ULP Error (avg of {num_iterations} runs)', fontsize=12)\n",
    "plt.title(f'Mean ULP: ttnn.conv2d vs unfold+matmul ({bias_str})', fontsize=13)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(fontsize=10)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Plot Max ULP vs Inner Dimension\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(inner_dims, max_ulp_bf16, 'o-', label='bf16, HiFi4', linewidth=2, markersize=4)\n",
    "plt.plot(inner_dims, max_ulp_bf16_fp32acc, 's-', label='bf16, HiFi4, fp32acc', linewidth=2, markersize=4)\n",
    "# plt.plot(inner_dims, max_ulp_f32_fp32acc, '^-', label='f32, HiFi4, fp32acc', linewidth=2, markersize=4)\n",
    "plt.xlabel('Inner Dimension K (in_channels × kH × kW)', fontsize=12)\n",
    "plt.ylabel(f'Max ULP Error (avg of {num_iterations} runs)', fontsize=12)\n",
    "plt.title(f'Max ULP: ttnn.conv2d vs unfold+matmul ({bias_str})', fontsize=13)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(fontsize=10)\n",
    "plt.tight_layout()\n",
    "\n",
    "bias_suffix = \"_with_bias\" if use_bias else \"_no_bias\"\n",
    "plt.savefig(f'output_conv_ulp{bias_suffix}.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "print(f\"\\n{'='*120}\")\n",
    "print(f\"ULP Statistics Per K Value (averaged over {num_iterations} iterations, {bias_str})\")\n",
    "print(f\"{'='*120}\")\n",
    "print(f\"Configuration: out_ch={out_ch}, kernel={kernel_h}x{kernel_w}, h={height}, w={width}\")\n",
    "print(f\"\\n{'K':<10} {'bf16 Mean':<12} {'bf16 Max':<12} {'bf16+fp32acc Mean':<18} {'bf16+fp32acc Max':<18} {'f32+fp32acc Mean':<18} {'f32+fp32acc Max':<18}\")\n",
    "print(f\"{'-'*120}\")\n",
    "for k, m_bf16, mx_bf16, m_bf16_fp32, mx_bf16_fp32 in zip(\n",
    "    inner_dims, mean_ulp_bf16, max_ulp_bf16, \n",
    "    mean_ulp_bf16_fp32acc, max_ulp_bf16_fp32acc, \n",
    "    # mean_ulp_f32_fp32acc, max_ulp_f32_fp32acc\n",
    "):\n",
    "    print(f\"{k:<10} {m_bf16:<12.2f} {mx_bf16:<12.2f} {m_bf16_fp32:<18.2f} {mx_bf16_fp32:<18.2f}\")\n",
    "\n",
    "print(f\"\\n{'='*120}\")\n",
    "print(f\"Overall Summary Statistics\")\n",
    "print(f\"{'='*120}\")\n",
    "print(f\"Inner dimension range: {min(inner_dims)} to {max(inner_dims)}\")\n",
    "print(f\"\\n{'Config':<30} {'Mean ULP (avg)':<20} {'Max ULP (avg)':<20}\")\n",
    "print(f\"{'-'*70}\")\n",
    "print(f\"{'bf16, HiFi4':<30} {np.mean(mean_ulp_bf16):>8.2f} {np.mean(max_ulp_bf16):>20.2f}\")\n",
    "print(f\"{'bf16, HiFi4, fp32acc':<30} {np.mean(mean_ulp_bf16_fp32acc):>8.2f} {np.mean(max_ulp_bf16_fp32acc):>20.2f}\")\n",
    "# print(f\"{'f32, HiFi4, fp32acc':<30} {np.mean(mean_ulp_f32_fp32acc):>8.2f} {np.mean(max_ulp_f32_fp32acc):>20.2f}\")\n",
    "print(f\"{'='*120}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wo9fx2eqg2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCC Analysis: ttnn.conv2d vs unfold+matmul across Inner Dimensions\n",
    "# Sweep over inner dimensions (K = in_channels × kernel_h × kernel_w)\n",
    "\n",
    "from models.common.utility_functions import comp_pcc\n",
    "\n",
    "# Generate input channels list (multiples of 32) to reach inner_dim ~100k\n",
    "kernel_h, kernel_w = 3, 3\n",
    "\n",
    "# Dense sampling with multiples of 32\n",
    "in_channels_list = [32,64,128,256,512,1024] + [1024*i for i in range(2,16)]\n",
    "print(f\"Input channels range: {min(in_channels_list)} to {max(in_channels_list)}\")\n",
    "print(f\"Number of test points: {len(in_channels_list)}\")\n",
    "\n",
    "# Fixed parameters\n",
    "out_ch = 32\n",
    "batch = 1\n",
    "height, width = 32, 32\n",
    "stride, padding = 1, 1\n",
    "num_iterations = 5  # Number of iterations per configuration to reduce flakiness\n",
    "use_bias = False  # Set to True to include bias, False to exclude bias\n",
    "\n",
    "# Storage for results\n",
    "inner_dims = []\n",
    "pcc_bf16 = []\n",
    "pcc_bf16_fp32acc = []\n",
    "pcc_f32_fp32acc = []\n",
    "pcc_f32 = []\n",
    "device = None\n",
    "\n",
    "bias_str = \"with bias\" if use_bias else \"without bias\"\n",
    "print(f\"\\nRunning PCC analysis {bias_str} with {num_iterations} iterations per configuration...\")\n",
    "\n",
    "import sys\n",
    "\n",
    "for idx, in_ch in enumerate(in_channels_list):\n",
    "    inner_dim = in_ch * kernel_h * kernel_w\n",
    "    inner_dims.append(inner_dim)\n",
    "    \n",
    "    # Collect PCC statistics across multiple iterations\n",
    "    iter_pcc_bf16 = []\n",
    "    iter_pcc_f32 = []\n",
    "    iter_pcc_bf16_fp32acc = []\n",
    "    iter_pcc_f32_fp32acc = []\n",
    "    for iteration in range(num_iterations):\n",
    "        print(f\"Progress: {iteration + 1}/{num_iterations} - K={inner_dim}\",flush=True)\n",
    "        # Generate test tensors (new random tensors for each iteration)\n",
    "        input_f32, weight_f32, bias_f32 = generate_torch_conv_tensors(\n",
    "            batch, in_ch, out_ch, height, width, kernel_h, kernel_w, torch.float32, 1, torch.rand,0\n",
    "        )\n",
    "        input_bf16 = input_f32.to(torch.bfloat16)\n",
    "        weight_bf16 = weight_f32.to(torch.bfloat16)\n",
    "        bias_bf16 = bias_f32.to(torch.bfloat16) if use_bias else None\n",
    "        bias_f32 = bias_f32 if use_bias else None\n",
    "        \n",
    "        # Compute reference using conv2d_unfold_matmul (torch implementation)\n",
    "        ref_unfold_matmul_f32 = run_conv2d_unfold_matmul(\n",
    "            input_f32, weight_f32, bias_f32.reshape(-1) if use_bias else None, \n",
    "            stride=stride, padding=padding\n",
    "        )\n",
    "        \n",
    "        # Run ttnn.conv2d with different configurations\n",
    "        # 1. bf16, HiFi4, no fp32_accum\n",
    "        ttnn_bf16 = run_ttnn_conv2d(\n",
    "            input_bf16, weight_bf16, bias_bf16, device, \n",
    "            stride=stride, padding=padding, \n",
    "            dtype=ttnn.bfloat16, fp32_accum=False, math_fidelity=ttnn.MathFidelity.HiFi4\n",
    "        )\n",
    "        \n",
    "        # 2. bf16, HiFi4, with fp32_accum\n",
    "        ttnn_bf16_fp32acc = run_ttnn_conv2d(\n",
    "            input_bf16, weight_bf16, bias_bf16, device, \n",
    "            stride=stride, padding=padding, \n",
    "            dtype=ttnn.bfloat16, fp32_accum=True, math_fidelity=ttnn.MathFidelity.HiFi4\n",
    "        )\n",
    "        \n",
    "        # 3. f32, HiFi4, with fp32_accum\n",
    "        ttnn_f32_fp32acc = run_ttnn_conv2d(\n",
    "            input_f32, weight_f32, bias_f32, device, \n",
    "            stride=stride, padding=padding, \n",
    "            dtype=ttnn.float32, fp32_accum=True, math_fidelity=ttnn.MathFidelity.HiFi4\n",
    "        )\n",
    "\n",
    "        ttnn_f32 = run_ttnn_conv2d(\n",
    "            input_f32, weight_f32, bias_f32, device, \n",
    "            stride=stride, padding=padding, \n",
    "            dtype=ttnn.float32, fp32_accum=False, math_fidelity=ttnn.MathFidelity.HiFi4\n",
    "        )\n",
    "        \n",
    "        # Compute PCC (comparing ttnn.conv2d to unfold+matmul reference)\n",
    "        # comp_pcc returns (pass_bool, pcc_value)\n",
    "        _, pcc_bf16_val = comp_pcc(ref_unfold_matmul_f32, ttnn_bf16)\n",
    "        _, pcc_bf16_fp32acc_val = comp_pcc(ref_unfold_matmul_f32, ttnn_bf16_fp32acc)\n",
    "        _, pcc_f32_val = comp_pcc(ref_unfold_matmul_f32, ttnn_f32)\n",
    "        _, pcc_f32_fp32acc_val = comp_pcc(ref_unfold_matmul_f32, ttnn_f32_fp32acc)\n",
    "        \n",
    "        # Store this iteration's PCC values\n",
    "        iter_pcc_bf16.append(pcc_bf16_val)\n",
    "        iter_pcc_bf16_fp32acc.append(pcc_bf16_fp32acc_val)\n",
    "        iter_pcc_f32.append(pcc_f32_val)\n",
    "        iter_pcc_f32_fp32acc.append(pcc_f32_fp32acc_val)\n",
    "    \n",
    "    # Average PCC across all iterations\n",
    "    pcc_bf16.append(np.mean(iter_pcc_bf16))\n",
    "    pcc_bf16_fp32acc.append(np.mean(iter_pcc_bf16_fp32acc))\n",
    "    pcc_f32.append(np.mean(iter_pcc_f32))\n",
    "    pcc_f32_fp32acc.append(np.mean(iter_pcc_f32_fp32acc))\n",
    "\n",
    "print(\"\\nPCC analysis complete!\")\n",
    "\n",
    "# Plot PCC vs Inner Dimension\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.plot(inner_dims, pcc_bf16, 'o-', label='bf16, HiFi4', linewidth=2, markersize=4)\n",
    "plt.plot(inner_dims, pcc_bf16_fp32acc, 's-', label='bf16, HiFi4, fp32acc', linewidth=2, markersize=4)\n",
    "plt.plot(inner_dims, pcc_f32_fp32acc, '^-', label='f32, HiFi4, fp32acc', linewidth=2, markersize=4)\n",
    "plt.plot(inner_dims, pcc_f32, 'v-', label='f32, HiFi4', linewidth=2, markersize=4)\n",
    "plt.xlabel('Inner Dimension K (in_channels × kH × kW)', fontsize=12)\n",
    "plt.ylabel(f'PCC (avg of {num_iterations} runs)', fontsize=12)\n",
    "plt.title(f'PCC: ttnn.conv2d vs unfold+matmul ({bias_str})', fontsize=13)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(fontsize=10)\n",
    "plt.tight_layout()\n",
    "\n",
    "bias_suffix = \"_with_bias\" if use_bias else \"_no_bias\"\n",
    "plt.savefig(f'output_conv_pcc{bias_suffix}.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"PCC Statistics Per K Value (averaged over {num_iterations} iterations, {bias_str})\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Configuration: out_ch={out_ch}, kernel={kernel_h}x{kernel_w}, h={height}, w={width}\")\n",
    "print(f\"\\n{'K':<10} {'bf16 PCC':<15} {'bf16+fp32acc PCC':<20} {'f32+fp32acc PCC':<20} {'f32 PCC':<20}\")\n",
    "print(f\"{'-'*80}\")\n",
    "for k, pcc_bf16_val, pcc_bf16_fp32_val, pcc_f32_val, pcc_f32_fp32_val,pcc_f32_val in zip(\n",
    "    inner_dims, pcc_bf16, pcc_bf16_fp32acc, pcc_f32_fp32acc, pcc_f32\n",
    "):\n",
    "    print(f\"{k:<10} {pcc_bf16_val:<15.8f} {pcc_bf16_fp32_val:<20.8f} {pcc_f32_val:<20.8f} {pcc_f32_fp32_val:<20.8f}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Overall Summary Statistics\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Inner dimension range: {min(inner_dims)} to {max(inner_dims)}\")\n",
    "print(f\"\\n{'Config':<30} {'Mean PCC':<20} {'Min PCC':<20}\")\n",
    "print(f\"{'-'*70}\")\n",
    "print(f\"{'bf16, HiFi4':<30} {np.mean(pcc_bf16):>8.8f} {np.min(pcc_bf16):>20.8f}\")\n",
    "print(f\"{'bf16, HiFi4, fp32acc':<30} {np.mean(pcc_bf16_fp32acc):>8.8f} {np.min(pcc_bf16_fp32acc):>20.8f}\")\n",
    "print(f\"{'f32, HiFi4, fp32acc':<30} {np.mean(pcc_f32_fp32acc):>8.8f} {np.min(pcc_f32_fp32acc):>20.8f}\")\n",
    "print(f\"{'f32, HiFi4':<30} {np.mean(pcc_f32):>8.8f} {np.min(pcc_f32):>20.8f}\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fb732e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a767b93d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
