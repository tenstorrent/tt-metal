#!/usr/bin/env python3
"""
Utility script to load PyTorch reference outputs generated by generate_torch_reference_outputs.py.

Usage:
    from load_torch_reference_outputs import ReferenceDataLoader

    loader = ReferenceDataLoader("torch_reference_outputs")

    # Load test case with automatic input regeneration and hash verification
    data = loader.load_test_case(dtype="bfloat16", input_channels=8, method="rand")

    # Access outputs
    conv2d_output = data['conv2d']['output']
    matmul_output = data['matmul']['output']

    # Access regenerated inputs (automatically verified against stored hashes)
    conv2d_input = data['conv2d']['input']
    conv2d_weight = data['conv2d']['weight']

    # Check verification results
    if data['input_verification']['all_passed']:
        print("✓ All inputs verified - same data generated on both machines")
"""

import numpy as np
import torch
import json
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import hashlib


class ReferenceDataLoader:
    """Loader for PyTorch reference outputs."""

    def __init__(self, output_dir: str = "torch_reference_outputs"):
        """
        Initialize the loader.

        Args:
            output_dir: Path to the directory containing reference outputs
        """
        self.output_dir = Path(output_dir)
        if not self.output_dir.exists():
            raise ValueError(f"Output directory not found: {output_dir}")

        # Load configuration
        with open(self.output_dir / "config.json") as f:
            self.config = json.load(f)

        # Load system info
        with open(self.output_dir / "system_info.json") as f:
            self.system_info = json.load(f)

        # Create K to input_channels mapping
        self.k_to_ic = dict(zip(self.config["k_values"], self.config["input_channels_sweep"]))
        self.ic_to_k = dict(zip(self.config["input_channels_sweep"], self.config["k_values"]))

    def get_filename_prefix(self, input_channels: int) -> str:
        """Get the filename prefix for a given input_channels value."""
        k = self.ic_to_k[input_channels]
        return f"k{k:04d}_ic{input_channels:03d}"

    def load_metadata(self, dtype: str, input_channels: int, method: str = "rand") -> Dict:
        """
        Load metadata for a specific test case.

        Args:
            dtype: Data type ('bfloat16' or 'float32')
            input_channels: Number of input channels
            method: Generation method ('rand' or 'randn')

        Returns:
            Dictionary containing shapes, dtypes, and input hashes
        """
        prefix = self.get_filename_prefix(input_channels)
        group_name = f"{dtype}_{method}"
        metadata_path = self.output_dir / group_name / f"{prefix}_metadata.json"

        with open(metadata_path) as f:
            return json.load(f)

    def load_tensor(
        self, dtype: str, input_channels: int, operation: str, tensor_name: str, method: str = "rand"
    ) -> np.ndarray:
        """
        Load a specific tensor.

        Args:
            dtype: Data type ('bfloat16' or 'float32')
            input_channels: Number of input channels
            operation: Operation type ('conv2d' or 'matmul')
            tensor_name: Tensor name (e.g., 'output')
            method: Generation method ('rand' or 'randn')

        Returns:
            Numpy array containing the tensor data
        """
        prefix = self.get_filename_prefix(input_channels)
        group_name = f"{dtype}_{method}"
        tensor_path = self.output_dir / group_name / f"{prefix}_{operation}_{tensor_name}.npy"

        return np.load(tensor_path)

    def load_test_case(self, dtype: str, input_channels: int, method: str = "rand", verify_inputs: bool = True) -> Dict:
        """
        Load all data for a specific test case, regenerate inputs, and verify hashes.

        Args:
            dtype: Data type ('bfloat16' or 'float32')
            input_channels: Number of input channels
            method: Generation method ('rand' or 'randn')
            verify_inputs: Whether to regenerate inputs and verify hashes (default: True)

        Returns:
            Dictionary with structure:
            {
                'metadata': {...},
                'conv2d': {
                    'output': np.ndarray,
                    'input': torch.Tensor (if verify_inputs=True),
                    'weight': torch.Tensor (if verify_inputs=True),
                    'bias': torch.Tensor (if verify_inputs=True)
                },
                'matmul': {
                    'output': np.ndarray,
                    'A': torch.Tensor (if verify_inputs=True),
                    'B': torch.Tensor (if verify_inputs=True)
                },
                'input_verification': {
                    'all_passed': bool,
                    'conv2d': {'input': bool, 'weight': bool, 'bias': bool},
                    'matmul': {'A': bool, 'B': bool}
                } (if verify_inputs=True)
            }
        """
        metadata = self.load_metadata(dtype, input_channels, method)

        conv2d_data = {
            "output": self.load_tensor(dtype, input_channels, "conv2d", "output", method),
        }

        matmul_data = {
            "output": self.load_tensor(dtype, input_channels, "matmul", "output", method),
        }

        result = {
            "metadata": metadata,
            "conv2d": conv2d_data,
            "matmul": matmul_data,
        }

        if verify_inputs:
            # Regenerate inputs using seed and method from metadata
            inputs = self.regenerate_inputs(dtype, input_channels, method)

            # Add regenerated inputs to result
            result["conv2d"].update(inputs["conv2d"])
            result["matmul"].update(inputs["matmul"])

            # Verify hashes
            expected_hashes = metadata["input_hashes"]
            verification = {"conv2d": {}, "matmul": {}}

            # Verify conv2d tensors
            for tensor_name in ["input", "weight", "bias"]:
                tensor = inputs["conv2d"][tensor_name]
                computed_hash = self.compute_torch_tensor_hash(tensor)
                expected_hash = expected_hashes["conv2d"][tensor_name]
                verification["conv2d"][tensor_name] = computed_hash == expected_hash

            # Verify matmul tensors
            for tensor_name in ["A", "B"]:
                tensor = inputs["matmul"][tensor_name]
                computed_hash = self.compute_torch_tensor_hash(tensor)
                expected_hash = expected_hashes["matmul"][tensor_name]
                verification["matmul"][tensor_name] = computed_hash == expected_hash

            # Add verification results
            all_passed = all(verification["conv2d"].values()) and all(verification["matmul"].values())
            result["input_verification"] = {
                "all_passed": all_passed,
                "conv2d": verification["conv2d"],
                "matmul": verification["matmul"],
            }

        return result

    def regenerate_inputs(self, dtype: str, input_channels: int, method: str = "rand") -> Dict:
        """
        Regenerate input tensors using the same seed and method.

        Args:
            dtype: Data type ('bfloat16' or 'float32')
            input_channels: Number of input channels
            method: Generation method ('rand' or 'randn')

        Returns:
            Dictionary with structure:
            {
                'conv2d': {
                    'input': torch.Tensor,
                    'weight': torch.Tensor,
                    'bias': torch.Tensor
                },
                'matmul': {
                    'A': torch.Tensor,
                    'B': torch.Tensor
                }
            }
        """
        torch_dtype = torch.bfloat16 if dtype == "bfloat16" else torch.float32
        seed = self.config["seed"]
        gen_fn = torch.rand if method == "rand" else torch.randn

        # Get configuration
        batch = self.config["batch"]
        input_height = self.config["input_height"]
        input_width = self.config["input_width"]
        out_channels = self.config["out_channels"]
        kernel_h = self.config["kernel_h"]
        kernel_w = self.config["kernel_w"]

        # Calculate matmul shape
        padding = self.config["padding"]
        stride = self.config["stride"]
        output_height = (input_height + 2 * padding[0] - kernel_h) // stride[0] + 1
        output_width = (input_width + 2 * padding[1] - kernel_w) // stride[1] + 1
        M = batch * output_height * output_width
        K = input_channels * kernel_h * kernel_w
        N = out_channels

        # Generate conv2d inputs with specified method
        torch.manual_seed(seed)
        conv2d_input = gen_fn((batch, input_channels, input_height, input_width), dtype=torch_dtype)
        conv2d_weight = gen_fn((out_channels, input_channels, kernel_h, kernel_w), dtype=torch_dtype)
        conv2d_bias = gen_fn((out_channels,), dtype=torch_dtype)

        # Generate matmul inputs with specified method
        torch.manual_seed(seed)
        matmul_A = gen_fn((M, K), dtype=torch_dtype)
        matmul_B = gen_fn((K, N), dtype=torch_dtype)

        return {
            "conv2d": {"input": conv2d_input, "weight": conv2d_weight, "bias": conv2d_bias},
            "matmul": {"A": matmul_A, "B": matmul_B},
        }

    def compute_tensor_hash(self, tensor: np.ndarray) -> str:
        """Compute SHA256 hash of a numpy array."""
        tensor_bytes = tensor.tobytes()
        return hashlib.sha256(tensor_bytes).hexdigest()

    def compute_torch_tensor_hash(self, tensor: torch.Tensor) -> str:
        """Compute SHA256 hash of a torch tensor (matches generator logic)."""
        # Convert to numpy (handling bfloat16)
        if tensor.dtype == torch.bfloat16:
            tensor_np = tensor.to(torch.float32).detach().cpu().numpy()
        else:
            tensor_np = tensor.detach().cpu().numpy()
        tensor_bytes = tensor_np.tobytes()
        return hashlib.sha256(tensor_bytes).hexdigest()

    def verify_inputs(self, dtype: str, input_channels: int, method: str = "rand") -> Dict[str, bool]:
        """
        Regenerate input tensors and verify they match expected hashes.

        Args:
            dtype: Data type ('bfloat16' or 'float32')
            input_channels: Number of input channels
            method: Generation method ('rand' or 'randn')

        Returns:
            Dictionary indicating which inputs passed verification:
            {
                'conv2d': {
                    'input': bool,
                    'weight': bool,
                    'bias': bool
                },
                'matmul': {
                    'A': bool,
                    'B': bool
                }
            }
        """
        metadata = self.load_metadata(dtype, input_channels, method)
        expected_hashes = metadata["input_hashes"]

        # Regenerate inputs with specified method
        inputs = self.regenerate_inputs(dtype, input_channels, method)

        results = {"conv2d": {}, "matmul": {}}

        # Verify conv2d tensors
        for tensor_name in ["input", "weight", "bias"]:
            tensor = inputs["conv2d"][tensor_name]
            computed_hash = self.compute_torch_tensor_hash(tensor)
            expected_hash = expected_hashes["conv2d"][tensor_name]
            results["conv2d"][tensor_name] = computed_hash == expected_hash

        # Verify matmul tensors
        for tensor_name in ["A", "B"]:
            tensor = inputs["matmul"][tensor_name]
            computed_hash = self.compute_torch_tensor_hash(tensor)
            expected_hash = expected_hashes["matmul"][tensor_name]
            results["matmul"][tensor_name] = computed_hash == expected_hash

        return results

    def list_available_cases(self) -> List[Tuple[str, int, str]]:
        """
        List all available test cases.

        Returns:
            List of tuples (dtype, input_channels, method)
        """
        cases = []
        for dtype in self.config["dtypes"]:
            for method in self.config.get("gen_methods", ["rand"]):  # Default to ['rand'] for old format
                for ic in self.config["input_channels_sweep"]:
                    cases.append((dtype, ic, method))
        return cases

    def print_summary(self):
        """Print a summary of available data."""
        print("=" * 80)
        print("PyTorch Reference Data Loader")
        print("=" * 80)
        print(f"\nData directory: {self.output_dir.absolute()}")
        print(f"\nSystem Info:")
        for key, value in self.system_info.items():
            print(f"  {key}: {value}")

        print(f"\nConfiguration:")
        print(f"  Seed: {self.config['seed']}")
        print(f"  Batch: {self.config['batch']}")
        print(f"  Input size: {self.config['input_height']}x{self.config['input_width']}")
        print(f"  Output channels: {self.config['out_channels']}")
        print(f"  Kernel: {self.config['kernel_h']}x{self.config['kernel_w']}")
        print(f"  Padding: {self.config['padding']}")
        print(f"  Stride: {self.config['stride']}")
        print(f"  Use bias: {self.config['use_bias']}")

        print(f"\nAvailable test cases:")
        print(f"  Data types: {self.config['dtypes']}")
        print(f"  Input channels: {self.config['input_channels_sweep']}")
        print(f"  K values: {self.config['k_values']}")
        print(f"  Total cases: {len(self.config['dtypes']) * len(self.config['input_channels_sweep'])}")
        print("=" * 80)


# Convenience functions for external scripts
def get_validated_inputs(
    dtype: str, input_channels: int, method: str = "rand", output_dir: str = "torch_reference_outputs"
) -> Dict:
    """
    Get validated input tensors for a test case.

    Args:
        dtype: Data type ('bfloat16' or 'float32')
        input_channels: Number of input channels
        method: Generation method ('rand' or 'randn')
        output_dir: Path to reference outputs directory

    Returns:
        Dictionary with structure:
        {
            'conv2d': {
                'input': torch.Tensor,
                'weight': torch.Tensor,
                'bias': torch.Tensor
            },
            'matmul': {
                'A': torch.Tensor,
                'B': torch.Tensor
            },
            'verification': {
                'all_passed': bool,
                'conv2d': {'input': bool, 'weight': bool, 'bias': bool},
                'matmul': {'A': bool, 'B': bool}
            }
        }

    Raises:
        AssertionError: If hash verification fails
    """
    loader = ReferenceDataLoader(output_dir)
    data = loader.load_test_case(dtype, input_channels, method, verify_inputs=True)

    # Check verification
    if not data["input_verification"]["all_passed"]:
        failed = []
        for op in ["conv2d", "matmul"]:
            for tensor_name, passed in data["input_verification"][op].items():
                if not passed:
                    failed.append(f"{op}/{tensor_name}")
        raise AssertionError(f"Hash verification failed for: {', '.join(failed)}")

    return {
        "conv2d": {
            "input": data["conv2d"]["input"],
            "weight": data["conv2d"]["weight"],
            "bias": data["conv2d"]["bias"],
        },
        "matmul": {"A": data["matmul"]["A"], "B": data["matmul"]["B"]},
        "verification": data["input_verification"],
    }


def get_conv2d_inputs(
    dtype: str, input_channels: int, method: str = "rand", output_dir: str = "torch_reference_outputs"
) -> Tuple:
    """
    Get validated conv2d input tensors.

    Args:
        dtype: Data type ('bfloat16' or 'float32')
        input_channels: Number of input channels
        method: Generation method ('rand' or 'randn')
        output_dir: Path to reference outputs directory

    Returns:
        Tuple of (input, weight, bias) torch tensors

    Raises:
        AssertionError: If hash verification fails
    """
    inputs = get_validated_inputs(dtype, input_channels, method, output_dir)
    return inputs["conv2d"]["input"], inputs["conv2d"]["weight"], inputs["conv2d"]["bias"]


def get_matmul_inputs(
    dtype: str, input_channels: int, method: str = "rand", output_dir: str = "torch_reference_outputs"
) -> Tuple:
    """
    Get validated matmul input tensors.

    Args:
        dtype: Data type ('bfloat16' or 'float32')
        input_channels: Number of input channels
        method: Generation method ('rand' or 'randn')
        output_dir: Path to reference outputs directory

    Returns:
        Tuple of (A, B) torch tensors

    Raises:
        AssertionError: If hash verification fails
    """
    inputs = get_validated_inputs(dtype, input_channels, method, output_dir)
    return inputs["matmul"]["A"], inputs["matmul"]["B"]


def get_reference_outputs(
    dtype: str, input_channels: int, method: str = "rand", output_dir: str = "torch_reference_outputs"
) -> Dict:
    """
    Get reference outputs (without regenerating inputs).

    Args:
        dtype: Data type ('bfloat16' or 'float32')
        input_channels: Number of input channels
        method: Generation method ('rand' or 'randn')
        output_dir: Path to reference outputs directory

    Returns:
        Dictionary with structure:
        {
            'conv2d_output': np.ndarray,
            'matmul_output': np.ndarray,
            'metadata': dict
        }
    """
    loader = ReferenceDataLoader(output_dir)
    data = loader.load_test_case(dtype, input_channels, method, verify_inputs=False)

    return {
        "conv2d_output": data["conv2d"]["output"],
        "matmul_output": data["matmul"]["output"],
        "metadata": data["metadata"],
    }


def main():
    """Example usage."""
    print("=" * 80)
    print("Reference Data Loader - Example Usage")
    print("=" * 80)

    # Initialize loader
    loader = ReferenceDataLoader("torch_reference_outputs")

    # Print summary
    loader.print_summary()

    # Load a specific test case (with automatic input verification)
    print("\n" + "=" * 80)
    print("Loading test case: bfloat16_rand, input_channels=8")
    print("=" * 80)

    data = loader.load_test_case(dtype="bfloat16", input_channels=8, method="rand", verify_inputs=True)

    print("\nLoaded outputs:")
    print(f"  Conv2D output shape: {data['conv2d']['output'].shape}")
    print(f"  Matmul output shape: {data['matmul']['output'].shape}")
    print(f"  Generation method: {data['metadata'].get('gen_method', 'unknown')}")

    print("\nRegenerated inputs (automatically):")
    print(f"  Conv2D input shape: {data['conv2d']['input'].shape}")
    print(f"  Conv2D weight shape: {data['conv2d']['weight'].shape}")
    print(f"  Conv2D bias shape: {data['conv2d']['bias'].shape}")
    print(f"  Matmul A shape: {data['matmul']['A'].shape}")
    print(f"  Matmul B shape: {data['matmul']['B'].shape}")

    print("\nAutomatic hash verification:")
    verification = data["input_verification"]
    overall_status = "✓ ALL PASS" if verification["all_passed"] else "✗ SOME FAILED"
    print(f"  Overall: {overall_status}")

    print("  Conv2D:")
    for tensor_name, is_valid in verification["conv2d"].items():
        status = "✓ PASS" if is_valid else "✗ FAIL"
        print(f"    {tensor_name}: {status}")

    print("  Matmul:")
    for tensor_name, is_valid in verification["matmul"].items():
        status = "✓ PASS" if is_valid else "✗ FAIL"
        print(f"    {tensor_name}: {status}")

    # List all available cases
    print("\n" + "=" * 80)
    print("All available test cases")
    print("=" * 80)

    cases = loader.list_available_cases()
    print(f"\nTotal: {len(cases)} cases")
    for dtype, ic, method in cases:
        k = loader.ic_to_k[ic]
        print(f"  - dtype={dtype}, input_channels={ic}, method={method}, K={k}")

    print("\n" + "=" * 80)


if __name__ == "__main__":
    main()
