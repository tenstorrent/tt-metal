// SPDX-FileCopyrightText: Â© 2025 Tenstorrent Inc.
//
// SPDX-License-Identifier: Apache-2.0

#pragma once

#include <functional>
#include <optional>

#include "argmax_device_operation_types.hpp"
#include "argmax_program_factory.hpp"
#include "ttnn/decorators.hpp"
#include "ttnn/device_operation.hpp"
#include "ttnn/tensor/tensor.hpp"

namespace ttnn::operations::reduction {

namespace detail {

/*
 * Generates the output shape for the reduction operation.
 * The output shape is generated by iterating over the input shape and adjusting
 * the output shape for keepdim.
 * @param input_tensor The input tensor on which reduction is performed.
 * @param dim The dimension to reduce on (optional).
 * @param keepdim Whether to keep the reduced dimension.
 * @return The output shape.
 */
inline ttnn::SmallVector<uint32_t> get_output_shape(
    const Tensor& input_tensor, const std::optional<int>& dim, bool keepdim) {
    auto input_shape = input_tensor.logical_shape();
    int rank = input_shape.size();
    ttnn::SmallVector<uint32_t> output_shape;

    // If no reduction dims are specified, we reduce all dimensions
    auto all_dim_reduce = not dim.has_value();
    auto red_dim = dim.value_or(0);
    TT_FATAL(
        (rank == 0) or ((red_dim >= -rank) and (red_dim < rank)),
        "Invalid reduction dimension {} for input tensor with rank {}",
        red_dim,
        rank);

    // Adjust negative reduction dimension to positive
    red_dim = red_dim < 0 ? red_dim + rank : red_dim;

    // Generate output shape
    // Iterate over the input shape and adjust the output shape for keepdim
    for (int d = 0; d < rank; ++d) {
        // If this is in the reduction dims, keep it only if keepdim is true
        bool is_reduction_dim = all_dim_reduce or (d == red_dim);

        if (is_reduction_dim) {
            TT_FATAL(input_shape[d] != 0, "Expected reduction dim {} to have non-zero size", d);
            if (keepdim) {
                output_shape.push_back(1);
            }
        } else {
            // If this is not a reduction dim, we keep the original size
            output_shape.push_back(input_shape[d]);
        }
    }

    return output_shape;
}

}  // namespace detail

struct ArgMaxDeviceOperation {
    using operation_attributes_t = reduction::operation_attributes_t;
    using tensor_args_t = reduction::tensor_args_t;
    using spec_return_value_t = reduction::spec_return_value_t;
    using tensor_return_value_t = reduction::tensor_return_value_t;
    using program_factory_t =
        std::variant<program::ArgMaxSingleCoreProgramFactory, program::ArgMaxMultiCoreProgramFactory>;

    static program_factory_t select_program_factory(const operation_attributes_t&, const tensor_args_t&);

    static void validate_on_program_cache_hit(const operation_attributes_t&, const tensor_args_t&);
    static void validate_on_program_cache_miss(const operation_attributes_t&, const tensor_args_t&);

    static spec_return_value_t compute_output_specs(const operation_attributes_t&, const tensor_args_t&);

    static tensor_return_value_t create_output_tensors(
        const operation_attributes_t& operation_attributes, const tensor_args_t&);

    static std::tuple<operation_attributes_t, tensor_args_t> invoke(
        const Tensor& input,
        tt::tt_metal::DataType output_dtype,
        std::optional<int> dim,
        bool keepdim,
        const std::optional<CoreRangeSet>& sub_core_grids,
        bool use_multicore,
        const tt::tt_metal::MemoryConfig& output_mem_config,
        std::optional<Tensor> optional_output_tensor);
};

}  // namespace ttnn::operations::reduction

namespace ttnn::prim {
constexpr auto argmax =
    ttnn::register_operation<"ttnn::prim::argmax", ttnn::operations::reduction::ArgMaxDeviceOperation>();
}  // namespace ttnn::prim
