// SPDX-FileCopyrightText: Â© 2023 Tenstorrent Inc.
//
// SPDX-License-Identifier: Apache-2.0

#include "ttnn/cpp/pybind11/decorators.hpp"

#include "ttnn/operations/experimental/paged_cache/paged_cache.hpp"
#include "ttnn/operations/experimental/paged_cache/paged_cache_pybind.hpp"

namespace ttnn::operations::experimental::paged_cache::detail {

namespace py = pybind11;

void bind_experimental_paged_cache_operations(py::module& module) {
    auto paged_update_cache_doc =
        R"doc(
         Paged update cache operation. This operation expects the following inputs: cache_tensor of shape [B, 1, kv_len, head_dim] and input_tensor of shape [1, B, 1[32], head_dim] where input_tensor is height sharded on B cores. update_idxs will specify for each batch element which token to update in the cache.
        )doc";

    using PagedUpdateCacheType = decltype(ttnn::experimental::paged_update_cache);
    ttnn::bind_registered_operation(module,
                                    ttnn::experimental::paged_update_cache,
                                    paged_update_cache_doc,
                                    ttnn::pybind_overload_t{
                                        [](const PagedUpdateCacheType& self,
                                           const ttnn::Tensor& cache_tensor,
                                           const ttnn::Tensor& input_tensor,
                                           const std::vector<uint32_t> update_idxs,
                                           const std::optional<const ttnn::Tensor> update_idxs_tensor,
                                           const std::optional<bool> share_cache,
                                           const std::optional<const ttnn::Tensor> page_table,
                                           const uint32_t batch_offset,
                                           std::optional<const ttnn::DeviceComputeKernelConfig> compute_kernel_config) {
                                            return self(cache_tensor,
                                                        input_tensor,
                                                        update_idxs,
                                                        update_idxs_tensor,
                                                        share_cache,
                                                        page_table,
                                                        batch_offset,
                                                        compute_kernel_config);
                                        },
                                        py::arg("cache_tensor").noconvert(),
                                        py::arg("input_tensor").noconvert(),
                                        py::kw_only(),
                                        py::arg("update_idxs").noconvert() = std::vector<uint32_t>(),
                                        py::arg("update_idxs_tensor").noconvert() = std::nullopt,
                                        py::arg("share_cache").noconvert() = std::nullopt,
                                        py::arg("page_table").noconvert() = std::nullopt,
                                        py::arg("batch_offset") = 0,
                                        py::arg("compute_kernel_config").noconvert() = std::nullopt,
                                    });

    auto paged_fill_cache_doc =
        R"doc(
        Paged fill cache operation. This operation expects the following inputs: cache_tensor of shape [B, 1, kv_len, head_dim] and input_tensor of shape [1, 1, seq_len, head_dim]. batch_idx specifies which index in the batch dimension to update with input_tensor.
        )doc";

    using PagedFillCacheType = decltype(ttnn::experimental::paged_fill_cache);
    ttnn::bind_registered_operation(
        module,
        ttnn::experimental::paged_fill_cache,
        paged_fill_cache_doc,
        ttnn::pybind_overload_t{
            [](const PagedFillCacheType& self,
               const ttnn::Tensor& cache_tensor,
               const ttnn::Tensor& input_tensor,
               const ttnn::Tensor& page_table,
               const uint32_t batch_idx,
               std::optional<const ttnn::DeviceComputeKernelConfig> compute_kernel_config) {
                return self(cache_tensor, input_tensor, page_table, batch_idx, compute_kernel_config);
            },
            py::arg("cache_tensor").noconvert(),
            py::arg("input_tensor").noconvert(),
            py::arg("page_table").noconvert(),
            py::kw_only(),
            py::arg("batch_idx") = 0,
            py::arg("compute_kernel_config").noconvert() = std::nullopt,
        });
}

}  // namespace ttnn::operations::experimental::paged_cache::detail
