// SPDX-FileCopyrightText: Â© 2024 Tenstorrent Inc.
//
// SPDX-License-Identifier: Apache-2.0

#include "cpp/ttnn-pybind/decorators.hpp"

#include "ttnn/operations/experimental/transformer/nlp_create_qkv_heads/nlp_create_qkv_heads.hpp"
#include "ttnn/operations/experimental/transformer/nlp_create_qkv_heads/nlp_create_qkv_heads_pybind.hpp"

namespace ttnn::operations::experimental::transformer::detail {

template <typename transformer_operation_t>
void bind_nlp_create_qkv_heads_template(pybind11::module& module, const transformer_operation_t& operation) {
    ttnn::bind_registered_operation(
        module,
        operation,
        R"doc(
             Shuffles [B, 1, S, 3 * head_dim * num_heads] fused qkv matrix into 3 Q, K, and V heads with shapes [B, num_heads, S, head_dim], [B, num_kv_heads, head_dim, S], and [B, num_kv_heads, S, head_dim]. If optional ``input_kv`` tensor is provided, K and V will be created from ``input_kv`` and ``input`` should have shape [B, 1, S, head_dim * num_heads] instead. ``num_kv_heads`` defaults to ``num_heads`` if not provided. An additional transpose along the last two dims is performed by default for K heads, but this can be skipped with ``transpose_k_heads=false``.
        )doc",
        ttnn::pybind_overload_t{
            [](const transformer_operation_t& self,
               const ttnn::Tensor& input_tensor_q,
               const std::optional<ttnn::Tensor>& input_tensor_kv,
               const uint32_t num_heads,
               const std::optional<uint32_t> num_kv_heads,
               const bool transpose_k_heads,
               const std::optional<ttnn::MemoryConfig>& memory_config,
               std::optional<std::vector<std::optional<ttnn::Tensor>>>& optional_output_tensors,
               QueueId queue_id) {
                return self(
                    queue_id,
                    input_tensor_q,
                    input_tensor_kv,
                    num_heads,
                    num_kv_heads,
                    transpose_k_heads,
                    memory_config,
                    optional_output_tensors);
            },
            pybind11::arg("input").noconvert(),
            pybind11::arg("input_kv").noconvert() = std::nullopt,
            pybind11::kw_only(),
            pybind11::arg("num_heads").noconvert(),
            pybind11::arg("num_kv_heads").noconvert() = std::nullopt,
            pybind11::arg("transpose_k_heads").noconvert() = true,
            pybind11::arg("memory_config").noconvert() = std::nullopt,
            pybind11::arg("output_tensors").noconvert() = std::nullopt,
            pybind11::arg("queue_id") = DefaultQueueId});
};

void bind_nlp_create_qkv_heads(pybind11::module& module) {
    bind_nlp_create_qkv_heads_template(module, ttnn::experimental::nlp_create_qkv_heads);
}
}  // namespace ttnn::operations::experimental::transformer::detail
