{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ece9c89",
   "metadata": {},
   "source": [
    "$$\n",
    "\\def\\CC{\\bf C}\n",
    "\\def\\QQ{\\bf Q}\n",
    "\\def\\RR{\\bf R}\n",
    "\\def\\ZZ{\\bf Z}\n",
    "\\def\\NN{\\bf N}\n",
    "$$\n",
    "# Basic Operations with TT-NN\n",
    "\n",
    "We will review a simple example that demonstrates how to create various\n",
    "tensors and perform basic arithmetic operations on them using TT-NN, a\n",
    "high-level Python API. These operations include addition,\n",
    "multiplication, and matrix multiplication, as well as simulating\n",
    "broadcasting a row vector across a tile.\n",
    "\n",
    "Let's create the example file, `ttnn_basic_operations.py`\n",
    "\n",
    "## Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9864d745",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import ttnn\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98f3e88",
   "metadata": {},
   "source": [
    "## Open Tenstorrent device\n",
    "\n",
    "Create device on which we will run our program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64940eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Tenstorrent device\n",
    "device = ttnn.open_device(device_id=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e34d476",
   "metadata": {},
   "source": [
    "## Helper Function for Tensor Preparation\n",
    "\n",
    "Let's create a helper function to convert PyTorch tensors to\n",
    "TT-NN tiled tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544b723b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to create a TT-NN tensor from torch with TILE_LAYOUT and bfloat16\n",
    "def to_tt_tile(torch_tensor):\n",
    "   return ttnn.from_torch(torch_tensor, dtype=ttnn.bfloat16, layout=ttnn.TILE_LAYOUT, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c23802",
   "metadata": {},
   "source": [
    "## Host Tensor Creation\n",
    "\n",
    "Create a tensor for our tests and fill with different values. We will\n",
    "use this and other tensors to demonstrate various operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dff6e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"\\n--- TT-NN Tensor Creation with Tiles (32x32) ---\")\n",
    "host_rand = torch.rand((32, 32), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc168d2",
   "metadata": {},
   "source": [
    "## Convert Host Tensors to TT-NN Tiled Tensors or Create Natively on Device\n",
    "\n",
    "Tensix cores operate most efficiently on tiled data, allowing them to\n",
    "perform a large amount of compute in parallel. \n",
    "\n",
    "Where necessary, let's convert host tensors to TT-NN tiled tensors using the `to_tt_tile()` helper function we\n",
    "created earlier, and transfer tensors to the TT device. Alternatively, we\n",
    "can create tensors natively using TT-NN's tensor creation functions, and\n",
    "initialize them directly on the TT device. TT-NN calls that create\n",
    "tensors natively on the device are a more efficient way to create\n",
    "tensors, as they avoid the overhead of transferring data from the host\n",
    "to the device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a85a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_t1 = ttnn.full(\n",
    "   shape=(32, 32),\n",
    "   fill_value=1.0,\n",
    "   dtype=ttnn.float32,\n",
    "   layout=ttnn.TILE_LAYOUT,\n",
    "   device=device,\n",
    ")\n",
    "\n",
    "tt_t2 = ttnn.zeros(\n",
    "   shape=(32, 32),\n",
    "   dtype=ttnn.bfloat16,\n",
    "   layout=ttnn.TILE_LAYOUT,\n",
    "   device=device,\n",
    ")\n",
    "tt_t3 = ttnn.ones(\n",
    "   shape=(32, 32),\n",
    "   dtype=ttnn.bfloat16,\n",
    "   layout=ttnn.TILE_LAYOUT,\n",
    "   device=device,\n",
    ")\n",
    "tt_t4 = to_tt_tile(host_rand)\n",
    "\n",
    "t5 = np.array([[5, 6], [7, 8]], dtype=np.float32).repeat(16, axis=0).repeat(16, axis=1)\n",
    "tt_t5 = ttnn.Tensor(t5, device=device, layout=ttnn.TILE_LAYOUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9284b70",
   "metadata": {},
   "source": [
    "## Tile-Based Arithmetic Operations\n",
    "\n",
    "Let's use some of the tensors we created and perform different operations\n",
    "on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682ab02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"\\n--- TT-NN Tensor Operations on (32x32) Tiles ---\")\n",
    "add_result = ttnn.add(tt_t3, tt_t4)\n",
    "logger.info(f\"Addition:\\n{add_result}\")\n",
    "\n",
    "mul_result = ttnn.mul(tt_t4, tt_t5)\n",
    "logger.info(f\"Element-wise Multiplication:\\n{mul_result}\")\n",
    "\n",
    "matmul_result = ttnn.matmul(tt_t3, tt_t4, memory_config=ttnn.DRAM_MEMORY_CONFIG)\n",
    "logger.info(f\"Matrix Multiplication:\\n{matmul_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e459c187-3ecc-4d2b-a74e-e664f59d7fce",
   "metadata": {},
   "source": [
    "## Simulated Broadcasting (Row Vector Expansion)\n",
    "\n",
    "Let's simulate broadcasting a row vector across a tile. Every element of a given column will contain the same value.\n",
    "\n",
    "This is useful for operations that require expanding a smaller tensor to match the dimensions of a larger one.\n",
    "\n",
    "$\n",
    "\\begin{bmatrix}\n",
    "1 & 2 & \\cdots & 30 & 31 \\\\\n",
    "\\end{bmatrix}\n",
    "\\rightarrow\n",
    "\\begin{bmatrix}\n",
    "1 & 2 & \\cdots & 30 & 31 \\\\\n",
    "1 & 2 & \\cdots & 30 & 31 \\\\\n",
    "\\cdots & \\cdots & \\cdots & \\cdots \\\\\n",
    "1 & 2 & \\cdots & 30 & 31 \\\\\n",
    "1 & 2 & \\cdots & 30 & 31 \\\\\n",
    "\\end{bmatrix}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9190899",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"\\n--- Simulated Broadcasting (32x32 + Broadcasted Row Vector) ---\")\n",
    "broadcast_vector = torch.tensor(np.arange(0, 32), dtype=torch.float32).repeat(32, 1)\n",
    "logger.info(f\"Broadcast Vector:\\n{broadcast_vector}\")\n",
    "\n",
    "broadcast_tt = to_tt_tile(broadcast_vector)\n",
    "broadcast_add_result = ttnn.add(tt_t4, broadcast_tt)\n",
    "logger.info(f\"Broadcast Add Result (TT-NN):\\n{ttnn.to_torch(broadcast_add_result)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc16d3a-aae6-4cc0-84c3-9f9d54b20104",
   "metadata": {},
   "source": [
    "## Closing Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd8eb7d-74fc-4cc4-9afa-90c831435820",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttnn.close_device(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
