{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ece9c89",
   "metadata": {},
   "source": [
    "$$\n",
    "\\def\\CC{\\bf C}\n",
    "\\def\\QQ{\\bf Q}\n",
    "\\def\\RR{\\bf R}\n",
    "\\def\\ZZ{\\bf Z}\n",
    "\\def\\NN{\\bf N}\n",
    "$$\n",
    "# Basic Operations with TT-NN\n",
    "\n",
    "We will review a simple example that demonstrates how to create various\n",
    "tensors and perform basic arithmetic operations on them using TT-NN, a\n",
    "high-level Python API. These operations include addition,\n",
    "multiplication, and matrix multiplication, as well as simulating\n",
    "broadcasting of a row vector across a tile.\n",
    "\n",
    "Lets create the example file, `ttnn_basic_operations.py`\n",
    "\n",
    "## Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9864d745",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import ttnn\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98f3e88",
   "metadata": {},
   "source": [
    "## Open Tenstorrent device\n",
    "\n",
    "Create necessary device on which we will run our program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64940eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Tenstorrent device\n",
    "device = ttnn.open_device(device_id=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e34d476",
   "metadata": {},
   "source": [
    "## Helper Function for Tensor Preparation\n",
    "\n",
    "Lets create a helper function to convert PyTorch tensors to\n",
    "TT-NN tiled tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544b723b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to create a TT-NN tensor from torch with TILE_LAYOUT and bfloat16\n",
    "def to_tt_tile(torch_tensor):\n",
    "   return ttnn.from_torch(torch_tensor, dtype=ttnn.bfloat16, layout=ttnn.TILE_LAYOUT, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c23802",
   "metadata": {},
   "source": [
    "## Host Tensor Creation\n",
    "\n",
    "Create a tensor for our tests and fill with different values. We will\n",
    "use this and other tensors to demonstrate various operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dff6e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"\\n--- TT-NN Tensor Creation with Tiles (32x32) ---\")\n",
    "host_rand = torch.rand((32, 32), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc168d2",
   "metadata": {},
   "source": [
    "## Convert Host Tensors to TT-NN Tiled Tensors or Create Natively on Device\n",
    "\n",
    "Tensix cores operate most efficiently on tiled data, allowing them to\n",
    "perform a large amount of compute in parallel. Where necessary, lets\n",
    "convert host tensors to TT-NN tiled tensors using the helper function we\n",
    "created earlier, and transfer them to the TT device. Alternatively, we\n",
    "can create tensors natively using TT-NN's tensor creation functions, and\n",
    "initialize them directly on the TT device. TT-NN calls that create\n",
    "tensors natively on the device are a more efficient way to create\n",
    "tensors, as they avoid the overhead of transferring data from the host\n",
    "to the device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a85a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_t1 = ttnn.full(\n",
    "   shape=(32, 32),\n",
    "   fill_value=1.0,\n",
    "   dtype=ttnn.float32,\n",
    "   layout=ttnn.TILE_LAYOUT,\n",
    "   device=device,\n",
    ")\n",
    "\n",
    "tt_t2 = ttnn.zeros(\n",
    "   shape=(32, 32),\n",
    "   dtype=ttnn.bfloat16,\n",
    "   layout=ttnn.TILE_LAYOUT,\n",
    "   device=device,\n",
    ")\n",
    "tt_t3 = ttnn.ones(\n",
    "   shape=(32, 32),\n",
    "   dtype=ttnn.bfloat16,\n",
    "   layout=ttnn.TILE_LAYOUT,\n",
    "   device=device,\n",
    ")\n",
    "tt_t4 = to_tt_tile(host_rand)\n",
    "\n",
    "t5 = np.array([[5, 6], [7, 8]], dtype=np.float32).repeat(16, axis=0).repeat(16, axis=1)\n",
    "tt_t5 = ttnn.Tensor(t5, device=device, layout=ttnn.TILE_LAYOUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9284b70",
   "metadata": {},
   "source": [
    "## Tile-Based Arithmetic Operations\n",
    "\n",
    "Let's use some of the tensors we created and perform different operations\n",
    "on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682ab02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"\\n--- TT-NN Tensor Operations on (32x32) Tiles ---\")\n",
    "add_result = ttnn.add(tt_t3, tt_t4)\n",
    "mul_result = ttnn.mul(tt_t4, tt_t5)\n",
    "matmul_result = ttnn.matmul(tt_t3, tt_t4, memory_config=ttnn.DRAM_MEMORY_CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e459c187-3ecc-4d2b-a74e-e664f59d7fce",
   "metadata": {},
   "source": [
    "## Simulated Broadcasting (Row Vector Expansion)\n",
    "\n",
    "Lets simulated broadcasting a row vector across a tile. This is useful\n",
    "for operations that require expanding a smaller tensor to match the\n",
    "dimensions of a larger one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9190899",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"\\n--- Simulated Broadcasting (32x32 + Broadcasted Row Vector) ---\")\n",
    "broadcast_vector = torch.tensor([[1.0] * 32], dtype=torch.float32).repeat(32, 1)\n",
    "broadcast_tt = to_tt_tile(broadcast_vector)\n",
    "broadcast_add_result = ttnn.add(tt_t4, broadcast_tt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc16d3a-aae6-4cc0-84c3-9f9d54b20104",
   "metadata": {},
   "source": [
    "## Full example and output\n",
    "\n",
    "Let's put everything together in a complete example that can be run\n",
    "directly. This example will open a Tenstorrent device, create some input\n",
    "tensors and perform operations on them, log the output tensors, and\n",
    "close the device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd8eb7d-74fc-4cc4-9afa-90c831435820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPDX-FileCopyrightText: Â© 2025 Tenstorrent AI ULC\n",
    "# SPDX-License-Identifier: Apache-2.0\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import ttnn\n",
    "from loguru import logger\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Open Tenstorrent device\n",
    "    device = ttnn.open_device(device_id=0)\n",
    "\n",
    "    try:\n",
    "        # Helper to create a TT-NN tensor from torch with TILE_LAYOUT and bfloat16\n",
    "        def to_tt_tile(torch_tensor):\n",
    "            return ttnn.from_torch(torch_tensor, dtype=ttnn.bfloat16, layout=ttnn.TILE_LAYOUT, device=device)\n",
    "\n",
    "        logger.info(\"\\n--- TT-NN Tensor Creation with Tiles (32x32) ---\")\n",
    "        host_rand = torch.rand((32, 32), dtype=torch.float32)\n",
    "\n",
    "        tt_t1 = ttnn.full(\n",
    "            shape=(32, 32),\n",
    "            fill_value=1.0,\n",
    "            dtype=ttnn.float32,\n",
    "            layout=ttnn.TILE_LAYOUT,\n",
    "            device=device,\n",
    "        )\n",
    "        tt_t2 = ttnn.zeros(\n",
    "            shape=(32, 32),\n",
    "            dtype=ttnn.bfloat16,\n",
    "            layout=ttnn.TILE_LAYOUT,\n",
    "            device=device,\n",
    "        )\n",
    "        tt_t3 = ttnn.ones(\n",
    "            shape=(32, 32),\n",
    "            dtype=ttnn.bfloat16,\n",
    "            layout=ttnn.TILE_LAYOUT,\n",
    "            device=device,\n",
    "        )\n",
    "        tt_t4 = to_tt_tile(host_rand)\n",
    "\n",
    "        t5 = np.array([[5, 6], [7, 8]], dtype=np.float32).repeat(16, axis=0).repeat(16, axis=1)\n",
    "        tt_t5 = ttnn.Tensor(t5, device=device, layout=ttnn.TILE_LAYOUT)\n",
    "\n",
    "        logger.info(f\"Tensor from fill value 1:\\n{ttnn.to_torch(tt_t1)}\")\n",
    "        logger.info(f\"Zeros:\\n{ttnn.to_torch(tt_t2)}\")\n",
    "        logger.info(f\"Ones:\\n{ttnn.to_torch(tt_t3)}\")\n",
    "        logger.info(f\"Random:\\n{ttnn.to_torch(tt_t4)}\")\n",
    "        logger.info(f\"From expanded NumPy (TT-NN):\\n{ttnn.to_torch(tt_t5)}\")\n",
    "\n",
    "        logger.info(\"\\n--- TT-NN Tensor Operations on (32x32) Tiles ---\")\n",
    "        add_result = ttnn.add(tt_t3, tt_t4)\n",
    "        mul_result = ttnn.mul(tt_t4, tt_t5)\n",
    "        matmul_result = ttnn.matmul(tt_t3, tt_t4, memory_config=ttnn.DRAM_MEMORY_CONFIG)\n",
    "\n",
    "        ttnn_add = ttnn.to_torch(add_result)\n",
    "        logger.info(f\"Addition:\\n{ttnn_add}\")\n",
    "\n",
    "        ttnn_mul = ttnn.to_torch(mul_result)\n",
    "        logger.info(f\"Element-wise Multiplication:\\n{ttnn_mul}\")\n",
    "\n",
    "        ttnn_matmul = ttnn.to_torch(matmul_result)\n",
    "        logger.info(f\"Matrix Multiplication:\\n{ttnn_matmul}\")\n",
    "\n",
    "        logger.info(\"\\n--- Simulated Broadcasting (32x32 + Broadcasted Row Vector) ---\")\n",
    "        broadcast_vector = torch.tensor([[1.0] * 32], dtype=torch.float32).repeat(32, 1)\n",
    "        broadcast_tt = to_tt_tile(broadcast_vector)\n",
    "        broadcast_add_result = ttnn.add(tt_t4, broadcast_tt)\n",
    "        logger.info(f\"Broadcast Add Result (TT-NN):\\n{ttnn.to_torch(broadcast_add_result)}\")\n",
    "\n",
    "    finally:\n",
    "        ttnn.close_device(device)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd273e29-d868-4854-9407-4ea5efb6c525",
   "metadata": {},
   "source": [
    "Running this script will output the operation results as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70c4cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "$ python3 $TT_METAL_HOME/ttnn/tutorials/basic_python/ttnn_basic_operations.py\n",
    "2025-06-23 09:47:12.093 | INFO     | __main__:main:19 -\n",
    "--- TT-NN Tensor Creation with Tiles (32x32) ---\n",
    "2025-06-23 09:47:12.117 | INFO     | __main__:main:47 - Tensor from fill value 1:\n",
    "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
    "      [1., 1., 1.,  ..., 1., 1., 1.],\n",
    "      [1., 1., 1.,  ..., 1., 1., 1.],\n",
    "      ...,\n",
    "      [1., 1., 1.,  ..., 1., 1., 1.],\n",
    "      [1., 1., 1.,  ..., 1., 1., 1.],\n",
    "      [1., 1., 1.,  ..., 1., 1., 1.]])\n",
    "2025-06-23 09:47:12.117 | INFO     | __main__:main:48 - Zeros:\n",
    "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
    "      [0., 0., 0.,  ..., 0., 0., 0.],\n",
    "      [0., 0., 0.,  ..., 0., 0., 0.],\n",
    "      ...,\n",
    "      [0., 0., 0.,  ..., 0., 0., 0.],\n",
    "      [0., 0., 0.,  ..., 0., 0., 0.],\n",
    "      [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.bfloat16)\n",
    "2025-06-23 09:47:12.118 | INFO     | __main__:main:49 - Ones:\n",
    "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
    "      [1., 1., 1.,  ..., 1., 1., 1.],\n",
    "      [1., 1., 1.,  ..., 1., 1., 1.],\n",
    "      ...,\n",
    "      [1., 1., 1.,  ..., 1., 1., 1.],\n",
    "      [1., 1., 1.,  ..., 1., 1., 1.],\n",
    "      [1., 1., 1.,  ..., 1., 1., 1.]], dtype=torch.bfloat16)\n",
    "2025-06-23 09:47:12.119 | INFO     | __main__:main:50 - Random:\n",
    "tensor([[0.1367, 0.3320, 0.8125,  ..., 0.7969, 0.6250, 0.8906],\n",
    "      [0.6914, 0.1377, 0.2480,  ..., 0.6406, 0.0109, 0.2080],\n",
    "      [0.6992, 0.8750, 0.6133,  ..., 0.3086, 0.6562, 0.6016],\n",
    "      ...,\n",
    "      [0.1455, 0.8672, 0.0221,  ..., 0.3926, 0.1074, 0.9414],\n",
    "      [0.5859, 0.1426, 0.8906,  ..., 0.5820, 0.0182, 0.7031],\n",
    "      [0.8711, 0.1377, 0.7305,  ..., 0.4102, 0.2812, 0.6836]],\n",
    "      dtype=torch.bfloat16)\n",
    "2025-06-23 09:47:12.120 | INFO     | __main__:main:51 - From expanded NumPy (TT-NN):\n",
    "tensor([[5., 5., 5.,  ..., 6., 6., 6.],\n",
    "      [5., 5., 5.,  ..., 6., 6., 6.],\n",
    "      [5., 5., 5.,  ..., 6., 6., 6.],\n",
    "      ...,\n",
    "      [7., 7., 7.,  ..., 8., 8., 8.],\n",
    "      [7., 7., 7.,  ..., 8., 8., 8.],\n",
    "      [7., 7., 7.,  ..., 8., 8., 8.]])\n",
    "2025-06-23 09:47:12.120 | INFO     | __main__:main:53 -\n",
    "--- TT-NN Tensor Operations on (32x32) Tiles ---\n",
    "2025-06-23 09:47:18.928 | INFO     | __main__:main:59 - Addition:\n",
    "tensor([[1.1406, 1.3359, 1.8125,  ..., 1.7969, 1.6250, 1.8906],\n",
    "      [1.6953, 1.1406, 1.2500,  ..., 1.6406, 1.0078, 1.2109],\n",
    "      [1.7031, 1.8750, 1.6172,  ..., 1.3125, 1.6562, 1.6016],\n",
    "      ...,\n",
    "      [1.1484, 1.8672, 1.0234,  ..., 1.3906, 1.1094, 1.9453],\n",
    "      [1.5859, 1.1406, 1.8906,  ..., 1.5859, 1.0156, 1.7031],\n",
    "      [1.8750, 1.1406, 1.7344,  ..., 1.4141, 1.2812, 1.6875]],\n",
    "      dtype=torch.bfloat16)\n",
    "2025-06-23 09:47:18.929 | INFO     | __main__:main:62 - Element-wise Multiplication:\n",
    "tensor([[0.6836, 1.6641, 4.0625,  ..., 4.7812, 3.7500, 5.3438],\n",
    "      [3.4531, 0.6875, 1.2422,  ..., 3.8438, 0.0654, 1.2500],\n",
    "      [3.5000, 4.3750, 3.0625,  ..., 1.8516, 3.9375, 3.6094],\n",
    "      ...,\n",
    "      [1.0156, 6.0625, 0.1543,  ..., 3.1406, 0.8594, 7.5312],\n",
    "      [4.0938, 1.0000, 6.2500,  ..., 4.6562, 0.1455, 5.6250],\n",
    "      [6.0938, 0.9648, 5.1250,  ..., 3.2812, 2.2500, 5.4688]],\n",
    "      dtype=torch.bfloat16)\n",
    "2025-06-23 09:47:18.930 | INFO     | __main__:main:65 - Matrix Multiplication:\n",
    "tensor([[17.5000, 13.4375, 16.7500,  ..., 15.2500, 13.0625, 17.2500],\n",
    "      [17.5000, 13.4375, 16.7500,  ..., 15.2500, 13.0625, 17.2500],\n",
    "      [17.5000, 13.4375, 16.7500,  ..., 15.2500, 13.0625, 17.2500],\n",
    "      ...,\n",
    "      [17.5000, 13.4375, 16.7500,  ..., 15.2500, 13.0625, 17.2500],\n",
    "      [17.5000, 13.4375, 16.7500,  ..., 15.2500, 13.0625, 17.2500],\n",
    "      [17.5000, 13.4375, 16.7500,  ..., 15.2500, 13.0625, 17.2500]],\n",
    "      dtype=torch.bfloat16)\n",
    "2025-06-23 09:47:18.930 | INFO     | __main__:main:67 -\n",
    "--- Simulated Broadcasting (32x32 + Broadcasted Row Vector) ---\n",
    "2025-06-23 09:47:18.932 | INFO     | __main__:main:71 - Broadcast Add Result (TT-NN):\n",
    "tensor([[1.1406, 1.3359, 1.8125,  ..., 1.7969, 1.6250, 1.8906],\n",
    "      [1.6953, 1.1406, 1.2500,  ..., 1.6406, 1.0078, 1.2109],\n",
    "      [1.7031, 1.8750, 1.6172,  ..., 1.3125, 1.6562, 1.6016],\n",
    "      ...,\n",
    "      [1.1484, 1.8672, 1.0234,  ..., 1.3906, 1.1094, 1.9453],\n",
    "      [1.5859, 1.1406, 1.8906,  ..., 1.5859, 1.0156, 1.7031],\n",
    "      [1.8750, 1.1406, 1.7344,  ..., 1.4141, 1.2812, 1.6875]],\n",
    "      dtype=torch.bfloat16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
