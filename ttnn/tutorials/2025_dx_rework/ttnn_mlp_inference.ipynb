{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c002ee57",
   "metadata": {},
   "source": [
    "# MLP inference with TT-NN\n",
    "\n",
    "In this example we will combine insight from the previous examples, and\n",
    "use TT-NN with PyTorch to perform a simple MLP inference task. This will\n",
    "demonstrate how to use TT-NN for tensor operations and model inference.\n",
    "\n",
    "Lets create the example file, `ttnn_mlp_inference_mnist.py`\n",
    "\n",
    "## Import the necessary libraries\n",
    "\n",
    "Amongst these, torchvision is used to load the MNIST dataset, and ttnn\n",
    "is used for tensor operations on the Tenstorrent device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a420325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import ttnn\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005a5754",
   "metadata": {},
   "source": [
    "## Open Tenstorrent device\n",
    "\n",
    "Create necessary device on which we will run our program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d68f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Tenstorrent device\n",
    "device = ttnn.open_device(device_id=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa9f9ab",
   "metadata": {},
   "source": [
    "## Load MNIST Test Data\n",
    "\n",
    "Load and convert the MNIST 28x28 grayscale images to tensors and\n",
    "normalize them. Subsequently, lets create a DataLoader to iterate\n",
    "through the dataset. This will allow us to perform inference on each\n",
    "image in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34628f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "testset = torchvision.datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c349e3",
   "metadata": {},
   "source": [
    "## Load Pretrained MLP Weights\n",
    "\n",
    "Load the pretrained MLP weights from a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771bd8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrained weights\n",
    "weights = torch.load(\"mlp_mnist_weights.pt\")\n",
    "W1 = weights[\"W1\"]\n",
    "b1 = weights[\"b1\"]\n",
    "W2 = weights[\"W2\"]\n",
    "b2 = weights[\"b2\"]\n",
    "W3 = weights[\"W3\"]\n",
    "b3 = weights[\"b3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff86916",
   "metadata": {},
   "source": [
    "## Basic accuracy tracking, inference, loop, and image flattening\n",
    "\n",
    "Loop through the first 5 images in the data set, and convert the image\n",
    "from 1x28x28 to 1x784 by flattening it. This is done to match the input\n",
    "shape of the MLP model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6b1ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for i, (image, label) in enumerate(testloader):\n",
    "   if i >= 5:\n",
    "      break\n",
    "\n",
    "      image = image.view(1, -1).to(torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c026449f",
   "metadata": {},
   "source": [
    "## Convert to TT-NN Tensor\n",
    "\n",
    "Convert the PyTorch tensor to TT-NN format with bfloat16 data type and\n",
    "TILE\\_LAYOUT. This is necessary for efficient computation on the\n",
    "Tenstorrent device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9cee8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input tensor\n",
    "image_tt = ttnn.from_torch(image, dtype=ttnn.bfloat16, layout=ttnn.ROW_MAJOR_LAYOUT, device=device)\n",
    "image_tt = ttnn.to_layout(image_tt, ttnn.TILE_LAYOUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a5c682",
   "metadata": {},
   "source": [
    "## Layer 1 (Linear + ReLU)\n",
    "\n",
    "Transposed weights are used to match TT-NN's expected shape. Bias\n",
    "reshaped to 1x128 for broadcasting, and compute output 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a0897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer 1\n",
    "W1_tt = ttnn.from_torch(W1.T, dtype=ttnn.bfloat16, layout=ttnn.ROW_MAJOR_LAYOUT, device=device)\n",
    "W1_tt = ttnn.to_layout(W1_tt, ttnn.TILE_LAYOUT)\n",
    "b1_tt = ttnn.from_torch(b1.view(1, -1), dtype=ttnn.bfloat16, layout=ttnn.ROW_MAJOR_LAYOUT, device=device)\n",
    "b1_tt = ttnn.to_layout(b1_tt, ttnn.TILE_LAYOUT)\n",
    "out1 = ttnn.linear(image_tt, W1_tt, bias=b1_tt)\n",
    "out1 = ttnn.relu(out1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf107d6a",
   "metadata": {},
   "source": [
    "## Layer 2 (Linear + ReLU)\n",
    "\n",
    "Same pattern as Layer 1, but with different weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d3377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer 2\n",
    "W2_tt = ttnn.from_torch(W2.T, dtype=ttnn.bfloat16, layout=ttnn.ROW_MAJOR_LAYOUT, device=device)\n",
    "W2_tt = ttnn.to_layout(W2_tt, ttnn.TILE_LAYOUT)\n",
    "b2_tt = ttnn.from_torch(b2.view(1, -1), dtype=ttnn.bfloat16, layout=ttnn.ROW_MAJOR_LAYOUT, device=device)\n",
    "b2_tt = ttnn.to_layout(b2_tt, ttnn.TILE_LAYOUT)\n",
    "out2 = ttnn.linear(out1, W2_tt, bias=b2_tt)\n",
    "out2 = ttnn.relu(out2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56f8f05",
   "metadata": {},
   "source": [
    "## Layer 3 (Output Layer)\n",
    "\n",
    "Final layer with 10 output (for digits 0-9). No ReLU activation here, as\n",
    "this is the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de7e553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer 3\n",
    "W3_tt = ttnn.from_torch(W3.T, dtype=ttnn.bfloat16, layout=ttnn.ROW_MAJOR_LAYOUT, device=device)\n",
    "W3_tt = ttnn.to_layout(W3_tt, ttnn.TILE_LAYOUT)\n",
    "b3_tt = ttnn.from_torch(b3.view(1, -1), dtype=ttnn.bfloat16, layout=ttnn.ROW_MAJOR_LAYOUT, device=device)\n",
    "b3_tt = ttnn.to_layout(b3_tt, ttnn.TILE_LAYOUT)\n",
    "out3 = ttnn.linear(out2, W3_tt, bias=b3_tt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1961458b",
   "metadata": {},
   "source": [
    "## Convert Back to PyTorch and sum results\n",
    "\n",
    "Final layer with 10 output (for digits 0-9). No ReLU activation here, as\n",
    "this is the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a264c5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert result back to torch\n",
    "prediction = ttnn.to_torch(out3)\n",
    "predicted_label = torch.argmax(prediction, dim=1).item()\n",
    "\n",
    "correct += predicted_label == label.item()\n",
    "total += 1\n",
    "\n",
    "logger.info(f\"Sample {i+1}: Predicted={predicted_label}, Actual={label.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bcf3ea",
   "metadata": {},
   "source": [
    "## Full example and output\n",
    "\n",
    "Lets put everything together in a complete example that can be run\n",
    "directly. This example will open a Tenstorrent device, create two\n",
    "tensors, perform the addition, and log the output tensor. You can run\n",
    "the provided `train_and_export_mlp.py` script to generate the weights to\n",
    "a file named `mlp_mnist_weights.pt`.\n",
    "\n",
    "<div class=\"literalinclude\" data-caption=\"Example Source Code\">\n",
    "\n",
    "ttnn\\_tutorials\\_basic\\_python/ttnn\\_mlp\\_inference\\_mnist.py\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"literalinclude\" data-caption=\"Script to generate weights for example\">\n",
    "\n",
    "ttnn\\_tutorials\\_basic\\_python/train\\_and\\_export\\_mlp.py\n",
    "\n",
    "</div>\n",
    "\n",
    "Running this script will output the input tensors and the result of\n",
    "their addition, which should be a tensor filled with 3s. As shown below\n",
    "\n",
    "``` console\n",
    "2025-06-23 09:51:47.723 | INFO     | __main__:main:17 -\n",
    "--- MLP Inference Using TT-NN on MNIST ---\n",
    "2025-06-23 09:52:10.480 | INFO     | __main__:main:85 - Sample 1: Predicted=7, Actual=7\n",
    "2025-06-23 09:52:10.491 | INFO     | __main__:main:85 - Sample 2: Predicted=2, Actual=2\n",
    "2025-06-23 09:52:10.499 | INFO     | __main__:main:85 - Sample 3: Predicted=1, Actual=1\n",
    "2025-06-23 09:52:10.506 | INFO     | __main__:main:85 - Sample 4: Predicted=0, Actual=0\n",
    "2025-06-23 09:52:10.514 | INFO     | __main__:main:85 - Sample 5: Predicted=4, Actual=4\n",
    "2025-06-23 09:52:10.514 | INFO     | __main__:main:87 -\n",
    "TT-NN MLP Inference Accuracy: 5/5 = 100.00%\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
