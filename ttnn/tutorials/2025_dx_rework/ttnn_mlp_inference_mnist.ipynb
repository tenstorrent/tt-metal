{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c002ee57",
   "metadata": {},
   "source": [
    "# MLP inference with TT-NN\n",
    "\n",
    "In this example we will combine insight from the previous examples, and\n",
    "use TT-NN with PyTorch to perform a simple MLP inference task. This will\n",
    "demonstrate how to use TT-NN for tensor operations and model inference.\n",
    "\n",
    "Lets create the example file, `ttnn_mlp_inference_mnist.py`\n",
    "\n",
    "## Import the necessary libraries\n",
    "\n",
    "Amongst these, torchvision is used to load the MNIST dataset, and ttnn\n",
    "is used for tensor operations on the Tenstorrent device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e8a746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import ttnn\n",
    "import os\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23308c8",
   "metadata": {},
   "source": [
    "## Open Tenstorrent device\n",
    "\n",
    "Create necessary device on which we will run our program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc24097c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Tenstorrent device\n",
    "device = ttnn.open_device(device_id=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75cd6fe",
   "metadata": {},
   "source": [
    "## Load MNIST Test Data\n",
    "\n",
    "Load and convert the MNIST 28x28 grayscale images to tensors and\n",
    "normalize them. Subsequently, lets create a DataLoader to iterate\n",
    "through the dataset. This will allow us to perform inference on each\n",
    "image in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6482d274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "testset = torchvision.datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14e13d0",
   "metadata": {},
   "source": [
    "## Load Pretrained MLP Weights\n",
    "\n",
    "Load the pretrained MLP weights from a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad17492d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"mlp_mnist_weights.pt\"):\n",
    "    # Pretrained weights\n",
    "    weights = torch.load(\"mlp_mnist_weights.pt\")\n",
    "    W1 = weights[\"W1\"]\n",
    "    b1 = weights[\"b1\"]\n",
    "    W2 = weights[\"W2\"]\n",
    "    b2 = weights[\"b2\"]\n",
    "    W3 = weights[\"W3\"]\n",
    "    b3 = weights[\"b3\"]\n",
    "    logger.info(\"Loaded pretrained weights from mlp_mnist_weights.pt\")\n",
    "else:\n",
    "    # Random weights for MLP - will not predict correctly\n",
    "    logger.warning(\"mlp_mnist_weights.pt not found, using random weights\")\n",
    "    torch.manual_seed(0)\n",
    "    W1 = torch.randn((128, 28 * 28), dtype=torch.float32)\n",
    "    b1 = torch.randn((128,), dtype=torch.float32)\n",
    "    W2 = torch.randn((64, 128), dtype=torch.float32)\n",
    "    b2 = torch.randn((64,), dtype=torch.float32)\n",
    "    W3 = torch.randn((10, 64), dtype=torch.float32)\n",
    "    b3 = torch.randn((10,), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396ded06",
   "metadata": {},
   "source": [
    "## Basic accuracy tracking, inference, loop, and image flattening\n",
    "\n",
    "Loop through the first 5 images in the data set, and convert the image\n",
    "from 1x28x28 to 1x784 by flattening it. This is done to match the input\n",
    "shape of the MLP model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4fa175",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for i, (image, label) in enumerate(testloader):\n",
    "    if i >= 5:\n",
    "        break\n",
    "\n",
    "    image = image.view(1, -1).to(torch.float32)\n",
    "    \n",
    "    # Convert to TT-NN Tensor\n",
    "    # Convert the PyTorch tensor to TT-NN format with bfloat16 data type and\n",
    "    # TILE\\_LAYOUT. This is necessary for efficient computation on the\n",
    "    # Tenstorrent device.\n",
    "    image_tt = ttnn.from_torch(image, dtype=ttnn.bfloat16, layout=ttnn.ROW_MAJOR_LAYOUT, device=device)\n",
    "    image_tt = ttnn.to_layout(image_tt, ttnn.TILE_LAYOUT)\n",
    "    \n",
    "    # Layer 1\n",
    "    # Transposed weights are used to match TT-NN's expected shape. Bias\n",
    "    # reshaped to 1x128 for broadcasting, and compute output 1.\n",
    "    W1_tt = ttnn.from_torch(W1.T, dtype=ttnn.bfloat16, layout=ttnn.ROW_MAJOR_LAYOUT, device=device)\n",
    "    W1_tt = ttnn.to_layout(W1_tt, ttnn.TILE_LAYOUT)\n",
    "    b1_tt = ttnn.from_torch(b1.view(1, -1), dtype=ttnn.bfloat16, layout=ttnn.ROW_MAJOR_LAYOUT, device=device)\n",
    "    b1_tt = ttnn.to_layout(b1_tt, ttnn.TILE_LAYOUT)\n",
    "    out1 = ttnn.linear(image_tt, W1_tt, bias=b1_tt)\n",
    "    out1 = ttnn.relu(out1)\n",
    "    \n",
    "    # Layer 2\n",
    "    # Same pattern as Layer 1, but with different weights and biases.\n",
    "    W2_tt = ttnn.from_torch(W2.T, dtype=ttnn.bfloat16, layout=ttnn.ROW_MAJOR_LAYOUT, device=device)\n",
    "    W2_tt = ttnn.to_layout(W2_tt, ttnn.TILE_LAYOUT)\n",
    "    b2_tt = ttnn.from_torch(b2.view(1, -1), dtype=ttnn.bfloat16, layout=ttnn.ROW_MAJOR_LAYOUT, device=device)\n",
    "    b2_tt = ttnn.to_layout(b2_tt, ttnn.TILE_LAYOUT)\n",
    "    out2 = ttnn.linear(out1, W2_tt, bias=b2_tt)\n",
    "    out2 = ttnn.relu(out2)\n",
    "    \n",
    "    # Layer 3\n",
    "    # Final layer with 10 output (for digits 0-9). No ReLU activation here, as\n",
    "    # this is the output layer.\n",
    "    W3_tt = ttnn.from_torch(W3.T, dtype=ttnn.bfloat16, layout=ttnn.ROW_MAJOR_LAYOUT, device=device)\n",
    "    W3_tt = ttnn.to_layout(W3_tt, ttnn.TILE_LAYOUT)\n",
    "    b3_tt = ttnn.from_torch(b3.view(1, -1), dtype=ttnn.bfloat16, layout=ttnn.ROW_MAJOR_LAYOUT, device=device)\n",
    "    b3_tt = ttnn.to_layout(b3_tt, ttnn.TILE_LAYOUT)\n",
    "    out3 = ttnn.linear(out2, W3_tt, bias=b3_tt)\n",
    "    \n",
    "    # Convert result back to torch\n",
    "    prediction = ttnn.to_torch(out3)\n",
    "    predicted_label = torch.argmax(prediction, dim=1).item()\n",
    "    \n",
    "    correct += predicted_label == label.item()\n",
    "    total += 1\n",
    "    \n",
    "    logger.info(f\"Sample {i+1}: Predicted={predicted_label}, Actual={label.item()}\")\n",
    "    \n",
    "logger.info(f\"\\nTT-NN MLP Inference Accuracy: {correct}/{total} = {100.0 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc74396",
   "metadata": {},
   "source": [
    "## Full example and output\n",
    "\n",
    "Lets put everything together in a complete example that can be run\n",
    "directly. This example will open a Tenstorrent device, create two\n",
    "tensors, perform the addition, and log the output tensor. You can run\n",
    "the provided `train_and_export_mlp.py` script to generate the weights to\n",
    "a file named `mlp_mnist_weights.pt`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65edabfc",
   "metadata": {},
   "source": [
    "## Close the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350adfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttnn.close_device(device)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
