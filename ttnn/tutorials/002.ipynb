{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;000;128;000m                  Metal\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Initializing device 0\n",
      "\u001b[38;2;000;128;000m                 Device\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Opening user mode device driver\n",
      "\u001b[32m2024-01-29 16:41:46.800\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Detected 1 PCI device : {0}\n",
      "\u001b[32m2024-01-29 16:41:46.810\u001b[0m | \u001b[1m\u001b[38;2;255;165;000mWARNING \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - init_detect_tt_device_numanodes(): Could not determine NumaNodeSet for TT device (physical_device_id: 0 pci_bus_id: 0000:00:08.0)\n",
      "\u001b[32m2024-01-29 16:41:46.810\u001b[0m | \u001b[1m\u001b[38;2;255;165;000mWARNING \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Could not find NumaNodeSet for TT Device (physical_device_id: 0 pci_bus_id: 0000:00:08.0)\n",
      "\u001b[32m2024-01-29 16:41:46.812\u001b[0m | \u001b[1m\u001b[38;2;255;165;000mWARNING \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - bind_area_memory_nodeset(): Unable to determine TT Device to NumaNode mapping for physical_device_id: 0. Skipping membind.\n",
      "\u001b[0;33m---- ttSiliconDevice::init_hugepage: bind_area_to_memory_nodeset() failed (physical_device_id: 0 ch: 0). Hugepage allocation is not on NumaNode matching TT Device. Side-Effect is decreased Device->Host perf (Issue #893).\n",
      "\u001b[0m\u001b[38;2;000;128;000m                  Metal\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | AI CLK for device 0 is:   1202 MHz\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import ttnn\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device_id = 0\n",
    "device = ttnn.open(device_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable program cache\n",
    "\n",
    "Enabling the program cache will speed up the execution of operations that run repeatedly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Program Cache: enabled.\n"
     ]
    }
   ],
   "source": [
    "ttnn.enable_program_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 1024\n",
    "k = 1024\n",
    "n = 1024"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize tensors a and b with random values using torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_a = torch.randn((m, k), dtype=torch.bfloat16)\n",
    "torch_b = torch.randn((k, n), dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.from_torch                                    in          225178 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.from_torch                                    in           35309 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.to_device                                     in          949984 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.to_device                                     in          838825 nanoseconds\n"
     ]
    }
   ],
   "source": [
    "a = ttnn.from_torch(torch_a)\n",
    "b = ttnn.from_torch(torch_b)\n",
    "\n",
    "a = ttnn.to_device(a, device)\n",
    "b = ttnn.to_device(b, device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix multiply tensor a and b\n",
    "The operation will run longer the first time because the kernels need to get compiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           38790 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           20710 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Tilize                               in       484012355 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Tilize                               in       484148844 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Tilize                               in         1534322 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Tilize                               in         1584541 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Matmul                               in       562087924 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Matmul                               in       562247364 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           93579 nanoseconds\n"
     ]
    }
   ],
   "source": [
    "output = a @ b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-running the operation shows significant speed up by utilizing program caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           31730 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           23860 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Tilize                               in         1545421 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Tilize                               in         1587351 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Tilize                               in         1532711 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Tilize                               in         1546921 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Matmul                               in         1185983 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Matmul                               in         1206063 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           30830 nanoseconds\n"
     ]
    }
   ],
   "source": [
    "output = a @ b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the layout of matrix multiplication output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layout.TILE\n"
     ]
    }
   ],
   "source": [
    "print(output.layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, matrix multiplication produces outputs in a tile layout. That is because it's much more efficient to use this layout for computing matrix multiplications on TensTorrent accelerators compared to a row-major layout.\n",
    "\n",
    "And this is aslo why the logs show 2 tilize operations, as the inputs get automatically convered to the tile layout if they are in a row-major layout.\n",
    "\n",
    "Learn more about tile layout here: TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the result of the matrix multiplication\n",
    "\n",
    "To inspect the results we will first convert to row-major layout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Printing ttnn tensor\n",
      "shape: ttnn.Shape([1024, 1024])\n",
      "Finished Program   tt::tt_metal::Untilize                             in       456451455 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Untilize                             in       456574574 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.from_device                                   in         2053188 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.to_torch                                      in          533017 nanoseconds\n",
      "chunk of a tensor:\n",
      "Tensor([ [34.25, 9.625, 11.3125, 0.964844, 1.45312, -26.875, 23.125, -1.39062, -20.375, 33, 5.8125, 10.6875, -18.625, 14.5, -42.75, -18.375, 27.75, 44.25, -27.25, -20.5, 43.5, -5.75, -46.75, -45.75, 43.75, 33, -16.125, 39.25, 11.6875, 9.4375, -39.75, -6.5625]], dtype=bfloat16 )\n",
      "\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation torch.Tensor.__getitem__                           in          851115 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.from_torch                                    in           86070 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.to_device                                     in           95590 nanoseconds\n"
     ]
    }
   ],
   "source": [
    "output = ttnn.to_layout(output, ttnn.ROW_MAJOR_LAYOUT)\n",
    "\n",
    "print(\"Printing ttnn tensor\")\n",
    "print(f\"shape: {output.shape}\")\n",
    "print(f\"chunk of a tensor:\\n{output[:1, :32]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tilize tensors before running matrix multiplication\n",
    "Inputs can be tilized before running matrix multiplication. \n",
    "\n",
    "And there are times when it's highly recommended to do that. For example, during inference, pre-tilizing weights gets rid of unnecessarily tilizing the weights every time a matmul is running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Tilize                               in         1827330 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Tilize                               in         1912949 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Tilize                               in         1536851 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Tilize                               in         1558681 nanoseconds\n"
     ]
    }
   ],
   "source": [
    "a = ttnn.to_layout(a, ttnn.TILE_LAYOUT)\n",
    "b = ttnn.to_layout(b, ttnn.TILE_LAYOUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running matrix multiplication with tilized inputs shows that only matrix multiplication operation is invoked without any additional pre-processing operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           35010 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           23800 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Matmul                               in         1198393 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Matmul                               in         1225833 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           25070 nanoseconds\n"
     ]
    }
   ],
   "source": [
    "output = a @ b"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix multiply tensor a and b by using more performant config\n",
    "By default, matrix multiplication might not be as effecient as it could be. To speed it up further, the user can specify how many cores they want matrix multiplication to use. This can speed up the operation significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.from_torch                                    in           49290 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.from_torch                                    in           34560 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.to_device                                     in          832296 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.to_device                                     in          950575 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Tilize                               in       406539472 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Tilize                               in       406609712 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Tilize                               in          448407 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Tilize                               in          487327 nanoseconds\n"
     ]
    }
   ],
   "source": [
    "a = ttnn.from_torch(torch_a)\n",
    "b = ttnn.from_torch(torch_b)\n",
    "\n",
    "a = ttnn.to_device(a, device, memory_config=ttnn.L1_MEMORY_CONFIG)\n",
    "b = ttnn.to_device(b, device, memory_config=ttnn.L1_MEMORY_CONFIG)\n",
    "\n",
    "a = ttnn.to_layout(a, ttnn.TILE_LAYOUT)\n",
    "b = ttnn.to_layout(b, ttnn.TILE_LAYOUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run once to compile the kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           63309 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           26090 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::operations::primary::Matmul                    in       601022529 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::operations::primary::Matmul                    in       601438087 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in          100719 nanoseconds\n"
     ]
    }
   ],
   "source": [
    "output = ttnn.matmul(a, b, memory_config=ttnn.L1_MEMORY_CONFIG, core_grid=(8, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enjoy a massive speed up on the subsequent runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           32349 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           21900 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::operations::primary::Matmul                    in          129279 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::operations::primary::Matmul                    in          177849 nanoseconds\n",
      "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           24300 nanoseconds\n"
     ]
    }
   ],
   "source": [
    "output = ttnn.matmul(a, b, memory_config=ttnn.L1_MEMORY_CONFIG, core_grid=(8, 8))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Close the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;000;128;000m                  Metal\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Closing device 0\n"
     ]
    }
   ],
   "source": [
    "ttnn.close(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
