Let me investigate each integration point to see exactly what gets tracked:

[6 tools called]

Now let me look at the actual allocator.cpp to see if the integration is applied:

[2 tools called]

Now let me check where buffer tracking actually happens:

[1 tool called]

Perfect! Now let me check where `track_allocate` is called from:

[1 tool called]

Perfect! Now let me check the actual calls from buffer.cpp:

[2 tools called]

Excellent! Now I have all the information. Let me create a comprehensive summary of what gets tracked at each integration point:

# TT-Metal Memory Allocation Monitor - Architecture Overview

## üèóÔ∏è Architecture (3 Components)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Python Application                        ‚îÇ
‚îÇ              (runs ML models on device)                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
                   ‚Üì calls
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ  TT-Metal Library    ‚îÇ
        ‚îÇ  (libtt_metal.so)    ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
                   ‚Üì reports via
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ  AllocationClient    ‚îÇ    (embedded in libtt_metal.so)
        ‚îÇ  - Tracks allocs     ‚îÇ
        ‚îÇ  - Sends to server   ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
                   ‚Üì Unix socket (/tmp/tt_allocation_server.sock)
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ AllocationServer     ‚îÇ    (standalone process)
        ‚îÇ  - Aggregates stats  ‚îÇ
        ‚îÇ  - Cross-process     ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
                   ‚Üë queries via socket
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ    tt_smi_umd        ‚îÇ    (monitoring tool)
        ‚îÇ  - Displays stats    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ  - Real-time UI      ‚îÇ    ‚îÇ
        ‚îÇ  - Telemetry graphs  ‚îÇ    ‚îÇ direct UMD access
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
                                    ‚Üì
                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                          ‚îÇ  Device (UMD)   ‚îÇ
                          ‚îÇ  - Temperature  ‚îÇ
                          ‚îÇ  - Clocks       ‚îÇ
                          ‚îÇ  - Power        ‚îÇ
                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üìÅ Key Files & Integration Points

### 1. **Buffer Allocation Tracking** (`tt_metal/impl/buffers/buffer.cpp`)

**Integration Point:** `Buffer::allocate_impl()` (line 554) and `Buffer::create()` for pre-allocated (line 432)

**What Gets Tracked:**
- ‚úÖ **DRAM Buffers** - User tensors, model weights
- ‚úÖ **L1 Buffers** - Compute core local memory
- ‚úÖ **L1_SMALL Buffers** - Small sharded allocations
- ‚úÖ **TRACE Buffers** - Trace capture regions
- ‚úÖ **Pre-allocated Buffers** - Buffers with fixed addresses (e.g., system buffers)
- ‚úÖ **Hooked Allocations** - Custom allocator-hooked buffers (GraphTracker hooks)
- ‚úÖ **MeshBuffer Device-Local Buffers** - Per-device copies in multi-device setups

**Call Flow:**
```
Python: CreateBuffer(device, size, BufferType.DRAM)
   ‚Üì
Buffer::allocate_impl()
   ‚Üì
Allocator::allocate_buffer()  (allocates from bank manager)
   ‚Üì
GraphTracker::track_allocate(this)
   ‚Üì
AllocationClient::report_allocation(device_id, size, buffer_type, address)
   ‚Üì
AllocationServer: tracks in allocations_ map
```

**Deallocation:**
```
del buffer (Python)
   ‚Üì
Buffer::deallocate()
   ‚Üì
GraphTracker::track_deallocate(this)
   ‚Üì
AllocationClient::report_deallocation(device_id, buffer_id)
```

---

### 2. **Circular Buffer Tracking** (`tt_metal/impl/program/program.cpp`)

**Integration Point:** `ProgramImpl::allocate_circular_buffers()` (lines 884-909, 939-944)

**What Gets Tracked:**
- ‚úÖ **Locally Allocated CBs** - Per-program circular buffers in L1
- ‚úÖ **Globally Allocated CBs** - Shared circular buffers across programs
- ‚úÖ **Multi-Device CBs** - CBs on MeshDevice (tracked per sub-device)

**Call Flow:**
```
Python: CreateCircularBuffer(program, core_range, size, ...)
   ‚Üì
Program::allocate_circular_buffers(device)  (called before program execution)
   ‚Üì
ProgramImpl::allocate_circular_buffers()  (line 846-949)
   ‚Üì
CircularBufferAllocator::mark_address()  (allocates CB in L1)
   ‚Üì
GraphTracker::track_allocate_cb(core_ranges, addr, size, device)  (line 939)
   ‚Üì
AllocationClient::report_cb_allocation(device_id, total_size, cb_id)
```

**Deallocation:**
```
Program destruction or Program::deallocate_circular_buffers()
   ‚Üì
ProgramImpl::deallocate_circular_buffers()  (line 951-961)
   ‚Üì
GraphTracker::track_deallocate_cb(device)
   ‚Üì
AllocationClient::report_cb_deallocation(device_id, size, cb_id)
```

**Key Detail:** CB size is multiplied by number of cores in the core range:
```cpp
total_size = cb_size * num_cores_in_range
```

---

### 3. **Application Kernel Tracking** (`tt_metal/impl/program/program.cpp`)

**Integration Point:**
- `ProgramImpl::finalize_offsets()` (lines 1776-1821) - Initial compilation
- `ProgramImpl::generate_dispatch_commands()` (lines 1431-1482) - Fast Dispatch first run

**What Gets Tracked:**
- ‚úÖ **Data Movement Kernels** - Reader/Writer kernels
- ‚úÖ **Compute Kernels** - Math operations on Tensix cores
- ‚úÖ **Ethernet Kernels** - Inter-chip communication
- ‚úÖ **Per-Core Binary Sizes** - `binary_size √ó num_cores`

**Call Flow (Initial Compilation):**
```
Program::finalize()
   ‚Üì
ProgramImpl::finalize_offsets()  (line 1748-1841)
   ‚Üì
For each kernel in {data_movement, compute, ethernet}:
   - Get binary_data.size() * sizeof(uint32_t)  (actual binary size)
   - Count total_cores using this->logical_cores()
   - Calculate total_l1 = binary_size * total_cores
   ‚Üì
GraphTracker::track_kernel_load(total_l1, kernel_id, device, KERNEL_TYPE_APP, total_cores)
```

**Call Flow (Fast Dispatch First Run):**
```
Program execution (Fast Dispatch)
   ‚Üì
ProgramImpl::generate_dispatch_commands()  (line 1431-1482)
   ‚Üì
If program not yet cached (first time):
   - Extract binary from program_transfer_info.binary_data
   - Count cores
   - Track kernel load
```

**Tracking Happens ONCE per kernel per program** (not on every execution in Fast Dispatch)

---

### 4. **System Kernel Tracking** (`tt_metal/impl/device/device.cpp`)

**Integration Point:**
- `Device::configure_command_queue_programs()` (line 203-286) - Dispatch kernels
- `Device::configure_fabric()` (line 373-412) - Fabric/Ethernet kernels

**What Gets Tracked:**
- ‚úÖ **Dispatch Kernels** - Prefetch, Dispatch, Dispatch-H kernels (kernel_type=2)
- ‚úÖ **Fabric Kernels** - Ethernet firmware for multi-chip (kernel_type=1)

**Call Flow (Dispatch):**
```
Device::initialize()
   ‚Üì
Device::init_command_queue_device()  (line 283)
   ‚Üì
Device::configure_command_queue_programs()  (line 286)
   ‚Üì
command_queue_program->set_kernel_type(DISPATCH)
   ‚Üì
Program::finalize_offsets()  (sees kernel_type=2)
   ‚Üì
GraphTracker::track_kernel_load(..., kernel_type=2)
```

**Call Flow (Fabric):**
```
Device::initialize()
   ‚Üì
Device::compile_fabric()
   ‚Üì
Device::configure_fabric()  (line 373)
   ‚Üì
fabric_program_->set_kernel_type(FABRIC)  (line 381)
   ‚Üì
Program::finalize_offsets()  (sees kernel_type=1)
   ‚Üì
GraphTracker::track_kernel_load(..., kernel_type=1)
```

---

## üéØ What We Track - Detailed Table

| Type | Integration Point | File Location | Tracked Via | Allocation | Deallocation | Notes |
|------|------------------|---------------|-------------|------------|--------------|-------|
| **DRAM Buffers** | `Buffer::allocate_impl()` | `buffer.cpp:554` | `GraphTracker::track_allocate()` | ‚úÖ Exact | ‚úÖ Exact | User tensors, weights |
| **L1 Buffers** | `Buffer::allocate_impl()` | `buffer.cpp:554` | `GraphTracker::track_allocate()` | ‚úÖ Exact | ‚úÖ Exact | Compute core memory |
| **L1_SMALL Buffers** | `Buffer::allocate_impl()` | `buffer.cpp:554` | `GraphTracker::track_allocate()` | ‚úÖ Exact | ‚úÖ Exact | Sharded allocations |
| **TRACE Buffers** | `Buffer::allocate_impl()` | `buffer.cpp:554` | `GraphTracker::track_allocate()` | ‚úÖ Exact | ‚úÖ Exact | Trace regions |
| **Pre-Allocated Buffers** | `Buffer::create(addr)` | `buffer.cpp:432` | `GraphTracker::track_allocate()` | ‚úÖ Exact | ‚úÖ Exact | System buffers |
| **Circular Buffers** | `Program::allocate_circular_buffers()` | `program.cpp:939` | `GraphTracker::track_allocate_cb()` | ‚úÖ Exact (size √ó cores) | ‚úÖ Exact | L1 circular buffers |
| **Application Kernels** | `Program::finalize_offsets()` | `program.cpp:1814-1819` | `GraphTracker::track_kernel_load()` | ‚úÖ Binary size √ó cores | ‚ùå Not tracked | Data/compute kernels |
| **Application Kernels (FD)** | `Program::generate_dispatch_commands()` | `program.cpp:1456-1471` | `GraphTracker::track_kernel_load()` | ‚úÖ Binary size √ó cores | ‚ùå Not tracked | Fast dispatch first run |
| **Dispatch Kernels** | `Device::configure_command_queue_programs()` | `device.cpp:203, 286` | `GraphTracker::track_kernel_load()` | ‚úÖ Binary size √ó cores | ‚ùå Not tracked | System dispatch |
| **Fabric Kernels** | `Device::configure_fabric()` | `device.cpp:373, 381` | `GraphTracker::track_kernel_load()` | ‚úÖ Binary size √ó cores | ‚ùå Not tracked | Ethernet firmware |

---

## üîÑ Complete Allocation Flow Examples

### Example 1: DRAM Tensor Allocation
```python
# Python
import ttnn
device = ttnn.open_device(0)
tensor = ttnn.from_torch(torch_tensor, device=device, memory_config=ttnn.DRAM_MEMORY_CONFIG)
```

```
TT-Metal Flow:
1. Buffer::allocate_impl() called
2. Allocator::allocate_buffer(BufferType::DRAM) ‚Üí returns address
3. GraphTracker::track_allocate(buffer) ‚Üí reports to AllocationClient
4. AllocationClient::report_allocation(device_id=0, size=X, buffer_type=0, address=Y)
5. Message sent via Unix socket to allocation_server_poc
6. Server updates: device_stats_[0].dram_allocated += size
7. Server stores: allocations_[{0, address}] = {size, type, pid, timestamp}
```

### Example 2: Circular Buffer Allocation
```python
# Python
cb = ttnn.experimental.operations.create_circular_buffer(
    program, core_range, config_dict, num_pages, page_size
)
```

```
TT-Metal Flow:
1. Program::add_circular_buffer() ‚Üí stores CB config
2. Program execution triggers Program::allocate_circular_buffers(device)
3. CircularBufferAllocator::mark_address() ‚Üí assigns L1 address
4. GraphTracker::track_allocate_cb(core_ranges, addr, size, device)
5. Calculate: total_size = cb_size * num_cores_in_range
6. AllocationClient::report_cb_allocation(device_id, total_size, cb_id)
7. Server updates: device_stats_[0].cb_allocated += total_size
```

### Example 3: Application Kernel Load
```python
# Python
program = ttnn.create_program()
kernel = ttnn.create_kernel(program, "my_kernel.cpp", core_range)
ttnn.compile_program(device, program)  # ‚Üê Tracking happens here
```

```
TT-Metal Flow:
1. Program::compile() ‚Üí compiles kernel to binary
2. Program::finalize() ‚Üí ProgramImpl::finalize_offsets()
3. For each kernel:
   - binary_size = program_transfer_info.binary_data.size() * 4
   - total_cores = count_cores_in_range(kernel_group)
   - total_l1 = binary_size * total_cores
4. GraphTracker::track_kernel_load(total_l1, kernel_id, device, 0, total_cores)
5. AllocationClient::report_kernel_load(device_id, total_l1, kernel_id, type=0)
6. Server updates: device_stats_[0].kernel_allocated += total_l1
```

---

## ‚úÖ Capabilities

### Memory Tracking
1. **Cross-Process Tracking**: Sees all allocations across all Python processes
2. **Per-Device Stats**: Separate counters for each device (0-7)
3. **Real-Time Updates**: tt_smi_umd polls every second
4. **Auto-Cleanup**: Dead processes automatically removed every 10s
5. **Multi-Type Tracking**: DRAM, L1, L1_SMALL, TRACE, CB, Kernels all separate
6. **Per-Buffer Tracking**: Each buffer tracked individually with buffer_id
7. **Reference Counting**: Handles same buffer allocated to multiple devices
8. **Per-Core Kernel Sizes**: Kernels tracked as `binary_size √ó num_cores`
9. **Hooked Allocation Support**: Works with GraphTracker custom allocators
10. **MeshDevice Support**: Tracks per-device allocations in multi-device setups

### DRAM/L1 Buffer Specifics
- **Tracked at Buffer level**: `GraphTracker::track_allocate()` in `buffer.cpp`
- **Includes all buffer types**: Regular, interleaved, sharded buffers
- **Tracks deallocations**: Subtracts from total when buffer is freed
- **Shows per-process**: Can see which PID owns which buffers
- **Handles pre-allocated**: System buffers with fixed addresses tracked
- **Exact accounting**: Reports actual allocated size, not requested size

### Circular Buffer Specifics
- **Tracked at Program level**: `allocate_circular_buffers()` in `program.cpp`
- **Per-core accounting**: `total_size = cb_size √ó num_cores`
- **Handles overlapping ranges**: Correctly counts CBs on intersecting core ranges
- **Globally allocated CBs**: Tracks both local and global CBs
- **Deallocation on program end**: CBs freed when program is destroyed

### Kernel Tracking Specifics
- **Tracked at compile time**: `finalize_offsets()` and `generate_dispatch_commands()`
- **Per-core binary size**: `total_l1 = binary_size √ó num_cores`
- **Three kernel types**: Application (0), Fabric (1), Dispatch (2)
- **One-time tracking**: Kernels tracked once per program (not per execution)
- **Fast Dispatch support**: Tracks on first `generate_dispatch_commands()` call

### Telemetry & Graphs (in tt_smi_umd)
11. **Direct UMD Access**: Reads firmware telemetry independently of allocation server
12. **Real-Time Graphs**: View 2 shows memory and telemetry history (60 seconds)
13. **Multiple Views**:
   - **View 1**: Main view (nvidia-smi style) - memory breakdown
   - **View 2**: Charts view - DRAM/L1 usage graphs with temperature/clock
   - **View 3**: Detailed telemetry - all sensor values

---

## ‚ö†Ô∏è Limitations

### **DRAM/L1 Buffer Limitations**
1. **System Buffers Pre-allocated Before Tracking**: Firmware buffers allocated during device init not visible
2. **Requires Server**: Tracking only works if `allocation_server_poc` is running
3. **Tracking Overhead**: Small socket send overhead per allocation (~1-5 Œºs)
4. **Process Death Cleanup**: Dead process buffers cleaned up every 10s (not immediate)

### **Kernel Tracking Limitation** (Important!)

**What we report**: Cumulative binary sizes across all cores
```
Example: 10 programs √ó 50KB each √ó 5 cores = 2.5 MB "kernel allocated"
```

**Reality**: Kernels use a **ring buffer cache** in L1:
- Ring buffer size: **~67 KB** (fixed per dispatch core)
- Only most recent programs cached
- Old kernels evicted automatically
- Shared across all programs

**Why the mismatch?**
- We track when kernels are **compiled** (total binary size)
- We **cannot** track when they're evicted from ring buffer
- Ring buffer is managed by hardware dispatch core
- Querying ring buffer state requires opening device (fails if in use)
- **Deallocation not tracked**: No way to know when kernel is evicted

### Other Limitations

3. **Protocol Must Match**: Client and server must use same message format (128 bytes)
4. **Socket Blocking**: Burst allocations can block if socket buffer fills
5. **Telemetry Requires Device Access**: Can't read telemetry if device is exclusively locked

---

## üîß How to Use

### Start Server (Required for memory tracking)
```bash
./build/programming_examples/allocation_server_poc &
```

### Enable Tracking in Application
```bash
export TT_ALLOC_TRACKING_ENABLED=1
python your_model.py
```

### Monitor
```bash
# Watch mode with 1 second refresh
./build/programming_examples/tt_smi_umd -w -r 1000

# In watch mode:
# Press '1' for main view (memory breakdown)
# Press '2' for charts view (graphs with telemetry)
# Press '3' for detailed telemetry
# Press 'q' to quit
```

---

## üìä What tt_smi_umd Shows

### View 1: Main View (Memory Breakdown)
```
Device 0: Blackhole (31GB DRAM, 306MB L1)  75¬∞C  1000MHz
Memory Breakdown:
  DRAM:       13.4 GB / 31.0 GB  [==========>        ] 43.2%
              ‚Üë Tracked via GraphTracker::track_allocate() in buffer.cpp

  L1 Memory:  1.2 MB  / 306.0 MB [                   ] 0.4%
    Buffers:  0.8 MB     ‚Üê Tracked via GraphTracker::track_allocate()
    CBs:      0.3 MB     ‚Üê Tracked via GraphTracker::track_allocate_cb()
    Kernels:  0.1 MB     ‚Üê Tracked via GraphTracker::track_kernel_load()
```

### View 2: Charts View (Graphs)
```
Device 0 [Blackhole] TEMP  75C CLK 1000MHz
DRAM[||||||||||               43.2%  13.4GB/31.0GB]
  L1[|||                       0.4%]
  +------------------------------------------------------------+
100|                                             ..*..         |
 80|                                         ...*    *         |
 60|                               .....*****           *      |
 40|                      ...*****                       **    |
 20|         .......*****                                  **  |
  0|....*****                                                **|
    +------------------------------------------------------------+
      ‚Üê 60s history    Green=DRAM  Cyan=L1
```

---

## üéØ Summary

**Good for**:
- ‚úÖ Tracking **all application DRAM allocations** (buffers, tensors) - **100% accurate**
- ‚úÖ Tracking **all application L1 allocations** (buffers, CBs) - **100% accurate**
- ‚úÖ Real-time telemetry monitoring (temp, clocks, power)
- ‚úÖ Visual graphs of memory and telemetry trends
- ‚úÖ Works during active workload execution
- ‚úÖ Cross-process visibility (see all Python processes)
- ‚úÖ Handles complex scenarios (MeshDevice, hooked allocators, pre-allocated buffers)

**Not good for**:
- ‚ùå System/firmware DRAM allocations (pre-allocated during init, not tracked)
- ‚ùå Exact L1 kernel footprint (ring buffer size limits this, no deallocation tracking)
- ‚ùå Telemetry when device is exclusively locked
- ‚ùå Instant cleanup on process crash (10s delay)

**Best practice**:
- Always start `allocation_server_poc` before running workloads
- Run `tt_smi_umd` in watch mode during model training/inference
- Use View 2 (charts) to see DRAM/L1 trends over time
- **DRAM and L1 buffer numbers are accurate** - trust them for OOM debugging
- **CB numbers are accurate** - exact per-core accounting
- **Kernel numbers are cumulative estimates** - use as relative indicator, not absolute L1 usage
