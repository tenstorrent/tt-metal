training_config:
  batch_size: 128
  logging_interval: 50
  num_epochs: 10
  learning_rate: 0.1
  momentum: 0.9
  weight_decay: 0.0
  is_eval: false
  model_save_interval: 500
  model_path: "/tmp/mnist_mlp.msgpack"
  mlp_config:
    input_features: 784
    hidden_features: [128, 128]
    output_features: 10
