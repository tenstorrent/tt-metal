{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7a20c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tokenizers safetensors\n",
    "\n",
    "import os, sys, math, random, textwrap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "from transformers import GPT2Tokenizer\n",
    "from yaml import safe_load, Loader\n",
    "\n",
    "sys.path.append(f\"{os.environ['TT_METAL_HOME']}/tt-train/build/sources/ttml\")\n",
    "import _ttml as ttml\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "set_seed()\n",
    "# Change working directory to TT_METAL_HOME\n",
    "os.chdir(os.environ['TT_METAL_HOME'])\n",
    "\n",
    "@dataclass\n",
    "class TransformerConfig:\n",
    "    n_head: int = 12\n",
    "    embed_dim: int = 768\n",
    "    dropout: float = 0.2\n",
    "    n_blocks : int = 12\n",
    "    vocab_size: int = 96\n",
    "    max_seq_len: int = 1024\n",
    "    runner_type: str = \"memory_efficient\"\n",
    "    weight_tying: str = \"enabled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea71a9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/tt-metal\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "print(os.getcwd())\n",
    "transformer_cfg = safe_load(open(\"tt-train/configs/training_shakespeare_gpt2s.yaml\", \"r\"))[\"training_config\"][\"transformer_config\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26b353af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_causal_mask(T: int) -> np.ndarray:\n",
    "    # [1,1,T,T] float32 with 1s for allowed positions (i >= j), else 0\n",
    "    m = np.tril(np.ones((T, T), dtype=np.float32))\n",
    "    return m.reshape(1, 1, T, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd89028f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer configuration:\n",
      "    Vocab size: 50257\n",
      "    Max sequence length: 1024\n",
      "    Embedding dim: 768\n",
      "    Num heads: 12\n",
      "    Dropout probability: 0.2\n",
      "    Num blocks: 12\n",
      "    Positional embedding type: Trainable\n",
      "    Runner type: Default\n",
      "    Composite layernorm: false\n",
      "    Weight tying: Disabled\n",
      "2025-09-26 22:17:28.744 | info     |          Device | Opening user mode device driver (tt_cluster.cpp:188)\n",
      "2025-09-26 22:17:28.795 | info     |   SiliconDriver | Harvesting mask for chip 0 is 0x80 (NOC0: 0x80, simulated harvesting mask: 0x0). (cluster.cpp:400)\n",
      "2025-09-26 22:17:28.832 | warning  |   SiliconDriver | init_detect_tt_device_numanodes(): Could not determine NumaNodeSet for TT device (physical_device_id: 0 pci_bus_id: 0000:04:00.0) (cpuset_lib.cpp:578)\n",
      "2025-09-26 22:17:28.832 | warning  |   SiliconDriver | Could not find NumaNodeSet for TT Device (physical_device_id: 0 pci_bus_id: 0000:04:00.0) (cpuset_lib.cpp:182)\n",
      "2025-09-26 22:17:28.833 | warning  |   SiliconDriver | bind_area_memory_nodeset(): Unable to determine TT Device to NumaNode mapping for physical_device_id: 0. Skipping membind. (cpuset_lib.cpp:463)\n",
      "2025-09-26 22:17:28.833 | warning  |   SiliconDriver | ---- ttSiliconDevice::init_hugepage: bind_area_to_memory_nodeset() failed (physical_device_id: 0 ch: 0). Hugepage allocation is not on NumaNode matching TT Device. Side-Effect is decreased Device->Host perf (Issue #893). (sysmem_manager.cpp:214)\n",
      "2025-09-26 22:17:28.833 | info     |   SiliconDriver | Opening local chip ids/PCIe ids: {0}/[0] and remote chip ids {} (cluster.cpp:249)\n",
      "2025-09-26 22:17:28.833 | info     |   SiliconDriver | All devices in cluster running firmware version: 18.10.0 (cluster.cpp:229)\n",
      "2025-09-26 22:17:28.833 | info     |   SiliconDriver | IOMMU: disabled (cluster.cpp:173)\n",
      "2025-09-26 22:17:28.833 | info     |   SiliconDriver | KMD version: 2.4.0 (cluster.cpp:176)\n",
      "2025-09-26 22:17:28.833 | info     |   SiliconDriver | Software version 6.0.0, Ethernet FW version 7.0.0 (Device 0) (cluster.cpp:1059)\n",
      "2025-09-26 22:17:28.836 | info     |   SiliconDriver | Pinning pages for Hugepage: virtual address 0x7f4e40000000 and size 0x40000000 pinned to physical address 0x240000000 (pci_device.cpp:612)\n",
      "2025-09-26 22:17:28.856 | info     |       Inspector | Inspector RPC server listening on localhost:50051 (rpc_server_controller.cpp:85)\n",
      "2025-09-26 22:17:30.354 | info     |           Metal | DPRINT enabled on device 0, worker core (x=0,y=0) (virtual (x=18,y=18)). (dprint_server.cpp:726)\n",
      "2025-09-26 22:17:30.354 | info     |           Metal | DPRINT Server attached device 0 (dprint_server.cpp:773)\n"
     ]
    }
   ],
   "source": [
    "def create_model(cfg, vocab_size: int, seq_len: int):\n",
    "    # GPT2 config via your bindings\n",
    "    gcfg = ttml.models.gpt2.GPT2TransformerConfig()\n",
    "    gcfg.num_heads = cfg[\"num_heads\"]\n",
    "    gcfg.embedding_dim = cfg[\"embedding_dim\"]\n",
    "    gcfg.num_blocks = cfg[\"num_blocks\"]\n",
    "    gcfg.vocab_size = int(vocab_size)\n",
    "    gcfg.max_sequence_length = seq_len\n",
    "    gcfg.dropout_prob = cfg[\"dropout_prob\"]\n",
    "    # optional flags exist (runner_type, weight_tying, positional_embedding_type, experimental, ...)\n",
    "    # we keep defaults for a minimal demo\n",
    "\n",
    "    model = ttml.models.gpt2.create_gpt2_model(gcfg)\n",
    "\n",
    "vocab_size = tokenizer.vocab_size\n",
    "model = create_model(transformer_cfg, vocab_size, transformer_cfg[\"max_sequence_length\"])\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8beb647",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'AutoContext' has no attribute 'GradientMode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ttml\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mAutoContext\u001b[38;5;241m.\u001b[39mset_gradient_mode(\u001b[43mttml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAutoContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGradientMode\u001b[49m\u001b[38;5;241m.\u001b[39mDISABLED)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m      4\u001b[0m     ttml\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39msample\u001b[38;5;241m.\u001b[39msample_op()\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'AutoContext' has no attribute 'GradientMode'"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    logits = model()\n",
    "    ttml.ops.sample.sample_op()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
