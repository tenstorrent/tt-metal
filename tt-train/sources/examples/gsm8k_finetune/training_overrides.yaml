training_config:
  batch_size: 4
  max_steps: 1000
  learning_rate: 0.0003
  gradient_accumulation_steps: 1
  eval_every: 100
  transformer_config:
    max_sequence_length: 512

scheduler_config:
  warmup_steps: 20
