<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Running a Simple CNN Inference on CIFAR-10 &mdash; TT-NN  documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/tt_theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/nbsphinx-code-cells.css" type="text/css" />
    <link rel="shortcut icon" href="../../../_static/favicon.png"/>
    <link rel="canonical" href="/tt-metal/latest/ttnn/ttnn/tutorials/2025_dx_rework/ttnn_simplecnn_inference.html" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js?v=b3ba4146"></script>
        <script src="../../../_static/doctools.js?v=888ff710"></script>
        <script src="../../../_static/sphinx_highlight.js?v=4825356b"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <script src="../../../_static/posthog.js?v=aa5946f9"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Building CLIP Model for Zero-Shot Image Classification with TT-NN" href="ttnn_clip_zero_shot_classification.html" />
    <link rel="prev" title="Basic Convolution" href="ttnn_basic_conv.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >



<a href="https://docs.tenstorrent.com/">
    <img src="../../../_static/tt_logo.svg" class="logo" alt="Logo"/>
</a>

<a href="../../../index.html">
    TT-NN
</a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">TTNN</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../about.html">What is TT-NN?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../get_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../installing.html">Install</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage.html">Using TT-NN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tensor.html">Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api.html">APIs</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../tutorials.html">Tutorials</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="ttnn_add_tensors.html">Add Tensors</a></li>
<li class="toctree-l2"><a class="reference internal" href="ttnn_basic_operations.html">Basic Tensor Operations</a></li>
<li class="toctree-l2"><a class="reference internal" href="ttnn_mlp_inference_mnist.html">MLP Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="ttnn_multihead_attention.html">Multi-Head Attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="ttnn_basic_conv.html">Basic Convolution</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Running a Simple CNN Inference on CIFAR-10</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Setup-and-Imports">Setup and Imports</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Open-the-Device">Open the Device</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Load-the-CIFAR-10-Dataset">Load the CIFAR-10 Dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Load-or-Initialize-Weights">Load or Initialize Weights</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Define-Convolution-and-Pooling-Stage">Define Convolution and Pooling Stage</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Run-Inference-on-Test-Samples">Run Inference on Test Samples</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Close-the-Device">Close the Device</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Full-Example-and-Output">Full Example and Output</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="ttnn_clip_zero_shot_classification.html">Building CLIP Model for Zero-Shot Image Classification with TT-NN</a></li>
<li class="toctree-l2"><a class="reference internal" href="ttnn_visualizer.html">TT-NN Visualizer</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../onboarding.html">Onboarding New Functionality</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../converting_torch_model_to_ttnn.html">Converting PyTorch Model to TT-NN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../adding_new_ttnn_operation.html">Adding New TT-NN Operation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../profiling_ttnn_operations.html">Profiling TT-NN Operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../demos.html">Building and Uplifting Demos</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Resources</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../resources/support.html">Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../resources/contributing.html">Contributing as a developer</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">TT-NN</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../tutorials.html">Tutorials</a></li>
      <li class="breadcrumb-item active">Running a Simple CNN Inference on CIFAR-10</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/ttnn/tutorials/2025_dx_rework/ttnn_simplecnn_inference.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="Running-a-Simple-CNN-Inference-on-CIFAR-10">
<h1>Running a Simple CNN Inference on CIFAR-10<a class="headerlink" href="#Running-a-Simple-CNN-Inference-on-CIFAR-10" title="Permalink to this heading"></a>
</h1>
<p>This tutorial demonstrates how to use <strong>TT-NN</strong> to perform inference with a simple Convolutional Neural Network (CNN) on the CIFAR-10 dataset.</p>
<p>We will:</p>
<ul class="simple">
<li><p>Load the CIFAR-10 dataset.</p></li>
<li><p>Define a simple CNN using TT-NN operations.</p></li>
<li><p>Run inference on sample images.</p></li>
<li><p>Observe outputs and accuracy.</p></li>
</ul>
<section id="Setup-and-Imports">
<h2>Setup and Imports<a class="headerlink" href="#Setup-and-Imports" title="Permalink to this heading"></a>
</h2>
<p>In this script, several libraries are imported to support image classification using a simple CNN on the CIFAR-10 dataset. The OS module checks if pretrained weight files exist on disk. Torch loads model weights, torchvision and its transforms submodule downloads the CIFAR-10 dataset and applies preprocessing, converting images to tensors and normalizing pixel values for example. The TT-NN library is Tenstorrent’s neural network API, responsible for interfacing with Tenstorrent hardware. TT-NN
performs operations like convolution, pooling, activation, linear layers, data layout management, and type conversions between PyTorch and TT-NN formats. Finally, loguru logs messages and debugging output, providing insights into model operations and predictions throughout the inference process.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate">
<div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate">
<div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torchvision</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torchvision.transforms</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">transforms</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">ttnn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">loguru</span><span class="w"> </span><span class="kn">import</span> <span class="n">logger</span>
</pre></div>
</div>
</div>
</section>
<section id="Open-the-Device">
<h2>Open the Device<a class="headerlink" href="#Open-the-Device" title="Permalink to this heading"></a>
</h2>
<p>Create the device to run the program with custom L1 memory config. The following parameter allocates on-chip L1 memory for sliding-window operations like convolutions, and other kernels that need quick, scratchpad-like memory: <code class="docutils literal notranslate"><span class="pre">l1_small_size</span></code>. 8 kB is enough for simple CNNS, complex models require up to 32 kB or more.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate">
<div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate">
<div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">open_device</span><span class="p">(</span><span class="n">device_id</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">l1_small_size</span><span class="o">=</span><span class="mi">8192</span><span class="p">)</span>
<span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">--- Simple CNN Inference Using TT-NN on CIFAR-10 ---"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Load-the-CIFAR-10-Dataset">
<h2>Load the CIFAR-10 Dataset<a class="headerlink" href="#Load-the-CIFAR-10-Dataset" title="Permalink to this heading"></a>
</h2>
<p>Normalize images and load the test set.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate">
<div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate">
<div class="highlight"><pre><span></span><span class="c1"># Define input transforms: Convert to tensor and normalize</span>
<span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))])</span>

<span class="c1"># Load CIFAR-10 test data</span>
<span class="n">testset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s2">"./data"</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
<span class="n">testloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">testset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Load-or-Initialize-Weights">
<h2>Load or Initialize Weights<a class="headerlink" href="#Load-or-Initialize-Weights" title="Permalink to this heading"></a>
</h2>
<p>Optimally, pretrained weights are loaded and used for the model, but in case the weights file is not found, default to random values which will likely yield poor results. Run the provided <code class="docutils literal notranslate"><span class="pre">train_and_export_cnn.py</span></code> script to generate weights to a file named <code class="docutils literal notranslate"><span class="pre">simple_cnn_cifar10_weights.pt</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate">
<div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate">
<div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="s2">"simple_cnn_cifar10_weights.pt"</span><span class="p">):</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"simple_cnn_cifar10_weights.pt"</span><span class="p">)</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">k</span><span class="p">:</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">from_torch</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">ROW_MAJOR_LAYOUT</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">weights</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
    <span class="p">}</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"Loaded pretrained weights"</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">"Weights not found, using random weights"</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">"conv1.weight"</span><span class="p">:</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">16</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">layout</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">ROW_MAJOR_LAYOUT</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span>
        <span class="s2">"conv1.bias"</span><span class="p">:</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">16</span><span class="p">,),</span> <span class="n">layout</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">ROW_MAJOR_LAYOUT</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span>
        <span class="s2">"conv2.weight"</span><span class="p">:</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">32</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">layout</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">ROW_MAJOR_LAYOUT</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span>
        <span class="s2">"conv2.bias"</span><span class="p">:</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">32</span><span class="p">,),</span> <span class="n">layout</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">ROW_MAJOR_LAYOUT</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span>
        <span class="s2">"fc1.weight"</span><span class="p">:</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">128</span><span class="p">,</span> <span class="mi">2048</span><span class="p">),</span> <span class="n">layout</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">ROW_MAJOR_LAYOUT</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span>
        <span class="s2">"fc1.bias"</span><span class="p">:</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">128</span><span class="p">,),</span> <span class="n">layout</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">ROW_MAJOR_LAYOUT</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span>
        <span class="s2">"fc2.weight"</span><span class="p">:</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="n">layout</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">ROW_MAJOR_LAYOUT</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span>
        <span class="s2">"fc2.bias"</span><span class="p">:</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">10</span><span class="p">,),</span> <span class="n">layout</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">ROW_MAJOR_LAYOUT</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span>
    <span class="p">}</span>
</pre></div>
</div>
</div>
</section>
<section id="Define-Convolution-and-Pooling-Stage">
<h2>Define Convolution and Pooling Stage<a class="headerlink" href="#Define-Convolution-and-Pooling-Stage" title="Permalink to this heading"></a>
</h2>
<p>The function, <code class="docutils literal notranslate"><span class="pre">conv_pool_stage</span></code>, encapsulates a typical convolutional neural network stage where an input tensor undergoes a 2D convolution followed by an activation and a max pooling operation, all using Tenstorrent’s TT-NN API. It accepts an input tensor in NHWC layout, along with metadata like shape, number of output channels, references to specific weight and bias tensors, activation type (e.g., ReLU), and the target hardware device. First, it extracts the appropriate weight and bias
tensors from the given dictionary and reshapes the bias to a broadcastable shape. It defines convolution parameters—kernel sizegur, stride, and padding. It sets up a TT-NN specific configuration including the activation function. If enabled, it logs details like tensor shapes and convolution parameters for debugging the first sample. The convolution is then performed using <code class="docutils literal notranslate"><span class="pre">ttnn.conv2d</span></code>, followed by a max pooling operation configured with standard 2×2 kernel and stride values. Again, if
logging is enabled, pooling parameters and resulting tensor shapes are recorded. Finally, the resulting TT tensor after max pooling is returned for use in the next stage of the network. This function modularizes a common pattern in CNNs and provides flexibility for different layers and debug logging.</p>
<p>For more information on convolution functions see: <a class="reference internal" href="../../api/ttnn.Conv2dConfig.html"><span class="doc">ttnn.Conv2dConfig</span></a>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate">
<div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate">
<div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">conv_pool_stage</span><span class="p">(</span>
    <span class="n">input_tensor</span><span class="p">:</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">input_NHWC</span><span class="p">:</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">Shape</span><span class="p">,</span>
    <span class="n">conv_outchannels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">weights</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
    <span class="n">weight_str</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">bias_str</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">activation</span><span class="p">:</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">UnaryWithParam</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">Device</span><span class="p">,</span>
    <span class="n">log_first_sample</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Perform convolution + activation + max pooling using TT-NN.</span>
<span class="sd">    Args:</span>
<span class="sd">        input_tensor: Input TT tensor in NHWC format.</span>
<span class="sd">        input_NHWC: Tuple representing (Batch, Height, Width, Channels) of the input tensor.</span>
<span class="sd">        conv_outchannels: Number of output channels for the convolution layer.</span>
<span class="sd">        weights: Dictionary containing model weights and biases.</span>
<span class="sd">        weight_str: Key name for convolution weights in the weights dict.</span>
<span class="sd">        bias_str: Key name for convolution biases in the weights dict.</span>
<span class="sd">        activation: Activation function as UnaryWithParam to apply after conv.</span>
<span class="sd">        device: Target TT device to execute the operations on.</span>
<span class="sd">        log_first_sample: Whether to log detailed info (used for debugging first sample).</span>
<span class="sd">    Returns:</span>
<span class="sd">        Output tensor after conv + max pooling (TT format).</span>
<span class="sd">    """</span>
    <span class="c1"># Extract weight and bias tensors from weights dictionary</span>
    <span class="n">W</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="n">weight_str</span><span class="p">]</span>
    <span class="n">B</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="n">bias_str</span><span class="p">]</span>
    <span class="n">B</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>  <span class="c1"># Ensure bias is in correct shape for TT-NN</span>

    <span class="c1"># Define convolution parameters</span>
    <span class="n">conv_kernel_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="n">conv_stride</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">conv_padding</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Set up TT-NN convolution configuration including activation function</span>
    <span class="n">conv_config</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">Conv2dConfig</span><span class="p">(</span><span class="n">weights_dtype</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">)</span>

    <span class="c1"># Optional detailed logging for the first sample (shape, config, etc.)</span>
    <span class="k">if</span> <span class="n">log_first_sample</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"====================================================================="</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"Input parameters to conv2d:"</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  input_tensor shape: </span><span class="si">{</span><span class="n">input_tensor</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  weight_tensor shape: </span><span class="si">{</span><span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  bias_tensor shape: </span><span class="si">{</span><span class="n">B</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  in_channels: </span><span class="si">{</span><span class="n">input_NHWC</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  out_channels: </span><span class="si">{</span><span class="n">conv_outchannels</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  device: </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  kernel_size: </span><span class="si">{</span><span class="n">conv_kernel_size</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  stride: </span><span class="si">{</span><span class="n">conv_stride</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  padding: </span><span class="si">{</span><span class="n">conv_padding</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  batch_size: </span><span class="si">{</span><span class="n">input_NHWC</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  input_height: </span><span class="si">{</span><span class="n">input_NHWC</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  input_width: </span><span class="si">{</span><span class="n">input_NHWC</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  conv_config: </span><span class="si">{</span><span class="n">conv_config</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  groups: </span><span class="si">{</span><span class="mi">0</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

    <span class="c1"># Perform convolution</span>
    <span class="n">conv1_out</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span>
        <span class="n">input_tensor</span><span class="o">=</span><span class="n">input_tensor</span><span class="p">,</span>
        <span class="n">weight_tensor</span><span class="o">=</span><span class="n">W</span><span class="p">,</span>
        <span class="n">bias_tensor</span><span class="o">=</span><span class="n">B</span><span class="p">,</span>
        <span class="n">in_channels</span><span class="o">=</span><span class="n">input_NHWC</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span>
        <span class="n">out_channels</span><span class="o">=</span><span class="n">conv_outchannels</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
        <span class="n">kernel_size</span><span class="o">=</span><span class="n">conv_kernel_size</span><span class="p">,</span>
        <span class="n">stride</span><span class="o">=</span><span class="n">conv_stride</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="n">conv_padding</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">input_NHWC</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
        <span class="n">input_height</span><span class="o">=</span><span class="n">input_NHWC</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
        <span class="n">input_width</span><span class="o">=</span><span class="n">input_NHWC</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
        <span class="n">conv_config</span><span class="o">=</span><span class="n">conv_config</span><span class="p">,</span>
        <span class="n">groups</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Define max pooling parameters</span>
    <span class="n">max_pool2d_kernel_size</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
    <span class="n">max_pool2d_stride</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
    <span class="n">max_pool2d_padding</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">max_pool2d_dilation</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>

    <span class="c1"># Optional logging for max pooling input and parameters</span>
    <span class="k">if</span> <span class="n">log_first_sample</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"Input parameters to max_pool2d:"</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  input shape: </span><span class="si">{</span><span class="n">conv1_out</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  batch_size: </span><span class="si">{</span><span class="n">input_NHWC</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  input_h: </span><span class="si">{</span><span class="n">input_NHWC</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  input_w: </span><span class="si">{</span><span class="n">input_NHWC</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  channels: </span><span class="si">{</span><span class="n">conv_outchannels</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  kernel_size: </span><span class="si">{</span><span class="n">max_pool2d_kernel_size</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  stride: </span><span class="si">{</span><span class="n">max_pool2d_stride</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  padding: </span><span class="si">{</span><span class="n">max_pool2d_padding</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  dilation: </span><span class="si">{</span><span class="n">max_pool2d_dilation</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  ceil_mode: </span><span class="si">{</span><span class="kc">False</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

    <span class="c1"># Perform max pooling</span>
    <span class="n">max_pool2d_out</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span>
        <span class="n">conv1_out</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">input_NHWC</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
        <span class="n">input_h</span><span class="o">=</span><span class="n">input_NHWC</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
        <span class="n">input_w</span><span class="o">=</span><span class="n">input_NHWC</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
        <span class="n">channels</span><span class="o">=</span><span class="n">conv_outchannels</span><span class="p">,</span>
        <span class="n">kernel_size</span><span class="o">=</span><span class="n">max_pool2d_kernel_size</span><span class="p">,</span>
        <span class="n">stride</span><span class="o">=</span><span class="n">max_pool2d_stride</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="n">max_pool2d_padding</span><span class="p">,</span>
        <span class="n">dilation</span><span class="o">=</span><span class="n">max_pool2d_dilation</span><span class="p">,</span>
        <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Log output shape after pooling</span>
    <span class="k">if</span> <span class="n">log_first_sample</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"max_pool2d output shape: </span><span class="si">{</span><span class="n">max_pool2d_out</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"====================================================================="</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">max_pool2d_out</span>
</pre></div>
</div>
</div>
</section>
<section id="Run-Inference-on-Test-Samples">
<h2>Run Inference on Test Samples<a class="headerlink" href="#Run-Inference-on-Test-Samples" title="Permalink to this heading"></a>
</h2>
<p>This code sample performs inference on the first five test samples from the CIFAR-10 dataset using a simple convolutional neural network (SimpleCNN) running on Tenstorrent hardware via the TT-NN API. It initializes counters tracking correct predictions and total samples processed. For each sample, it converts the input image from a PyTorch tensor to a TT-NN tensor, rearranging its layout from NCHW to NHWC format. The image is then passed through two convolution and pooling stages using the
<code class="docutils literal notranslate"><span class="pre">conv_pool_stage</span></code> function. The output is flattened and passed through two fully connected layers (FC1 and FC2), with ReLU applied after FC1. The weights and biases for these layers are converted to the appropriate TT-NN format with tiling and transposing as needed. After obtaining the final logits from FC2, the output is converted back to a PyTorch tensor, and the predicted label is determined by taking the index of the highest logit. The prediction is compared to the true label to update the
accuracy counters, and the result for each sample is logged. Finally, the overall inference accuracy is printed after processing the five samples.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate">
<div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate">
<div class="highlight"><pre><span></span><span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>

<span class="c1"># Run inference on a few test samples</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">testloader</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="mi">5</span><span class="p">:</span>
        <span class="k">break</span>

    <span class="c1"># Convert image to TT tensor</span>
    <span class="n">ttnn_image</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">from_torch</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">ROW_MAJOR_LAYOUT</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">ttnn_image_permuated</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="n">ttnn_image</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>  <span class="c1"># NCHW -&gt; NHWC</span>

    <span class="c1"># Only log details for first sample</span>
    <span class="n">log_this</span> <span class="o">=</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span>

    <span class="c1"># Apply first conv + pool stage</span>
    <span class="n">conv1_pool</span> <span class="o">=</span> <span class="n">conv_pool_stage</span><span class="p">(</span>
        <span class="n">ttnn_image_permuated</span><span class="p">,</span>
        <span class="n">ttnn_image_permuated</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
        <span class="mi">16</span><span class="p">,</span>
        <span class="n">weights</span><span class="p">,</span>
        <span class="s2">"conv1.weight"</span><span class="p">,</span>
        <span class="s2">"conv1.bias"</span><span class="p">,</span>
        <span class="n">ttnn</span><span class="o">.</span><span class="n">UnaryWithParam</span><span class="p">(</span><span class="n">ttnn</span><span class="o">.</span><span class="n">UnaryOpType</span><span class="o">.</span><span class="n">RELU</span><span class="p">),</span>
        <span class="n">device</span><span class="p">,</span>
        <span class="n">log_first_sample</span><span class="o">=</span><span class="n">log_this</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Apply second conv + pool stage</span>
    <span class="n">conv2_pool</span> <span class="o">=</span> <span class="n">conv_pool_stage</span><span class="p">(</span>
        <span class="n">conv1_pool</span><span class="p">,</span>
        <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span>
        <span class="mi">32</span><span class="p">,</span>
        <span class="n">weights</span><span class="p">,</span>
        <span class="s2">"conv2.weight"</span><span class="p">,</span>
        <span class="s2">"conv2.bias"</span><span class="p">,</span>
        <span class="n">ttnn</span><span class="o">.</span><span class="n">UnaryWithParam</span><span class="p">(</span><span class="n">ttnn</span><span class="o">.</span><span class="n">UnaryOpType</span><span class="o">.</span><span class="n">RELU</span><span class="p">),</span>
        <span class="n">device</span><span class="p">,</span>
        <span class="n">log_first_sample</span><span class="o">=</span><span class="n">log_this</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Flatten for FC layers</span>
    <span class="n">B</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">C</span> <span class="o">=</span> <span class="n">conv2_pool</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">out_flat</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">to_torch</span><span class="p">(</span><span class="n">conv2_pool</span><span class="p">)</span>  <span class="c1"># Convert back to torch</span>
    <span class="n">out_flat</span> <span class="o">=</span> <span class="n">out_flat</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># NHWC -&gt; NCHW -&gt; Flatten</span>

    <span class="c1"># Prepare fully connected layers</span>
    <span class="n">W3</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="s2">"fc1.weight"</span><span class="p">]</span>
    <span class="n">B3</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="s2">"fc1.bias"</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>  <span class="c1"># Reshape bias for broadcast compatibility</span>
    <span class="n">W4</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="s2">"fc2.weight"</span><span class="p">]</span>
    <span class="n">B4</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="s2">"fc2.bias"</span><span class="p">]</span>

    <span class="c1"># Convert to TT format for FC1</span>
    <span class="n">W3_tt</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">to_layout</span><span class="p">(</span><span class="n">ttnn</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">W3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">TILE_LAYOUT</span><span class="p">)</span>
    <span class="n">B3_tt</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">to_layout</span><span class="p">(</span><span class="n">B3</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)),</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">TILE_LAYOUT</span><span class="p">)</span>

    <span class="c1"># Convert input to TT format</span>
    <span class="n">x_tt</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">from_torch</span><span class="p">(</span><span class="n">out_flat</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">TILE_LAYOUT</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># Apply FC1 + ReLU</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x_tt</span><span class="p">,</span> <span class="n">W3_tt</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">B3_tt</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

    <span class="c1"># Convert to TT format for FC2</span>
    <span class="n">W4_tt</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">to_layout</span><span class="p">(</span><span class="n">ttnn</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">W4</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">TILE_LAYOUT</span><span class="p">)</span>
    <span class="n">B4_tt</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">to_layout</span><span class="p">(</span><span class="n">B4</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)),</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">TILE_LAYOUT</span><span class="p">)</span>

    <span class="c1"># Apply FC2 (output logits)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">W4_tt</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">B4_tt</span><span class="p">)</span>

    <span class="c1"># Convert prediction back to torch</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">to_torch</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
    <span class="n">predicted_label</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="n">correct</span> <span class="o">+=</span> <span class="n">predicted_label</span> <span class="o">==</span> <span class="n">label</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="n">total</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Sample </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">: Predicted=</span><span class="si">{</span><span class="n">predicted_label</span><span class="si">}</span><span class="s2">, Actual=</span><span class="si">{</span><span class="n">label</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">TT-NN SimpleCNN Inference Accuracy: </span><span class="si">{</span><span class="n">correct</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">total</span><span class="si">}</span><span class="s2"> = </span><span class="si">{</span><span class="mf">100.0</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">correct</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">total</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Close-the-Device">
<h2>Close the Device<a class="headerlink" href="#Close-the-Device" title="Permalink to this heading"></a>
</h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate">
<div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate">
<div class="highlight"><pre><span></span><span class="n">ttnn</span><span class="o">.</span><span class="n">close_device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>We have built and run a simple CNN using Tenstorrent’s TT-NN library on the CIFAR-10 dataset, observed predictions, and computed accuracy on a few samples.</p>
<p>For full-scale inference or training, pre-trained weights should be used, and additional optimization strategies may be applied.</p>
</section>
<section id="Full-Example-and-Output">
<h2>Full Example and Output<a class="headerlink" href="#Full-Example-and-Output" title="Permalink to this heading"></a>
</h2>
<p>Lets put everything together in a complete example that can be run directly.</p>
<p><a class="reference external" href="https://github.com/tenstorrent/tt-metal/tree/main/ttnn/tutorials/basic_python/ttnn_simplecnn_inference.py">ttnn_simplecnn_inference.py</a></p>
<p>Running this script will generate the following output:</p>
<div class="highlight-console notranslate">
<div class="highlight"><pre><span></span><span class="gp">$ </span>python3<span class="w"> </span><span class="nv">$TT_METAL_HOME</span>/ttnn/tutorials/basic_python/ttnn_simplecnn_inference.py
<span class="go">2025-07-07 13:10:17.041 | info     |   SiliconDriver | Opened PCI device 7; KMD version: 1.34.0; API: 1; IOMMU: disabled (pci_device.cpp:198)</span>
<span class="go">2025-07-07 13:10:17.043 | info     |   SiliconDriver | Opened PCI device 7; KMD version: 1.34.0; API: 1; IOMMU: disabled (pci_device.cpp:198)</span>
<span class="go">2025-07-07 13:10:17.050 | info     |          Device | Opening user mode device driver (tt_cluster.cpp:190)</span>
<span class="go">2025-07-07 13:10:17.050 | info     |   SiliconDriver | Opened PCI device 7; KMD version: 1.34.0; API: 1; IOMMU: disabled (pci_device.cpp:198)</span>
<span class="go">2025-07-07 13:10:17.051 | info     |   SiliconDriver | Opened PCI device 7; KMD version: 1.34.0; API: 1; IOMMU: disabled (pci_device.cpp:198)</span>
<span class="go">2025-07-07 13:10:17.057 | info     |   SiliconDriver | Opened PCI device 7; KMD version: 1.34.0; API: 1; IOMMU: disabled (pci_device.cpp:198)</span>
<span class="go">2025-07-07 13:10:17.058 | info     |   SiliconDriver | Opened PCI device 7; KMD version: 1.34.0; API: 1; IOMMU: disabled (pci_device.cpp:198)</span>
<span class="go">2025-07-07 13:10:17.064 | info     |   SiliconDriver | Harvesting mask for chip 0 is 0x100 (NOC0: 0x100, simulated harvesting mask: 0x0). (cluster.cpp:282)</span>
<span class="go">2025-07-07 13:10:17.161 | info     |   SiliconDriver | Opened PCI device 7; KMD version: 1.34.0; API: 1; IOMMU: disabled (pci_device.cpp:198)</span>
<span class="go">2025-07-07 13:10:17.224 | info     |   SiliconDriver | Opening local chip ids/pci ids: {0}/[7] and remote chip ids {} (cluster.cpp:147)</span>
<span class="go">2025-07-07 13:10:17.235 | info     |   SiliconDriver | Software version 6.0.0, Ethernet FW version 6.14.0 (Device 0) (cluster.cpp:1039)</span>
<span class="go">2025-07-07 13:10:17.321 | info     |           Metal | AI CLK for device 0 is:   1000 MHz (metal_context.cpp:128)</span>
<span class="go">2025-07-07 13:10:17.889 | info     |           Metal | Initializing device 0. Program cache is enabled (device.cpp:428)</span>
<span class="go">2025-07-07 13:10:17.891 | warning  |           Metal | Unable to bind worker thread to CPU Core. May see performance degradation. Error Code: 22 (hardware_command_queue.cpp:74)</span>
<span class="go">2025-07-07 13:10:19.734 | INFO     | __main__:main:15 -</span>
<span class="go">--- Simple CNN Inference Using TT-NN on CIFAR-10 ---</span>
<span class="go">Files already downloaded and verified</span>
<span class="go">2025-07-07 13:10:20.471 | INFO     | __main__:main:30 - Loaded pretrained weights</span>
<span class="go">2025-07-07 13:10:21.075 | INFO     | __main__:conv_pool_stage:86 - =====================================================================</span>
<span class="go">2025-07-07 13:10:21.075 | INFO     | __main__:conv_pool_stage:87 - Input parameters to conv2d:</span>
<span class="go">2025-07-07 13:10:21.075 | INFO     | __main__:conv_pool_stage:88 -   input_tensor shape: Shape([1, 32, 32, 3])</span>
<span class="go">2025-07-07 13:10:21.075 | INFO     | __main__:conv_pool_stage:89 -   weight_tensor shape: Shape([16, 3, 3, 3])</span>
<span class="go">2025-07-07 13:10:21.076 | INFO     | __main__:conv_pool_stage:90 -   bias_tensor shape: Shape([1, 1, 1, 16])</span>
<span class="go">2025-07-07 13:10:21.076 | INFO     | __main__:conv_pool_stage:91 -   in_channels: 3</span>
<span class="go">2025-07-07 13:10:21.076 | INFO     | __main__:conv_pool_stage:92 -   out_channels: 16</span>
<span class="go">2025-07-07 13:10:21.076 | INFO     | __main__:conv_pool_stage:93 -   device: MeshDevice(1x1 grid, 1 devices)</span>
<span class="go">2025-07-07 13:10:21.076 | INFO     | __main__:conv_pool_stage:94 -   kernel_size: (3, 3)</span>
<span class="go">2025-07-07 13:10:21.076 | INFO     | __main__:conv_pool_stage:95 -   stride: (1, 1)</span>
<span class="go">2025-07-07 13:10:21.076 | INFO     | __main__:conv_pool_stage:96 -   padding: (1, 1)</span>
<span class="go">2025-07-07 13:10:21.076 | INFO     | __main__:conv_pool_stage:97 -   batch_size: 1</span>
<span class="go">2025-07-07 13:10:21.076 | INFO     | __main__:conv_pool_stage:98 -   input_height: 32</span>
<span class="go">2025-07-07 13:10:21.076 | INFO     | __main__:conv_pool_stage:99 -   input_width: 32</span>
<span class="go">2025-07-07 13:10:21.076 | INFO     | __main__:conv_pool_stage:100 -   conv_config: Conv2dConfig(weights_dtype=DataType::BFLOAT16,activation=relu,deallocate_activation=0,reallocate_halo_output=1,act_block_h_override=0,act_block_w_div=1,reshard_if_not_optimal=0,override_sharding_config=0,shard_layout=std::nullopt,core_grid=std::nullopt,transpose_shards=0,output_layout=Layout::TILE,enable_act_double_buffer=0,enable_weights_double_buffer=0,enable_split_reader=0,enable_subblock_padding=0,in_place=0,enable_kernel_stride_folding=0)</span>
<span class="go">2025-07-07 13:10:21.076 | INFO     | __main__:conv_pool_stage:101 -   groups: 0</span>
<span class="go">2025-07-07 13:10:22.960 | INFO     | __main__:conv_pool_stage:129 - Input parameters to max_pool2d:</span>
<span class="go">2025-07-07 13:10:22.960 | INFO     | __main__:conv_pool_stage:130 -   input shape: Shape([1, 1, 1024, 16])</span>
<span class="go">2025-07-07 13:10:22.960 | INFO     | __main__:conv_pool_stage:131 -   batch_size: 1</span>
<span class="go">2025-07-07 13:10:22.961 | INFO     | __main__:conv_pool_stage:132 -   input_h: 32</span>
<span class="go">2025-07-07 13:10:22.961 | INFO     | __main__:conv_pool_stage:133 -   input_w: 32</span>
<span class="go">2025-07-07 13:10:22.961 | INFO     | __main__:conv_pool_stage:134 -   channels: 16</span>
<span class="go">2025-07-07 13:10:22.961 | INFO     | __main__:conv_pool_stage:135 -   kernel_size: [2, 2]</span>
<span class="go">2025-07-07 13:10:22.961 | INFO     | __main__:conv_pool_stage:136 -   stride: [2, 2]</span>
<span class="go">2025-07-07 13:10:22.961 | INFO     | __main__:conv_pool_stage:137 -   padding: [0, 0]</span>
<span class="go">2025-07-07 13:10:22.961 | INFO     | __main__:conv_pool_stage:138 -   dilation: [1, 1]</span>
<span class="go">2025-07-07 13:10:22.961 | INFO     | __main__:conv_pool_stage:139 -   ceil_mode: False</span>
<span class="go">2025-07-07 13:10:24.026 | INFO     | __main__:conv_pool_stage:157 - max_pool2d output shape: Shape([1, 1, 256, 32])</span>
<span class="go">2025-07-07 13:10:24.026 | INFO     | __main__:conv_pool_stage:158 - =====================================================================</span>
<span class="go">2025-07-07 13:10:24.026 | INFO     | __main__:conv_pool_stage:86 - =====================================================================</span>
<span class="go">2025-07-07 13:10:24.026 | INFO     | __main__:conv_pool_stage:87 - Input parameters to conv2d:</span>
<span class="go">2025-07-07 13:10:24.026 | INFO     | __main__:conv_pool_stage:88 -   input_tensor shape: Shape([1, 1, 256, 32])</span>
<span class="go">2025-07-07 13:10:24.026 | INFO     | __main__:conv_pool_stage:89 -   weight_tensor shape: Shape([32, 16, 3, 3])</span>
<span class="go">2025-07-07 13:10:24.026 | INFO     | __main__:conv_pool_stage:90 -   bias_tensor shape: Shape([1, 1, 1, 32])</span>
<span class="go">2025-07-07 13:10:24.026 | INFO     | __main__:conv_pool_stage:91 -   in_channels: 16</span>
<span class="go">2025-07-07 13:10:24.026 | INFO     | __main__:conv_pool_stage:92 -   out_channels: 32</span>
<span class="go">2025-07-07 13:10:24.027 | INFO     | __main__:conv_pool_stage:93 -   device: MeshDevice(1x1 grid, 1 devices)</span>
<span class="go">2025-07-07 13:10:24.027 | INFO     | __main__:conv_pool_stage:94 -   kernel_size: (3, 3)</span>
<span class="go">2025-07-07 13:10:24.027 | INFO     | __main__:conv_pool_stage:95 -   stride: (1, 1)</span>
<span class="go">2025-07-07 13:10:24.027 | INFO     | __main__:conv_pool_stage:96 -   padding: (1, 1)</span>
<span class="go">2025-07-07 13:10:24.027 | INFO     | __main__:conv_pool_stage:97 -   batch_size: 1</span>
<span class="go">2025-07-07 13:10:24.027 | INFO     | __main__:conv_pool_stage:98 -   input_height: 16</span>
<span class="go">2025-07-07 13:10:24.027 | INFO     | __main__:conv_pool_stage:99 -   input_width: 16</span>
<span class="go">2025-07-07 13:10:24.027 | INFO     | __main__:conv_pool_stage:100 -   conv_config: Conv2dConfig(weights_dtype=DataType::BFLOAT16,activation=relu,deallocate_activation=0,reallocate_halo_output=1,act_block_h_override=0,act_block_w_div=1,reshard_if_not_optimal=0,override_sharding_config=0,shard_layout=std::nullopt,core_grid=std::nullopt,transpose_shards=0,output_layout=Layout::TILE,enable_act_double_buffer=0,enable_weights_double_buffer=0,enable_split_reader=0,enable_subblock_padding=0,in_place=0,enable_kernel_stride_folding=0)</span>
<span class="go">2025-07-07 13:10:24.027 | INFO     | __main__:conv_pool_stage:101 -   groups: 0</span>
<span class="go">2025-07-07 13:10:25.120 | INFO     | __main__:conv_pool_stage:129 - Input parameters to max_pool2d:</span>
<span class="go">2025-07-07 13:10:25.121 | INFO     | __main__:conv_pool_stage:130 -   input shape: Shape([1, 1, 256, 32])</span>
<span class="go">2025-07-07 13:10:25.121 | INFO     | __main__:conv_pool_stage:131 -   batch_size: 1</span>
<span class="go">2025-07-07 13:10:25.121 | INFO     | __main__:conv_pool_stage:132 -   input_h: 16</span>
<span class="go">2025-07-07 13:10:25.121 | INFO     | __main__:conv_pool_stage:133 -   input_w: 16</span>
<span class="go">2025-07-07 13:10:25.121 | INFO     | __main__:conv_pool_stage:134 -   channels: 32</span>
<span class="go">2025-07-07 13:10:25.121 | INFO     | __main__:conv_pool_stage:135 -   kernel_size: [2, 2]</span>
<span class="go">2025-07-07 13:10:25.121 | INFO     | __main__:conv_pool_stage:136 -   stride: [2, 2]</span>
<span class="go">2025-07-07 13:10:25.121 | INFO     | __main__:conv_pool_stage:137 -   padding: [0, 0]</span>
<span class="go">2025-07-07 13:10:25.121 | INFO     | __main__:conv_pool_stage:138 -   dilation: [1, 1]</span>
<span class="go">2025-07-07 13:10:25.121 | INFO     | __main__:conv_pool_stage:139 -   ceil_mode: False</span>
<span class="go">2025-07-07 13:10:25.669 | INFO     | __main__:conv_pool_stage:157 - max_pool2d output shape: Shape([1, 1, 64, 32])</span>
<span class="go">2025-07-07 13:10:25.669 | INFO     | __main__:conv_pool_stage:158 - =====================================================================</span>
<span class="go">2025-07-07 13:10:30.120 | INFO     | __main__:main:238 - Sample 1: Predicted=8, Actual=3</span>
<span class="go">2025-07-07 13:10:30.136 | INFO     | __main__:main:238 - Sample 2: Predicted=8, Actual=8</span>
<span class="go">2025-07-07 13:10:30.151 | INFO     | __main__:main:238 - Sample 3: Predicted=8, Actual=8</span>
<span class="go">2025-07-07 13:10:30.166 | INFO     | __main__:main:238 - Sample 4: Predicted=0, Actual=0</span>
<span class="go">2025-07-07 13:10:30.181 | INFO     | __main__:main:238 - Sample 5: Predicted=6, Actual=6</span>
<span class="go">2025-07-07 13:10:30.181 | INFO     | __main__:main:240 -</span>
<span class="go">TT-NN SimpleCNN Inference Accuracy: 4/5 = 80.00%</span>
<span class="go">2025-07-07 13:10:30.181 | info     |           Metal | Closing mesh device 1 (mesh_device.cpp:488)</span>
<span class="go">2025-07-07 13:10:30.182 | info     |           Metal | Closing mesh device 0 (mesh_device.cpp:488)</span>
<span class="go">2025-07-07 13:10:30.182 | info     |           Metal | Closing device 0 (device.cpp:468)</span>
<span class="go">2025-07-07 13:10:30.182 | info     |           Metal | Disabling and clearing program cache on device 0 (device.cpp:783)</span>
<span class="go">2025-07-07 13:10:30.183 | info     |           Metal | Closing mesh device 1 (mesh_device.cpp:488)</span>
</pre></div>
</div>
</section>
</section>



           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="ttnn_basic_conv.html" class="btn btn-neutral float-left" title="Basic Convolution" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="ttnn_clip_zero_shot_classification.html" class="btn btn-neutral float-right" title="Building CLIP Model for Zero-Shot Image Classification with TT-NN" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright Tenstorrent.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
        Version: <span id="current-version">latest</span>
        <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
        <dl id="version-list">
            <dt>Versions</dt>
        </dl>
        <br>
        </dl>
    </div>
</div>

<script>
const VERSIONS_URL = 'https://raw.githubusercontent.com/tenstorrent/tt-metal/refs/heads/main/docs/published_versions.json';

async function loadVersions() {
    try {
        const response = await fetch(VERSIONS_URL);
        const data = await response.json();
        const versionList = document.getElementById('version-list');
        const projectCode = location.pathname.split('/')[3];

        data.versions.forEach(version => {
            const dd = document.createElement('dd');
            const link = document.createElement('a');
            link.href = `https://docs.tenstorrent.com/tt-metal/${version}/${projectCode}/index.html`;
            link.textContent = version;
            dd.appendChild(link);
            versionList.appendChild(dd);
        });
    } catch (error) {
        console.error('Error loading versions:', error);
    }
}

loadVersions();

function getCurrentVersion() {
    return window.location.pathname.split('/')[2];
}
document.getElementById('current-version').textContent = getCurrentVersion();

const versionEl = document.createElement("span");
versionEl.innerText = getCurrentVersion();
versionEl.className = "project-versions";
const wySideSearchEl = document.getElementsByClassName("wy-side-nav-search").item(0);
if (wySideSearchEl) {
    const projectNameEl = wySideSearchEl.children.item(1);
    if (projectNameEl) projectNameEl.appendChild(versionEl);
}

</script><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>