<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Tiles &mdash; TT-Metalium  documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/tt_theme.css" type="text/css" />
    <link rel="shortcut icon" href="../../_static/favicon.png"/>
    <link rel="canonical" href="/tt-metal/latest/tt-metalium/tt_metal/advanced_topics/tiles.html" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js?v=b3ba4146"></script>
        <script src="../../_static/doctools.js?v=888ff710"></script>
        <script src="../../_static/sphinx_highlight.js?v=4825356b"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script src="../../_static/posthog.js?v=aa5946f9"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Memory from a kernel developer’s perspective" href="memory_for_kernel_developers.html" />
    <link rel="prev" title="Advanced Topics" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >



<a href="https://docs.tenstorrent.com/">
    <img src="../../_static/tt_logo.svg" class="logo" alt="Logo"/>
</a>

<a href="../../index.html">
    TT-Metalium
</a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../get_started/get_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../installing.html">Install</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">TT-Metalium</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../programming_model/index.html">Programming Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/index.html">Programming Examples</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Advanced Topics</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="index.html#hardware-implications-and-the-effects">Hardware implications and the effects</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">Tiles</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#internal-structure-of-a-tile">Internal structure of a Tile</a></li>
<li class="toctree-l4"><a class="reference internal" href="#conversion-between-tiles-and-row-major-format">Conversion between tiles and row-major format</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="memory_for_kernel_developers.html">Memory from a kernel developer’s perspective</a></li>
<li class="toctree-l3"><a class="reference internal" href="compute_engines_and_dataflow_within_tensix.html">Compute Engines and Data Flow within Tensix</a></li>
<li class="toctree-l3"><a class="reference internal" href="fp32_accuracy.html">Achieving FP32 Accuracy for Computation</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../apis/index.html">APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../environment_variables/index.html">Environment Variables</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tools/index.html">Tools</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Resources</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../resources/support.html">Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../resources/contributing.html">Contributing as a developer</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">TT-Metalium</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">Advanced Topics</a></li>
      <li class="breadcrumb-item active">Tiles</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/tt_metal/advanced_topics/tiles.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="tiles">
<span id="id1"></span><h1>Tiles<a class="headerlink" href="#tiles" title="Permalink to this heading"></a>
</h1>
<p>Most compute and data movement on the Tensix processor use a tile as the fundamental unit. This page describes the tile structure, the memory layout of a tile and conversion between tiles and row major data (as used by most applications).</p>
<p>A tile is a 32x32 grid of values. Other tile sizes exist but currently have limited support. All elements in a tile share the same data type (integer, floating point, or block floating point).</p>
<p>A tile’s memory footprint depends on the underlying element’s data type. For 32-bit floating point elements, a tile occupies 4KB (32 x 32 x 4 bytes = 4096 bytes). For bfloat16 elements, a tile occupies 2KB (32 x 32 x 2 bytes = 2048 bytes). The size of each tile can be looked up programmatically by calling <code class="docutils literal notranslate"><span class="pre">tt::tile_size(DataFormat)</span></code>.</p>
<p>Tiles are fixed-size data structures, so matrices and tensors must be aligned to tile boundaries. When data dimensions don’t align naturally, they must be padded to the nearest tile boundary. As tiles are 2D structures, padding is only needed in the last two dimensions. Higher-dimensional tensors (3D or more) only require padding in their final two dimensions. Most operations do not care about the specific value of padding as eventually they are disregarded when converted back into row-major. However, some, including matrix multiplication do. Thus it is advised to pad with zeros.</p>
<figure class="align-center" id="id3">
<img alt="padding 1024x48 tensor to tiles" src="../../_images/tenstorrent-tile-memory-layout.webp">
<figcaption>
<p><span class="caption-text">A 1024x48 matrix would be padded to 1024x64 to ensure that each row of 32 elements is aligned to a tile boundary.</span><a class="headerlink" href="#id3" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The Tensix Processor is a little-endian architecture. Though all officially host architectures supported by Metalium are all little-endian, extra care must be taken when the host system may be big-endian.</p>
</div>
<section id="internal-structure-of-a-tile">
<span id="id2"></span><h2>Internal structure of a Tile<a class="headerlink" href="#internal-structure-of-a-tile" title="Permalink to this heading"></a>
</h2>
<p>Most tiles are not stored as a simple flat array. Instead, a 32x32 tile is subdivided into four 16x16 faces, where each face is stored as a contiguous block in memory. The faces are arranged sequentially in memory, creating a hierarchical structure that enables efficient access patterns for the matrix and vector engines in each Tensix core.</p>
<figure class="align-center" id="id4">
<a class="reference internal image-reference" href="../../_images/tenstorrent-32x32tile-16x16face-structure.webp"><img alt="32x32 tile with 16x16 faces" src="../../_images/tenstorrent-32x32tile-16x16face-structure.webp" style="width: 85%;"></a>
<figcaption>
<p><span class="caption-text">A 32x32 tile is organized into four 16x16 faces.</span><a class="headerlink" href="#id4" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<p>For example, consider a bfloat16 tile starting at address <code class="docutils literal notranslate"><span class="pre">0x1000</span></code> with a size of <code class="docutils literal notranslate"><span class="pre">0x800</span></code> (2KB). The tile occupies memory from <code class="docutils literal notranslate"><span class="pre">0x1000</span></code> to <code class="docutils literal notranslate"><span class="pre">0x17FF</span></code>, with the four 16x16 faces located at addresses <code class="docutils literal notranslate"><span class="pre">0x1000</span></code>, <code class="docutils literal notranslate"><span class="pre">0x1200</span></code>, <code class="docutils literal notranslate"><span class="pre">0x1400</span></code>, and <code class="docutils literal notranslate"><span class="pre">0x1600</span></code> respectively.</p>
<figure class="align-center" id="id5">
<a class="reference internal image-reference" href="../../_images/tenstorrent-32x32tile-16x16face-memory-layout.webp"><img alt="32x32 tile with 16x16 face memory layout" src="../../_images/tenstorrent-32x32tile-16x16face-memory-layout.webp" style="width: 85%;"></a>
<figcaption>
<p><span class="caption-text">Memory layout of a 32x32 tile with 16x16 faces with address of each face annotated.</span><a class="headerlink" href="#id5" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Other face sizes, orientation and count are possible but with limited support. The 32x32 tile with four 16x16 faces stored in a 2D array format is the most common and well supported configuration of tiles.</p>
</div>
<p>The following C function demonstrates the conversion from a 32x32 row-major matrix to the tile format with 16x16 faces:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="kt">void</span><span class="w"> </span><span class="nf">convert_to_tile</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">out</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">input</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// input must be a 32x32 tile</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">32</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">32</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="kt">int</span><span class="w"> </span><span class="n">face_row</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">16</span><span class="p">;</span>
<span class="w">            </span><span class="kt">int</span><span class="w"> </span><span class="n">face_col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">16</span><span class="p">;</span>
<span class="w">            </span><span class="kt">int</span><span class="w"> </span><span class="n">face_index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">face_row</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">face_col</span><span class="p">;</span>
<span class="w">            </span><span class="kt">int</span><span class="w"> </span><span class="n">element_row</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">16</span><span class="p">;</span>
<span class="w">            </span><span class="kt">int</span><span class="w"> </span><span class="n">element_col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">16</span><span class="p">;</span>
<span class="w">            </span><span class="kt">int</span><span class="w"> </span><span class="n">offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">face_index</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">16</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">16</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">element_row</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">16</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">element_col</span><span class="p">;</span>
<span class="w">            </span><span class="n">out</span><span class="p">[</span><span class="n">offset</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">32</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">j</span><span class="p">];</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The following Python implementation achieves the same conversion using NumPy’s array operations:</p>
<div class="highlight-python notranslate">
<div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="k">def</span><span class="w"> </span><span class="nf">convert_to_tile</span><span class="p">(</span><span class="n">arr</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">arr</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"Input must have shape (32, 32)"</span><span class="p">)</span>
    <span class="n">faces</span> <span class="o">=</span> <span class="n">arr</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">faces</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span> <span class="c1"># Now the data is ordered in the tile format</span>
</pre></div>
</div>
<p>To convert from tile format back to row-major format, the process is reversed by swapping the source and destination arrays in the indexing calculation:</p>
<div class="highlight-c notranslate">
<div class="highlight"><pre><span></span><span class="kt">void</span><span class="w"> </span><span class="nf">convert_from_tile</span><span class="p">(</span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">out</span><span class="p">,</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="kt">float</span><span class="o">*</span><span class="w"> </span><span class="n">input</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="c1">// input must be a 32x32 tile</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">32</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">32</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="kt">int</span><span class="w"> </span><span class="n">face_row</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">16</span><span class="p">;</span>
<span class="w">            </span><span class="kt">int</span><span class="w"> </span><span class="n">face_col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">16</span><span class="p">;</span>
<span class="w">            </span><span class="kt">int</span><span class="w"> </span><span class="n">face_index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">face_row</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">face_col</span><span class="p">;</span>
<span class="w">            </span><span class="kt">int</span><span class="w"> </span><span class="n">element_row</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">16</span><span class="p">;</span>
<span class="w">            </span><span class="kt">int</span><span class="w"> </span><span class="n">element_col</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">16</span><span class="p">;</span>
<span class="w">            </span><span class="kt">int</span><span class="w"> </span><span class="n">offset</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">face_index</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">16</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">16</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">element_row</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">16</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">element_col</span><span class="p">;</span>
<span class="w">            </span><span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">32</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">j</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">input</span><span class="p">[</span><span class="n">offset</span><span class="p">];</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>A Python/NumPy implementation of the same reversal is as follows:</p>
<div class="highlight-python notranslate">
<div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="k">def</span><span class="w"> </span><span class="nf">convert_from_tile</span><span class="p">(</span><span class="n">arr</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="c1"># arr must be a 32x32 matrix in the tile data format</span>
    <span class="k">if</span> <span class="n">arr</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"Input must have shape (32, 32)"</span><span class="p">)</span>
    <span class="n">faces</span> <span class="o">=</span> <span class="n">arr</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>
    <span class="n">rm</span> <span class="o">=</span> <span class="n">faces</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">rm</span> <span class="c1"># Now the data is ordered row major</span>
</pre></div>
</div>
</section>
<section id="conversion-between-tiles-and-row-major-format">
<h2>Conversion between tiles and row-major format<a class="headerlink" href="#conversion-between-tiles-and-row-major-format" title="Permalink to this heading"></a>
</h2>
<p>Metalium provides <code class="docutils literal notranslate"><span class="pre">convert_layout</span></code> to convert matrices and tensors into tile format that resides in host memory. This function handles data beyond single tiles, provided the input is aligned and padded to tile boundaries, and supports all CPU-handled element types (standard integer types, FP32, bfloat16, etc.) - most formats except block floating point variants.</p>
<p><code class="docutils literal notranslate"><span class="pre">convert_layout</span></code> requires four parameters:</p>
<ul class="simple">
<li><p>Input data</p></li>
<li><p>Input data shape</p></li>
<li><p>Source layout type</p></li>
<li><p>Target layout type</p></li>
</ul>
<p>The following example shows matrix conversion to tile format. <code class="docutils literal notranslate"><span class="pre">NFACES</span></code> in <code class="docutils literal notranslate"><span class="pre">TILED_NFACES</span></code> refers to the number of faces within each tile. The function supports different tile and face configurations. By default, it uses 32x32 tiles with four 16x16 faces as described above:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="c1">// matrix of shape 2x64x64</span>
<span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="w"> </span><span class="n">input_matrix</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="mi">64</span><span class="o">*</span><span class="mi">64</span><span class="p">);</span>
<span class="c1">// Do something with input_matrix</span>
<span class="p">...</span>
<span class="c1">// convert to tiles</span>
<span class="k">auto</span><span class="w"> </span><span class="n">tiled_matrix</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tt</span><span class="o">::</span><span class="n">tt_metal</span><span class="o">::</span><span class="n">convert_layout</span><span class="p">(</span><span class="n">input_matrix</span><span class="p">,</span>
<span class="w">    </span><span class="p">{</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">64</span><span class="p">,</span><span class="w"> </span><span class="mi">64</span><span class="p">},</span>
<span class="w">    </span><span class="n">tt</span><span class="o">::</span><span class="n">tt_metal</span><span class="o">::</span><span class="n">TensorLayoutType</span><span class="o">::</span><span class="n">LIN_ROW_MAJOR</span><span class="p">,</span>
<span class="w">    </span><span class="n">tt</span><span class="o">::</span><span class="n">tt_metal</span><span class="o">::</span><span class="n">TensorLayoutType</span><span class="o">::</span><span class="n">TILED_NFACES</span><span class="p">);</span>
</pre></div>
</div>
<p>And the reverse:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="c1">// convert back to original layout</span>
<span class="k">auto</span><span class="w"> </span><span class="n">original_matrix</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tt</span><span class="o">::</span><span class="n">tt_metal</span><span class="o">::</span><span class="n">convert_layout</span><span class="p">(</span><span class="n">tiled_matrix</span><span class="p">,</span>
<span class="w">    </span><span class="p">{</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">64</span><span class="p">,</span><span class="w"> </span><span class="mi">64</span><span class="p">},</span>
<span class="w">    </span><span class="n">tt</span><span class="o">::</span><span class="n">tt_metal</span><span class="o">::</span><span class="n">TensorLayoutType</span><span class="o">::</span><span class="n">TILED_NFACES</span><span class="p">,</span>
<span class="w">    </span><span class="n">tt</span><span class="o">::</span><span class="n">tt_metal</span><span class="o">::</span><span class="n">TensorLayoutType</span><span class="o">::</span><span class="n">LIN_ROW_MAJOR</span><span class="p">);</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For TTNN users: <code class="docutils literal notranslate"><span class="pre">convert_layout</span></code> executes on the CPU in a single thread and does not use the Tensix Processor. Use <code class="docutils literal notranslate"><span class="pre">ttnn::tilize()</span></code> and <code class="docutils literal notranslate"><span class="pre">ttnn::untilize()</span></code> for layout conversion, or <code class="docutils literal notranslate"><span class="pre">ttnn::tilize_with_zero_padding()</span></code> and <code class="docutils literal notranslate"><span class="pre">ttnn::tilize_with_val_padding()</span></code> to handle non tile aligned data automatically. In most cases these on-device functions are much faster then the CPU counterpart as they can take advantage of the higher DRAM bandwidth and higher core count of the device. Please refer to the TTNN documentation for detail.</p>
<p>For example:</p>
<div class="highlight-c++ notranslate">
<div class="highlight"><pre><span></span><span class="k">auto</span><span class="w"> </span><span class="n">t</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ttnn</span><span class="o">::</span><span class="n">ones</span><span class="p">(</span><span class="n">ttnn</span><span class="o">::</span><span class="n">Shape</span><span class="p">({</span><span class="mi">1024</span><span class="p">,</span><span class="w"> </span><span class="mi">48</span><span class="p">})).</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">);</span>
<span class="c1">// Conversion happens on device</span>
<span class="k">auto</span><span class="w"> </span><span class="n">tiled</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ttnn</span><span class="o">::</span><span class="n">tilize_with_zero_padding</span><span class="p">(</span><span class="n">t</span><span class="p">);</span>
<span class="k">auto</span><span class="w"> </span><span class="n">untiled</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ttnn</span><span class="o">::</span><span class="n">untilize</span><span class="p">(</span><span class="n">tiled</span><span class="p">);</span>
</pre></div>
</div>
</div>
</section>
</section>



           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="Advanced Topics" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="memory_for_kernel_developers.html" class="btn btn-neutral float-right" title="Memory from a kernel developer’s perspective" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright Tenstorrent.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
        Version: <span id="current-version">latest</span>
        <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
        <dl id="version-list">
            <dt>Versions</dt>
        </dl>
        <br>
        </dl>
    </div>
</div>

<script>
const VERSIONS_URL = 'https://raw.githubusercontent.com/tenstorrent/tt-metal/refs/heads/main/docs/published_versions.json';

async function loadVersions() {
    try {
        const response = await fetch(VERSIONS_URL);
        const data = await response.json();
        const versionList = document.getElementById('version-list');
        const projectCode = location.pathname.split('/')[3];

        data.versions.forEach(version => {
            const dd = document.createElement('dd');
            const link = document.createElement('a');
            link.href = `https://docs.tenstorrent.com/tt-metal/${version}/${projectCode}/index.html`;
            link.textContent = version;
            dd.appendChild(link);
            versionList.appendChild(dd);
        });
    } catch (error) {
        console.error('Error loading versions:', error);
    }
}

loadVersions();

function getCurrentVersion() {
    return window.location.pathname.split('/')[2];
}
document.getElementById('current-version').textContent = getCurrentVersion();

const versionEl = document.createElement("span");
versionEl.innerText = getCurrentVersion();
versionEl.className = "project-versions";
const wySideSearchEl = document.getElementsByClassName("wy-side-nav-search").item(0);
if (wySideSearchEl) {
    const projectNameEl = wySideSearchEl.children.item(1);
    if (projectNameEl) projectNameEl.appendChild(versionEl);
}

</script><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>