<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Basic Operations with TT-NN &mdash; TT-NN  documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/tt_theme.css" type="text/css" />
    <link rel="shortcut icon" href="../../_static/favicon.png"/>
    <link rel="canonical" href="/tt-metal/latest/ttnn/ttnn/tutorials/ttnn_basic_operations.html" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js?v=b3ba4146"></script>
        <script src="../../_static/doctools.js?v=888ff710"></script>
        <script src="../../_static/sphinx_highlight.js?v=4825356b"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="MLP inference with TT-NN" href="ttnn_mlp_inference.html" />
    <link rel="prev" title="Create and Add Two Tensors" href="ttnn_add_tensors.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >



<a href="https://docs.tenstorrent.com/">
    <img src="../../_static/tt_logo.svg" class="logo" alt="Logo"/>
</a>

<a href="../../index.html">
    TT-NN
</a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">TTNN</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../about.html">What is TT-NN?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../get_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installing.html">Install</a></li>
<li class="toctree-l1"><a class="reference internal" href="../usage.html">Using TT-NN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tensor.html">Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api.html">APIs</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../tutorials.html">Tutorials</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="ttnn_add_tensors.html">Create and Add Two Tensors</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Basic Operations with TT-NN</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#import-the-necessary-libraries">Import the necessary libraries</a></li>
<li class="toctree-l3"><a class="reference internal" href="#open-tenstorrent-device">Open Tenstorrent device</a></li>
<li class="toctree-l3"><a class="reference internal" href="#helper-function-for-tensor-preparation">Helper Function for Tensor Preparation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#host-tensor-creation">Host Tensor Creation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#convert-host-tensors-to-tt-nn-tiled-tensors-or-create-natively-on-device">Convert Host Tensors to TT-NN Tiled Tensors or Create Natively on Device</a></li>
<li class="toctree-l3"><a class="reference internal" href="#tile-based-arithmetic-operations">Tile-Based Arithmetic Operations</a></li>
<li class="toctree-l3"><a class="reference internal" href="#simulated-broadcasting-row-vector-expansion">Simulated Broadcasting (Row Vector Expansion)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#full-example-and-output">Full example and output</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="ttnn_mlp_inference.html">MLP inference with TT-NN</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../onboarding.html">Onboarding New Functionality</a></li>
<li class="toctree-l1"><a class="reference internal" href="../converting_torch_model_to_ttnn.html">Converting PyTorch Model to TT-NN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../adding_new_ttnn_operation.html">Adding New TT-NN Operation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../profiling_ttnn_operations.html">Profiling TT-NN Operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../demos.html">Building and Uplifting Demos</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Resources</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../resources/support.html">Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../resources/contributing.html">Contributing as a developer</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">TT-NN</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../tutorials.html">Tutorials</a></li>
      <li class="breadcrumb-item active">Basic Operations with TT-NN</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/ttnn/tutorials/ttnn_basic_operations.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="basic-operations-with-tt-nn">
<h1>Basic Operations with TT-NN<a class="headerlink" href="#basic-operations-with-tt-nn" title="Permalink to this heading"></a>
</h1>
<p>We will review a simple example that demonstrates how to create various tensors and
perform basic arithmetic operations on them using TT-NN, a high-level Python API.  These
operations include addition, multiplication, and matrix multiplication, as well as simulating
broadcasting of a row vector across a tile.</p>
<p>Lets create the example file,
<code class="docutils literal notranslate"><span class="pre">ttnn_basic_operations.py</span></code></p>
<section id="import-the-necessary-libraries">
<h2>Import the necessary libraries<a class="headerlink" href="#import-the-necessary-libraries" title="Permalink to this heading"></a>
</h2>
<div class="highlight-python notranslate">
<div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">ttnn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">loguru</span><span class="w"> </span><span class="kn">import</span> <span class="n">logger</span>
</pre></div>
</div>
</section>
<section id="open-tenstorrent-device">
<h2>Open Tenstorrent device<a class="headerlink" href="#open-tenstorrent-device" title="Permalink to this heading"></a>
</h2>
<p>Create necessary device on which we will run our program.</p>
<div class="highlight-python notranslate">
<div class="highlight"><pre><span></span><span class="c1"># Open Tenstorrent device</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">open_device</span><span class="p">(</span><span class="n">device_id</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="helper-function-for-tensor-preparation">
<h2>Helper Function for Tensor Preparation<a class="headerlink" href="#helper-function-for-tensor-preparation" title="Permalink to this heading"></a>
</h2>
<p>Lets create a helper function for convering from PyTorch tensors to TT-NN tiled tensors.</p>
<div class="highlight-python notranslate">
<div class="highlight"><pre><span></span><span class="c1"># Helper to create a TT-NN tensor from torch with TILE_LAYOUT and bfloat16</span>
<span class="k">def</span><span class="w"> </span><span class="nf">to_tt_tile</span><span class="p">(</span><span class="n">torch_tensor</span><span class="p">):</span>
   <span class="k">return</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">from_torch</span><span class="p">(</span><span class="n">torch_tensor</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">TILE_LAYOUT</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="host-tensor-creation">
<h2>Host Tensor Creation<a class="headerlink" href="#host-tensor-creation" title="Permalink to this heading"></a>
</h2>
<p>Create a tensor for our tests and fill with different values. We will use this and other tensors to demonstrate various operations.</p>
<div class="highlight-python notranslate">
<div class="highlight"><pre><span></span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">--- TT-NN Tensor Creation with Tiles (32x32) ---"</span><span class="p">)</span>
<span class="n">host_rand</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="convert-host-tensors-to-tt-nn-tiled-tensors-or-create-natively-on-device">
<h2>Convert Host Tensors to TT-NN Tiled Tensors or Create Natively on Device<a class="headerlink" href="#convert-host-tensors-to-tt-nn-tiled-tensors-or-create-natively-on-device" title="Permalink to this heading"></a>
</h2>
<p>Tensix cores operate most efficiently on tiled data, allowing them to perform a large amount of compute in parallel. Where necesasry, lets convert
host tensors to TT-NN tiled tensors using the helper function we created earlier, and transfer them to the TT device.  Alternatively, we can create tensors
natively using TT-NN’s tensor creation functions, and initialize them directly on the TT device.  TT-NN calls that create tensors natively on the device are a
more efficient way to create tensors, as they avoid the overhead of transferring data from the host to the device.</p>
<div class="highlight-python notranslate">
<div class="highlight"><pre><span></span><span class="n">tt_t1</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">full</span><span class="p">(</span>
   <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span>
   <span class="n">fill_value</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
   <span class="n">dtype</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
   <span class="n">layout</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">TILE_LAYOUT</span><span class="p">,</span>
   <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">tt_t2</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
   <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span>
   <span class="n">dtype</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span>
   <span class="n">layout</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">TILE_LAYOUT</span><span class="p">,</span>
   <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">tt_t3</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
   <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span>
   <span class="n">dtype</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span>
   <span class="n">layout</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">TILE_LAYOUT</span><span class="p">,</span>
   <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">tt_t4</span> <span class="o">=</span> <span class="n">to_tt_tile</span><span class="p">(</span><span class="n">host_rand</span><span class="p">)</span>

<span class="n">t5</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">tt_t5</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">t5</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">TILE_LAYOUT</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="tile-based-arithmetic-operations">
<h2>Tile-Based Arithmetic Operations<a class="headerlink" href="#tile-based-arithmetic-operations" title="Permalink to this heading"></a>
</h2>
<p>Lets use some of the tensors we created and perform different operations on them.</p>
<div class="highlight-python notranslate">
<div class="highlight"><pre><span></span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">--- TT-NN Tensor Operations on (32x32) Tiles ---"</span><span class="p">)</span>
<span class="n">add_result</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tt_t3</span><span class="p">,</span> <span class="n">tt_t4</span><span class="p">)</span>
<span class="n">mul_result</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">tt_t4</span><span class="p">,</span> <span class="n">tt_t5</span><span class="p">)</span>
<span class="n">matmul_result</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">tt_t3</span><span class="p">,</span> <span class="n">tt_t4</span><span class="p">,</span> <span class="n">memory_config</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">DRAM_MEMORY_CONFIG</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="simulated-broadcasting-row-vector-expansion">
<h2>Simulated Broadcasting (Row Vector Expansion)<a class="headerlink" href="#simulated-broadcasting-row-vector-expansion" title="Permalink to this heading"></a>
</h2>
<p>Lets simulated broadcasting a row vector across a tile. This is useful for operations that require expanding a smaller tensor to match the dimensions of a larger one.</p>
<div class="highlight-python notranslate">
<div class="highlight"><pre><span></span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">--- Simulated Broadcasting (32x32 + Broadcasted Row Vector) ---"</span><span class="p">)</span>
<span class="n">broadcast_vector</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">1.0</span><span class="p">]</span> <span class="o">*</span> <span class="mi">32</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">broadcast_tt</span> <span class="o">=</span> <span class="n">to_tt_tile</span><span class="p">(</span><span class="n">broadcast_vector</span><span class="p">)</span>
<span class="n">broadcast_add_result</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tt_t4</span><span class="p">,</span> <span class="n">broadcast_tt</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="full-example-and-output">
<h2>Full example and output<a class="headerlink" href="#full-example-and-output" title="Permalink to this heading"></a>
</h2>
<p>Lets put everything together in a complete example that can be run directly. This example will open a Tenstorrent device, create some input tensors and perform operations on them, log the output tensors, and close the device.</p>
<div class="literal-block-wrapper docutils container" id="id1">
<div class="code-block-caption">
<span class="caption-text">Source Code</span><a class="headerlink" href="#id1" title="Permalink to this code"></a>
</div>
<div class="highlight-default notranslate">
<div class="highlight"><pre><span></span><span class="c1"># SPDX-FileCopyrightText: © 2025 Tenstorrent AI ULC</span>
<span class="c1"># SPDX-License-Identifier: Apache-2.0</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">ttnn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">loguru</span><span class="w"> </span><span class="kn">import</span> <span class="n">logger</span>


<span class="k">def</span><span class="w"> </span><span class="nf">main</span><span class="p">():</span>
    <span class="c1"># Open Tenstorrent device</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">open_device</span><span class="p">(</span><span class="n">device_id</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># Helper to create a TT-NN tensor from torch with TILE_LAYOUT and bfloat16</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">to_tt_tile</span><span class="p">(</span><span class="n">torch_tensor</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">from_torch</span><span class="p">(</span><span class="n">torch_tensor</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">TILE_LAYOUT</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">--- TT-NN Tensor Creation with Tiles (32x32) ---"</span><span class="p">)</span>
        <span class="n">host_rand</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

        <span class="n">tt_t1</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">full</span><span class="p">(</span>
            <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span>
            <span class="n">fill_value</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
            <span class="n">layout</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">TILE_LAYOUT</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">tt_t2</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
            <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span>
            <span class="n">layout</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">TILE_LAYOUT</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">tt_t3</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
            <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span>
            <span class="n">layout</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">TILE_LAYOUT</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">tt_t4</span> <span class="o">=</span> <span class="n">to_tt_tile</span><span class="p">(</span><span class="n">host_rand</span><span class="p">)</span>

        <span class="n">t5</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">tt_t5</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">t5</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">TILE_LAYOUT</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Tensor from fill value 1:</span><span class="se">\n</span><span class="si">{</span><span class="n">ttnn</span><span class="o">.</span><span class="n">to_torch</span><span class="p">(</span><span class="n">tt_t1</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Zeros:</span><span class="se">\n</span><span class="si">{</span><span class="n">ttnn</span><span class="o">.</span><span class="n">to_torch</span><span class="p">(</span><span class="n">tt_t2</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Ones:</span><span class="se">\n</span><span class="si">{</span><span class="n">ttnn</span><span class="o">.</span><span class="n">to_torch</span><span class="p">(</span><span class="n">tt_t3</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Random:</span><span class="se">\n</span><span class="si">{</span><span class="n">ttnn</span><span class="o">.</span><span class="n">to_torch</span><span class="p">(</span><span class="n">tt_t4</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"From expanded NumPy (TT-NN):</span><span class="se">\n</span><span class="si">{</span><span class="n">ttnn</span><span class="o">.</span><span class="n">to_torch</span><span class="p">(</span><span class="n">tt_t5</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">--- TT-NN Tensor Operations on (32x32) Tiles ---"</span><span class="p">)</span>
        <span class="n">add_result</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tt_t3</span><span class="p">,</span> <span class="n">tt_t4</span><span class="p">)</span>
        <span class="n">mul_result</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">tt_t4</span><span class="p">,</span> <span class="n">tt_t5</span><span class="p">)</span>
        <span class="n">matmul_result</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">tt_t3</span><span class="p">,</span> <span class="n">tt_t4</span><span class="p">,</span> <span class="n">memory_config</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">DRAM_MEMORY_CONFIG</span><span class="p">)</span>

        <span class="n">ttnn_add</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">to_torch</span><span class="p">(</span><span class="n">add_result</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Addition:</span><span class="se">\n</span><span class="si">{</span><span class="n">ttnn_add</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

        <span class="n">ttnn_mul</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">to_torch</span><span class="p">(</span><span class="n">mul_result</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Element-wise Multiplication:</span><span class="se">\n</span><span class="si">{</span><span class="n">ttnn_mul</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

        <span class="n">ttnn_matmul</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">to_torch</span><span class="p">(</span><span class="n">matmul_result</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Matrix Multiplication:</span><span class="se">\n</span><span class="si">{</span><span class="n">ttnn_matmul</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">--- Simulated Broadcasting (32x32 + Broadcasted Row Vector) ---"</span><span class="p">)</span>
        <span class="n">broadcast_vector</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">1.0</span><span class="p">]</span> <span class="o">*</span> <span class="mi">32</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">broadcast_tt</span> <span class="o">=</span> <span class="n">to_tt_tile</span><span class="p">(</span><span class="n">broadcast_vector</span><span class="p">)</span>
        <span class="n">broadcast_add_result</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tt_t4</span><span class="p">,</span> <span class="n">broadcast_tt</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Broadcast Add Result (TT-NN):</span><span class="se">\n</span><span class="si">{</span><span class="n">ttnn</span><span class="o">.</span><span class="n">to_torch</span><span class="p">(</span><span class="n">broadcast_add_result</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

    <span class="k">finally</span><span class="p">:</span>
        <span class="n">ttnn</span><span class="o">.</span><span class="n">close_device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">"__main__"</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>Running this script will output the operation results as shown below</p>
<div class="highlight-console notranslate">
<div class="highlight"><pre><span></span><span class="gp">$ </span>python3<span class="w"> </span><span class="nv">$TT_METAL_HOME</span>/ttnn/tutorials/basic_python/ttnn_basic_operations.py
<span class="go">2025-06-23 09:47:12.093 | INFO     | __main__:main:19 -</span>
<span class="go">--- TT-NN Tensor Creation with Tiles (32x32) ---</span>
<span class="go">2025-06-23 09:47:12.117 | INFO     | __main__:main:47 - Tensor from fill value 1:</span>
<span class="go">tensor([[1., 1., 1.,  ..., 1., 1., 1.],</span>
<span class="go">      [1., 1., 1.,  ..., 1., 1., 1.],</span>
<span class="go">      [1., 1., 1.,  ..., 1., 1., 1.],</span>
<span class="go">      ...,</span>
<span class="go">      [1., 1., 1.,  ..., 1., 1., 1.],</span>
<span class="go">      [1., 1., 1.,  ..., 1., 1., 1.],</span>
<span class="go">      [1., 1., 1.,  ..., 1., 1., 1.]])</span>
<span class="go">2025-06-23 09:47:12.117 | INFO     | __main__:main:48 - Zeros:</span>
<span class="go">tensor([[0., 0., 0.,  ..., 0., 0., 0.],</span>
<span class="go">      [0., 0., 0.,  ..., 0., 0., 0.],</span>
<span class="go">      [0., 0., 0.,  ..., 0., 0., 0.],</span>
<span class="go">      ...,</span>
<span class="go">      [0., 0., 0.,  ..., 0., 0., 0.],</span>
<span class="go">      [0., 0., 0.,  ..., 0., 0., 0.],</span>
<span class="go">      [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.bfloat16)</span>
<span class="go">2025-06-23 09:47:12.118 | INFO     | __main__:main:49 - Ones:</span>
<span class="go">tensor([[1., 1., 1.,  ..., 1., 1., 1.],</span>
<span class="go">      [1., 1., 1.,  ..., 1., 1., 1.],</span>
<span class="go">      [1., 1., 1.,  ..., 1., 1., 1.],</span>
<span class="go">      ...,</span>
<span class="go">      [1., 1., 1.,  ..., 1., 1., 1.],</span>
<span class="go">      [1., 1., 1.,  ..., 1., 1., 1.],</span>
<span class="go">      [1., 1., 1.,  ..., 1., 1., 1.]], dtype=torch.bfloat16)</span>
<span class="go">2025-06-23 09:47:12.119 | INFO     | __main__:main:50 - Random:</span>
<span class="go">tensor([[0.1367, 0.3320, 0.8125,  ..., 0.7969, 0.6250, 0.8906],</span>
<span class="go">      [0.6914, 0.1377, 0.2480,  ..., 0.6406, 0.0109, 0.2080],</span>
<span class="go">      [0.6992, 0.8750, 0.6133,  ..., 0.3086, 0.6562, 0.6016],</span>
<span class="go">      ...,</span>
<span class="go">      [0.1455, 0.8672, 0.0221,  ..., 0.3926, 0.1074, 0.9414],</span>
<span class="go">      [0.5859, 0.1426, 0.8906,  ..., 0.5820, 0.0182, 0.7031],</span>
<span class="go">      [0.8711, 0.1377, 0.7305,  ..., 0.4102, 0.2812, 0.6836]],</span>
<span class="go">      dtype=torch.bfloat16)</span>
<span class="go">2025-06-23 09:47:12.120 | INFO     | __main__:main:51 - From expanded NumPy (TT-NN):</span>
<span class="go">tensor([[5., 5., 5.,  ..., 6., 6., 6.],</span>
<span class="go">      [5., 5., 5.,  ..., 6., 6., 6.],</span>
<span class="go">      [5., 5., 5.,  ..., 6., 6., 6.],</span>
<span class="go">      ...,</span>
<span class="go">      [7., 7., 7.,  ..., 8., 8., 8.],</span>
<span class="go">      [7., 7., 7.,  ..., 8., 8., 8.],</span>
<span class="go">      [7., 7., 7.,  ..., 8., 8., 8.]])</span>
<span class="go">2025-06-23 09:47:12.120 | INFO     | __main__:main:53 -</span>
<span class="go">--- TT-NN Tensor Operations on (32x32) Tiles ---</span>
<span class="go">2025-06-23 09:47:18.928 | INFO     | __main__:main:59 - Addition:</span>
<span class="go">tensor([[1.1406, 1.3359, 1.8125,  ..., 1.7969, 1.6250, 1.8906],</span>
<span class="go">      [1.6953, 1.1406, 1.2500,  ..., 1.6406, 1.0078, 1.2109],</span>
<span class="go">      [1.7031, 1.8750, 1.6172,  ..., 1.3125, 1.6562, 1.6016],</span>
<span class="go">      ...,</span>
<span class="go">      [1.1484, 1.8672, 1.0234,  ..., 1.3906, 1.1094, 1.9453],</span>
<span class="go">      [1.5859, 1.1406, 1.8906,  ..., 1.5859, 1.0156, 1.7031],</span>
<span class="go">      [1.8750, 1.1406, 1.7344,  ..., 1.4141, 1.2812, 1.6875]],</span>
<span class="go">      dtype=torch.bfloat16)</span>
<span class="go">2025-06-23 09:47:18.929 | INFO     | __main__:main:62 - Element-wise Multiplication:</span>
<span class="go">tensor([[0.6836, 1.6641, 4.0625,  ..., 4.7812, 3.7500, 5.3438],</span>
<span class="go">      [3.4531, 0.6875, 1.2422,  ..., 3.8438, 0.0654, 1.2500],</span>
<span class="go">      [3.5000, 4.3750, 3.0625,  ..., 1.8516, 3.9375, 3.6094],</span>
<span class="go">      ...,</span>
<span class="go">      [1.0156, 6.0625, 0.1543,  ..., 3.1406, 0.8594, 7.5312],</span>
<span class="go">      [4.0938, 1.0000, 6.2500,  ..., 4.6562, 0.1455, 5.6250],</span>
<span class="go">      [6.0938, 0.9648, 5.1250,  ..., 3.2812, 2.2500, 5.4688]],</span>
<span class="go">      dtype=torch.bfloat16)</span>
<span class="go">2025-06-23 09:47:18.930 | INFO     | __main__:main:65 - Matrix Multiplication:</span>
<span class="go">tensor([[17.5000, 13.4375, 16.7500,  ..., 15.2500, 13.0625, 17.2500],</span>
<span class="go">      [17.5000, 13.4375, 16.7500,  ..., 15.2500, 13.0625, 17.2500],</span>
<span class="go">      [17.5000, 13.4375, 16.7500,  ..., 15.2500, 13.0625, 17.2500],</span>
<span class="go">      ...,</span>
<span class="go">      [17.5000, 13.4375, 16.7500,  ..., 15.2500, 13.0625, 17.2500],</span>
<span class="go">      [17.5000, 13.4375, 16.7500,  ..., 15.2500, 13.0625, 17.2500],</span>
<span class="go">      [17.5000, 13.4375, 16.7500,  ..., 15.2500, 13.0625, 17.2500]],</span>
<span class="go">      dtype=torch.bfloat16)</span>
<span class="go">2025-06-23 09:47:18.930 | INFO     | __main__:main:67 -</span>
<span class="go">--- Simulated Broadcasting (32x32 + Broadcasted Row Vector) ---</span>
<span class="go">2025-06-23 09:47:18.932 | INFO     | __main__:main:71 - Broadcast Add Result (TT-NN):</span>
<span class="go">tensor([[1.1406, 1.3359, 1.8125,  ..., 1.7969, 1.6250, 1.8906],</span>
<span class="go">      [1.6953, 1.1406, 1.2500,  ..., 1.6406, 1.0078, 1.2109],</span>
<span class="go">      [1.7031, 1.8750, 1.6172,  ..., 1.3125, 1.6562, 1.6016],</span>
<span class="go">      ...,</span>
<span class="go">      [1.1484, 1.8672, 1.0234,  ..., 1.3906, 1.1094, 1.9453],</span>
<span class="go">      [1.5859, 1.1406, 1.8906,  ..., 1.5859, 1.0156, 1.7031],</span>
<span class="go">      [1.8750, 1.1406, 1.7344,  ..., 1.4141, 1.2812, 1.6875]],</span>
<span class="go">      dtype=torch.bfloat16)</span>
</pre></div>
</div>
</section>
</section>



           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="ttnn_add_tensors.html" class="btn btn-neutral float-left" title="Create and Add Two Tensors" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="ttnn_mlp_inference.html" class="btn btn-neutral float-right" title="MLP inference with TT-NN" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright Tenstorrent.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
        Version: <span id="current-version">latest</span>
        <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
        <dl id="version-list">
            <dt>Versions</dt>
        </dl>
        <br>
        </dl>
    </div>
</div>

<script>
const VERSIONS_URL = 'https://raw.githubusercontent.com/tenstorrent/tt-metal/refs/heads/main/docs/published_versions.json';

async function loadVersions() {
    try {
        const response = await fetch(VERSIONS_URL);
        const data = await response.json();
        const versionList = document.getElementById('version-list');
        const projectCode = location.pathname.split('/')[3];

        data.versions.forEach(version => {
            const dd = document.createElement('dd');
            const link = document.createElement('a');
            link.href = `https://docs.tenstorrent.com/tt-metal/${version}/${projectCode}/index.html`;
            link.textContent = version;
            dd.appendChild(link);
            versionList.appendChild(dd);
        });
    } catch (error) {
        console.error('Error loading versions:', error);
    }
}

loadVersions();

function getCurrentVersion() {
    return window.location.pathname.split('/')[2];
}
document.getElementById('current-version').textContent = getCurrentVersion();

const versionEl = document.createElement("span");
versionEl.innerText = getCurrentVersion();
versionEl.className = "project-versions";
const wySideSearchEl = document.getElementsByClassName("wy-side-nav-search").item(0);
if (wySideSearchEl) {
    const projectNameEl = wySideSearchEl.children.item(1);
    if (projectNameEl) projectNameEl.appendChild(versionEl);
}

</script><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>