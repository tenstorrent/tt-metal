{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf05ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Tuple\n",
    "from models.common.utility_functions import ulp\n",
    "import os\n",
    "from loguru import logger\n",
    "import ttnn\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "SEED = 0\n",
    "# torch.manual_seed(SEED)\n",
    "# np.random.seed(SEED)\n",
    "\n",
    "# Disable TT logging\n",
    "os.environ[\"TT_LOGGER_LEVEL\"] = \"off\"\n",
    "os.environ[\"TT_METAL_CACHE\"] = \"/localdev/astancov/tt-metal/built\"\n",
    "logger.disable(\"ttnn\")\n",
    "\n",
    "default_fig_size = (8, 5)\n",
    "\n",
    "\n",
    "def ulp_error(res, ref):\n",
    "    \"\"\"\n",
    "    Compute the ULP error (in ref ULPs) between two tensors.\n",
    "\n",
    "    Args:\n",
    "        res: Result tensor (calculated/actual)\n",
    "        ref: Reference tensor (golden/expected)\n",
    "\n",
    "    Returns:\n",
    "        tuple: (ulp_errors, ulp_details) where:\n",
    "            - ulp_errors: ULP error tensor between res and ref (in ULPs of ref)\n",
    "            - ulp_details: dict containing max ULP error location and values\n",
    "    \"\"\"\n",
    "    ref_ulp = ulp(ref)\n",
    "    ulp_errors = torch.abs((res.to(torch.float64) - ref.to(torch.float64)) / ref_ulp.to(torch.float64))\n",
    "\n",
    "    # Track details about max ULP error\n",
    "    max_ulp = torch.max(ulp_errors)\n",
    "    ulp_index = torch.argmax(ulp_errors)\n",
    "    ulp_index_tuple = tuple(int(idx) for idx in torch.unravel_index(ulp_index, ref.shape))\n",
    "\n",
    "    ulp_details = {\n",
    "        \"max_ulp\": float(max_ulp),\n",
    "        \"max_ulp_index\": ulp_index_tuple,\n",
    "        \"calculated_value\": float(res[ulp_index_tuple]),\n",
    "        \"golden_value\": float(ref[ulp_index_tuple]),\n",
    "        \"ulp_value\": float(ref_ulp[ulp_index_tuple]),\n",
    "    }\n",
    "\n",
    "    return ulp_errors, ulp_details\n",
    "\n",
    "\n",
    "def make_rand_seeded():\n",
    "    def rand_seeded(*args, **kwargs):\n",
    "        torch.manual_seed(SEED)\n",
    "        return torch.rand(*args, **kwargs)\n",
    "    return rand_seeded\n",
    "\n",
    "def make_randn_seeded():\n",
    "    def randn_seeded(*args, **kwargs):\n",
    "        torch.manual_seed(SEED)\n",
    "        return torch.randn(*args, **kwargs)\n",
    "    return randn_seeded\n",
    "\n",
    "def make_randn_clamped(min_val, max_val):\n",
    "    \"\"\"\n",
    "    Create a randn generator function that clamps values to [min_val, max_val].\n",
    "\n",
    "    Args:\n",
    "        min_val: Minimum value to clamp to\n",
    "        max_val: Maximum value to clamp to\n",
    "\n",
    "    Returns:\n",
    "        Function that generates clamped random normal values\n",
    "    \"\"\"\n",
    "    def randn_clamped(*args, **kwargs):\n",
    "        torch.manual_seed(SEED)\n",
    "        return torch.clamp(torch.randn(*args, **kwargs), min=min_val, max=max_val)\n",
    "\n",
    "    return randn_clamped\n",
    "\n",
    "\n",
    "def make_randn_clamped_to_dtype_max(dtype=torch.float32):\n",
    "    \"\"\"\n",
    "    Generate random normal values clamped to the maximum finite value of the given dtype.\n",
    "    This prevents infinity values from appearing in the tensors.\n",
    "\n",
    "    Args:\n",
    "        dtype: PyTorch dtype to use for clamping range\n",
    "\n",
    "    Returns:\n",
    "        Function that generates clamped random normal values\n",
    "    \"\"\"\n",
    "\n",
    "    def randn_clamped(*args, **kwargs):\n",
    "        torch.manual_seed(SEED)\n",
    "        max_val = torch.finfo(dtype).max\n",
    "        min_val = torch.finfo(dtype).min\n",
    "        return torch.clamp(torch.randn(*args, **kwargs), min=min_val, max=max_val)\n",
    "\n",
    "    return randn_clamped\n",
    "\n",
    "\n",
    "def run_ttnn_conv_transpose2d(\n",
    "    input_tensor, weight_tensor, bias_tensor, padding, stride, output_padding=(0, 0), fp32_acc=False, device=None, use_bias=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Run conv_transpose2d in ttnn.\n",
    "\n",
    "    Args:\n",
    "        input_tensor: Input tensor (torch) in NCHW format\n",
    "        weight_tensor: Weight tensor (torch) in IOHW format (note: different from conv2d!)\n",
    "        bias_tensor: Bias tensor (torch)\n",
    "        padding: Padding tuple (h, w)\n",
    "        stride: Stride tuple (h, w)\n",
    "        output_padding: Output padding tuple (h, w)\n",
    "        fp32_acc: Whether to use fp32 accumulation\n",
    "        device: TTNN device\n",
    "        use_bias: Whether to use bias\n",
    "\n",
    "    Returns:\n",
    "        Output tensor (torch) in NCHW format\n",
    "    \"\"\"\n",
    "    create_local_device = device is None\n",
    "    if create_local_device:\n",
    "        device = ttnn.CreateDevice(0, l1_small_size=16384)\n",
    "\n",
    "    # Extract dimensions\n",
    "    batch_size = input_tensor.shape[0]\n",
    "    in_channels = input_tensor.shape[1]\n",
    "    input_height = input_tensor.shape[2]\n",
    "    input_width = input_tensor.shape[3]\n",
    "    out_channels = weight_tensor.shape[1]  # Note: weight is IOHW for transposed conv\n",
    "    kernel_h = weight_tensor.shape[2]\n",
    "    kernel_w = weight_tensor.shape[3]\n",
    "\n",
    "    # Handle padding and stride\n",
    "    if isinstance(padding, int):\n",
    "        pad_h, pad_w = padding, padding\n",
    "    else:\n",
    "        pad_h, pad_w = padding[0], padding[1]\n",
    "\n",
    "    if isinstance(stride, int):\n",
    "        str_h, str_w = stride, stride\n",
    "    else:\n",
    "        str_h, str_w = stride[0], stride[1]\n",
    "\n",
    "    if isinstance(output_padding, int):\n",
    "        out_pad_h, out_pad_w = output_padding, output_padding\n",
    "    else:\n",
    "        out_pad_h, out_pad_w = output_padding[0], output_padding[1]\n",
    "\n",
    "    # Convert input from NCHW to NHWC format\n",
    "    input_nhwc = input_tensor.permute(0, 2, 3, 1).contiguous()\n",
    "\n",
    "    # Prepare bias - reshape to (1, 1, 1, out_channels) if needed\n",
    "    if use_bias:\n",
    "        if bias_tensor.dim() == 1:\n",
    "            bias_tensor = bias_tensor.reshape(1, 1, 1, -1)\n",
    "        elif bias_tensor.shape != (1, 1, 1, out_channels):\n",
    "            bias_tensor = bias_tensor.reshape(1, 1, 1, -1)\n",
    "\n",
    "    # Determine ttnn dtype\n",
    "    ttnn_dtype = ttnn.bfloat16 if input_tensor.dtype == torch.bfloat16 else ttnn.float32\n",
    "\n",
    "    # Convert to ttnn tensors\n",
    "    tt_input = ttnn.from_torch(input_nhwc, dtype=ttnn_dtype, layout=ttnn.ROW_MAJOR_LAYOUT, device=device)\n",
    "    tt_weight = ttnn.from_torch(weight_tensor, dtype=ttnn_dtype)\n",
    "    tt_bias = ttnn.from_torch(bias_tensor, dtype=ttnn_dtype) if use_bias else None\n",
    "\n",
    "    # Configure compute kernel\n",
    "    compute_config = ttnn.init_device_compute_kernel_config(\n",
    "        device.arch(),\n",
    "        math_fidelity=ttnn.MathFidelity.HiFi4,\n",
    "        math_approx_mode=False,\n",
    "        fp32_dest_acc_en=fp32_acc,\n",
    "        packer_l1_acc=True,  # l1_acc is turned on\n",
    "    )\n",
    "\n",
    "    # Run conv_transpose2d\n",
    "    [tt_output, out_dims, _] = ttnn.conv_transpose2d(\n",
    "        input_tensor=tt_input,\n",
    "        weight_tensor=tt_weight,\n",
    "        bias_tensor=tt_bias,\n",
    "        device=device,\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        batch_size=batch_size,\n",
    "        input_height=input_height,\n",
    "        input_width=input_width,\n",
    "        kernel_size=(kernel_h, kernel_w),\n",
    "        stride=(str_h, str_w),\n",
    "        padding=(pad_h, pad_w),\n",
    "        output_padding=(out_pad_h, out_pad_w),\n",
    "        dilation=(1, 1),\n",
    "        groups=1,\n",
    "        compute_config=compute_config,\n",
    "        return_output_dim=True,\n",
    "        return_weights_and_bias=True,\n",
    "        dtype=ttnn_dtype,\n",
    "    )\n",
    "\n",
    "    # Convert back to torch and reshape to NCHW\n",
    "    output_torch = ttnn.to_torch(tt_output)\n",
    "    out_height, out_width = out_dims\n",
    "    output_nchw = output_torch.reshape(batch_size, out_height, out_width, out_channels).permute(0, 3, 1, 2)\n",
    "    # Trim to actual output channels\n",
    "    output_nchw = output_nchw[:, :out_channels, :, :]\n",
    "\n",
    "    if create_local_device:\n",
    "        ttnn.close_device(device)\n",
    "\n",
    "    return output_nchw\n",
    "\n",
    "\n",
    "def run_conv_transpose_k_sweep(inner_channels_values, input_generator=\"rand\", use_bias=False, clamp_tuple=None):\n",
    "    \"\"\"\n",
    "    Run conv_transpose2d with varying inner channels values where:\n",
    "    - K = inner_channels * kernel_h * kernel_w\n",
    "    - For transposed conv, the matmul dimensions are similar but output size is larger\n",
    "\n",
    "    Args:\n",
    "        inner_channels_values: List of inner channels values to test\n",
    "        input_generator: 'rand' or 'randn' for input generation\n",
    "        use_bias: Whether to use bias\n",
    "        clamp_tuple: Tuple of (min_val, max_val) to clamp the input to\n",
    "    Returns:\n",
    "        Dictionary with results for each configuration\n",
    "    \"\"\"\n",
    "    device = ttnn.CreateDevice(0, l1_small_size=16384)\n",
    "\n",
    "    # Configurations to test: (dtype, fp32_acc, name)\n",
    "    configs = [\n",
    "        (torch.bfloat16, False, \"bfp16\"),\n",
    "        (torch.bfloat16, True, \"bfp16+fp32acc\"),\n",
    "        (torch.float32, False, \"fp32\"),\n",
    "        (torch.float32, True, \"fp32+fp32acc\"),\n",
    "    ]\n",
    "    results = {\n",
    "        config[2]: {\n",
    "            \"k_values\": [],\n",
    "            \"mean_ulp\": [],\n",
    "            \"median_ulp\": [],\n",
    "            \"max_ulp\": [],\n",
    "            \"p99_ulp\": [],\n",
    "            \"all_ulp_errors\": [],\n",
    "            \"ulp_details\": [],  # Track ULP details for each K value\n",
    "        }\n",
    "        for config in configs\n",
    "    }\n",
    "\n",
    "    for inner_channels in inner_channels_values:\n",
    "        print(f\"\\nTesting inner channels={inner_channels}\", flush=True)\n",
    "\n",
    "        # Create convolution configuration\n",
    "        batch_size = 1\n",
    "        in_channels = inner_channels\n",
    "        out_channels = 96\n",
    "\n",
    "        # Input spatial dimensions\n",
    "        h = 12\n",
    "        w = 8\n",
    "\n",
    "        # 2x2 convolution kernel (as requested)\n",
    "        kernel_h, kernel_w = 2, 2\n",
    "        padding = (0, 0)\n",
    "        stride = (2, 2)\n",
    "        output_padding = (0, 0)\n",
    "\n",
    "        # Select generation function based on input_generator\n",
    "        if input_generator == \"rand\":\n",
    "            gen_fn = make_rand_seeded()\n",
    "        elif input_generator == \"randn\" and clamp_tuple is not None:\n",
    "            gen_fn = make_randn_clamped(clamp_tuple[0], clamp_tuple[1])\n",
    "        elif input_generator == \"randn\":\n",
    "            gen_fn = make_randn_seeded()\n",
    "        elif input_generator == \"randn_clamped_fp32_max\":\n",
    "            gen_fn = make_randn_clamped_to_dtype_max(torch.float32)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown input_generator: {input_generator}\")\n",
    "\n",
    "        # Generate input tensors in fp32 once for this K value\n",
    "        # All configurations will use the same input data for fair comparison\n",
    "        input_tensor_fp32 = gen_fn(batch_size, in_channels, h, w)\n",
    "        weight_tensor_fp32 = gen_fn(in_channels, out_channels, kernel_h, kernel_w)\n",
    "        bias_tensor_fp32 = gen_fn(out_channels) if use_bias else torch.zeros(out_channels)\n",
    "\n",
    "        # Test each configuration with the same input data\n",
    "        for dtype, fp32_acc, config_name in configs:\n",
    "            print(f\"  Config: {config_name}\", flush=True)\n",
    "\n",
    "            # Cast tensors to target dtype for this configuration\n",
    "            input_tensor = input_tensor_fp32.to(dtype)\n",
    "            weight_tensor = weight_tensor_fp32.to(dtype)\n",
    "            bias_tensor = bias_tensor_fp32.to(dtype)\n",
    "\n",
    "            # Compute reference in the same dtype as the configuration\n",
    "            with torch.no_grad():\n",
    "                reference = torch.nn.functional.conv_transpose2d(\n",
    "                    input_tensor,\n",
    "                    weight_tensor,\n",
    "                    bias=bias_tensor if use_bias else None,\n",
    "                    padding=padding,\n",
    "                    stride=stride,\n",
    "                    output_padding=output_padding,\n",
    "                )\n",
    "\n",
    "            # Run TTNN conv_transpose2d\n",
    "            try:\n",
    "                ttnn_output = run_ttnn_conv_transpose2d(\n",
    "                    input_tensor,\n",
    "                    weight_tensor,\n",
    "                    bias_tensor,\n",
    "                    padding=padding,\n",
    "                    stride=stride,\n",
    "                    output_padding=output_padding,\n",
    "                    fp32_acc=fp32_acc,\n",
    "                    device=device,\n",
    "                    use_bias=use_bias,\n",
    "                )\n",
    "\n",
    "                # Compute ULP errors and details\n",
    "                ulp_errors_tensor, ulp_details = ulp_error(ttnn_output, reference)\n",
    "                ulp_errors = ulp_errors_tensor.detach().cpu().numpy().flatten()\n",
    "\n",
    "                # Compute statistics manually for this K\n",
    "                ulp_stats = {\n",
    "                    \"mean\": float(np.mean(ulp_errors)),\n",
    "                    \"median\": float(np.median(ulp_errors)),\n",
    "                    \"max\": float(np.max(ulp_errors)),\n",
    "                    \"p99\": float(np.percentile(ulp_errors, 99)),\n",
    "                }\n",
    "\n",
    "                results[config_name][\"k_values\"].append(inner_channels * kernel_h * kernel_w)\n",
    "                results[config_name][\"mean_ulp\"].append(ulp_stats[\"mean\"])\n",
    "                results[config_name][\"median_ulp\"].append(ulp_stats[\"median\"])\n",
    "                results[config_name][\"max_ulp\"].append(ulp_stats[\"max\"])\n",
    "                results[config_name][\"p99_ulp\"].append(ulp_stats[\"p99\"])\n",
    "\n",
    "                # Store ULP errors and details for aggregated analysis\n",
    "                results[config_name][\"all_ulp_errors\"].append(ulp_errors)\n",
    "                results[config_name][\"ulp_details\"].append(ulp_details)\n",
    "\n",
    "                # Print detailed ULP information including near-zero division detection\n",
    "                print(\n",
    "                    f\"    Mean ULP: {ulp_stats['mean']:.2f}, Median ULP: {ulp_stats['median']:.2f}, P99 ULP: {ulp_stats['p99']:.2f}, Max ULP: {ulp_stats['max']:.2f}\",\n",
    "                    flush=True,\n",
    "                )\n",
    "                print(\n",
    "                    f\"    Max ULP details @ {list(ulp_details['max_ulp_index'])}: \"\n",
    "                    f\"|{ulp_details['calculated_value']} - {ulp_details['golden_value']}| / {ulp_details['ulp_value']}\",\n",
    "                    flush=True,\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"    Error: {e}\", flush=True)\n",
    "                results[config_name][\"k_values\"].append(inner_channels * kernel_h * kernel_w)\n",
    "                results[config_name][\"mean_ulp\"].append(np.nan)\n",
    "                results[config_name][\"median_ulp\"].append(np.nan)\n",
    "                results[config_name][\"max_ulp\"].append(np.nan)\n",
    "                results[config_name][\"p99_ulp\"].append(np.nan)\n",
    "\n",
    "    # Compute aggregated statistics across all K values\n",
    "    print(\"\\n\" + \"=\" * 80, flush=True)\n",
    "    if input_generator == \"rand\":\n",
    "        values_range = \"[0,1)\"\n",
    "    elif input_generator == \"randn\" and clamp_tuple is not None:\n",
    "        values_range = f\"[{clamp_tuple[0]:.2e},{clamp_tuple[1]:.2e}]\"\n",
    "    elif input_generator == \"randn_clamped_fp32_max\":\n",
    "        max_fp32 = torch.finfo(torch.float32).max\n",
    "        values_range = f\"[{torch.finfo(torch.float32).min:.2e},{max_fp32:.2e}]\"\n",
    "    else:\n",
    "        values_range = \"(-inf,inf)\"\n",
    "    print(\n",
    "        f\"AGGREGATED STATISTICS (All K values combined) - values: {values_range}\",\n",
    "        flush=True,\n",
    "    )\n",
    "    print(\"=\" * 80, flush=True)\n",
    "\n",
    "    aggregated_stats = {}\n",
    "    for config_name in results.keys():\n",
    "        if len(results[config_name][\"all_ulp_errors\"]) > 0:\n",
    "            # Concatenate all ULP error arrays\n",
    "            all_ulp_errors = np.concatenate(results[config_name][\"all_ulp_errors\"])\n",
    "\n",
    "            # Find the worst-case ULP details across all K values\n",
    "            ulp_details_list = results[config_name][\"ulp_details\"]\n",
    "            worst_case_idx = max(range(len(ulp_details_list)), key=lambda i: ulp_details_list[i][\"max_ulp\"])\n",
    "            worst_case_details = ulp_details_list[worst_case_idx]\n",
    "            worst_case_k = results[config_name][\"k_values\"][worst_case_idx]\n",
    "\n",
    "            # Compute statistics on combined ULP errors\n",
    "            agg_stats = {\n",
    "                \"mean\": float(np.mean(all_ulp_errors)),\n",
    "                \"median\": float(np.median(all_ulp_errors)),\n",
    "                \"max\": float(np.max(all_ulp_errors)),\n",
    "                \"min\": float(np.min(all_ulp_errors)),\n",
    "                \"p95\": float(np.percentile(all_ulp_errors, 95)),\n",
    "                \"p99\": float(np.percentile(all_ulp_errors, 99)),\n",
    "                \"worst_case_details\": worst_case_details,\n",
    "                \"worst_case_k\": worst_case_k,\n",
    "            }\n",
    "            aggregated_stats[config_name] = agg_stats\n",
    "\n",
    "            print(f\"\\n{config_name}:\", flush=True)\n",
    "            print(f\"  K values tested: {results[config_name]['k_values']}\", flush=True)\n",
    "            print(f\"  Total samples: {len(all_ulp_errors)}\", flush=True)\n",
    "            print(f\"  Mean ULP:   {agg_stats['mean']:.4f}\", flush=True)\n",
    "            print(f\"  Median ULP: {agg_stats['median']:.4f}\", flush=True)\n",
    "            print(f\"  Max ULP:    {agg_stats['max']:.4f}\", flush=True)\n",
    "            print(f\"  P95 ULP:    {agg_stats['p95']:.4f}\", flush=True)\n",
    "            print(f\"  P99 ULP:    {agg_stats['p99']:.4f}\", flush=True)\n",
    "            print(f\"  Worst case ULP details (K={worst_case_k}):\", flush=True)\n",
    "            print(\n",
    "                f\"    @ {list(worst_case_details['max_ulp_index'])}: \"\n",
    "                f\"|{worst_case_details['calculated_value']:.6e} - {worst_case_details['golden_value']:.6e}| / {worst_case_details['ulp_value']:.6e}\",\n",
    "                flush=True,\n",
    "            )\n",
    "\n",
    "    results[\"_aggregated\"] = aggregated_stats\n",
    "\n",
    "    ttnn.close_device(device)\n",
    "    return results\n",
    "\n",
    "\n",
    "def plot_k_sweep_results(results, input_generator, metric=\"mean_ulp\"):\n",
    "    \"\"\"\n",
    "    Plot ULP results across K values for different configurations.\n",
    "\n",
    "    Args:\n",
    "        results: Dictionary with results from run_conv_transpose_k_sweep\n",
    "        input_generator: Name of input generator used ('rand' or 'randn')\n",
    "        metric: Which ULP metric to plot ('mean_ulp', 'median_ulp', or 'max_ulp')\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 7))\n",
    "\n",
    "    for config_name, data in results.items():\n",
    "        if config_name != \"_aggregated\":  # Skip aggregated stats\n",
    "            plt.plot(data[\"k_values\"], data[metric], marker=\"o\", linewidth=2, label=config_name, markersize=8)\n",
    "\n",
    "    plt.xlabel(\"K (inner_channels * kernel_h * kernel_w)\", fontsize=12)\n",
    "    plt.ylabel(f'{metric.replace(\"_\", \" \").title()}', fontsize=12)\n",
    "    plt.title(f\"Conv2D Transposed (2x2 kernel) ULP vs K - {input_generator} inputs\", fontsize=14)\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"conv_transpose_k_sweep_{input_generator}_{metric}.png\", dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_aggregated_comparison(results, input_generator):\n",
    "    \"\"\"\n",
    "    Plot aggregated ULP statistics comparison across all K values.\n",
    "\n",
    "    Args:\n",
    "        results: Dictionary with results from run_conv_transpose_k_sweep\n",
    "        input_generator: Name of input generator used ('rand' or 'randn')\n",
    "    \"\"\"\n",
    "    if \"_aggregated\" not in results:\n",
    "        print(\"No aggregated statistics available\", flush=True)\n",
    "        return\n",
    "\n",
    "    aggregated = results[\"_aggregated\"]\n",
    "    config_names = list(aggregated.keys())\n",
    "    metrics = [\"p95\", \"p99\", \"max\"]\n",
    "\n",
    "    # Prepare data for plotting\n",
    "    data_by_metric = {metric: [] for metric in metrics}\n",
    "    for config_name in config_names:\n",
    "        for metric in metrics:\n",
    "            data_by_metric[metric].append(aggregated[config_name][metric])\n",
    "\n",
    "    # Create bar plot\n",
    "    x = np.arange(len(config_names))\n",
    "    width = 0.15\n",
    "    fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "    for i, metric in enumerate(metrics):\n",
    "        offset = width * (i - len(metrics) / 2 + 0.5)\n",
    "        bars = ax.bar(x + offset, data_by_metric[metric], width, label=metric.upper())\n",
    "\n",
    "        # Add value labels on bars\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width() / 2.0, height, f\"{height:.1f}\", ha=\"center\", va=\"bottom\", fontsize=7)\n",
    "\n",
    "    ax.set_xlabel(\"Configuration\", fontsize=12)\n",
    "    ax.set_ylabel(\"ULP Error\", fontsize=12)\n",
    "    ax.set_title(f\"Conv2D Transposed (2x2 kernel) Aggregated ULP Statistics - {input_generator} inputs\", fontsize=14)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(config_names, rotation=20, ha=\"right\")\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"conv_transpose_k_sweep_{input_generator}_aggregated.png\", dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_all_inputs_comparison(all_results_dict, metric=\"max_ulp\"):\n",
    "    \"\"\"\n",
    "    Plot ULP results across K values for all input types on the same graph.\n",
    "\n",
    "    Args:\n",
    "        all_results_dict: Dictionary mapping input type names to their results\n",
    "        metric: Which ULP metric to plot ('mean_ulp', 'median_ulp', or 'max_ulp')\n",
    "    \"\"\"\n",
    "    configs = [\"bfp16\", \"bfp16+fp32acc\", \"fp32\", \"fp32+fp32acc\"]\n",
    "\n",
    "    # Define distinct line styles, markers, and colors for each input type\n",
    "    line_styles = ['-', '--', '-.', ':', '-']\n",
    "    markers = ['o', 's', '^', 'D', 'v']\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "\n",
    "    # Create subplots: one for each configuration\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, config_name in enumerate(configs):\n",
    "        ax = axes[idx]\n",
    "\n",
    "        for style_idx, (input_name, results) in enumerate(all_results_dict.items()):\n",
    "            if config_name in results:\n",
    "                data = results[config_name]\n",
    "                ax.plot(data[\"k_values\"], data[metric],\n",
    "                       marker=markers[style_idx % len(markers)],\n",
    "                       linestyle=line_styles[style_idx % len(line_styles)],\n",
    "                       color=colors[style_idx % len(colors)],\n",
    "                       linewidth=2.5,\n",
    "                       label=input_name,\n",
    "                       markersize=7,\n",
    "                       alpha=0.85,\n",
    "                       markeredgewidth=1.5,\n",
    "                       markeredgecolor='white')\n",
    "\n",
    "        ax.set_xlabel(\"K (inner_channels × kernel_h × kernel_w)\", fontsize=11)\n",
    "        ax.set_ylabel(f'{metric.replace(\"_\", \" \").title()}', fontsize=11)\n",
    "        ax.set_title(f'{config_name}', fontsize=12, fontweight='bold')\n",
    "        ax.legend(fontsize=8, loc='best', framealpha=0.9)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "    fig.suptitle(f\"Conv2D Transposed (2x2 kernel) {metric.replace('_', ' ').title()} Comparison - All Input Types\",\n",
    "                 fontsize=14, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"conv_transpose_all_inputs_comparison_{metric}.png\", dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define K values to test\n",
    "    # For 2x2 kernel: K = inner_channels * 2 * 2 = inner_channels * 4\n",
    "    inner_channels_values = [64, 128, 256, 512, 1024, 2048, 3072, 4096, 8092, 10140]\n",
    "\n",
    "    print(\"=\" * 80, flush=True)\n",
    "    print(\"Testing Conv2D Transposed with 2x2 kernel\", flush=True)\n",
    "    print(\"=\" * 80, flush=True)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80, flush=True)\n",
    "    print(\"Testing with RAND input generator\", flush=True)\n",
    "    print(\"=\" * 80, flush=True)\n",
    "    results_rand = run_conv_transpose_k_sweep(inner_channels_values, input_generator=\"rand\", use_bias=True)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80, flush=True)\n",
    "    clamp_tuple = (torch.finfo(torch.bfloat16).min, torch.finfo(torch.bfloat16).max)\n",
    "    print(f\"Testing with RANDN CLAMPED [{clamp_tuple[0]:.2e},{clamp_tuple[1]:.2e}] input generator\", flush=True)\n",
    "    print(\"=\" * 80, flush=True)\n",
    "    results_randn_clamped = run_conv_transpose_k_sweep(inner_channels_values, input_generator=\"randn\", use_bias=True, clamp_tuple=clamp_tuple)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80, flush=True)\n",
    "    print(\"Testing with RANDN input generator\", flush=True)\n",
    "    print(\"=\" * 80, flush=True)\n",
    "    results_randn = run_conv_transpose_k_sweep(inner_channels_values, input_generator=\"randn\", use_bias=True)\n",
    "\n",
    "\n",
    "    # # Generate plots\n",
    "    # print(\"\\nGenerating plots...\", flush=True)\n",
    "\n",
    "    # # Create a dictionary with all results for comparison\n",
    "    # all_results = {\n",
    "    #     \"rand [0,1)\": results_rand,\n",
    "    #     \"randn (-∞,∞)\": results_randn,\n",
    "    #     f\"randn clamped [bf16_min, bf16_max]\": results_randn_clamped,\n",
    "    # }\n",
    "\n",
    "    # # Plot comparison across all input types\n",
    "    # for metric in ['max_ulp', 'p99_ulp']:\n",
    "    #     print(f\"  Plotting {metric} comparison for all input types...\", flush=True)\n",
    "    #     plot_all_inputs_comparison(all_results, metric=metric)\n",
    "\n",
    "    # print(\"\\nAll plots generated successfully!\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3350005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Tuple\n",
    "from models.common.utility_functions import ulp, comp_ulp\n",
    "import os\n",
    "from loguru import logger\n",
    "import ttnn\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "SEED = 0\n",
    "# torch.manual_seed(SEED)\n",
    "# np.random.seed(SEED)\n",
    "\n",
    "# Disable TT logging\n",
    "os.environ[\"TT_LOGGER_LEVEL\"] = \"off\"\n",
    "os.environ[\"TT_METAL_CACHE\"] = \"/localdev/astancov/tt-metal/built\"\n",
    "logger.disable(\"ttnn\")\n",
    "\n",
    "default_fig_size = (8, 5)\n",
    "\n",
    "\n",
    "def ulp_error(res, ref):\n",
    "    \"\"\"\n",
    "    Compute the ULP error (in ref ULPs) between two tensors.\n",
    "\n",
    "    Args:\n",
    "        res: Result tensor (calculated/actual)\n",
    "        ref: Reference tensor (golden/expected)\n",
    "\n",
    "    Returns:\n",
    "        tuple: (ulp_errors, ulp_details) where:\n",
    "            - ulp_errors: ULP error tensor between res and ref (in ULPs of ref)\n",
    "              Formula: |res - ref| / ULP(ref)\n",
    "            - ulp_details: dict containing:\n",
    "                - max_ulp: maximum ULP error value\n",
    "                - max_ulp_index: index tuple where max ULP occurs\n",
    "                - calculated_value: res value at max ULP location\n",
    "                - golden_value: ref value at max ULP location\n",
    "                - ulp_value: ULP(ref) value at max ULP location (to detect near-zero division)\n",
    "    \"\"\"\n",
    "    ref_ulp = ulp(ref)\n",
    "    ulp_errors = torch.abs((res.to(torch.float64) - ref.to(torch.float64)) / ref_ulp.to(torch.float64))\n",
    "\n",
    "    # Track details about max ULP error (similar to comp_ulp)\n",
    "    max_ulp = torch.max(ulp_errors)\n",
    "    ulp_index = torch.argmax(ulp_errors)\n",
    "    ulp_index_tuple = tuple(int(idx) for idx in torch.unravel_index(ulp_index, ref.shape))\n",
    "\n",
    "    ulp_details = {\n",
    "        \"max_ulp\": float(max_ulp),\n",
    "        \"max_ulp_index\": ulp_index_tuple,\n",
    "        \"calculated_value\": float(res[ulp_index_tuple]),\n",
    "        \"golden_value\": float(ref[ulp_index_tuple]),\n",
    "        \"ulp_value\": float(ref_ulp[ulp_index_tuple]),\n",
    "    }\n",
    "\n",
    "    return ulp_errors, ulp_details\n",
    "\n",
    "\n",
    "def compute_ulp_statistics(res, ref):\n",
    "    \"\"\"\n",
    "    Compute ULP error statistics.\n",
    "\n",
    "    Args:\n",
    "        res: Result tensor\n",
    "        ref: Reference tensor (numpy or torch)\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with ULP statistics including details about max ULP error\n",
    "    \"\"\"\n",
    "    # Convert numpy to torch if needed\n",
    "    if isinstance(ref, np.ndarray):\n",
    "        ref = torch.from_numpy(ref)\n",
    "\n",
    "    ulp_errors, ulp_details = ulp_error(res, ref)\n",
    "    ulp_vals = ulp_errors.detach().cpu().numpy().flatten()\n",
    "\n",
    "    stats = {\n",
    "        \"mean\": float(np.mean(ulp_vals)),\n",
    "        \"median\": float(np.median(ulp_vals)),\n",
    "        \"max\": float(np.max(ulp_vals)),\n",
    "        \"min\": float(np.min(ulp_vals)),\n",
    "        \"p95\": float(np.percentile(ulp_vals, 95)),\n",
    "        \"p99\": float(np.percentile(ulp_vals, 99)),\n",
    "    }\n",
    "\n",
    "    # Add ULP details to track near-zero division\n",
    "    stats.update(ulp_details)\n",
    "\n",
    "    return stats\n",
    "\n",
    "\n",
    "def run_ttnn_conv2d(\n",
    "    input_tensor, weight_tensor, bias_tensor, padding, stride, fp32_acc=False, device=None, use_bias=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Run conv2d in ttnn.\n",
    "\n",
    "    Args:\n",
    "        input_tensor: Input tensor (torch) in NCHW format\n",
    "        weight_tensor: Weight tensor (torch) in OIHW format\n",
    "        bias_tensor: Bias tensor (torch)\n",
    "        padding: Padding tuple (h, w)\n",
    "        stride: Stride tuple (h, w)\n",
    "        fp32_acc: Whether to use fp32 accumulation\n",
    "        device: TTNN device\n",
    "        use_bias: Whether to use bias\n",
    "\n",
    "    Returns:\n",
    "        Output tensor (torch) in NCHW format\n",
    "    \"\"\"\n",
    "    create_local_device = device is None\n",
    "    if create_local_device:\n",
    "        device = ttnn.CreateDevice(0, l1_small_size=16384)\n",
    "\n",
    "    # Extract dimensions\n",
    "    batch_size = input_tensor.shape[0]\n",
    "    in_channels = input_tensor.shape[1]\n",
    "    input_height = input_tensor.shape[2]\n",
    "    input_width = input_tensor.shape[3]\n",
    "    out_channels = weight_tensor.shape[0]\n",
    "    kernel_h = weight_tensor.shape[2]\n",
    "    kernel_w = weight_tensor.shape[3]\n",
    "\n",
    "    # Handle padding and stride\n",
    "    if isinstance(padding, int):\n",
    "        pad_h, pad_w = padding, padding\n",
    "    else:\n",
    "        pad_h, pad_w = padding[0], padding[1]\n",
    "\n",
    "    if isinstance(stride, int):\n",
    "        str_h, str_w = stride, stride\n",
    "    else:\n",
    "        str_h, str_w = stride[0], stride[1]\n",
    "\n",
    "    # Convert input from NCHW to NHWC format\n",
    "    input_nhwc = input_tensor.permute(0, 2, 3, 1).contiguous()\n",
    "\n",
    "    # Prepare bias - reshape to (1, 1, 1, out_channels) if needed\n",
    "    if use_bias:\n",
    "        if bias_tensor.dim() == 1:\n",
    "            bias_tensor = bias_tensor.reshape(1, 1, 1, -1)\n",
    "        elif bias_tensor.shape != (1, 1, 1, out_channels):\n",
    "            bias_tensor = bias_tensor.reshape(1, 1, 1, -1)\n",
    "\n",
    "    # Determine ttnn dtype\n",
    "    ttnn_dtype = ttnn.bfloat16 if input_tensor.dtype == torch.bfloat16 else ttnn.float32\n",
    "\n",
    "    # Convert to ttnn tensors\n",
    "    tt_input = ttnn.from_torch(input_nhwc, dtype=ttnn_dtype, layout=ttnn.ROW_MAJOR_LAYOUT, device=device)\n",
    "    tt_weight = ttnn.from_torch(weight_tensor, dtype=ttnn_dtype)\n",
    "    tt_bias = ttnn.from_torch(bias_tensor, dtype=ttnn_dtype) if use_bias else None\n",
    "\n",
    "    # Configure compute kernel\n",
    "    compute_config = ttnn.init_device_compute_kernel_config(\n",
    "        device.arch(),\n",
    "        math_fidelity=ttnn.MathFidelity.HiFi4,\n",
    "        math_approx_mode=False,\n",
    "        fp32_dest_acc_en=fp32_acc,\n",
    "        packer_l1_acc=True,  # l1_acc is turned on\n",
    "    )\n",
    "\n",
    "    # Run conv2d\n",
    "    [tt_output, out_dims, _] = ttnn.conv2d(\n",
    "        input_tensor=tt_input,\n",
    "        weight_tensor=tt_weight,\n",
    "        bias_tensor=tt_bias,\n",
    "        device=device,\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        batch_size=batch_size,\n",
    "        input_height=input_height,\n",
    "        input_width=input_width,\n",
    "        kernel_size=(kernel_h, kernel_w),\n",
    "        stride=(str_h, str_w),\n",
    "        padding=(pad_h, pad_h, pad_w, pad_w),\n",
    "        dilation=(1, 1),\n",
    "        groups=1,\n",
    "        compute_config=compute_config,\n",
    "        return_output_dim=True,\n",
    "        return_weights_and_bias=True,\n",
    "    )\n",
    "\n",
    "    # Convert back to torch and reshape to NCHW\n",
    "    output_torch = ttnn.to_torch(tt_output)\n",
    "    out_height, out_width = out_dims\n",
    "    output_nchw = output_torch.reshape(batch_size, out_height, out_width, out_channels).permute(0, 3, 1, 2)\n",
    "\n",
    "    if create_local_device:\n",
    "        ttnn.close_device(device)\n",
    "\n",
    "    return output_nchw\n",
    "\n",
    "\n",
    "def make_rand_seeded():\n",
    "    def rand_seeded(*args, **kwargs):\n",
    "        torch.manual_seed(SEED)\n",
    "        return torch.rand(*args, **kwargs)\n",
    "    return rand_seeded\n",
    "\n",
    "def make_randn_seeded():\n",
    "    def randn_seeded(*args, **kwargs):\n",
    "        torch.manual_seed(SEED)\n",
    "        return torch.randn(*args, **kwargs)\n",
    "    return randn_seeded\n",
    "\n",
    "def make_randn_clamped(min_val, max_val):\n",
    "    \"\"\"\n",
    "    Create a randn generator function that clamps values to [min_val, max_val].\n",
    "\n",
    "    Args:\n",
    "        min_val: Minimum value to clamp to\n",
    "        max_val: Maximum value to clamp to\n",
    "\n",
    "    Returns:\n",
    "        Function that generates clamped random normal values\n",
    "    \"\"\"\n",
    "    def randn_clamped(*args, **kwargs):\n",
    "        torch.manual_seed(SEED)\n",
    "        return torch.clamp(torch.randn(*args, **kwargs), min=min_val, max=max_val)\n",
    "\n",
    "    return randn_clamped\n",
    "\n",
    "\n",
    "def make_randn_clamped_to_dtype_max(dtype=torch.float32):\n",
    "    \"\"\"\n",
    "    Generate random normal values clamped to the maximum finite value of the given dtype.\n",
    "    This prevents infinity values from appearing in the tensors.\n",
    "\n",
    "    Args:\n",
    "        dtype: PyTorch dtype to use for clamping range\n",
    "\n",
    "    Returns:\n",
    "        Function that generates clamped random normal values\n",
    "    \"\"\"\n",
    "\n",
    "    def randn_clamped(*args, **kwargs):\n",
    "        torch.manual_seed(SEED)\n",
    "        max_val = torch.finfo(dtype).max\n",
    "        min_val = torch.finfo(dtype).min\n",
    "        return torch.clamp(torch.randn(*args, **kwargs), min=min_val, max=max_val)\n",
    "\n",
    "    return randn_clamped\n",
    "\n",
    "\n",
    "def run_conv_k_sweep(inner_channels_values, input_generator=\"rand\", use_bias=False, clamp_tuple=None):\n",
    "    \"\"\"\n",
    "    Run convolution with varying inner channels values where:\n",
    "    - K = inner_channels * kernel_h * kernel_w\n",
    "    - Activation matrix: 32 x K\n",
    "    - Weight matrix: K x 32\n",
    "\n",
    "    Args:\n",
    "        inner_channels_values: List of inner channels values to test\n",
    "        input_generator: 'rand' or 'randn' for input generation\n",
    "        use_bias: Whether to use bias\n",
    "        clamp_tuple: Tuple of (min_val, max_val) to clamp the input to\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with results for each configuration\n",
    "    \"\"\"\n",
    "    device = ttnn.CreateDevice(0, l1_small_size=16384)\n",
    "\n",
    "    # Configurations to test: (dtype, fp32_acc, name)\n",
    "    configs = [\n",
    "        (torch.bfloat16, False, \"bfp16\"),\n",
    "        (torch.bfloat16, True, \"bfp16+fp32acc\"),\n",
    "        (torch.float32, False, \"fp32\"),\n",
    "        (torch.float32, True, \"fp32+fp32acc\"),\n",
    "    ]\n",
    "    results = {\n",
    "        config[2]: {\n",
    "            \"k_values\": [],\n",
    "            \"mean_ulp\": [],\n",
    "            \"median_ulp\": [],\n",
    "            \"max_ulp\": [],\n",
    "            \"p99_ulp\": [],\n",
    "            \"all_ulp_errors\": [],\n",
    "            \"ulp_details\": [],  # Track ULP details for each K value\n",
    "        }\n",
    "        for config in configs\n",
    "    }\n",
    "\n",
    "    for inner_channels in inner_channels_values:\n",
    "        print(f\"\\nTesting inner channels={inner_channels}\", flush=True)\n",
    "\n",
    "        # Create convolution configuration\n",
    "        # Input: (N, C_in, H, W) where C_in=32 and H*W=K\n",
    "        # For simplicity, use H=K, W=1 (or factorize K for more realistic spatial dims)\n",
    "        batch_size = 1\n",
    "        in_channels = inner_channels\n",
    "        out_channels = 96\n",
    "\n",
    "        # Factorize K into H x W for more realistic spatial dimensions\n",
    "        h = 12\n",
    "        w = 8\n",
    "\n",
    "        # 1x1 convolution kernel\n",
    "        kernel_h, kernel_w = 3, 3\n",
    "        padding = (1, 1)\n",
    "        stride = (1, 1)\n",
    "\n",
    "        # Select generation function based on input_generator\n",
    "        if input_generator == \"rand\":\n",
    "            gen_fn = make_rand_seeded()\n",
    "        elif input_generator == \"randn\" and clamp_tuple is not None:\n",
    "            gen_fn = make_randn_clamped(clamp_tuple[0], clamp_tuple[1])\n",
    "        elif input_generator == \"randn\":\n",
    "            gen_fn = make_randn_seeded()\n",
    "        elif input_generator == \"randn_clamped_fp32_max\":\n",
    "            gen_fn = make_randn_clamped_to_dtype_max(torch.float32)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown input_generator: {input_generator}\")\n",
    "\n",
    "        # Generate input tensors in fp32 once for this K value\n",
    "        # All configurations will use the same input data for fair comparison\n",
    "        input_tensor_fp32 = gen_fn(batch_size, in_channels, h, w)\n",
    "        weight_tensor_fp32 = gen_fn(out_channels, in_channels, kernel_h, kernel_w)\n",
    "        bias_tensor_fp32 = gen_fn(out_channels) if use_bias else torch.zeros(out_channels)\n",
    "\n",
    "        # Test each configuration with the same input data\n",
    "        for dtype, fp32_acc, config_name in configs:\n",
    "            print(f\"  Config: {config_name}\", flush=True)\n",
    "\n",
    "            # Cast tensors to target dtype for this configuration\n",
    "            input_tensor = input_tensor_fp32.to(dtype)\n",
    "            weight_tensor = weight_tensor_fp32.to(dtype)\n",
    "            bias_tensor = bias_tensor_fp32.to(dtype)\n",
    "\n",
    "            # Compute reference in the same dtype as the configuration\n",
    "            with torch.no_grad():\n",
    "                reference = torch.nn.functional.conv2d(\n",
    "                    input_tensor, weight_tensor, bias=bias_tensor if use_bias else None, padding=padding, stride=stride\n",
    "                )\n",
    "\n",
    "            # Run TTNN conv2d\n",
    "            try:\n",
    "                ttnn_output = run_ttnn_conv2d(\n",
    "                    input_tensor,\n",
    "                    weight_tensor,\n",
    "                    bias_tensor,\n",
    "                    padding=padding,\n",
    "                    stride=stride,\n",
    "                    fp32_acc=fp32_acc,\n",
    "                    device=device,\n",
    "                    use_bias=use_bias,\n",
    "                )\n",
    "\n",
    "                # Compute ULP errors and details\n",
    "                ulp_errors_tensor, ulp_details = ulp_error(ttnn_output, reference)\n",
    "                ulp_errors = ulp_errors_tensor.detach().cpu().numpy().flatten()\n",
    "\n",
    "                # Compute statistics manually for this K\n",
    "                ulp_stats = {\n",
    "                    \"mean\": float(np.mean(ulp_errors)),\n",
    "                    \"median\": float(np.median(ulp_errors)),\n",
    "                    \"max\": float(np.max(ulp_errors)),\n",
    "                    \"p99\": float(np.percentile(ulp_errors, 99)),\n",
    "                }\n",
    "\n",
    "                results[config_name][\"k_values\"].append(inner_channels * kernel_h * kernel_w)\n",
    "                results[config_name][\"mean_ulp\"].append(ulp_stats[\"mean\"])\n",
    "                results[config_name][\"median_ulp\"].append(ulp_stats[\"median\"])\n",
    "                results[config_name][\"max_ulp\"].append(ulp_stats[\"max\"])\n",
    "                results[config_name][\"p99_ulp\"].append(ulp_stats[\"p99\"])\n",
    "\n",
    "                # Store ULP errors and details for aggregated analysis\n",
    "                results[config_name][\"all_ulp_errors\"].append(ulp_errors)\n",
    "                results[config_name][\"ulp_details\"].append(ulp_details)\n",
    "\n",
    "                # Print detailed ULP information including near-zero division detection\n",
    "                print(\n",
    "                    f\"    Mean ULP: {ulp_stats['mean']:.2f}, Median ULP: {ulp_stats['median']:.2f}, P99 ULP: {ulp_stats['p99']:.2f}, Max ULP: {ulp_stats['max']:.2f}\",\n",
    "                    flush=True,\n",
    "                )\n",
    "                print(\n",
    "                    f\"    Max ULP details @ {list(ulp_details['max_ulp_index'])}: \"\n",
    "                    f\"|{ulp_details['calculated_value']} - {ulp_details['golden_value']}| / {ulp_details['ulp_value']}\",\n",
    "                    flush=True,\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"    Error: {e}\", flush=True)\n",
    "                results[config_name][\"k_values\"].append(inner_channels * kernel_h * kernel_w)\n",
    "                results[config_name][\"mean_ulp\"].append(np.nan)\n",
    "                results[config_name][\"median_ulp\"].append(np.nan)\n",
    "                results[config_name][\"max_ulp\"].append(np.nan)\n",
    "                results[config_name][\"p99_ulp\"].append(np.nan)\n",
    "\n",
    "    # Compute aggregated statistics across all K values\n",
    "    print(\"\\n\" + \"=\" * 80, flush=True)\n",
    "    if input_generator == \"rand\":\n",
    "        values_range = \"[0,1)\"\n",
    "    elif input_generator == \"randn\" and clamp_tuple is not None:\n",
    "        values_range = f\"[{clamp_tuple[0]:.2e},{clamp_tuple[1]:.2e}]\"\n",
    "    elif input_generator == \"randn_clamped_fp32_max\":\n",
    "        max_fp32 = torch.finfo(torch.float32).max\n",
    "        values_range = f\"[{torch.finfo(torch.float32).min:.2e},{max_fp32:.2e}]\"\n",
    "    else:\n",
    "        values_range = \"(-inf,inf)\"\n",
    "    print(\n",
    "        f\"AGGREGATED STATISTICS (All K values combined) - values: {values_range}\",\n",
    "        flush=True,\n",
    "    )\n",
    "    print(\"=\" * 80, flush=True)\n",
    "\n",
    "    aggregated_stats = {}\n",
    "    for config_name in results.keys():\n",
    "        if len(results[config_name][\"all_ulp_errors\"]) > 0:\n",
    "            # Concatenate all ULP error arrays\n",
    "            all_ulp_errors = np.concatenate(results[config_name][\"all_ulp_errors\"])\n",
    "\n",
    "            # Find the worst-case ULP details across all K values\n",
    "            ulp_details_list = results[config_name][\"ulp_details\"]\n",
    "            worst_case_idx = max(range(len(ulp_details_list)), key=lambda i: ulp_details_list[i][\"max_ulp\"])\n",
    "            worst_case_details = ulp_details_list[worst_case_idx]\n",
    "            worst_case_k = results[config_name][\"k_values\"][worst_case_idx]\n",
    "\n",
    "            # Compute statistics on combined ULP errors\n",
    "            agg_stats = {\n",
    "                \"mean\": float(np.mean(all_ulp_errors)),\n",
    "                \"median\": float(np.median(all_ulp_errors)),\n",
    "                \"max\": float(np.max(all_ulp_errors)),\n",
    "                \"min\": float(np.min(all_ulp_errors)),\n",
    "                \"p95\": float(np.percentile(all_ulp_errors, 95)),\n",
    "                \"p99\": float(np.percentile(all_ulp_errors, 99)),\n",
    "                \"worst_case_details\": worst_case_details,\n",
    "                \"worst_case_k\": worst_case_k,\n",
    "            }\n",
    "            aggregated_stats[config_name] = agg_stats\n",
    "\n",
    "            print(f\"\\n{config_name}:\", flush=True)\n",
    "            print(f\"  K values tested: {results[config_name]['k_values']}\", flush=True)\n",
    "            print(f\"  Total samples: {len(all_ulp_errors)}\", flush=True)\n",
    "            print(f\"  Mean ULP:   {agg_stats['mean']:.4f}\", flush=True)\n",
    "            print(f\"  Median ULP: {agg_stats['median']:.4f}\", flush=True)\n",
    "            print(f\"  Max ULP:    {agg_stats['max']:.4f}\", flush=True)\n",
    "            print(f\"  P95 ULP:    {agg_stats['p95']:.4f}\", flush=True)\n",
    "            print(f\"  P99 ULP:    {agg_stats['p99']:.4f}\", flush=True)\n",
    "            print(f\"  Worst case ULP details (K={worst_case_k}):\", flush=True)\n",
    "            print(\n",
    "                f\"    @ {list(worst_case_details['max_ulp_index'])}: \"\n",
    "                f\"|{worst_case_details['calculated_value']:.6e} - {worst_case_details['golden_value']:.6e}| / {worst_case_details['ulp_value']:.6e}\",\n",
    "                flush=True,\n",
    "            )\n",
    "\n",
    "    results[\"_aggregated\"] = aggregated_stats\n",
    "\n",
    "    ttnn.close_device(device)\n",
    "    return results\n",
    "\n",
    "\n",
    "def plot_k_sweep_results(results, input_generator, metric=\"mean_ulp\"):\n",
    "    \"\"\"\n",
    "    Plot ULP results across K values for different configurations.\n",
    "\n",
    "    Args:\n",
    "        results: Dictionary with results from run_conv_k_sweep\n",
    "        input_generator: Name of input generator used ('rand' or 'randn')\n",
    "        metric: Which ULP metric to plot ('mean_ulp', 'median_ulp', or 'max_ulp')\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 7))\n",
    "\n",
    "    for config_name, data in results.items():\n",
    "        if config_name != \"_aggregated\":  # Skip aggregated stats\n",
    "            plt.plot(data[\"k_values\"], data[metric], marker=\"o\", linewidth=2, label=config_name, markersize=8)\n",
    "\n",
    "    plt.xlabel(\"K (inner_channels * kernel_h * kernel_w)\", fontsize=12)\n",
    "    plt.ylabel(f'{metric.replace(\"_\", \" \").title()}', fontsize=12)\n",
    "    plt.title(f\"Conv2D (3x3 kernel) ULP vs K - {input_generator} inputs\", fontsize=14)\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"conv_k_sweep_{input_generator}_{metric}.png\", dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_aggregated_comparison(results, input_generator):\n",
    "    \"\"\"\n",
    "    Plot aggregated ULP statistics comparison across all K values.\n",
    "\n",
    "    Args:\n",
    "        results: Dictionary with results from run_conv_k_sweep\n",
    "        input_generator: Name of input generator used ('rand' or 'randn')\n",
    "    \"\"\"\n",
    "    if \"_aggregated\" not in results:\n",
    "        print(\"No aggregated statistics available\", flush=True)\n",
    "        return\n",
    "\n",
    "    aggregated = results[\"_aggregated\"]\n",
    "    config_names = list(aggregated.keys())\n",
    "    metrics = [\"p95\", \"p99\", \"max\"]\n",
    "\n",
    "    # Prepare data for plotting\n",
    "    data_by_metric = {metric: [] for metric in metrics}\n",
    "    for config_name in config_names:\n",
    "        for metric in metrics:\n",
    "            data_by_metric[metric].append(aggregated[config_name][metric])\n",
    "\n",
    "    # Create bar plot\n",
    "    x = np.arange(len(config_names))\n",
    "    width = 0.15\n",
    "    fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "    for i, metric in enumerate(metrics):\n",
    "        offset = width * (i - len(metrics) / 2 + 0.5)\n",
    "        bars = ax.bar(x + offset, data_by_metric[metric], width, label=metric.upper())\n",
    "\n",
    "        # Add value labels on bars\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width() / 2.0, height, f\"{height:.1f}\", ha=\"center\", va=\"bottom\", fontsize=7)\n",
    "\n",
    "    ax.set_xlabel(\"Configuration\", fontsize=12)\n",
    "    ax.set_ylabel(\"ULP Error\", fontsize=12)\n",
    "    ax.set_title(f\"Conv2D (3x3 kernel) Aggregated ULP Statistics - {input_generator} inputs\", fontsize=14)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(config_names, rotation=20, ha=\"right\")\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"conv_k_sweep_{input_generator}_aggregated.png\", dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_all_inputs_comparison(all_results_dict, metric=\"max_ulp\"):\n",
    "    \"\"\"\n",
    "    Plot ULP results across K values for all input types on the same graph.\n",
    "\n",
    "    Args:\n",
    "        all_results_dict: Dictionary mapping input type names to their results\n",
    "        metric: Which ULP metric to plot ('mean_ulp', 'median_ulp', or 'max_ulp')\n",
    "    \"\"\"\n",
    "    configs = [\"bfp16\", \"bfp16+fp32acc\", \"fp32\", \"fp32+fp32acc\"]\n",
    "\n",
    "    # Define distinct line styles, markers, and colors for each input type\n",
    "    line_styles = ['-', '--', '-.', ':', '-']\n",
    "    markers = ['o', 's', '^', 'D', 'v']\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "\n",
    "    # Create subplots: one for each configuration\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, config_name in enumerate(configs):\n",
    "        ax = axes[idx]\n",
    "\n",
    "        for style_idx, (input_name, results) in enumerate(all_results_dict.items()):\n",
    "            if config_name in results:\n",
    "                data = results[config_name]\n",
    "                ax.plot(data[\"k_values\"], data[metric],\n",
    "                       marker=markers[style_idx % len(markers)],\n",
    "                       linestyle=line_styles[style_idx % len(line_styles)],\n",
    "                       color=colors[style_idx % len(colors)],\n",
    "                       linewidth=2.5,\n",
    "                       label=input_name,\n",
    "                       markersize=7,\n",
    "                       alpha=0.85,\n",
    "                       markeredgewidth=1.5,\n",
    "                       markeredgecolor='white')\n",
    "\n",
    "        ax.set_xlabel(\"K (inner_channels × kernel_h × kernel_w)\", fontsize=11)\n",
    "        ax.set_ylabel(f'{metric.replace(\"_\", \" \").title()}', fontsize=11)\n",
    "        ax.set_title(f'{config_name}', fontsize=12, fontweight='bold')\n",
    "        ax.legend(fontsize=8, loc='best', framealpha=0.9)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "    fig.suptitle(f\"Conv2D (3x3 kernel) {metric.replace('_', ' ').title()} Comparison - All Input Types\",\n",
    "                 fontsize=14, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"conv_all_inputs_comparison_{metric}.png\", dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define K values to test\n",
    "    # For 3x3 kernel: K = inner_channels * 3 * 3 = inner_channels * 9\n",
    "    inner_channels_values = [64, 128, 256, 512, 1024, 2048, 3072, 4096, 8092, 10140]\n",
    "\n",
    "    print(\"=\" * 80, flush=True)\n",
    "    print(\"Testing Conv2D with 3x3 kernel\", flush=True)\n",
    "    print(\"=\" * 80, flush=True)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80, flush=True)\n",
    "    print(\"Testing with RAND input generator\", flush=True)\n",
    "    print(\"=\" * 80, flush=True)\n",
    "    results_rand = run_conv_k_sweep(inner_channels_values, input_generator=\"rand\", use_bias=True)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80, flush=True)\n",
    "    clamp_tuple = (torch.finfo(torch.bfloat16).min, torch.finfo(torch.bfloat16).max)\n",
    "    print(f\"Testing with RANDN CLAMPED [{clamp_tuple[0]:.2e},{clamp_tuple[1]:.2e}] input generator\", flush=True)\n",
    "    print(\"=\" * 80, flush=True)\n",
    "    results_randn_clamped = run_conv_k_sweep(inner_channels_values, input_generator=\"randn\", use_bias=True, clamp_tuple=clamp_tuple)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80, flush=True)\n",
    "    print(\"Testing with RANDN input generator\", flush=True)\n",
    "    print(\"=\" * 80, flush=True)\n",
    "    results_randn = run_conv_k_sweep(inner_channels_values, input_generator=\"randn\", use_bias=True)\n",
    "\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80, flush=True)\n",
    "    eps = torch.finfo(torch.bfloat16).eps\n",
    "    clamp_tuple = (-1 + eps,1 - eps)\n",
    "    print(f\"Testing with RANDN CLAMPED [{clamp_tuple[0]},{clamp_tuple[1]}] input generator\", flush=True)\n",
    "    print(\"=\" * 80, flush=True)\n",
    "    results_randn_clamped_eps = run_conv_k_sweep(inner_channels_values, input_generator=\"randn\", use_bias=True, clamp_tuple=clamp_tuple)\n",
    "\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80, flush=True)\n",
    "    eps = torch.finfo(torch.bfloat16).eps\n",
    "    clamp_tuple = (0, 1 - eps)\n",
    "    print(f\"Testing with RANDN CLAMPED [{clamp_tuple[0]},{clamp_tuple[1]}] input generator\", flush=True)\n",
    "    print(\"=\" * 80, flush=True)\n",
    "    results_randn_clamped_0_1 = run_conv_k_sweep(inner_channels_values, input_generator=\"randn\", use_bias=True, clamp_tuple=clamp_tuple)\n",
    "\n",
    "    # Generate plots\n",
    "    print(\"\\nGenerating plots...\", flush=True)\n",
    "\n",
    "    # Create a dictionary with all results for comparison\n",
    "    all_results = {\n",
    "        \"rand [0,1)\": results_rand,\n",
    "        \"randn (-∞,∞)\": results_randn,\n",
    "        f\"randn clamped [bf16_min, bf16_max]\": results_randn_clamped,\n",
    "        f\"randn clamped [-1+ε, 1-ε]\": results_randn_clamped_eps,\n",
    "        f\"randn clamped [0, 1-ε]\": results_randn_clamped_0_1,\n",
    "    }\n",
    "\n",
    "    # Plot comparison across all input types\n",
    "    for metric in ['max_ulp', 'p99_ulp']:\n",
    "        print(f\"  Plotting {metric} comparison for all input types...\", flush=True)\n",
    "        plot_all_inputs_comparison(all_results, metric=metric)\n",
    "\n",
    "    print(\"\\nAll plots generated successfully!\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9441e892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Tuple\n",
    "from models.common.utility_functions import ulp\n",
    "import os\n",
    "from loguru import logger\n",
    "import ttnn\n",
    "\n",
    "# Disable TT logging\n",
    "os.environ[\"TT_LOGGER_LEVEL\"] = \"off\"\n",
    "os.environ[\"TT_METAL_CACHE\"] = \"/localdev/astancov/tt-metal/built\"\n",
    "logger.disable(\"ttnn\")\n",
    "\n",
    "default_fig_size = (8, 5)\n",
    "\n",
    "\n",
    "def ulp_error(res, ref):\n",
    "    \"\"\"\n",
    "    Compute the ULP error (in ref ULPs) between two tensors.\n",
    "\n",
    "    Args:\n",
    "        res: Result tensor (calculated/actual)\n",
    "        ref: Reference tensor (golden/expected)\n",
    "\n",
    "    Returns:\n",
    "        tuple: (ulp_errors, ulp_details) where:\n",
    "            - ulp_errors: ULP error tensor between res and ref (in ULPs of ref)\n",
    "            - ulp_details: dict containing max ULP error location and values\n",
    "    \"\"\"\n",
    "    ref_ulp = ulp(ref)\n",
    "    ulp_errors = torch.abs((res.to(torch.float64) - ref.to(torch.float64)) / ref_ulp.to(torch.float64))\n",
    "    # ulp_errors = torch.abs((res - ref) / ref_ulp)\n",
    "\n",
    "\n",
    "    # Track details about max ULP error\n",
    "    max_ulp = torch.max(ulp_errors)\n",
    "    ulp_index = torch.argmax(ulp_errors)\n",
    "    ulp_index_tuple = tuple(int(idx) for idx in torch.unravel_index(ulp_index, ref.shape))\n",
    "\n",
    "    ulp_details = {\n",
    "        \"max_ulp\": float(max_ulp),\n",
    "        \"max_ulp_index\": ulp_index_tuple,\n",
    "        \"calculated_value\": float(res[ulp_index_tuple]),\n",
    "        \"golden_value\": float(ref[ulp_index_tuple]),\n",
    "        \"ulp_value\": float(ref_ulp[ulp_index_tuple]),\n",
    "    }\n",
    "\n",
    "    return ulp_errors, ulp_details\n",
    "\n",
    "\n",
    "def run_ttnn_conv2d(\n",
    "    input_tensor, weight_tensor, bias_tensor, padding, stride, fp32_acc=False, device=None, use_bias=True\n",
    "):\n",
    "    \"\"\"Run conv2d in ttnn.\"\"\"\n",
    "    create_local_device = device is None\n",
    "    if create_local_device:\n",
    "        device = ttnn.CreateDevice(0, l1_small_size=16384)\n",
    "\n",
    "    # Extract dimensions\n",
    "    batch_size = input_tensor.shape[0]\n",
    "    in_channels = input_tensor.shape[1]\n",
    "    input_height = input_tensor.shape[2]\n",
    "    input_width = input_tensor.shape[3]\n",
    "    out_channels = weight_tensor.shape[0]\n",
    "    kernel_h = weight_tensor.shape[2]\n",
    "    kernel_w = weight_tensor.shape[3]\n",
    "\n",
    "    # Handle padding and stride\n",
    "    if isinstance(padding, int):\n",
    "        pad_h, pad_w = padding, padding\n",
    "    else:\n",
    "        pad_h, pad_w = padding[0], padding[1]\n",
    "\n",
    "    if isinstance(stride, int):\n",
    "        str_h, str_w = stride, stride\n",
    "    else:\n",
    "        str_h, str_w = stride[0], stride[1]\n",
    "\n",
    "    # Convert input from NCHW to NHWC format\n",
    "    input_nhwc = input_tensor.permute(0, 2, 3, 1).contiguous()\n",
    "\n",
    "    # Prepare bias - reshape to (1, 1, 1, out_channels) if needed\n",
    "    if use_bias:\n",
    "        if bias_tensor.dim() == 1:\n",
    "            bias_tensor = bias_tensor.reshape(1, 1, 1, -1)\n",
    "        elif bias_tensor.shape != (1, 1, 1, out_channels):\n",
    "            bias_tensor = bias_tensor.reshape(1, 1, 1, -1)\n",
    "\n",
    "    # Determine ttnn dtype\n",
    "    ttnn_dtype = ttnn.bfloat16 if input_tensor.dtype == torch.bfloat16 else ttnn.float32\n",
    "\n",
    "    # Convert to ttnn tensors\n",
    "    tt_input = ttnn.from_torch(input_nhwc, dtype=ttnn_dtype, layout=ttnn.ROW_MAJOR_LAYOUT, device=device)\n",
    "    tt_weight = ttnn.from_torch(weight_tensor, dtype=ttnn_dtype)\n",
    "    tt_bias = ttnn.from_torch(bias_tensor, dtype=ttnn_dtype) if use_bias else None\n",
    "\n",
    "    # Configure compute kernel\n",
    "    compute_config = ttnn.init_device_compute_kernel_config(\n",
    "        device.arch(),\n",
    "        math_fidelity=ttnn.MathFidelity.HiFi4,\n",
    "        math_approx_mode=False,\n",
    "        fp32_dest_acc_en=fp32_acc,\n",
    "        packer_l1_acc=True,\n",
    "    )\n",
    "\n",
    "    # Run conv2d\n",
    "    [tt_output, out_dims, _] = ttnn.conv2d(\n",
    "        input_tensor=tt_input,\n",
    "        weight_tensor=tt_weight,\n",
    "        bias_tensor=tt_bias,\n",
    "        device=device,\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        batch_size=batch_size,\n",
    "        input_height=input_height,\n",
    "        input_width=input_width,\n",
    "        kernel_size=(kernel_h, kernel_w),\n",
    "        stride=(str_h, str_w),\n",
    "        padding=(pad_h, pad_h, pad_w, pad_w),\n",
    "        dilation=(1, 1),\n",
    "        groups=1,\n",
    "        compute_config=compute_config,\n",
    "        return_output_dim=True,\n",
    "        return_weights_and_bias=True,\n",
    "    )\n",
    "\n",
    "    # Convert back to torch and reshape to NCHW\n",
    "    output_torch = ttnn.to_torch(tt_output,dtype=input_tensor.dtype)\n",
    "    out_height, out_width = out_dims\n",
    "    output_nchw = output_torch.reshape(batch_size, out_height, out_width, out_channels).permute(0, 3, 1, 2)\n",
    "\n",
    "    if create_local_device:\n",
    "        ttnn.close_device(device)\n",
    "\n",
    "    return output_nchw\n",
    "\n",
    "\n",
    "def run_ttnn_conv_transpose2d(\n",
    "    input_tensor, weight_tensor, bias_tensor, padding, stride, output_padding=(0, 0), fp32_acc=False, device=None, use_bias=True\n",
    "):\n",
    "    \"\"\"Run conv_transpose2d in ttnn.\"\"\"\n",
    "    create_local_device = device is None\n",
    "    if create_local_device:\n",
    "        device = ttnn.CreateDevice(0, l1_small_size=16384)\n",
    "\n",
    "    # Extract dimensions\n",
    "    batch_size = input_tensor.shape[0]\n",
    "    in_channels = input_tensor.shape[1]\n",
    "    input_height = input_tensor.shape[2]\n",
    "    input_width = input_tensor.shape[3]\n",
    "    out_channels = weight_tensor.shape[1]  # Note: weight is IOHW for transposed conv\n",
    "    kernel_h = weight_tensor.shape[2]\n",
    "    kernel_w = weight_tensor.shape[3]\n",
    "\n",
    "    # Handle padding and stride\n",
    "    if isinstance(padding, int):\n",
    "        pad_h, pad_w = padding, padding\n",
    "    else:\n",
    "        pad_h, pad_w = padding[0], padding[1]\n",
    "\n",
    "    if isinstance(stride, int):\n",
    "        str_h, str_w = stride, stride\n",
    "    else:\n",
    "        str_h, str_w = stride[0], stride[1]\n",
    "\n",
    "    if isinstance(output_padding, int):\n",
    "        out_pad_h, out_pad_w = output_padding, output_padding\n",
    "    else:\n",
    "        out_pad_h, out_pad_w = output_padding[0], output_padding[1]\n",
    "\n",
    "    # Convert input from NCHW to NHWC format\n",
    "    input_nhwc = input_tensor.permute(0, 2, 3, 1).contiguous()\n",
    "\n",
    "    # Prepare bias - reshape to (1, 1, 1, out_channels) if needed\n",
    "    if use_bias:\n",
    "        if bias_tensor.dim() == 1:\n",
    "            bias_tensor = bias_tensor.reshape(1, 1, 1, -1)\n",
    "        elif bias_tensor.shape != (1, 1, 1, out_channels):\n",
    "            bias_tensor = bias_tensor.reshape(1, 1, 1, -1)\n",
    "\n",
    "    # Determine ttnn dtype\n",
    "    ttnn_dtype = ttnn.bfloat16 if input_tensor.dtype == torch.bfloat16 else ttnn.float32\n",
    "\n",
    "    # Convert to ttnn tensors\n",
    "    tt_input = ttnn.from_torch(input_nhwc, dtype=ttnn_dtype, layout=ttnn.ROW_MAJOR_LAYOUT, device=device)\n",
    "    tt_weight = ttnn.from_torch(weight_tensor, dtype=ttnn_dtype)\n",
    "    tt_bias = ttnn.from_torch(bias_tensor, dtype=ttnn_dtype) if use_bias else None\n",
    "\n",
    "    # Configure compute kernel\n",
    "    compute_config = ttnn.init_device_compute_kernel_config(\n",
    "        device.arch(),\n",
    "        math_fidelity=ttnn.MathFidelity.HiFi4,\n",
    "        math_approx_mode=False,\n",
    "        fp32_dest_acc_en=fp32_acc,\n",
    "        packer_l1_acc=True,\n",
    "    )\n",
    "\n",
    "    # Run conv_transpose2d\n",
    "    [tt_output, out_dims, _] = ttnn.conv_transpose2d(\n",
    "        input_tensor=tt_input,\n",
    "        weight_tensor=tt_weight,\n",
    "        bias_tensor=tt_bias,\n",
    "        device=device,\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        batch_size=batch_size,\n",
    "        input_height=input_height,\n",
    "        input_width=input_width,\n",
    "        kernel_size=(kernel_h, kernel_w),\n",
    "        stride=(str_h, str_w),\n",
    "        padding=(pad_h, pad_w),\n",
    "        output_padding=(out_pad_h, out_pad_w),\n",
    "        dilation=(1, 1),\n",
    "        groups=1,\n",
    "        compute_config=compute_config,\n",
    "        return_output_dim=True,\n",
    "        return_weights_and_bias=True,\n",
    "        dtype=ttnn_dtype,\n",
    "    )\n",
    "\n",
    "    # Convert back to torch and reshape to NCHW\n",
    "    output_torch = ttnn.to_torch(tt_output,dtype=input_tensor.dtype)\n",
    "    out_height, out_width = out_dims\n",
    "    output_nchw = output_torch.reshape(batch_size, out_height, out_width, out_channels).permute(0, 3, 1, 2)\n",
    "    # Trim to actual output channels\n",
    "    output_nchw = output_nchw[:, :out_channels, :, :]\n",
    "\n",
    "    if create_local_device:\n",
    "        ttnn.close_device(device)\n",
    "\n",
    "    return output_nchw\n",
    "\n",
    "\n",
    "def run_conv_k_sweep_with_seed_variation(\n",
    "    inner_channels_values,\n",
    "    num_iterations=5,\n",
    "    input_generator=\"rand\",\n",
    "    use_bias=False,\n",
    "    conv_type=\"conv2d\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Run convolution with varying inner channels values, repeating each K with different random seeds.\n",
    "\n",
    "    Args:\n",
    "        inner_channels_values: List of inner channels values to test\n",
    "        num_iterations: Number of times to run each K value with different random data\n",
    "        input_generator: 'rand' or 'randn' for input generation\n",
    "        use_bias: Whether to use bias\n",
    "        conv_type: 'conv2d' or 'conv_transpose2d'\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with results for each configuration\n",
    "    \"\"\"\n",
    "    # Configurations to test: (dtype, fp32_acc, name)\n",
    "    configs = [\n",
    "        (torch.bfloat16, False, \"bfp16\"),\n",
    "        (torch.bfloat16, True, \"bfp16+fp32acc\"),\n",
    "        (torch.float32, False, \"fp32\"),\n",
    "        (torch.float32, True, \"fp32+fp32acc\"),\n",
    "    ]\n",
    "\n",
    "    results = {\n",
    "        config[2]: {\n",
    "            \"k_values\": [],\n",
    "            \"max_ulp_mean\": [],        # Mean of max_ulp across iterations\n",
    "            \"max_ulp_std\": [],         # Std dev of max_ulp across iterations\n",
    "            \"max_ulp_min\": [],         # Min of max_ulp across iterations\n",
    "            \"max_ulp_max\": [],         # Max of max_ulp across iterations\n",
    "            \"max_ulp_all_iterations\": [],  # List of lists: all max_ulp values for each K\n",
    "            \"max_ulp_details\": [],     # List of lists: ulp_details for each K and iteration\n",
    "            \"p99_ulp_mean\": [],\n",
    "            \"p99_ulp_std\": [],\n",
    "        }\n",
    "        for config in configs\n",
    "    }\n",
    "\n",
    "    # Set up conv parameters based on type\n",
    "    if conv_type == \"conv2d\":\n",
    "        kernel_h, kernel_w = 3, 3\n",
    "        padding = (1, 1)\n",
    "        stride = (1, 1)\n",
    "        output_padding = None\n",
    "    else:  # conv_transpose2d\n",
    "        kernel_h, kernel_w = 2, 2\n",
    "        padding = (0, 0)\n",
    "        stride = (2, 2)\n",
    "        output_padding = (0, 0)\n",
    "\n",
    "    for inner_channels in inner_channels_values:\n",
    "        print(f\"\\nTesting inner channels={inner_channels}\", flush=True)\n",
    "\n",
    "        # Create convolution configuration\n",
    "        batch_size = 1\n",
    "        in_channels = inner_channels\n",
    "        out_channels = 96\n",
    "        h = 12\n",
    "        w = 8\n",
    "\n",
    "        k_value = inner_channels * kernel_h * kernel_w\n",
    "\n",
    "        # Store max_ulp for each iteration for each config\n",
    "        iteration_results = {config[2]: {\"max_ulp\": [], \"p99_ulp\": [], \"ulp_details\": []} for config in configs}\n",
    "\n",
    "        for iteration in range(num_iterations):\n",
    "            print(f\"  Iteration {iteration + 1}/{num_iterations}\", flush=True)\n",
    "\n",
    "            # Generate new random data for this iteration (no seed set)\n",
    "            if input_generator == \"rand\":\n",
    "                input_tensor_fp32 = torch.rand(batch_size, in_channels, h, w)\n",
    "                if conv_type == \"conv2d\":\n",
    "                    weight_tensor_fp32 = torch.rand(out_channels, in_channels, kernel_h, kernel_w)\n",
    "                else:\n",
    "                    weight_tensor_fp32 = torch.rand(in_channels, out_channels, kernel_h, kernel_w)\n",
    "                bias_tensor_fp32 = torch.rand(out_channels) if use_bias else torch.zeros(out_channels)\n",
    "            elif input_generator == \"randn\":\n",
    "                input_tensor_fp32 = torch.randn(batch_size, in_channels, h, w)\n",
    "                if conv_type == \"conv2d\":\n",
    "                    weight_tensor_fp32 = torch.randn(out_channels, in_channels, kernel_h, kernel_w)\n",
    "                else:\n",
    "                    weight_tensor_fp32 = torch.randn(in_channels, out_channels, kernel_h, kernel_w)\n",
    "                bias_tensor_fp32 = torch.randn(out_channels) if use_bias else torch.zeros(out_channels)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown input_generator: {input_generator}\")\n",
    "\n",
    "            # Test each configuration with this random data\n",
    "            for dtype, fp32_acc, config_name in configs:\n",
    "                # Cast tensors to target dtype\n",
    "                input_tensor = input_tensor_fp32.to(dtype)\n",
    "                weight_tensor = weight_tensor_fp32.to(dtype)\n",
    "                bias_tensor = bias_tensor_fp32.to(dtype)\n",
    "\n",
    "                # Compute reference\n",
    "                with torch.no_grad():\n",
    "                    if conv_type == \"conv2d\":\n",
    "                        reference = torch.nn.functional.conv2d(\n",
    "                            input_tensor,\n",
    "                            weight_tensor,\n",
    "                            bias=bias_tensor if use_bias else None,\n",
    "                            padding=padding,\n",
    "                            stride=stride,\n",
    "                        )\n",
    "                    else:  # conv_transpose2d\n",
    "                        reference = torch.nn.functional.conv_transpose2d(\n",
    "                            input_tensor,\n",
    "                            weight_tensor,\n",
    "                            bias=bias_tensor if use_bias else None,\n",
    "                            padding=padding,\n",
    "                            stride=stride,\n",
    "                            output_padding=output_padding,\n",
    "                        )\n",
    "\n",
    "                # Run TTNN convolution (device will be created and closed internally)\n",
    "                try:\n",
    "                    if conv_type == \"conv2d\":\n",
    "                        ttnn_output = run_ttnn_conv2d(\n",
    "                            input_tensor,\n",
    "                            weight_tensor,\n",
    "                            bias_tensor,\n",
    "                            padding=padding,\n",
    "                            stride=stride,\n",
    "                            fp32_acc=fp32_acc,\n",
    "                            device=None,\n",
    "                            use_bias=use_bias,\n",
    "                        )\n",
    "                    else:  # conv_transpose2d\n",
    "                        ttnn_output = run_ttnn_conv_transpose2d(\n",
    "                            input_tensor,\n",
    "                            weight_tensor,\n",
    "                            bias_tensor,\n",
    "                            padding=padding,\n",
    "                            stride=stride,\n",
    "                            output_padding=output_padding,\n",
    "                            fp32_acc=fp32_acc,\n",
    "                            device=None,\n",
    "                            use_bias=use_bias,\n",
    "                        )\n",
    "\n",
    "                    # Compute ULP errors\n",
    "                    ulp_errors_tensor, ulp_details = ulp_error(ttnn_output, reference)\n",
    "                    ulp_errors = ulp_errors_tensor.detach().cpu().numpy().flatten()\n",
    "\n",
    "                    max_ulp = float(np.max(ulp_errors))\n",
    "                    p99_ulp = float(np.percentile(ulp_errors, 99))\n",
    "\n",
    "                    iteration_results[config_name][\"max_ulp\"].append(max_ulp)\n",
    "                    iteration_results[config_name][\"p99_ulp\"].append(p99_ulp)\n",
    "                    iteration_results[config_name][\"ulp_details\"].append(ulp_details)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"    Error in {config_name}: {e}\", flush=True)\n",
    "                    iteration_results[config_name][\"max_ulp\"].append(np.nan)\n",
    "                    iteration_results[config_name][\"p99_ulp\"].append(np.nan)\n",
    "                    iteration_results[config_name][\"ulp_details\"].append(None)\n",
    "\n",
    "        # Compute statistics across iterations for each config\n",
    "        for config_name in [config[2] for config in configs]:\n",
    "            max_ulp_values = iteration_results[config_name][\"max_ulp\"]\n",
    "            p99_ulp_values = iteration_results[config_name][\"p99_ulp\"]\n",
    "            ulp_details_list = iteration_results[config_name][\"ulp_details\"]\n",
    "\n",
    "            # Filter out NaNs and corresponding details\n",
    "            valid_indices = [i for i, v in enumerate(max_ulp_values) if not np.isnan(v)]\n",
    "            max_ulp_values = [max_ulp_values[i] for i in valid_indices]\n",
    "            p99_ulp_values = [p99_ulp_values[i] for i in valid_indices]\n",
    "            ulp_details_list = [ulp_details_list[i] for i in valid_indices]\n",
    "\n",
    "            if len(max_ulp_values) > 0:\n",
    "                results[config_name][\"k_values\"].append(k_value)\n",
    "                results[config_name][\"max_ulp_mean\"].append(np.mean(max_ulp_values))\n",
    "                results[config_name][\"max_ulp_std\"].append(np.std(max_ulp_values))\n",
    "                results[config_name][\"max_ulp_min\"].append(np.min(max_ulp_values))\n",
    "                results[config_name][\"max_ulp_max\"].append(np.max(max_ulp_values))\n",
    "                results[config_name][\"max_ulp_all_iterations\"].append(max_ulp_values)\n",
    "                results[config_name][\"max_ulp_details\"].append(ulp_details_list)\n",
    "                results[config_name][\"p99_ulp_mean\"].append(np.mean(p99_ulp_values))\n",
    "                results[config_name][\"p99_ulp_std\"].append(np.std(p99_ulp_values))\n",
    "\n",
    "                # Print breakdown of individual seed values\n",
    "                print(f\"    {config_name}: K={k_value}\", flush=True)\n",
    "                print(f\"      Individual max_ulp values: {[f'{v:.2f}' for v in max_ulp_values]}\", flush=True)\n",
    "                print(f\"      Min: {np.min(max_ulp_values):.2f}, Max: {np.max(max_ulp_values):.2f}, \"\n",
    "                      f\"Mean: {np.mean(max_ulp_values):.2f}, Std: {np.std(max_ulp_values):.2f}\", flush=True)\n",
    "\n",
    "    # Print summary breakdown with calculation details\n",
    "    print(\"\\n\" + \"=\" * 80, flush=True)\n",
    "    print(\"SUMMARY: Max ULP Breakdown by K and Iteration with Calculation Details\", flush=True)\n",
    "    print(\"=\" * 80, flush=True)\n",
    "\n",
    "    for config_name in [config[2] for config in configs]:\n",
    "        if len(results[config_name][\"k_values\"]) > 0:\n",
    "            print(f\"\\n{config_name}:\", flush=True)\n",
    "            print(\"-\" * 80, flush=True)\n",
    "            for i, k_value in enumerate(results[config_name][\"k_values\"]):\n",
    "                max_ulp_values = results[config_name][\"max_ulp_all_iterations\"][i]\n",
    "                ulp_details_list = results[config_name][\"max_ulp_details\"][i]\n",
    "                print(f\"  K={k_value}:\", flush=True)\n",
    "                for iter_idx, (val, details) in enumerate(zip(max_ulp_values, ulp_details_list)):\n",
    "                    if details is not None:\n",
    "                        res_val = details[\"calculated_value\"]\n",
    "                        ref_val = details[\"golden_value\"]\n",
    "                        ulp_val = details[\"ulp_value\"]\n",
    "                        diff = abs(res_val - ref_val)\n",
    "                        print(f\"    Iteration {iter_idx}: max_ulp = {val:.4f}\", flush=True)\n",
    "                        print(f\"      |res - ref| / ulp(ref) = |{res_val:.6e} - {ref_val:.6e}| / {ulp_val:.6e}\", flush=True)\n",
    "                        print(f\"                            = {diff:.6e} / {ulp_val:.6e} = {val:.4f}\", flush=True)\n",
    "                    else:\n",
    "                        print(f\"    Iteration {iter_idx}: max_ulp = {val:.4f}\", flush=True)\n",
    "                print(f\"    → Min={min(max_ulp_values):.4f}, Max={max(max_ulp_values):.4f}\", flush=True)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def plot_seed_variation_results(results, input_generator, conv_type=\"conv2d\"):\n",
    "    \"\"\"\n",
    "    Plot max ULP variation across different random seeds.\n",
    "\n",
    "    Args:\n",
    "        results: Dictionary with results from run_conv_k_sweep_with_seed_variation\n",
    "        input_generator: Name of input generator used\n",
    "        conv_type: Type of convolution ('conv2d' or 'conv_transpose2d')\n",
    "    \"\"\"\n",
    "    configs = [\"bfp16\", \"bfp16+fp32acc\", \"fp32\", \"fp32+fp32acc\"]\n",
    "\n",
    "    kernel_str = \"3x3\" if conv_type == \"conv2d\" else \"2x2\"\n",
    "    op_str = \"Conv2D\" if conv_type == \"conv2d\" else \"Conv2D Transposed\"\n",
    "\n",
    "    # Create subplots: one for each configuration\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, config_name in enumerate(configs):\n",
    "        ax = axes[idx]\n",
    "        data = results[config_name]\n",
    "\n",
    "        if len(data[\"k_values\"]) == 0:\n",
    "            continue\n",
    "\n",
    "        k_values = data[\"k_values\"]\n",
    "        max_ulp_min = data[\"max_ulp_min\"]\n",
    "        max_ulp_max = data[\"max_ulp_max\"]\n",
    "\n",
    "        # Plot min line\n",
    "        ax.plot(k_values, max_ulp_min, marker='o', linewidth=2.5, markersize=7,\n",
    "               label='Min', alpha=0.85, color='#2ca02c', linestyle='-',\n",
    "               markeredgewidth=1.5, markeredgecolor='white')\n",
    "\n",
    "        # Plot max line\n",
    "        ax.plot(k_values, max_ulp_max, marker='s', linewidth=2.5, markersize=7,\n",
    "               label='Max', alpha=0.85, color='#d62728', linestyle='--',\n",
    "               markeredgewidth=1.5, markeredgecolor='white')\n",
    "\n",
    "        # Plot shaded area between min and max\n",
    "        ax.fill_between(k_values, max_ulp_min, max_ulp_max, alpha=0.2, color='#1f77b4', label='Min-Max Range')\n",
    "\n",
    "        ax.set_xlabel(\"K (inner_channels × kernel_h × kernel_w)\", fontsize=11)\n",
    "        ax.set_ylabel(\"Max ULP\", fontsize=11)\n",
    "        ax.set_title(f'{config_name}', fontsize=12, fontweight='bold')\n",
    "        ax.legend(fontsize=9, loc='best', framealpha=0.9)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "    fig.suptitle(f\"{op_str} ({kernel_str} kernel) Max ULP Min-Max Range Across Random Seeds - {input_generator} inputs\",\n",
    "                 fontsize=14, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{conv_type}_seed_variation_{input_generator}_max_ulp.png\", dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_seed_variation_comparison(all_results, conv_type=\"conv2d\"):\n",
    "    \"\"\"\n",
    "    Compare seed variation across different input generators.\n",
    "\n",
    "    Args:\n",
    "        all_results: Dictionary mapping input generator names to their results\n",
    "        conv_type: Type of convolution ('conv2d' or 'conv_transpose2d')\n",
    "    \"\"\"\n",
    "    configs = [\"bfp16\", \"bfp16+fp32acc\", \"fp32\", \"fp32+fp32acc\"]\n",
    "\n",
    "    kernel_str = \"3x3\" if conv_type == \"conv2d\" else \"2x2\"\n",
    "    op_str = \"Conv2D\" if conv_type == \"conv2d\" else \"Conv2D Transposed\"\n",
    "\n",
    "    # Define distinct line styles and colors\n",
    "    line_styles = ['-', '--']\n",
    "    colors = ['#1f77b4', '#ff7f0e']\n",
    "    markers = ['o', 's']\n",
    "\n",
    "    # Create subplots: one for each configuration\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, config_name in enumerate(configs):\n",
    "        ax = axes[idx]\n",
    "\n",
    "        for style_idx, (input_name, results) in enumerate(all_results.items()):\n",
    "            if config_name in results:\n",
    "                data = results[config_name]\n",
    "\n",
    "                if len(data[\"k_values\"]) == 0:\n",
    "                    continue\n",
    "\n",
    "                k_values = data[\"k_values\"]\n",
    "                max_ulp_min = data[\"max_ulp_min\"]\n",
    "                max_ulp_max = data[\"max_ulp_max\"]\n",
    "\n",
    "                color = colors[style_idx % len(colors)]\n",
    "                marker = markers[style_idx % len(markers)]\n",
    "                linestyle = line_styles[style_idx % len(line_styles)]\n",
    "\n",
    "                # Plot max line\n",
    "                ax.plot(k_values, max_ulp_max,\n",
    "                       marker=marker,\n",
    "                       linestyle=linestyle,\n",
    "                       color=color,\n",
    "                       linewidth=2.5,\n",
    "                       markersize=7,\n",
    "                       label=f'{input_name} (max)',\n",
    "                       alpha=0.85,\n",
    "                       markeredgewidth=1.5,\n",
    "                       markeredgecolor='white')\n",
    "\n",
    "                # Plot shaded area between min and max\n",
    "                ax.fill_between(k_values, max_ulp_min, max_ulp_max, alpha=0.15, color=color)\n",
    "\n",
    "        ax.set_xlabel(\"K (inner_channels × kernel_h × kernel_w)\", fontsize=11)\n",
    "        ax.set_ylabel(\"Max ULP\", fontsize=11)\n",
    "        ax.set_title(f'{config_name}', fontsize=12, fontweight='bold')\n",
    "        ax.legend(fontsize=8, loc='best', framealpha=0.9)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "    fig.suptitle(f\"{op_str} ({kernel_str} kernel) Max ULP Min-Max Range Comparison - All Input Types\",\n",
    "                 fontsize=14, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{conv_type}_seed_variation_comparison_max_ulp.png\", dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_p99_comparison(all_results, conv_type=\"conv2d\"):\n",
    "    \"\"\"\n",
    "    Plot P99 ULP values across K for different input generators.\n",
    "\n",
    "    Args:\n",
    "        all_results: Dictionary mapping input generator names to their results\n",
    "        conv_type: Type of convolution ('conv2d' or 'conv_transpose2d')\n",
    "    \"\"\"\n",
    "    configs = [\"bfp16\", \"bfp16+fp32acc\", \"fp32\", \"fp32+fp32acc\"]\n",
    "\n",
    "    kernel_str = \"3x3\" if conv_type == \"conv2d\" else \"2x2\"\n",
    "    op_str = \"Conv2D\" if conv_type == \"conv2d\" else \"Conv2D Transposed\"\n",
    "\n",
    "    # Define distinct line styles and colors\n",
    "    line_styles = ['-', '--']\n",
    "    colors = ['#1f77b4', '#ff7f0e']\n",
    "    markers = ['o', 's']\n",
    "\n",
    "    # Create subplots: one for each configuration\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, config_name in enumerate(configs):\n",
    "        ax = axes[idx]\n",
    "\n",
    "        for style_idx, (input_name, results) in enumerate(all_results.items()):\n",
    "            if config_name in results:\n",
    "                data = results[config_name]\n",
    "\n",
    "                if len(data[\"k_values\"]) == 0:\n",
    "                    continue\n",
    "\n",
    "                k_values = data[\"k_values\"]\n",
    "                p99_ulp_mean = data[\"p99_ulp_mean\"]\n",
    "                p99_ulp_std = data[\"p99_ulp_std\"]\n",
    "\n",
    "                color = colors[style_idx % len(colors)]\n",
    "                marker = markers[style_idx % len(markers)]\n",
    "                linestyle = line_styles[style_idx % len(line_styles)]\n",
    "\n",
    "                # Plot P99 mean with error bars for std\n",
    "                ax.errorbar(k_values, p99_ulp_mean, yerr=p99_ulp_std,\n",
    "                           marker=marker,\n",
    "                           linestyle=linestyle,\n",
    "                           color=color,\n",
    "                           linewidth=2.5,\n",
    "                           markersize=7,\n",
    "                           capsize=4,\n",
    "                           label=input_name,\n",
    "                           alpha=0.85,\n",
    "                           markeredgewidth=1.5,\n",
    "                           markeredgecolor='white')\n",
    "\n",
    "        ax.set_xlabel(\"K (inner_channels × kernel_h × kernel_w)\", fontsize=11)\n",
    "        ax.set_ylabel(\"P99 ULP (Mean ± Std)\", fontsize=11)\n",
    "        ax.set_title(f'{config_name}', fontsize=12, fontweight='bold')\n",
    "        ax.legend(fontsize=8, loc='best', framealpha=0.9)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "    fig.suptitle(f\"{op_str} ({kernel_str} kernel) P99 ULP Across Random Seeds - All Input Types\",\n",
    "                 fontsize=14, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{conv_type}_seed_variation_p99_comparison.png\", dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Number of iterations per K value\n",
    "    num_iterations = 5\n",
    "\n",
    "    # Define K values to test\n",
    "    # For Conv2D (3x3): K = inner_channels * 9, so increment inner_channels by ~111 for K increment of ~1000\n",
    "    # For Conv2D Transposed (2x2): K = inner_channels * 4, so increment inner_channels by ~250 for K increment of ~1000\n",
    "    # Using 128 increment as a compromise that works reasonably for both\n",
    "    inner_channels_values = [64, 128, 256, 384, 512, 640, 768, 896, 1024, 1152, 1280, 1408, 1536, 1664, 1792, 1920, 2048]\n",
    "\n",
    "    # Test Conv2D\n",
    "    print(\"=\" * 80, flush=True)\n",
    "    print(f\"Testing Conv2D with 3x3 kernel - {num_iterations} iterations per K\", flush=True)\n",
    "    print(\"=\" * 80, flush=True)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80, flush=True)\n",
    "    print(\"Testing with RAND input generator\", flush=True)\n",
    "    print(\"=\" * 80, flush=True)\n",
    "    conv2d_results_rand = run_conv_k_sweep_with_seed_variation(\n",
    "        inner_channels_values,\n",
    "        num_iterations=num_iterations,\n",
    "        input_generator=\"rand\",\n",
    "        # use_bias=True,\n",
    "        use_bias=False,\n",
    "        conv_type=\"conv2d\"\n",
    "    )\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80, flush=True)\n",
    "    print(\"Testing with RANDN input generator\", flush=True)\n",
    "    print(\"=\" * 80, flush=True)\n",
    "    conv2d_results_randn = run_conv_k_sweep_with_seed_variation(\n",
    "        inner_channels_values,\n",
    "        num_iterations=num_iterations,\n",
    "        input_generator=\"randn\",\n",
    "        # use_bias=True,\n",
    "        use_bias=False,\n",
    "        conv_type=\"conv2d\"\n",
    "    )\n",
    "\n",
    "    # Test Conv Transpose2D\n",
    "    print(\"\\n\" + \"=\" * 80, flush=True)\n",
    "    print(f\"Testing Conv2D Transposed with 2x2 kernel - {num_iterations} iterations per K\", flush=True)\n",
    "    print(\"=\" * 80, flush=True)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80, flush=True)\n",
    "    print(\"Testing with RAND input generator\", flush=True)\n",
    "    print(\"=\" * 80, flush=True)\n",
    "    conv_transpose_results_rand = run_conv_k_sweep_with_seed_variation(\n",
    "        inner_channels_values,\n",
    "        num_iterations=num_iterations,\n",
    "        input_generator=\"rand\",\n",
    "        # use_bias=True,\n",
    "        use_bias=False,\n",
    "        conv_type=\"conv_transpose2d\"\n",
    "    )\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80, flush=True)\n",
    "    print(\"Testing with RANDN input generator\", flush=True)\n",
    "    print(\"=\" * 80, flush=True)\n",
    "    conv_transpose_results_randn = run_conv_k_sweep_with_seed_variation(\n",
    "        inner_channels_values,\n",
    "        num_iterations=num_iterations,\n",
    "        input_generator=\"randn\",\n",
    "        # use_bias=True,\n",
    "        use_bias=False,\n",
    "        conv_type=\"conv_transpose2d\"\n",
    "    )\n",
    "\n",
    "    # Generate plots\n",
    "    print(\"\\nGenerating plots...\", flush=True)\n",
    "\n",
    "    # Individual plots for each input type and conv type\n",
    "    print(\"  Plotting Conv2D rand seed variation...\", flush=True)\n",
    "    plot_seed_variation_results(conv2d_results_rand, \"rand\", conv_type=\"conv2d\")\n",
    "\n",
    "    print(\"  Plotting Conv2D randn seed variation...\", flush=True)\n",
    "    plot_seed_variation_results(conv2d_results_randn, \"randn\", conv_type=\"conv2d\")\n",
    "\n",
    "    print(\"  Plotting Conv2D Transposed rand seed variation...\", flush=True)\n",
    "    plot_seed_variation_results(conv_transpose_results_rand, \"rand\", conv_type=\"conv_transpose2d\")\n",
    "\n",
    "    print(\"  Plotting Conv2D Transposed randn seed variation...\", flush=True)\n",
    "    plot_seed_variation_results(conv_transpose_results_randn, \"randn\", conv_type=\"conv_transpose2d\")\n",
    "\n",
    "    # Comparison plots\n",
    "    print(\"  Plotting Conv2D comparison across input types...\", flush=True)\n",
    "    plot_seed_variation_comparison(\n",
    "        {\n",
    "            \"rand [0,1)\": conv2d_results_rand,\n",
    "            \"randn (-∞,∞)\": conv2d_results_randn\n",
    "        },\n",
    "        conv_type=\"conv2d\"\n",
    "    )\n",
    "\n",
    "    print(\"  Plotting Conv2D Transposed comparison across input types...\", flush=True)\n",
    "    plot_seed_variation_comparison(\n",
    "        {\n",
    "            \"rand [0,1)\": conv_transpose_results_rand,\n",
    "            \"randn (-∞,∞)\": conv_transpose_results_randn\n",
    "        },\n",
    "        conv_type=\"conv_transpose2d\"\n",
    "    )\n",
    "\n",
    "    # P99 plots\n",
    "    print(\"  Plotting Conv2D P99 ULP comparison...\", flush=True)\n",
    "    plot_p99_comparison(\n",
    "        {\n",
    "            \"rand [0,1)\": conv2d_results_rand,\n",
    "            \"randn (-∞,∞)\": conv2d_results_randn\n",
    "        },\n",
    "        conv_type=\"conv2d\"\n",
    "    )\n",
    "\n",
    "    print(\"  Plotting Conv2D Transposed P99 ULP comparison...\", flush=True)\n",
    "    plot_p99_comparison(\n",
    "        {\n",
    "            \"rand [0,1)\": conv_transpose_results_rand,\n",
    "            \"randn (-∞,∞)\": conv_transpose_results_randn\n",
    "        },\n",
    "        conv_type=\"conv_transpose2d\"\n",
    "    )\n",
    "\n",
    "    print(\"\\nAll plots generated successfully!\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bef912",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
