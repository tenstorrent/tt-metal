# SPDX-FileCopyrightText: Â© 2025 Tenstorrent AI ULC

# SPDX-License-Identifier: Apache-2.0


import pytest
import torch

import ttnn
from models.demos.vit.tt import ttnn_optimized_vit_highres_gs as ttnn_optimized_vit_highres
from models.utility_functions import get_tensors_from_input_spec
from tests.ttnn.utils_for_testing import assert_with_pcc


def ref_COMPOSITE_48(var0, *args):
    var1 = torch.ops.aten.view(var0, [1, 3, 224, 224])
    var2 = torch.ops.aten.convolution(var1, args[0], args[1], [14, 14], [0, 0], [1, 1], False, [0, 0], 1)
    var3 = torch.ops.aten.view(var2, [1, 1024, 256])
    var4 = torch.ops.aten.transpose.int(var3, 1, 2)
    var5 = torch.ops.aten.add.Tensor(var4, args[2])
    var6 = torch.ops.aten.cat([args[3], args[4], var5], 1)
    return var6


def ref_COMPOSITE_23(var0, *args):
    var1 = torch.ops.aten.native_layer_norm(var0, [1024], args[0], args[1], 1e-06)
    var2 = var1[0]
    var3 = torch.ops.aten.view(var2, [261, 1024])
    var4 = torch.ops.aten.addmm(args[2], var3, args[3])
    var5 = torch.ops.aten.view(var4, [1, 261, 3072])
    var6 = torch.ops.aten.view(var5, [1, 261, 3, 16, 64])
    var7 = torch.ops.aten.permute(var6, [2, 0, 3, 1, 4])
    var8 = torch.ops.aten.unbind.int(var7)
    var9 = var8[0]
    var10 = var8[1]
    var11 = var8[2]
    var12 = torch.ops.aten._scaled_dot_product_flash_attention(var9, var10, var11)
    var13 = var12[0]
    var14 = torch.ops.aten.transpose.int(var13, 1, 2)
    var15 = torch.ops.aten.view(var14, [1, 261, 1024])
    var16 = torch.ops.aten.view(var15, [261, 1024])
    var17 = torch.ops.aten.addmm(args[4], var16, args[5])
    var18 = torch.ops.aten.view(var17, [1, 261, 1024])
    var19 = torch.ops.aten.mul.Tensor(var18, args[6])
    var20 = torch.ops.aten.add.Tensor(var0, var19)
    return var20


def ref_COMPOSITE_47(var0, *args):
    var1 = torch.ops.aten.native_layer_norm(var0, [1024], args[0], args[1], 1e-06)
    var2 = var1[0]
    var3 = torch.ops.aten.view(var2, [261, 1024])
    var4 = torch.ops.aten.addmm(args[2], var3, args[3])
    var5 = torch.ops.aten.view(var4, [1, 261, 4096])
    var6 = torch.ops.aten.gelu(var5)
    var7 = torch.ops.aten.view(var6, [261, 4096])
    var8 = torch.ops.aten.addmm(args[4], var7, args[5])
    var9 = torch.ops.aten.view(var8, [1, 261, 1024])
    var10 = torch.ops.aten.mul.Tensor(var9, args[6])
    var11 = torch.ops.aten.add.Tensor(var0, var10)
    return var11


def ref_COMPOSITE_49(var0, *args):
    var1 = torch.ops.aten.native_layer_norm(var0, [1024], args[0], args[1], 1e-06)
    var2 = var1[0]
    var3 = torch.ops.aten.slice.Tensor(var2, 0, 0, 9223372036854775807)
    var4 = torch.ops.aten.select.int(var3, 1, 0)
    return var4


def ttnn_COMPOSITE_48(var0, *args):
    var2 = ttnn_optimized_vit_highres.vit_patch_embeddings_weight_vars(None, var0, args[0], args[1], patch_size=14)
    var5 = ttnn.add(var2, args[2])
    var6 = ttnn.concat([args[3], args[4], var5], dim=1)
    return var6


def ttnn_COMPOSITE_23(var0, *args):
    hidden_states = ttnn.layer_norm(
        var0,
        weight=args[0],
        bias=args[1],
        epsilon=1e-06,
        memory_config=ttnn.L1_MEMORY_CONFIG,
    )
    query_key_value = ttnn.linear(
        hidden_states,
        args[3],
        bias=args[2],
        memory_config=ttnn.L1_MEMORY_CONFIG,
        dtype=ttnn.bfloat16,
        core_grid=ttnn.CoreGrid(y=8, x=8),
        # program_config=program_configs["query_key_value_matmul_program_config"],
    )
    ttnn.reallocate(hidden_states)
    (
        query,
        key,
        value,
    ) = ttnn.transformer.split_query_key_value_and_split_heads(
        query_key_value,
        memory_config=ttnn.L1_MEMORY_CONFIG,
        num_heads=16,
    )
    ttnn.deallocate(query_key_value)
    value = ttnn.reallocate(value)
    scale_factor = 1 / (query.shape[-1] ** 0.5)
    attention_scores = (
        ttnn.matmul(
            query,
            key,
            memory_config=ttnn.L1_MEMORY_CONFIG,
            dtype=ttnn.bfloat16,
            core_grid=ttnn.CoreGrid(y=8, x=8),
            # program_config=program_configs["query_by_key_matmul_program_config"],
        )
        * scale_factor
    )
    ttnn.deallocate(query)
    ttnn.deallocate(key)
    attention_probs = ttnn.transformer.attention_softmax(attention_scores, head_size=64)
    context_layer = ttnn.matmul(
        attention_probs,
        value,
        memory_config=ttnn.L1_MEMORY_CONFIG,
        dtype=ttnn.bfloat16,
        core_grid=ttnn.CoreGrid(y=8, x=8),
        # program_config=program_configs["attention_probabilities_by_value_matmul_program_config"],
    )
    ttnn.deallocate(attention_probs)
    ttnn.deallocate(value)
    context_layer = ttnn.transformer.concatenate_heads(
        context_layer,
        memory_config=ttnn.L1_MEMORY_CONFIG,
    )
    self_output = ttnn.linear(
        context_layer,
        args[5],
        bias=args[4],
        memory_config=ttnn.L1_MEMORY_CONFIG,
        dtype=ttnn.bfloat8_b,
        core_grid=ttnn.CoreGrid(y=8, x=12),
        # program_config=program_configs["self_output_matmul_program_config"],
    )
    ttnn.deallocate(context_layer)
    var19 = ttnn.mul(self_output, args[6])
    var20 = ttnn.add(var0, var19)
    return var20


def ttnn_COMPOSITE_47(var0, *args):
    hidden_states = ttnn.layer_norm(
        var0,
        weight=args[0],
        bias=args[1],
        epsilon=1e-06,
        memory_config=ttnn.L1_MEMORY_CONFIG,
    )
    hidden_states = ttnn.linear(
        hidden_states,
        args[3],
        bias=args[2],
        memory_config=ttnn.L1_MEMORY_CONFIG,
        dtype=ttnn.bfloat16,
        # program_config=program_configs["ff1_matmul_program_config"],
        core_grid=ttnn.CoreGrid(y=8, x=8),
        activation="gelu",
    )
    hidden_states = ttnn.linear(
        hidden_states,
        args[5],
        bias=args[4],
        memory_config=ttnn.L1_MEMORY_CONFIG,
        dtype=ttnn.bfloat16,
        core_grid=ttnn.CoreGrid(y=8, x=8),
        # program_config=program_configs["ff2_matmul_program_config"],
    )
    hidden_states = ttnn.mul(hidden_states, args[6])
    var11 = ttnn.add(var0, hidden_states)
    return var11


def ttnn_COMPOSITE_49(var0, *args):
    var1 = ttnn.layer_norm(
        var0,
        weight=args[0],
        bias=args[1],
        epsilon=1e-06,
        memory_config=ttnn.L1_MEMORY_CONFIG,
    )
    return var1[:, 0, :]


@pytest.mark.parametrize(
    "input_specs",
    [
        [
            ([1, 3, 224, 224], "torch.float32", [-1.0, 1.0]),
            (
                [1024, 3, 14, 14],
                "torch.float32",
                [-0.09228319674730301, 0.08909129351377487],
            ),
            ([1024], "torch.float32", [-2.4681828022003174, 0.7945129871368408]),
            (
                [1, 256, 1024],
                "torch.float32",
                [-0.22743600606918335, 0.215612530708313],
            ),
            (
                [1, 1, 1024],
                "torch.float32",
                [-0.24574124813079834, 0.19561439752578735],
            ),
            ([1, 4, 1024], "torch.float32", [-0.14077593386173248, 0.3741534352302551]),
        ]
    ],
)
def test_COMPOSITE_48(device, input_specs):
    torch.manual_seed(0)
    tensors = get_tensors_from_input_spec(input_specs)
    out_ref = ref_COMPOSITE_48(*tensors)
    pixel_values = torch.permute(tensors[0], (0, 2, 3, 1))
    pixel_values = torch.nn.functional.pad(pixel_values, (0, 1, 0, 0, 0, 0, 0, 0))
    tensors[0] = pixel_values
    proj_weight = tensors[1]
    proj_bias = tensors[2]
    three_times_hidden_size, c, _, _ = proj_weight.shape
    pad_value = 4 - c
    preprocessed_weight = torch.nn.functional.pad(proj_weight, (0, 0, 0, 0, 0, pad_value))
    preprocessed_weight = torch.permute(preprocessed_weight, (2, 3, 1, 0))
    preprocessed_weight = torch.reshape(preprocessed_weight, (-1, three_times_hidden_size))

    tensors[1] = ttnn.from_torch(preprocessed_weight, dtype=ttnn.bfloat8_b, layout=ttnn.TILE_LAYOUT, device=device)
    tensors[2] = ttnn.from_torch(proj_bias.unsqueeze(0), dtype=ttnn.bfloat8_b, layout=ttnn.TILE_LAYOUT, device=device)
    tensors_tt = [
        ttnn.from_torch(t, dtype=ttnn.bfloat16, device=device) if isinstance(t, torch.Tensor) else t for t in tensors
    ]
    out_opt = ttnn_COMPOSITE_48(*tensors_tt)
    out_opt = ttnn.to_torch(out_opt)
    assert_with_pcc(out_ref, out_opt, 0.999)


@pytest.mark.parametrize(
    "input_specs",
    [
        [
            (
                [1, 261, 1024],
                "torch.float32",
                [-3.8973159790039062, 2.1018617153167725],
            ),
            ([1024], "torch.float32", [-0.9972073435783386, 2.277644395828247]),
            ([1024], "torch.float32", [-1.4099681377410889, 2.0188519954681396]),
            ([3072], "torch.float32", [-7.551997661590576, 6.266356945037842]),
            ([1024, 3072], "torch.float32", [-0.6130378842353821, 0.6052843928337097]),
            ([1024], "torch.float32", [-2.769901752471924, 1.516294002532959]),
            ([1024, 1024], "torch.float32", [-0.502251386642456, 0.3898993134498596]),
            ([1024], "torch.float32", [-1.4109489917755127, 2.9486806392669678]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-1300.8948974609375, 2876.71630859375]),
            ([1024], "torch.float32", [-0.7587265968322754, 5.114859104156494]),
            ([1024], "torch.float32", [-1.595598578453064, 5.028568267822266]),
            ([3072], "torch.float32", [-8.166372299194336, 8.21214485168457]),
            ([1024, 3072], "torch.float32", [-0.5473097562789917, 0.426037073135376]),
            ([1024], "torch.float32", [-2.424449920654297, 1.7707648277282715]),
            ([1024, 1024], "torch.float32", [-0.5630823373794556, 0.44710206985473633]),
            ([1024], "torch.float32", [-4.691793441772461, 1.3178715705871582]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-39576.1953125, 12166.716796875]),
            ([1024], "torch.float32", [-0.030967149883508682, 7.5998616218566895]),
            ([1024], "torch.float32", [-2.0746333599090576, 3.4258363246917725]),
            ([3072], "torch.float32", [-11.446070671081543, 9.624371528625488]),
            ([1024, 3072], "torch.float32", [-0.6534904837608337, 0.5125086903572083]),
            ([1024], "torch.float32", [-1.5815411806106567, 2.937875747680664]),
            (
                [1024, 1024],
                "torch.float32",
                [-0.33504417538642883, 0.30804023146629333],
            ),
            ([1024], "torch.float32", [-2.861898183822632, 1.883652925491333]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-36208.62890625, 56564.875]),
            ([1024], "torch.float32", [-0.00766104506328702, 3.9288065433502197]),
            ([1024], "torch.float32", [-1.6602047681808472, 4.184655666351318]),
            ([3072], "torch.float32", [-5.250730037689209, 5.573263645172119]),
            ([1024, 3072], "torch.float32", [-0.5389775037765503, 0.5936310291290283]),
            ([1024], "torch.float32", [-3.253624677658081, 2.1843621730804443]),
            ([1024, 1024], "torch.float32", [-0.3114267885684967, 0.35526832938194275]),
            ([1024], "torch.float32", [-1.1817095279693604, 2.6771976947784424]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-32728.396484375, 61746.91796875]),
            ([1024], "torch.float32", [-0.260704904794693, 6.0461955070495605]),
            ([1024], "torch.float32", [-2.0229597091674805, 4.030432224273682]),
            ([3072], "torch.float32", [-5.706607341766357, 4.469921588897705]),
            (
                [1024, 3072],
                "torch.float32",
                [-0.38067907094955444, 0.36417585611343384],
            ),
            ([1024], "torch.float32", [-3.5963969230651855, 2.4373412132263184]),
            ([1024, 1024], "torch.float32", [-0.2389807403087616, 0.2888849675655365]),
            ([1024], "torch.float32", [-2.454477071762085, 1.6008474826812744]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-31589.4140625, 62497.45703125]),
            ([1024], "torch.float32", [0.0001155700592789799, 4.489715099334717]),
            ([1024], "torch.float32", [-1.0762659311294556, 1.7797342538833618]),
            ([3072], "torch.float32", [-5.142393589019775, 5.987254619598389]),
            ([1024, 3072], "torch.float32", [-0.3541185259819031, 0.3847804665565491]),
            ([1024], "torch.float32", [-0.750967264175415, 2.82637357711792]),
            ([1024, 1024], "torch.float32", [-0.3005251884460449, 0.2587447166442871]),
            ([1024], "torch.float32", [-1.7491101026535034, 1.2869082689285278]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-31410.275390625, 62519.796875]),
            ([1024], "torch.float32", [0.001616079593077302, 5.438040733337402]),
            ([1024], "torch.float32", [-1.7400729656219482, 1.7546939849853516]),
            ([3072], "torch.float32", [-5.5517048835754395, 6.3765740394592285]),
            ([1024, 3072], "torch.float32", [-0.37463513016700745, 0.3571391999721527]),
            ([1024], "torch.float32", [-2.407273769378662, 3.5475897789001465]),
            ([1024, 1024], "torch.float32", [-0.2749887704849243, 0.33567309379577637]),
            ([1024], "torch.float32", [-1.9051580429077148, 0.6256861686706543]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-31387.21875, 62521.51953125]),
            ([1024], "torch.float32", [0.00147351436316967, 9.833724975585938]),
            ([1024], "torch.float32", [-2.315448760986328, 4.111699104309082]),
            ([3072], "torch.float32", [-7.032127380371094, 5.248210906982422]),
            ([1024, 3072], "torch.float32", [-0.29671385884284973, 0.2974347770214081]),
            ([1024], "torch.float32", [-2.8730833530426025, 3.1343791484832764]),
            ([1024, 1024], "torch.float32", [-0.22362923622131348, 0.2526867389678955]),
            ([1024], "torch.float32", [-0.6622850298881531, 1.953864574432373]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-31877.9921875, 62045.33203125]),
            ([1024], "torch.float32", [0.13639003038406372, 12.93942928314209]),
            ([1024], "torch.float32", [-1.767283320426941, 4.255636215209961]),
            ([3072], "torch.float32", [-15.860111236572266, 12.615781784057617]),
            ([1024, 3072], "torch.float32", [-0.5873074531555176, 0.5371944904327393]),
            ([1024], "torch.float32", [-2.1544759273529053, 3.6200268268585205]),
            ([1024, 1024], "torch.float32", [-0.2751169204711914, 0.26533186435699463]),
            ([1024], "torch.float32", [-3.034104108810425, 2.5826313495635986]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-31705.595703125, 61710.8046875]),
            ([1024], "torch.float32", [0.12592223286628723, 4.983702659606934]),
            ([1024], "torch.float32", [-1.9284499883651733, 4.530211925506592]),
            ([3072], "torch.float32", [-6.68885612487793, 6.079488754272461]),
            ([1024, 3072], "torch.float32", [-0.337238073348999, 0.34388452768325806]),
            ([1024], "torch.float32", [-3.61708927154541, 2.6289424896240234]),
            ([1024, 1024], "torch.float32", [-0.3624327480792999, 0.2844119966030121]),
            ([1024], "torch.float32", [-1.4535458087921143, 1.0085413455963135]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-31610.353515625, 61617.66015625]),
            ([1024], "torch.float32", [0.132377490401268, 5.1803412437438965]),
            ([1024], "torch.float32", [-1.8489869832992554, 4.90647029876709]),
            ([3072], "torch.float32", [-4.272024154663086, 5.865405082702637]),
            ([1024, 3072], "torch.float32", [-0.29452943801879883, 0.2878829836845398]),
            ([1024], "torch.float32", [-3.431459665298462, 1.2135603427886963]),
            (
                [1024, 1024],
                "torch.float32",
                [-0.24886275827884674, 0.22305069863796234],
            ),
            ([1024], "torch.float32", [-1.4043244123458862, 1.1114283800125122]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-28346.267578125, 65542.1328125]),
            ([1024], "torch.float32", [0.10557108372449875, 5.4127702713012695]),
            ([1024], "torch.float32", [-1.8507834672927856, 6.120368957519531]),
            ([3072], "torch.float32", [-5.360270023345947, 5.691600322723389]),
            ([1024, 3072], "torch.float32", [-0.317717969417572, 0.33958733081817627]),
            ([1024], "torch.float32", [-1.231102705001831, 3.7562482357025146]),
            ([1024, 1024], "torch.float32", [-0.28276851773262024, 0.3248703181743622]),
            ([1024], "torch.float32", [-2.0881803035736084, 1.3429815769195557]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-44656.390625, 79771.0703125]),
            ([1024], "torch.float32", [0.11910516023635864, 3.59104323387146]),
            ([1024], "torch.float32", [-1.9410929679870605, 4.938908100128174]),
            ([3072], "torch.float32", [-6.976982116699219, 5.399110794067383]),
            ([1024, 3072], "torch.float32", [-0.2640496492385864, 0.2558917999267578]),
            ([1024], "torch.float32", [-3.350377082824707, 5.021939277648926]),
            ([1024, 1024], "torch.float32", [-0.4142473042011261, 0.33312204480171204]),
            ([1024], "torch.float32", [-3.2973108291625977, 1.6686668395996094]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-44975.8515625, 76956.6640625]),
            ([1024], "torch.float32", [0.14029891788959503, 10.97653865814209]),
            ([1024], "torch.float32", [-2.656738042831421, 5.543571472167969]),
            ([3072], "torch.float32", [-6.551697731018066, 6.132184028625488]),
            (
                [1024, 3072],
                "torch.float32",
                [-0.32532578706741333, 0.34986501932144165],
            ),
            ([1024], "torch.float32", [-4.092000961303711, 2.0876073837280273]),
            ([1024, 1024], "torch.float32", [-0.2716386020183563, 0.2223113477230072]),
            ([1024], "torch.float32", [-1.5894075632095337, 4.091859817504883]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-45295.92578125, 76740.0546875]),
            ([1024], "torch.float32", [0.1525888592004776, 6.713857650756836]),
            ([1024], "torch.float32", [-2.7453482151031494, 5.112979888916016]),
            ([3072], "torch.float32", [-6.937283515930176, 6.149680137634277]),
            ([1024, 3072], "torch.float32", [-0.36433371901512146, 0.2699503004550934]),
            ([1024], "torch.float32", [-4.309192657470703, 2.4991707801818848]),
            ([1024, 1024], "torch.float32", [-0.2299771010875702, 0.29394248127937317]),
            ([1024], "torch.float32", [-2.0265839099884033, 4.71481990814209]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-50204.58203125, 75887.6875]),
            ([1024], "torch.float32", [0.1686292439699173, 7.036809921264648]),
            ([1024], "torch.float32", [-3.2784318923950195, 3.743321418762207]),
            ([3072], "torch.float32", [-5.916319370269775, 6.692896366119385]),
            (
                [1024, 3072],
                "torch.float32",
                [-0.31902870535850525, 0.29397502541542053],
            ),
            ([1024], "torch.float32", [-3.0213680267333984, 5.3092193603515625]),
            (
                [1024, 1024],
                "torch.float32",
                [-0.29448968172073364, 0.27494996786117554],
            ),
            ([1024], "torch.float32", [-5.1384477615356445, 2.286327838897705]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-50605.5859375, 75654.109375]),
            ([1024], "torch.float32", [0.15730954706668854, 9.51411247253418]),
            ([1024], "torch.float32", [-3.9912257194519043, 3.8167805671691895]),
            ([3072], "torch.float32", [-6.861941337585449, 5.999968528747559]),
            (
                [1024, 3072],
                "torch.float32",
                [-0.23978370428085327, 0.23974382877349854],
            ),
            ([1024], "torch.float32", [-6.223902702331543, 1.825439453125]),
            ([1024, 1024], "torch.float32", [-0.2599611282348633, 0.3020399808883667]),
            ([1024], "torch.float32", [-2.2910032272338867, 5.310751438140869]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-66713.1015625, 71428.4765625]),
            ([1024], "torch.float32", [0.14225077629089355, 9.944427490234375]),
            ([1024], "torch.float32", [-4.152271747589111, 2.535245418548584]),
            ([3072], "torch.float32", [-5.703541278839111, 7.301305294036865]),
            (
                [1024, 3072],
                "torch.float32",
                [-0.26247116923332214, 0.28380951285362244],
            ),
            ([1024], "torch.float32", [-8.099340438842773, 1.4094781875610352]),
            ([1024, 1024], "torch.float32", [-0.31370821595191956, 0.3341057002544403]),
            ([1024], "torch.float32", [-3.6880722045898438, 5.67233943939209]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-67034.0078125, 71409.3515625]),
            ([1024], "torch.float32", [0.169513538479805, 3.7802746295928955]),
            ([1024], "torch.float32", [-4.058709144592285, 2.9693055152893066]),
            ([3072], "torch.float32", [-7.680529594421387, 6.580745697021484]),
            ([1024, 3072], "torch.float32", [-0.2405354082584381, 0.250144898891449]),
            ([1024], "torch.float32", [-0.5715538263320923, 8.469474792480469]),
            (
                [1024, 1024],
                "torch.float32",
                [-0.23413796722888947, 0.22512595355510712],
            ),
            ([1024], "torch.float32", [-5.932210445404053, 3.360321521759033]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-70056.2890625, 71531.7578125]),
            ([1024], "torch.float32", [0.22170710563659668, 4.261665344238281]),
            ([1024], "torch.float32", [-3.7703590393066406, 3.1700501441955566]),
            ([3072], "torch.float32", [-7.094350337982178, 6.994099140167236]),
            (
                [1024, 3072],
                "torch.float32",
                [-0.28150060772895813, 0.27523377537727356],
            ),
            ([1024], "torch.float32", [-2.760679006576538, 8.371052742004395]),
            ([1024, 1024], "torch.float32", [-0.3300646245479584, 0.24257102608680725]),
            ([1024], "torch.float32", [-8.235992431640625, 5.26439094543457]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-70107.9140625, 71646.1015625]),
            ([1024], "torch.float32", [0.20085720717906952, 4.3421950340271]),
            ([1024], "torch.float32", [-3.9230434894561768, 3.5844943523406982]),
            ([3072], "torch.float32", [-6.352383136749268, 6.9427876472473145]),
            ([1024, 3072], "torch.float32", [-0.2862774729728699, 0.3012378215789795]),
            ([1024], "torch.float32", [-1.7964330911636353, 9.38552188873291]),
            ([1024, 1024], "torch.float32", [-0.445331335067749, 0.272768497467041]),
            ([1024], "torch.float32", [-8.955381393432617, 5.261157989501953]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-69772.15625, 71991.3125]),
            ([1024], "torch.float32", [0.1784178912639618, 5.123940467834473]),
            ([1024], "torch.float32", [-4.610101699829102, 3.9813671112060547]),
            ([3072], "torch.float32", [-7.113914966583252, 8.55377197265625]),
            (
                [1024, 3072],
                "torch.float32",
                [-0.28103750944137573, 0.26386046409606934],
            ),
            ([1024], "torch.float32", [-11.650721549987793, 1.7884063720703125]),
            ([1024, 1024], "torch.float32", [-0.27712348103523254, 0.3211784064769745]),
            ([1024], "torch.float32", [-6.393329620361328, 9.868194580078125]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-61409.15625, 78722.5078125]),
            ([1024], "torch.float32", [0.21942904591560364, 5.398574352264404]),
            ([1024], "torch.float32", [-5.672608852386475, 4.329784870147705]),
            ([3072], "torch.float32", [-46.055274963378906, 17.187522888183594]),
            ([1024, 3072], "torch.float32", [-0.2730860114097595, 0.272699236869812]),
            ([1024], "torch.float32", [-2.3949806690216064, 19.748931884765625]),
            ([1024, 1024], "torch.float32", [-0.681000828742981, 0.4660073518753052]),
            ([1024], "torch.float32", [-15.407838821411133, 17.482187271118164]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-79920.1328125, 84350.796875]),
            ([1024], "torch.float32", [0.23857194185256958, 6.47585916519165]),
            ([1024], "torch.float32", [-5.41374397277832, 7.007572174072266]),
            ([3072], "torch.float32", [-5.987196445465088, 8.836477279663086]),
            ([1024, 3072], "torch.float32", [-0.2930929362773895, 0.2864401042461395]),
            ([1024], "torch.float32", [-1.4539847373962402, 25.14094352722168]),
            ([1024, 1024], "torch.float32", [-0.7565663456916809, 0.6223523020744324]),
            ([1024], "torch.float32", [-18.004188537597656, 22.66645050048828]),
        ],
    ],
)
def test_COMPOSITE_23(device, input_specs):
    torch.manual_seed(0)
    tensors = get_tensors_from_input_spec(input_specs)
    out_ref = ref_COMPOSITE_23(*tensors)
    tensors[0] = ttnn.from_torch(tensors[0], dtype=ttnn.bfloat16, layout=ttnn.TILE_LAYOUT, device=device)
    tensors[1] = ttnn.from_torch(tensors[1].unsqueeze(0), dtype=ttnn.bfloat16, layout=ttnn.TILE_LAYOUT, device=device)
    tensors[2] = ttnn.from_torch(tensors[2].unsqueeze(0), dtype=ttnn.bfloat16, layout=ttnn.TILE_LAYOUT, device=device)
    tensors[3] = ttnn.from_torch(tensors[3].unsqueeze(0), dtype=ttnn.bfloat16, layout=ttnn.TILE_LAYOUT, device=device)
    tensors[4] = ttnn.from_torch(tensors[4].contiguous(), dtype=ttnn.bfloat16, layout=ttnn.TILE_LAYOUT, device=device)
    tensors[5] = ttnn.from_torch(tensors[5].unsqueeze(0), dtype=ttnn.bfloat16, layout=ttnn.TILE_LAYOUT, device=device)
    tensors[6] = ttnn.from_torch(tensors[6].contiguous(), dtype=ttnn.bfloat16, layout=ttnn.TILE_LAYOUT, device=device)
    tensors[7] = ttnn.from_torch(tensors[7].contiguous(), dtype=ttnn.bfloat16, layout=ttnn.TILE_LAYOUT, device=device)
    tensors_tt = [
        ttnn.from_torch(t, dtype=ttnn.bfloat16, device=device) if isinstance(t, torch.Tensor) else t for t in tensors
    ]
    out_opt = ttnn_COMPOSITE_23(*tensors_tt)
    out_opt = ttnn.to_torch(out_opt)
    diff = torch.abs(out_ref - out_opt)
    print(diff.mean(), diff.std(), diff.max(), diff.min())
    print(out_ref.mean(), out_ref.std(), out_ref.max(), out_ref.min())
    print(out_opt.mean(), out_opt.std(), out_opt.max(), out_opt.min())
    assert_with_pcc(out_ref, out_opt, 0.999)


@pytest.mark.parametrize(
    "input_specs",
    [
        [
            ([1, 261, 1024], "torch.float32", [-745.9947509765625, 1511.8240966796875]),
            ([1024], "torch.float32", [-0.71913081407547, 4.1613450050354]),
            ([1024], "torch.float32", [-2.1383767127990723, 2.2746849060058594]),
            ([4096], "torch.float32", [-3.1954517364501953, 0.9298934936523438]),
            ([1024, 4096], "torch.float32", [-0.6800490021705627, 0.5398532748222351]),
            ([1024], "torch.float32", [-3.8677589893341064, 1.1368606090545654]),
            ([4096, 1024], "torch.float32", [-0.6781558990478516, 0.4983741044998169]),
            ([1024], "torch.float32", [-2.0965240001678467, 1.0363974571228027]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-51596.03125, 16217.0439453125]),
            ([1024], "torch.float32", [-0.005767493508756161, 4.844785690307617]),
            ([1024], "torch.float32", [-0.9688762426376343, 1.6315613985061646]),
            ([4096], "torch.float32", [-4.0399556159973145, 0.9707040786743164]),
            ([1024, 4096], "torch.float32", [-0.3958445191383362, 0.42457497119903564]),
            ([1024], "torch.float32", [-3.878873586654663, 1.8034441471099854]),
            ([4096, 1024], "torch.float32", [-0.49955666065216064, 0.5291657447814941]),
            ([1024], "torch.float32", [-4.234683990478516, 0.35187721252441406]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-52885.34375, 16517.39453125]),
            ([1024], "torch.float32", [-0.006787598133087158, 4.924600601196289]),
            ([1024], "torch.float32", [-1.6494511365890503, 3.204216480255127]),
            ([4096], "torch.float32", [-4.682658672332764, 0.13007402420043945]),
            ([1024, 4096], "torch.float32", [-0.526309072971344, 0.560850203037262]),
            ([1024], "torch.float32", [-1.7464029788970947, 2.4602744579315186]),
            ([4096, 1024], "torch.float32", [-0.6090922951698303, 0.8315674662590027]),
            ([1024], "torch.float32", [-0.9357437491416931, 2.386103630065918]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-51613.59375, 18939.40625]),
            ([1024], "torch.float32", [-0.0033199002500623465, 4.333300590515137]),
            ([1024], "torch.float32", [-2.562267541885376, 2.5232789516448975]),
            ([4096], "torch.float32", [-4.2304768562316895, 0.5227131843566895]),
            ([1024, 4096], "torch.float32", [-0.523443341255188, 0.6844340562820435]),
            ([1024], "torch.float32", [-1.698938012123108, 2.8028392791748047]),
            ([4096, 1024], "torch.float32", [-0.5711591839790344, 0.7734660506248474]),
            ([1024], "torch.float32", [-1.2332044839859009, 3.053835391998291]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-48696.76171875, 25612.8828125]),
            ([1024], "torch.float32", [-0.12728425860404968, 2.671093225479126]),
            ([1024], "torch.float32", [-2.4961328506469727, 1.8207879066467285]),
            ([4096], "torch.float32", [-4.453862190246582, 0.10371589660644531]),
            ([1024, 4096], "torch.float32", [-0.5294806361198425, 0.4479283094406128]),
            ([1024], "torch.float32", [-2.4138944149017334, 1.8144786357879639]),
            ([4096, 1024], "torch.float32", [-0.5001221895217896, 0.4688640236854553]),
            ([1024], "torch.float32", [-1.8238449096679688, 0.8102011680603027]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-47181.98828125, 27484.123046875]),
            ([1024], "torch.float32", [-0.2894373834133148, 6.020302772521973]),
            ([1024], "torch.float32", [-1.7642701864242554, 1.2462650537490845]),
            ([4096], "torch.float32", [-5.04186487197876, 0.300447940826416]),
            ([1024, 4096], "torch.float32", [-0.5435001254081726, 0.5866528153419495]),
            ([1024], "torch.float32", [-1.3923954963684082, 3.0301685333251953]),
            ([4096, 1024], "torch.float32", [-0.47627124190330505, 0.499799519777298]),
            ([1024], "torch.float32", [-0.715236485004425, 1.0992202758789062]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-47260.76171875, 27425.8203125]),
            ([1024], "torch.float32", [-0.37312689423561096, 4.993313789367676]),
            ([1024], "torch.float32", [-2.4929816722869873, 1.3326375484466553]),
            ([4096], "torch.float32", [-3.971008777618408, 0.08761358261108398]),
            ([1024, 4096], "torch.float32", [-0.4305934011936188, 0.5030640363693237]),
            ([1024], "torch.float32", [-2.7961862087249756, 3.6330759525299072]),
            ([4096, 1024], "torch.float32", [-0.3233073949813843, 0.4184013605117798]),
            ([1024], "torch.float32", [-0.5399353504180908, 0.9087061882019043]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-47243.69921875, 27438.287109375]),
            ([1024], "torch.float32", [0.0005578235723078251, 2.7908036708831787]),
            ([1024], "torch.float32", [-2.3613271713256836, 1.702354907989502]),
            ([4096], "torch.float32", [-3.2008519172668457, 0.1729435920715332]),
            ([1024, 4096], "torch.float32", [-0.6104245781898499, 0.5260249972343445]),
            ([1024], "torch.float32", [-3.5780789852142334, 4.148021697998047]),
            ([4096, 1024], "torch.float32", [-0.7416326403617859, 0.6563871502876282]),
            ([1024], "torch.float32", [-0.8473319411277771, 1.373565435409546]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-47374.83984375, 27515.87890625]),
            ([1024], "torch.float32", [-0.001916992594487965, 3.8938183784484863]),
            ([1024], "torch.float32", [-2.5814049243927, 2.2936418056488037]),
            ([4096], "torch.float32", [-3.229285955429077, 0.32872748374938965]),
            ([1024, 4096], "torch.float32", [-0.5282995104789734, 0.7925122380256653]),
            ([1024], "torch.float32", [-4.012734413146973, 2.048750877380371]),
            ([4096, 1024], "torch.float32", [-0.4474693834781647, 0.40071699023246765]),
            ([1024], "torch.float32", [-1.4263639450073242, 1.428412914276123]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-47494.5390625, 27770.45703125]),
            ([1024], "torch.float32", [-0.1336677521467209, 3.0354154109954834]),
            ([1024], "torch.float32", [-2.4394524097442627, 2.0295135974884033]),
            ([4096], "torch.float32", [-3.1458382606506348, 0.4745328426361084]),
            ([1024, 4096], "torch.float32", [-0.4913727939128876, 0.6466919183731079]),
            ([1024], "torch.float32", [-2.5768373012542725, 3.6022040843963623]),
            ([4096, 1024], "torch.float32", [-0.8653794527053833, 0.533966064453125]),
            ([1024], "torch.float32", [-1.635188341140747, 0.735969066619873]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-47479.8125, 27815.951171875]),
            ([1024], "torch.float32", [-0.16457150876522064, 4.228553771972656]),
            ([1024], "torch.float32", [-2.306849479675293, 2.120244026184082]),
            ([4096], "torch.float32", [-3.2094078063964844, 0.33803462982177734]),
            ([1024, 4096], "torch.float32", [-0.7778867483139038, 0.47798359394073486]),
            ([1024], "torch.float32", [-3.2401022911071777, 0.8368802070617676]),
            ([4096, 1024], "torch.float32", [-0.5815610885620117, 0.8539087772369385]),
            ([1024], "torch.float32", [-0.682362973690033, 1.971832036972046]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-45949.75390625, 27836.2890625]),
            ([1024], "torch.float32", [-0.2509111762046814, 3.5921380519866943]),
            ([1024], "torch.float32", [-3.012559413909912, 2.6745829582214355]),
            ([4096], "torch.float32", [-3.4784088134765625, 0.4207878112792969]),
            ([1024, 4096], "torch.float32", [-0.7860430479049683, 0.2618788480758667]),
            ([1024], "torch.float32", [-4.447467803955078, 1.5011553764343262]),
            ([4096, 1024], "torch.float32", [-0.4908146262168884, 0.44136178493499756]),
            ([1024], "torch.float32", [-2.6546688079833984, 3.4734392166137695]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-56356.1484375, 23750.7890625]),
            ([1024], "torch.float32", [0.19856907427310944, 5.898419380187988]),
            ([1024], "torch.float32", [-3.1389894485473633, 2.446359157562256]),
            ([4096], "torch.float32", [-4.243358135223389, 0.6754517555236816]),
            ([1024, 4096], "torch.float32", [-0.4085068106651306, 0.39984989166259766]),
            ([1024], "torch.float32", [-0.7805183529853821, 6.32512903213501]),
            ([4096, 1024], "torch.float32", [-0.6467349529266357, 0.6415923833847046]),
            ([1024], "torch.float32", [-3.3549320697784424, 2.3891236782073975]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-56879.03515625, 23320.52734375]),
            ([1024], "torch.float32", [0.17962665855884552, 3.8875396251678467]),
            ([1024], "torch.float32", [-2.8025546073913574, 2.0491108894348145]),
            ([4096], "torch.float32", [-3.651341676712036, 0.39433979988098145]),
            ([1024, 4096], "torch.float32", [-0.4137301445007324, 0.5130394697189331]),
            ([1024], "torch.float32", [-4.5689616203308105, 2.2284445762634277]),
            ([4096, 1024], "torch.float32", [-0.5641575455665588, 0.7188783288002014]),
            ([1024], "torch.float32", [-1.429654836654663, 3.7333176136016846]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-60226.68359375, 22742.638671875]),
            ([1024], "torch.float32", [0.19465982913970947, 4.041149139404297]),
            ([1024], "torch.float32", [-2.67140531539917, 2.120922565460205]),
            ([4096], "torch.float32", [-4.186313629150391, 0.13288021087646484]),
            ([1024, 4096], "torch.float32", [-0.452627569437027, 0.500394344329834]),
            ([1024], "torch.float32", [-4.860381603240967, 2.4574618339538574]),
            ([4096, 1024], "torch.float32", [-0.6214635372161865, 0.8382631540298462]),
            ([1024], "torch.float32", [-5.979875564575195, 4.248311996459961]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-60146.87109375, 22314.279296875]),
            ([1024], "torch.float32", [0.24118241667747498, 4.886488914489746]),
            ([1024], "torch.float32", [-2.6172502040863037, 1.8546526432037354]),
            ([4096], "torch.float32", [-3.7039096355438232, 0.5039207935333252]),
            (
                [1024, 4096],
                "torch.float32",
                [-0.48281529545783997, 0.49681898951530457],
            ),
            ([1024], "torch.float32", [-2.493297576904297, 4.863455772399902]),
            ([4096, 1024], "torch.float32", [-0.6431464552879333, 0.4843394160270691]),
            ([1024], "torch.float32", [-4.18101167678833, 6.6578192710876465]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-62363.90625, 21913.822265625]),
            ([1024], "torch.float32", [0.15567517280578613, 4.291872024536133]),
            ([1024], "torch.float32", [-2.5966243743896484, 2.4231948852539062]),
            ([4096], "torch.float32", [-4.072901725769043, 0.5976719856262207]),
            ([1024, 4096], "torch.float32", [-0.4474306106567383, 0.6815497875213623]),
            ([1024], "torch.float32", [-4.115330696105957, 2.1579771041870117]),
            ([4096, 1024], "torch.float32", [-0.49912092089653015, 0.3482132852077484]),
            ([1024], "torch.float32", [-3.8454010486602783, 7.044654846191406]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-62377.640625, 21828.953125]),
            ([1024], "torch.float32", [-0.00042845317511819303, 4.967170715332031]),
            ([1024], "torch.float32", [-2.3589887619018555, 2.3818087577819824]),
            ([4096], "torch.float32", [-3.6279845237731934, 0.11163997650146484]),
            (
                [1024, 4096],
                "torch.float32",
                [-0.26037275791168213, 0.27956777811050415],
            ),
            ([1024], "torch.float32", [-3.566675901412964, 1.464834451675415]),
            ([4096, 1024], "torch.float32", [-0.31166356801986694, 0.3490235209465027]),
            ([1024], "torch.float32", [-3.6162514686584473, 8.173044204711914]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-62390.4140625, 21868.826171875]),
            ([1024], "torch.float32", [-0.0029136009979993105, 4.3000102043151855]),
            ([1024], "torch.float32", [-2.0226802825927734, 1.4927775859832764]),
            ([4096], "torch.float32", [-3.5170159339904785, 0.6545119285583496]),
            ([1024, 4096], "torch.float32", [-0.41221192479133606, 0.3363179862499237]),
            ([1024], "torch.float32", [-3.49204421043396, 4.368810653686523]),
            (
                [4096, 1024],
                "torch.float32",
                [-0.48068082332611084, 0.41178393363952637],
            ),
            ([1024], "torch.float32", [-5.765349388122559, 11.419585227966309]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-62448.06640625, 21607.564453125]),
            ([1024], "torch.float32", [-0.38388001918792725, 3.269458770751953]),
            ([1024], "torch.float32", [-3.2662856578826904, 1.7501204013824463]),
            ([4096], "torch.float32", [-3.3108391761779785, 0.8967962265014648]),
            ([1024, 4096], "torch.float32", [-0.3069664239883423, 0.4411500096321106]),
            ([1024], "torch.float32", [-5.041738510131836, 3.30161190032959]),
            (
                [4096, 1024],
                "torch.float32",
                [-0.49066752195358276, 0.35147249698638916],
            ),
            ([1024], "torch.float32", [-14.337873458862305, 8.525259017944336]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-62433.15234375, 21214.8984375]),
            ([1024], "torch.float32", [-3.8630951166851446e-05, 3.284700870513916]),
            ([1024], "torch.float32", [-2.7213664054870605, 2.790252208709717]),
            ([4096], "torch.float32", [-3.207028865814209, 0.47649168968200684]),
            ([1024, 4096], "torch.float32", [-0.35111120343208313, 0.3066960275173187]),
            ([1024], "torch.float32", [-4.400380611419678, 1.7393717765808105]),
            ([4096, 1024], "torch.float32", [-0.432548463344574, 0.3592377305030823]),
            ([1024], "torch.float32", [-21.745040893554688, 12.84878921508789]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-64193.1640625, 21835.583984375]),
            ([1024], "torch.float32", [-3.7366455217124894e-05, 5.222842216491699]),
            ([1024], "torch.float32", [-3.0550146102905273, 3.0686440467834473]),
            ([4096], "torch.float32", [-3.2814788818359375, 0.5334506034851074]),
            ([1024, 4096], "torch.float32", [-0.3728378713130951, 0.4853293001651764]),
            ([1024], "torch.float32", [-6.607576370239258, 5.242364883422852]),
            ([4096, 1024], "torch.float32", [-0.5200672745704651, 0.4330783486366272]),
            ([1024], "torch.float32", [-19.979387283325195, 11.27247428894043]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-63776.86328125, 23207.310546875]),
            ([1024], "torch.float32", [-0.10223201662302017, 6.105518341064453]),
            ([1024], "torch.float32", [-3.828547716140747, 2.920858144760132]),
            ([4096], "torch.float32", [-3.7226052284240723, 0.7122678756713867]),
            ([1024, 4096], "torch.float32", [-0.4204418659210205, 0.4565697908401489]),
            ([1024], "torch.float32", [-2.2185864448547363, 11.930837631225586]),
            ([4096, 1024], "torch.float32", [-0.5407703518867493, 0.9054933190345764]),
            ([1024], "torch.float32", [-20.46320343017578, 28.604530334472656]),
        ],
        [
            ([1, 261, 1024], "torch.float32", [-87557.8203125, 55248.8515625]),
            ([1024], "torch.float32", [-0.5762249827384949, 12.026883125305176]),
            ([1024], "torch.float32", [-4.607396125793457, 3.738844871520996]),
            ([4096], "torch.float32", [-3.276296615600586, 1.003739356994629]),
            ([1024, 4096], "torch.float32", [-0.32931774854660034, 0.2979375123977661]),
            ([1024], "torch.float32", [-2.4487273693084717, 4.535098075866699]),
            ([4096, 1024], "torch.float32", [-0.628217339515686, 0.5629584789276123]),
            ([1024], "torch.float32", [-37.90998458862305, 16.328594207763672]),
        ],
    ],
)
def test_COMPOSITE_47(device, input_specs):
    torch.manual_seed(0)
    tensors = get_tensors_from_input_spec(input_specs)
    out_ref = ref_COMPOSITE_47(*tensors)
    tensors[0] = ttnn.from_torch(tensors[0], dtype=ttnn.bfloat16, layout=ttnn.TILE_LAYOUT, device=device)
    tensors[1] = ttnn.from_torch(tensors[1].unsqueeze(0), dtype=ttnn.bfloat16, layout=ttnn.TILE_LAYOUT, device=device)
    tensors[2] = ttnn.from_torch(tensors[2].unsqueeze(0), dtype=ttnn.bfloat16, layout=ttnn.TILE_LAYOUT, device=device)
    tensors[3] = ttnn.from_torch(tensors[3].unsqueeze(0), dtype=ttnn.bfloat16, layout=ttnn.TILE_LAYOUT, device=device)
    tensors[4] = ttnn.from_torch(tensors[4].contiguous(), dtype=ttnn.bfloat16, layout=ttnn.TILE_LAYOUT, device=device)
    tensors[5] = ttnn.from_torch(tensors[5].unsqueeze(0), dtype=ttnn.bfloat16, layout=ttnn.TILE_LAYOUT, device=device)
    tensors[6] = ttnn.from_torch(tensors[6].contiguous(), dtype=ttnn.bfloat16, layout=ttnn.TILE_LAYOUT, device=device)
    tensors[7] = ttnn.from_torch(tensors[7].contiguous(), dtype=ttnn.bfloat16, layout=ttnn.TILE_LAYOUT, device=device)
    tensors_tt = [
        ttnn.from_torch(t, dtype=ttnn.bfloat16, device=device) if isinstance(t, torch.Tensor) else t for t in tensors
    ]
    out_opt = ttnn_COMPOSITE_47(*tensors_tt)
    out_opt = ttnn.to_torch(out_opt)
    diff = torch.abs(out_ref - out_opt)
    print(diff.mean(), diff.std(), diff.max(), diff.min())
    print(out_ref.mean(), out_ref.std(), out_ref.max(), out_ref.min())
    print(out_opt.mean(), out_opt.std(), out_opt.max(), out_opt.min())
    assert_with_pcc(out_ref, out_opt, 0.999)


@pytest.mark.parametrize(
    "input_specs",
    [
        [
            ([1, 261, 1024], "torch.float32", [-86709.75, 76080.09375]),
            ([1024], "torch.float32", [0.0014023169642314315, 8.986737251281738]),
            ([1024], "torch.float32", [-1.212966799736023, 2.319694995880127]),
        ]
    ],
)
def test_COMPOSITE_49(device, input_specs):
    torch.manual_seed(0)
    tensors = get_tensors_from_input_spec(input_specs)
    out_ref = ref_COMPOSITE_49(*tensors)
    tensors[0] = ttnn.from_torch(tensors[0], dtype=ttnn.bfloat16, layout=ttnn.TILE_LAYOUT, device=device)
    tensors[1] = ttnn.from_torch(tensors[1].unsqueeze(0), dtype=ttnn.bfloat16, layout=ttnn.TILE_LAYOUT, device=device)
    tensors[2] = ttnn.from_torch(tensors[2].unsqueeze(0), dtype=ttnn.bfloat16, layout=ttnn.TILE_LAYOUT, device=device)
    tensors_tt = [
        ttnn.from_torch(t, dtype=ttnn.bfloat16, device=device) if isinstance(t, torch.Tensor) else t for t in tensors
    ]
    out_opt = ttnn_COMPOSITE_49(*tensors_tt)
    out_opt = ttnn.to_torch(out_opt)
    assert_with_pcc(out_ref, out_opt, 0.999)
