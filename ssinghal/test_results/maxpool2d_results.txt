2025-08-01 23:03:02.072 | DEBUG    | ttnn:<module>:83 - Initial ttnn.CONFIG:
Config{cache_path=/home/ttuser/.cache/ttnn,model_cache_path=/home/ttuser/.cache/ttnn/models,tmp_dir=/tmp/ttnn,enable_model_cache=false,enable_fast_runtime_mode=true,throw_exception_on_fallback=false,enable_logging=false,enable_graph_report=false,enable_detailed_buffer_report=false,enable_detailed_tensor_report=false,enable_comparison_mode=false,comparison_mode_should_raise_exception=false,comparison_mode_pcc=0.9999,root_report_path=generated/ttnn/reports,report_name=std::nullopt,std::nullopt}
2025-08-01 23:03:02.172 | info     |   SiliconDriver | Opened PCI device 0; KMD version: 2.0.0; API: 2; IOMMU: disabled (pci_device.cpp:197)
2025-08-01 23:03:02.174 | info     |   SiliconDriver | Opened PCI device 1; KMD version: 2.0.0; API: 2; IOMMU: disabled (pci_device.cpp:197)
2025-08-01 23:03:02.177 | info     |   SiliconDriver | Opened PCI device 2; KMD version: 2.0.0; API: 2; IOMMU: disabled (pci_device.cpp:197)
2025-08-01 23:03:02.179 | info     |   SiliconDriver | Opened PCI device 3; KMD version: 2.0.0; API: 2; IOMMU: disabled (pci_device.cpp:197)
2025-08-01 23:03:02.205 | info     |          Device | Opening user mode device driver (tt_cluster.cpp:192)
2025-08-01 23:03:02.205 | info     |   SiliconDriver | Opened PCI device 0; KMD version: 2.0.0; API: 2; IOMMU: disabled (pci_device.cpp:197)
2025-08-01 23:03:02.207 | info     |   SiliconDriver | Opened PCI device 1; KMD version: 2.0.0; API: 2; IOMMU: disabled (pci_device.cpp:197)
2025-08-01 23:03:02.210 | info     |   SiliconDriver | Opened PCI device 2; KMD version: 2.0.0; API: 2; IOMMU: disabled (pci_device.cpp:197)
2025-08-01 23:03:02.212 | info     |   SiliconDriver | Opened PCI device 3; KMD version: 2.0.0; API: 2; IOMMU: disabled (pci_device.cpp:197)
2025-08-01 23:03:02.237 | info     |   SiliconDriver | Opened PCI device 0; KMD version: 2.0.0; API: 2; IOMMU: disabled (pci_device.cpp:197)
2025-08-01 23:03:02.239 | info     |   SiliconDriver | Opened PCI device 1; KMD version: 2.0.0; API: 2; IOMMU: disabled (pci_device.cpp:197)
2025-08-01 23:03:02.241 | info     |   SiliconDriver | Opened PCI device 2; KMD version: 2.0.0; API: 2; IOMMU: disabled (pci_device.cpp:197)
2025-08-01 23:03:02.244 | info     |   SiliconDriver | Opened PCI device 3; KMD version: 2.0.0; API: 2; IOMMU: disabled (pci_device.cpp:197)
2025-08-01 23:03:02.268 | info     |   SiliconDriver | Harvesting mask for chip 3 is 0x210 (NOC0: 0x210, simulated harvesting mask: 0x0). (cluster.cpp:295)
2025-08-01 23:03:02.278 | info     |   SiliconDriver | Opened PCI device 0; KMD version: 2.0.0; API: 2; IOMMU: disabled (pci_device.cpp:197)
2025-08-01 23:03:02.331 | info     |   SiliconDriver | Harvesting mask for chip 2 is 0x204 (NOC0: 0x204, simulated harvesting mask: 0x0). (cluster.cpp:295)
2025-08-01 23:03:02.340 | info     |   SiliconDriver | Opened PCI device 1; KMD version: 2.0.0; API: 2; IOMMU: disabled (pci_device.cpp:197)
2025-08-01 23:03:02.342 | info     |   SiliconDriver | Harvesting mask for chip 1 is 0x202 (NOC0: 0x202, simulated harvesting mask: 0x0). (cluster.cpp:295)
2025-08-01 23:03:02.352 | info     |   SiliconDriver | Opened PCI device 2; KMD version: 2.0.0; API: 2; IOMMU: disabled (pci_device.cpp:197)
2025-08-01 23:03:02.354 | info     |   SiliconDriver | Harvesting mask for chip 0 is 0x300 (NOC0: 0x300, simulated harvesting mask: 0x0). (cluster.cpp:295)
2025-08-01 23:03:02.363 | info     |   SiliconDriver | Opened PCI device 3; KMD version: 2.0.0; API: 2; IOMMU: disabled (pci_device.cpp:197)
2025-08-01 23:03:02.365 | info     |   SiliconDriver | Harvesting mask for chip 7 is 0x210 (NOC0: 0x210, simulated harvesting mask: 0x0). (cluster.cpp:295)
2025-08-01 23:03:02.376 | info     |   SiliconDriver | Harvesting mask for chip 6 is 0x300 (NOC0: 0x300, simulated harvesting mask: 0x0). (cluster.cpp:295)
2025-08-01 23:03:02.388 | info     |   SiliconDriver | Harvesting mask for chip 5 is 0x300 (NOC0: 0x300, simulated harvesting mask: 0x0). (cluster.cpp:295)
2025-08-01 23:03:02.399 | info     |   SiliconDriver | Harvesting mask for chip 4 is 0x208 (NOC0: 0x208, simulated harvesting mask: 0x0). (cluster.cpp:295)
2025-08-01 23:03:02.410 | info     |   SiliconDriver | Opening local chip ids/pci ids: {0, 1, 2, 3}/[3, 2, 1, 0] and remote chip ids {4, 5, 6, 7} (cluster.cpp:157)
2025-08-01 23:03:02.414 | info     |   SiliconDriver | All devices in cluster running firmware version: 80.17.0 (cluster.cpp:138)
2025-08-01 23:03:02.414 | info     |   SiliconDriver | Software version 6.0.0, Ethernet FW version 6.14.0 (Device 0) (cluster.cpp:935)
2025-08-01 23:03:02.414 | info     |   SiliconDriver | Software version 6.0.0, Ethernet FW version 6.14.0 (Device 1) (cluster.cpp:935)
2025-08-01 23:03:02.414 | info     |   SiliconDriver | Software version 6.0.0, Ethernet FW version 6.14.0 (Device 2) (cluster.cpp:935)
2025-08-01 23:03:02.414 | info     |   SiliconDriver | Software version 6.0.0, Ethernet FW version 6.14.0 (Device 3) (cluster.cpp:935)
2025-08-01 23:03:02.415 | info     |   SiliconDriver | Software version 6.0.0, Ethernet FW version 6.14.0 (Device 4) (cluster.cpp:935)
2025-08-01 23:03:02.415 | info     |   SiliconDriver | Software version 6.0.0, Ethernet FW version 6.14.0 (Device 5) (cluster.cpp:935)
2025-08-01 23:03:02.416 | info     |   SiliconDriver | Software version 6.0.0, Ethernet FW version 6.14.0 (Device 6) (cluster.cpp:935)
2025-08-01 23:03:02.417 | info     |   SiliconDriver | Software version 6.0.0, Ethernet FW version 6.14.0 (Device 7) (cluster.cpp:935)
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-7.2.2, pluggy-1.6.0 -- /home/ttuser/ssinghal/main/tt-metal/python_env/bin/python
cachedir: .pytest_cache
benchmark: 4.0.0 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)
rootdir: /home/ttuser/ssinghal/main/tt-metal, configfile: pytest.ini
plugins: xdist-3.6.1, split-0.8.2, anyio-4.9.0, dash-2.15.0, timeout-2.2.0, benchmark-4.0.0, github-actions-annotate-failures-0.3.0
timeout: 300.0s
timeout method: signal
timeout func_only: False
collecting ... collected 13 items

ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape0] 2025-08-01 23:03:03.487 | warning  |           Metal | Opening subset of mmio devices slows down UMD read/write to remote chips. If opening more devices, consider using CreateDevices API. (device_pool.cpp:304)
SKIPPED (Type error: [1, 512, 40, 25] - __call__(): incompatible function arguments. The following argument types are supported:
    1. (self: ttnn._ttnn.operations.pool.max_pool2d_t, input_tensor: ttnn._ttnn.tensor.Tensor, batch_size: int, input_h: int, input_w: int, channels: int, kernel_size: Annotated[list[int], FixedSize(2)], stride: Annotated[list[int], FixedSize(2)], padding: Union[Annotated[list[int], FixedSize(2)], Annotated[list[int], FixedSize(4)]], dilation: Annotated[list[int], FixedSize(2)], ceil_mode: bool = False, *, memory_config: Optional[ttnn._ttnn.tensor.MemoryConfig] = None, applied_shard_scheme: Optional[ttnn._ttnn.tensor.TensorMemoryLayout] = None, in_place_halo: bool = False, queue_id: ttnn._ttnn.types.QueueId = QueueId(0)) -> ttnn._ttnn.tensor.Tensor

Invoked with: <ttnn._ttnn.operations.pool.max_pool2d_t object at 0x7f14560ca530>, ttnn.Tensor([[[[ 0.67188,  0.15234,  ...,  0.97656,  0.32812],
               [ 0.18359,  0.91406,  ...,  0.12891,  0.00391],
               ...,
               [ 0.67969,  0.39844,  ...,  0.55859,  0.92578],
               [ 0.34375,  0.07812,  ...,  0.20312,  0.99609]],

              [[ 0.31641,  0.66797,  ...,  0.26172,  0.39062],
               [ 0.64453,  0.46094,  ...,  0.08984,  0.71875],
               ...,
               [ 0.55469,  0.29297,  ...,  0.44141,  0.30078],
               [ 0.65234,  0.44531,  ...,  0.67188,  0.59375]],

              ...,

              [[ 0.28906,  0.76953,  ...,  0.88672,  0.15625],
               [ 0.32812,  0.12891,  ...,  0.62109,  0.31250],
               ...,
               [ 0.45703,  0.97656,  ...,  0.74219,  0.05859],
               [ 0.39062,  0.23828,  ...,  0.52734,  0.53125]],

              [[ 0.35156,  0.41406,  ...,  0.06641,  0.86328],
               [ 0.26562,  0.82422,  ...,  0.64062,  0.62891],
               ...,
               [ 0.59766,  0.23828,  ...,  0.06250,  0.07031],
               [ 0.59375,  0.70703,  ...,  0.36328,  0.42188]]]], shape=Shape([1, 40, 25, 512]), dtype=DataType::BFLOAT16, layout=Layout::TILE))
ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape1] 2025-08-01 23:03:04.804 | warning  |          Always | Closing and re-initializing MetalContext with same parameters due to force_reinit flag. (metal_context.cpp:77)
2025-08-01 23:03:05.158 | warning  |           Metal | Opening subset of mmio devices slows down UMD read/write to remote chips. If opening more devices, consider using CreateDevices API. (device_pool.cpp:304)
SKIPPED (Type error: [1, 256, 320, 200] - __call__(): incompatible function arguments. The following argument types are supported:
    1. (self: ttnn._ttnn.operations.pool.max_pool2d_t, input_tensor: ttnn._ttnn.tensor.Tensor, batch_size: int, input_h: int, input_w: int, channels: int, kernel_size: Annotated[list[int], FixedSize(2)], stride: Annotated[list[int], FixedSize(2)], padding: Union[Annotated[list[int], FixedSize(2)], Annotated[list[int], FixedSize(4)]], dilation: Annotated[list[int], FixedSize(2)], ceil_mode: bool = False, *, memory_config: Optional[ttnn._ttnn.tensor.MemoryConfig] = None, applied_shard_scheme: Optional[ttnn._ttnn.tensor.TensorMemoryLayout] = None, in_place_halo: bool = False, queue_id: ttnn._ttnn.types.QueueId = QueueId(0)) -> ttnn._ttnn.tensor.Tensor

Invoked with: <ttnn._ttnn.operations.pool.max_pool2d_t object at 0x7f14560ca530>, ttnn.Tensor([[[[ 0.67188,  0.65625,  ...,  0.18750,  0.63281],
               [ 0.18359,  0.55078,  ...,  0.77734,  0.89062],
               ...,
               [ 0.11719,  0.14844,  ...,  0.16016,  0.97656],
               [ 0.09375,  0.67578,  ...,  0.62500,  0.04297]],

              [[ 0.48828,  0.02734,  ...,  0.58984,  0.79688],
               [ 0.00781,  0.41797,  ...,  0.28516,  0.88672],
               ...,
               [ 0.61719,  0.89062,  ...,  0.00391,  0.42578],
               [ 0.56641,  0.01562,  ...,  0.71484,  0.59766]],

              ...,

              [[ 0.51562,  0.38281,  ...,  0.48438,  0.08594],
               [ 0.24219,  0.22266,  ...,  0.32812,  0.11328],
               ...,
               [ 0.35547,  0.00000,  ...,  0.39844,  0.91406],
               [ 0.07812,  0.32422,  ...,  0.37109,  0.55078]],

              [[ 0.69531,  0.67188,  ...,  0.87109,  0.11719],
               [ 0.28125,  0.83203,  ...,  0.94531,  0.42188],
               ...,
               [ 0.05469,  0.25781,  ...,  0.27344,  0.70312],
               [ 0.16016,  0.36719,  ...,  0.98438,  0.16016]]]], shape=Shape([1, 320, 200, 256]), dtype=DataType::BFLOAT16, layout=Layout::TILE))
ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape2] 2025-08-01 23:03:05.742 | warning  |          Always | Closing and re-initializing MetalContext with same parameters due to force_reinit flag. (metal_context.cpp:77)
2025-08-01 23:03:06.096 | warning  |           Metal | Opening subset of mmio devices slows down UMD read/write to remote chips. If opening more devices, consider using CreateDevices API. (device_pool.cpp:304)
SKIPPED (Type error: [1, 512, 160, 100] - __call__(): incompatible function arguments. The following argument types are supported:
    1. (self: ttnn._ttnn.operations.pool.max_pool2d_t, input_tensor: ttnn._ttnn.tensor.Tensor, batch_size: int, input_h: int, input_w: int, channels: int, kernel_size: Annotated[list[int], FixedSize(2)], stride: Annotated[list[int], FixedSize(2)], padding: Union[Annotated[list[int], FixedSize(2)], Annotated[list[int], FixedSize(4)]], dilation: Annotated[list[int], FixedSize(2)], ceil_mode: bool = False, *, memory_config: Optional[ttnn._ttnn.tensor.MemoryConfig] = None, applied_shard_scheme: Optional[ttnn._ttnn.tensor.TensorMemoryLayout] = None, in_place_halo: bool = False, queue_id: ttnn._ttnn.types.QueueId = QueueId(0)) -> ttnn._ttnn.tensor.Tensor

Invoked with: <ttnn._ttnn.operations.pool.max_pool2d_t object at 0x7f14560ca530>, ttnn.Tensor([[[[ 0.67188,  0.30859,  ...,  0.51953,  0.38281],
               [ 0.18359,  0.60156,  ...,  0.67969,  0.12500],
               ...,
               [ 0.20703,  0.23047,  ...,  0.73828,  0.98047],
               [ 0.54688,  0.94531,  ...,  0.11719,  0.17578]],

              [[ 0.47266,  0.77734,  ...,  0.84375,  0.00000],
               [ 0.66406,  0.66406,  ...,  0.29688,  0.62500],
               ...,
               [ 0.11719,  0.80859,  ...,  0.86328,  0.98828],
               [ 0.09375,  0.19922,  ...,  0.74219,  0.77734]],

              ...,

              [[ 0.09766,  0.90625,  ...,  0.85938,  0.38672],
               [ 0.05859,  0.21875,  ...,  0.57812,  0.56250],
               ...,
               [ 0.04297,  0.38672,  ...,  0.46875,  0.35547],
               [ 0.92969,  0.14453,  ...,  0.47656,  0.12109]],

              [[ 0.89453,  0.39062,  ...,  0.88281,  0.33984],
               [ 0.18750,  0.62891,  ...,  0.52344,  0.10156],
               ...,
               [ 0.07812,  0.47656,  ...,  0.91016,  0.66016],
               [ 0.71094,  0.76172,  ...,  0.08594,  0.26172]]]], shape=Shape([1, 160, 100, 512]), dtype=DataType::BFLOAT16, layout=Layout::TILE))
ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape3] 2025-08-01 23:03:06.359 | warning  |          Always | Closing and re-initializing MetalContext with same parameters due to force_reinit flag. (metal_context.cpp:77)
2025-08-01 23:03:06.689 | warning  |           Metal | Opening subset of mmio devices slows down UMD read/write to remote chips. If opening more devices, consider using CreateDevices API. (device_pool.cpp:304)
SKIPPED (Type error: [1, 1024, 80, 50] - __call__(): incompatible function arguments. The following argument types are supported:
    1. (self: ttnn._ttnn.operations.pool.max_pool2d_t, input_tensor: ttnn._ttnn.tensor.Tensor, batch_size: int, input_h: int, input_w: int, channels: int, kernel_size: Annotated[list[int], FixedSize(2)], stride: Annotated[list[int], FixedSize(2)], padding: Union[Annotated[list[int], FixedSize(2)], Annotated[list[int], FixedSize(4)]], dilation: Annotated[list[int], FixedSize(2)], ceil_mode: bool = False, *, memory_config: Optional[ttnn._ttnn.tensor.MemoryConfig] = None, applied_shard_scheme: Optional[ttnn._ttnn.tensor.TensorMemoryLayout] = None, in_place_halo: bool = False, queue_id: ttnn._ttnn.types.QueueId = QueueId(0)) -> ttnn._ttnn.tensor.Tensor

Invoked with: <ttnn._ttnn.operations.pool.max_pool2d_t object at 0x7f14560ca530>, ttnn.Tensor([[[[ 0.67188,  0.73047,  ...,  0.90234,  0.20703],
               [ 0.18359,  0.16797,  ...,  0.04688,  0.51172],
               ...,
               [ 0.55469,  0.71875,  ...,  0.71484,  0.19141],
               [ 0.65234,  0.87109,  ...,  0.23828,  0.76562]],

              [[ 0.12500,  0.86719,  ...,  0.34375,  0.26562],
               [ 0.75391,  0.01953,  ...,  0.65234,  0.62109],
               ...,
               [ 0.20703,  0.30859,  ...,  0.16016,  0.34375],
               [ 0.54688,  0.49609,  ...,  0.54297,  0.78906]],

              ...,

              [[ 0.16016,  0.23047,  ...,  0.55469,  0.39844],
               [ 0.07422,  0.45312,  ...,  0.08594,  0.17969],
               ...,
               [ 0.91016,  0.33984,  ...,  0.94141,  0.56250],
               [ 0.16016,  0.00391,  ...,  0.54297,  0.67578]],

              [[ 0.01172,  0.98047,  ...,  0.12109,  0.72266],
               [ 0.65234,  0.36328,  ...,  0.08594,  0.03906],
               ...,
               [ 0.13281,  0.59766,  ...,  0.87109,  0.99609],
               [ 0.29688,  0.54688,  ...,  0.60156,  0.57031]]]], shape=Shape([1, 80, 50, 1024]), dtype=DataType::BFLOAT16, layout=Layout::TILE))
ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape4] 2025-08-01 23:03:06.824 | warning  |          Always | Closing and re-initializing MetalContext with same parameters due to force_reinit flag. (metal_context.cpp:77)
2025-08-01 23:03:07.200 | warning  |           Metal | Opening subset of mmio devices slows down UMD read/write to remote chips. If opening more devices, consider using CreateDevices API. (device_pool.cpp:304)
SKIPPED (Type error: [1, 128, 160, 100] - __call__(): incompatible function arguments. The following argument types are supported:
    1. (self: ttnn._ttnn.operations.pool.max_pool2d_t, input_tensor: ttnn._ttnn.tensor.Tensor, batch_size: int, input_h: int, input_w: int, channels: int, kernel_size: Annotated[list[int], FixedSize(2)], stride: Annotated[list[int], FixedSize(2)], padding: Union[Annotated[list[int], FixedSize(2)], Annotated[list[int], FixedSize(4)]], dilation: Annotated[list[int], FixedSize(2)], ceil_mode: bool = False, *, memory_config: Optional[ttnn._ttnn.tensor.MemoryConfig] = None, applied_shard_scheme: Optional[ttnn._ttnn.tensor.TensorMemoryLayout] = None, in_place_halo: bool = False, queue_id: ttnn._ttnn.types.QueueId = QueueId(0)) -> ttnn._ttnn.tensor.Tensor

Invoked with: <ttnn._ttnn.operations.pool.max_pool2d_t object at 0x7f14560ca530>, ttnn.Tensor([[[[ 0.67188,  0.30859,  ...,  0.55078,  0.02734],
               [ 0.18359,  0.60156,  ...,  0.95312,  0.47656],
               ...,
               [ 0.20703,  0.23047,  ...,  0.56250,  0.53516],
               [ 0.54688,  0.94531,  ...,  0.90234,  0.73047]],

              [[ 0.47266,  0.77734,  ...,  0.56250,  0.28516],
               [ 0.66406,  0.66406,  ...,  0.82812,  0.05469],
               ...,
               [ 0.11719,  0.80859,  ...,  0.97656,  0.63672],
               [ 0.09375,  0.19922,  ...,  0.80859,  0.85938]],

              ...,

              [[ 0.09766,  0.90625,  ...,  0.95312,  0.93359],
               [ 0.05859,  0.21875,  ...,  0.35547,  0.06641],
               ...,
               [ 0.04297,  0.38672,  ...,  0.70703,  0.94531],
               [ 0.92969,  0.14453,  ...,  0.75391,  0.06250]],

              [[ 0.89453,  0.39062,  ...,  0.07422,  0.57812],
               [ 0.18750,  0.62891,  ...,  0.37500,  0.95312],
               ...,
               [ 0.07812,  0.47656,  ...,  0.42578,  0.16797],
               [ 0.71094,  0.76172,  ...,  0.00000,  0.03516]]]], shape=Shape([1, 160, 100, 128]), dtype=DataType::BFLOAT16, layout=Layout::TILE))
ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape5] 2025-08-01 23:03:07.279 | warning  |          Always | Closing and re-initializing MetalContext with same parameters due to force_reinit flag. (metal_context.cpp:77)
2025-08-01 23:03:07.655 | warning  |           Metal | Opening subset of mmio devices slows down UMD read/write to remote chips. If opening more devices, consider using CreateDevices API. (device_pool.cpp:304)
SKIPPED (Type error: [1, 256, 80, 50] - __call__(): incompatible function arguments. The following argument types are supported:
    1. (self: ttnn._ttnn.operations.pool.max_pool2d_t, input_tensor: ttnn._ttnn.tensor.Tensor, batch_size: int, input_h: int, input_w: int, channels: int, kernel_size: Annotated[list[int], FixedSize(2)], stride: Annotated[list[int], FixedSize(2)], padding: Union[Annotated[list[int], FixedSize(2)], Annotated[list[int], FixedSize(4)]], dilation: Annotated[list[int], FixedSize(2)], ceil_mode: bool = False, *, memory_config: Optional[ttnn._ttnn.tensor.MemoryConfig] = None, applied_shard_scheme: Optional[ttnn._ttnn.tensor.TensorMemoryLayout] = None, in_place_halo: bool = False, queue_id: ttnn._ttnn.types.QueueId = QueueId(0)) -> ttnn._ttnn.tensor.Tensor

Invoked with: <ttnn._ttnn.operations.pool.max_pool2d_t object at 0x7f14560ca530>, ttnn.Tensor([[[[ 0.67188,  0.73047,  ...,  0.95703,  0.53125],
               [ 0.18359,  0.16797,  ...,  0.00391,  0.90625],
               ...,
               [ 0.55469,  0.71875,  ...,  0.07031,  0.30859],
               [ 0.65234,  0.87109,  ...,  0.98438,  0.00781]],

              [[ 0.12500,  0.86719,  ...,  0.98828,  0.96094],
               [ 0.75391,  0.01953,  ...,  0.17969,  0.71094],
               ...,
               [ 0.20703,  0.30859,  ...,  0.16797,  0.59375],
               [ 0.54688,  0.49609,  ...,  0.60938,  0.58203]],

              ...,

              [[ 0.16016,  0.23047,  ...,  0.65625,  0.55859],
               [ 0.07422,  0.45312,  ...,  0.67969,  0.35156],
               ...,
               [ 0.91016,  0.33984,  ...,  0.00391,  0.19141],
               [ 0.16016,  0.00391,  ...,  0.47656,  0.06641]],

              [[ 0.01172,  0.98047,  ...,  0.42578,  0.08984],
               [ 0.65234,  0.36328,  ...,  0.81250,  0.37891],
               ...,
               [ 0.13281,  0.59766,  ...,  0.54688,  0.60547],
               [ 0.29688,  0.54688,  ...,  0.29688,  0.08203]]]], shape=Shape([1, 80, 50, 256]), dtype=DataType::BFLOAT16, layout=Layout::TILE))
ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape6] 2025-08-01 23:03:07.701 | warning  |          Always | Closing and re-initializing MetalContext with same parameters due to force_reinit flag. (metal_context.cpp:77)
2025-08-01 23:03:08.078 | warning  |           Metal | Opening subset of mmio devices slows down UMD read/write to remote chips. If opening more devices, consider using CreateDevices API. (device_pool.cpp:304)
SKIPPED (Type error: [1, 320, 40, 25] - __call__(): incompatible function arguments. The following argument types are supported:
    1. (self: ttnn._ttnn.operations.pool.max_pool2d_t, input_tensor: ttnn._ttnn.tensor.Tensor, batch_size: int, input_h: int, input_w: int, channels: int, kernel_size: Annotated[list[int], FixedSize(2)], stride: Annotated[list[int], FixedSize(2)], padding: Union[Annotated[list[int], FixedSize(2)], Annotated[list[int], FixedSize(4)]], dilation: Annotated[list[int], FixedSize(2)], ceil_mode: bool = False, *, memory_config: Optional[ttnn._ttnn.tensor.MemoryConfig] = None, applied_shard_scheme: Optional[ttnn._ttnn.tensor.TensorMemoryLayout] = None, in_place_halo: bool = False, queue_id: ttnn._ttnn.types.QueueId = QueueId(0)) -> ttnn._ttnn.tensor.Tensor

Invoked with: <ttnn._ttnn.operations.pool.max_pool2d_t object at 0x7f14560ca530>, ttnn.Tensor([[[[ 0.67188,  0.15234,  ...,  0.99219,  0.25000],
               [ 0.18359,  0.91406,  ...,  0.17188,  0.58203],
               ...,
               [ 0.67969,  0.39844,  ...,  0.26172,  0.34766],
               [ 0.34375,  0.07812,  ...,  0.19141,  0.98047]],

              [[ 0.31641,  0.66797,  ...,  0.35547,  0.34766],
               [ 0.64453,  0.46094,  ...,  0.64844,  0.23047],
               ...,
               [ 0.55469,  0.29297,  ...,  0.92578,  0.20703],
               [ 0.65234,  0.44531,  ...,  0.55469,  0.01172]],

              ...,

              [[ 0.28906,  0.76953,  ...,  0.78516,  0.13672],
               [ 0.32812,  0.12891,  ...,  0.98047,  0.09375],
               ...,
               [ 0.45703,  0.97656,  ...,  0.93750,  0.16797],
               [ 0.39062,  0.23828,  ...,  0.33203,  0.69531]],

              [[ 0.35156,  0.41406,  ...,  0.52344,  0.91797],
               [ 0.26562,  0.82422,  ...,  0.62891,  0.20703],
               ...,
               [ 0.59766,  0.23828,  ...,  0.19141,  0.10547],
               [ 0.59375,  0.70703,  ...,  0.32031,  0.33203]]]], shape=Shape([1, 40, 25, 320]), dtype=DataType::BFLOAT16, layout=Layout::TILE))
ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape7] 2025-08-01 23:03:08.098 | warning  |          Always | Closing and re-initializing MetalContext with same parameters due to force_reinit flag. (metal_context.cpp:77)
2025-08-01 23:03:08.473 | warning  |           Metal | Opening subset of mmio devices slows down UMD read/write to remote chips. If opening more devices, consider using CreateDevices API. (device_pool.cpp:304)
SKIPPED (Type error: [1, 256, 40, 25] - __call__(): incompatible function arguments. The following argument types are supported:
    1. (self: ttnn._ttnn.operations.pool.max_pool2d_t, input_tensor: ttnn._ttnn.tensor.Tensor, batch_size: int, input_h: int, input_w: int, channels: int, kernel_size: Annotated[list[int], FixedSize(2)], stride: Annotated[list[int], FixedSize(2)], padding: Union[Annotated[list[int], FixedSize(2)], Annotated[list[int], FixedSize(4)]], dilation: Annotated[list[int], FixedSize(2)], ceil_mode: bool = False, *, memory_config: Optional[ttnn._ttnn.tensor.MemoryConfig] = None, applied_shard_scheme: Optional[ttnn._ttnn.tensor.TensorMemoryLayout] = None, in_place_halo: bool = False, queue_id: ttnn._ttnn.types.QueueId = QueueId(0)) -> ttnn._ttnn.tensor.Tensor

Invoked with: <ttnn._ttnn.operations.pool.max_pool2d_t object at 0x7f14560ca530>, ttnn.Tensor([[[[ 0.67188,  0.15234,  ...,  0.10938,  0.19531],
               [ 0.18359,  0.91406,  ...,  0.14062,  0.41406],
               ...,
               [ 0.67969,  0.39844,  ...,  0.85547,  0.49609],
               [ 0.34375,  0.07812,  ...,  0.16406,  0.57812]],

              [[ 0.31641,  0.66797,  ...,  0.87109,  0.07812],
               [ 0.64453,  0.46094,  ...,  0.23047,  0.83984],
               ...,
               [ 0.55469,  0.29297,  ...,  0.50391,  0.57422],
               [ 0.65234,  0.44531,  ...,  0.96094,  0.01172]],

              ...,

              [[ 0.28906,  0.76953,  ...,  0.68359,  0.00000],
               [ 0.32812,  0.12891,  ...,  0.73828,  0.91016],
               ...,
               [ 0.45703,  0.97656,  ...,  0.03516,  0.76953],
               [ 0.39062,  0.23828,  ...,  0.87500,  0.42188]],

              [[ 0.35156,  0.41406,  ...,  0.87109,  0.86719],
               [ 0.26562,  0.82422,  ...,  0.48438,  0.22266],
               ...,
               [ 0.59766,  0.23828,  ...,  0.73438,  0.36719],
               [ 0.59375,  0.70703,  ...,  0.34375,  0.83203]]]], shape=Shape([1, 40, 25, 256]), dtype=DataType::BFLOAT16, layout=Layout::TILE))
ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape8] 2025-08-01 23:03:08.489 | warning  |          Always | Closing and re-initializing MetalContext with same parameters due to force_reinit flag. (metal_context.cpp:77)
2025-08-01 23:03:08.865 | warning  |           Metal | Opening subset of mmio devices slows down UMD read/write to remote chips. If opening more devices, consider using CreateDevices API. (device_pool.cpp:304)
SKIPPED (Type error: [1, 128, 40, 25] - __call__(): incompatible function arguments. The following argument types are supported:
    1. (self: ttnn._ttnn.operations.pool.max_pool2d_t, input_tensor: ttnn._ttnn.tensor.Tensor, batch_size: int, input_h: int, input_w: int, channels: int, kernel_size: Annotated[list[int], FixedSize(2)], stride: Annotated[list[int], FixedSize(2)], padding: Union[Annotated[list[int], FixedSize(2)], Annotated[list[int], FixedSize(4)]], dilation: Annotated[list[int], FixedSize(2)], ceil_mode: bool = False, *, memory_config: Optional[ttnn._ttnn.tensor.MemoryConfig] = None, applied_shard_scheme: Optional[ttnn._ttnn.tensor.TensorMemoryLayout] = None, in_place_halo: bool = False, queue_id: ttnn._ttnn.types.QueueId = QueueId(0)) -> ttnn._ttnn.tensor.Tensor

Invoked with: <ttnn._ttnn.operations.pool.max_pool2d_t object at 0x7f14560ca530>, ttnn.Tensor([[[[ 0.67188,  0.15234,  ...,  0.52344,  0.94141],
               [ 0.18359,  0.91406,  ...,  0.64453,  0.09375],
               ...,
               [ 0.67969,  0.39844,  ...,  0.15234,  0.85938],
               [ 0.34375,  0.07812,  ...,  0.05078,  0.47266]],

              [[ 0.31641,  0.66797,  ...,  0.68750,  0.22656],
               [ 0.64453,  0.46094,  ...,  0.30859,  0.31250],
               ...,
               [ 0.55469,  0.29297,  ...,  0.48438,  0.62891],
               [ 0.65234,  0.44531,  ...,  0.54688,  0.67188]],

              ...,

              [[ 0.28906,  0.76953,  ...,  0.89844,  0.42578],
               [ 0.32812,  0.12891,  ...,  0.83984,  0.41016],
               ...,
               [ 0.45703,  0.97656,  ...,  0.89453,  0.39062],
               [ 0.39062,  0.23828,  ...,  0.50000,  0.14453]],

              [[ 0.35156,  0.41406,  ...,  0.28906,  0.15234],
               [ 0.26562,  0.82422,  ...,  0.16406,  0.32812],
               ...,
               [ 0.59766,  0.23828,  ...,  0.02734,  0.25781],
               [ 0.59375,  0.70703,  ...,  0.19922,  0.36719]]]], shape=Shape([1, 40, 25, 128]), dtype=DataType::BFLOAT16, layout=Layout::TILE))
ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape9] 2025-08-01 23:03:08.879 | warning  |          Always | Closing and re-initializing MetalContext with same parameters due to force_reinit flag. (metal_context.cpp:77)
2025-08-01 23:03:09.256 | warning  |           Metal | Opening subset of mmio devices slows down UMD read/write to remote chips. If opening more devices, consider using CreateDevices API. (device_pool.cpp:304)
SKIPPED (Type error: [1, 32, 641, 401] - __call__(): incompatible function arguments. The following argument types are supported:
    1. (self: ttnn._ttnn.operations.pool.max_pool2d_t, input_tensor: ttnn._ttnn.tensor.Tensor, batch_size: int, input_h: int, input_w: int, channels: int, kernel_size: Annotated[list[int], FixedSize(2)], stride: Annotated[list[int], FixedSize(2)], padding: Union[Annotated[list[int], FixedSize(2)], Annotated[list[int], FixedSize(4)]], dilation: Annotated[list[int], FixedSize(2)], ceil_mode: bool = False, *, memory_config: Optional[ttnn._ttnn.tensor.MemoryConfig] = None, applied_shard_scheme: Optional[ttnn._ttnn.tensor.TensorMemoryLayout] = None, in_place_halo: bool = False, queue_id: ttnn._ttnn.types.QueueId = QueueId(0)) -> ttnn._ttnn.tensor.Tensor

Invoked with: <ttnn._ttnn.operations.pool.max_pool2d_t object at 0x7f14560ca530>, ttnn.Tensor([[[[ 0.67188,  0.76172,  ...,  0.92188,  0.10547],
               [ 0.18359,  0.42578,  ...,  0.26562,  0.83984],
               ...,
               [ 0.56641,  0.94531,  ...,  0.80469,  0.55078],
               [ 0.77344,  0.97656,  ...,  0.38281,  0.80859]],

              [[ 0.77734,  0.42578,  ...,  0.49609,  0.94531],
               [ 0.07031,  0.16016,  ...,  0.62891,  0.68750],
               ...,
               [ 0.25391,  0.48047,  ...,  0.11328,  0.78516],
               [ 0.75000,  0.16016,  ...,  0.14844,  0.96875]],

              ...,

              [[ 0.63672,  0.35547,  ...,  0.62891,  0.48828],
               [ 0.08594,  0.80469,  ...,  0.65234,  0.53516],
               ...,
               [ 0.91016,  0.96875,  ...,  0.40625,  0.80859],
               [ 0.55859,  0.12891,  ...,  0.23047,  0.60938]],

              [[ 0.11328,  0.56250,  ...,  0.83594,  0.25781],
               [ 0.85938,  0.52734,  ...,  0.14453,  0.76562],
               ...,
               [ 0.19531,  0.17969,  ...,  0.14062,  0.55859],
               [ 0.04688,  0.71875,  ...,  0.90625,  0.67188]]]], shape=Shape([1, 641, 401, 32]), dtype=DataType::BFLOAT16, layout=Layout::TILE))
ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape10] 2025-08-01 23:03:09.535 | warning  |          Always | Closing and re-initializing MetalContext with same parameters due to force_reinit flag. (metal_context.cpp:77)
2025-08-01 23:03:09.911 | warning  |           Metal | Opening subset of mmio devices slows down UMD read/write to remote chips. If opening more devices, consider using CreateDevices API. (device_pool.cpp:304)
SKIPPED (Type error: [1, 64, 640, 400] - __call__(): incompatible function arguments. The following argument types are supported:
    1. (self: ttnn._ttnn.operations.pool.max_pool2d_t, input_tensor: ttnn._ttnn.tensor.Tensor, batch_size: int, input_h: int, input_w: int, channels: int, kernel_size: Annotated[list[int], FixedSize(2)], stride: Annotated[list[int], FixedSize(2)], padding: Union[Annotated[list[int], FixedSize(2)], Annotated[list[int], FixedSize(4)]], dilation: Annotated[list[int], FixedSize(2)], ceil_mode: bool = False, *, memory_config: Optional[ttnn._ttnn.tensor.MemoryConfig] = None, applied_shard_scheme: Optional[ttnn._ttnn.tensor.TensorMemoryLayout] = None, in_place_halo: bool = False, queue_id: ttnn._ttnn.types.QueueId = QueueId(0)) -> ttnn._ttnn.tensor.Tensor

Invoked with: <ttnn._ttnn.operations.pool.max_pool2d_t object at 0x7f14560ca530>, ttnn.Tensor([[[[ 0.67188,  0.11328,  ...,  0.45312,  0.32812],
               [ 0.18359,  0.32812,  ...,  0.81250,  0.44922],
               ...,
               [ 0.61719,  0.43750,  ...,  0.09375,  0.03125],
               [ 0.56641,  0.15234,  ...,  0.65625,  0.72266]],

              [[ 0.77344,  0.31641,  ...,  0.77734,  0.93750],
               [ 0.77734,  0.37891,  ...,  0.77734,  0.94922],
               ...,
               [ 0.71875,  0.98828,  ...,  0.91016,  0.48047],
               [ 0.46875,  0.99609,  ...,  0.81641,  0.01562]],

              ...,

              [[ 0.59375,  0.04688,  ...,  0.25000,  0.71094],
               [ 0.76172,  0.75391,  ...,  0.91797,  0.87500],
               ...,
               [ 0.09375,  0.09375,  ...,  0.43750,  0.92969],
               [ 0.60547,  0.35547,  ...,  0.54297,  0.08594]],

              [[ 0.28906,  0.01953,  ...,  0.04688,  0.08594],
               [ 0.25781,  0.56641,  ...,  0.16797,  0.11328],
               ...,
               [ 0.36719,  0.07031,  ...,  0.76953,  0.70312],
               [ 0.83203,  0.42188,  ...,  0.50391,  0.16016]]]], shape=Shape([1, 640, 400, 64]), dtype=DataType::BFLOAT16, layout=Layout::TILE))
ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape11] 2025-08-01 23:03:10.478 | warning  |          Always | Closing and re-initializing MetalContext with same parameters due to force_reinit flag. (metal_context.cpp:77)
2025-08-01 23:03:10.851 | warning  |           Metal | Opening subset of mmio devices slows down UMD read/write to remote chips. If opening more devices, consider using CreateDevices API. (device_pool.cpp:304)
2025-08-01 23:03:11.400 | critical |          Always | Out of Memory: Not enough space to allocate 131072000 B L1 buffer across 64 banks, where each bank needs to store 2048000 B (assert.hpp:107)
SKIPPED (OOM: [1, 64, 1280, 800] - TT_THROW @ /home/ttuser/ssinghal/main/tt-metal/tt_metal/impl/allocator/bank_manager.cpp:141: tt::exception
info:
Out of Memory: Not enough space to allocate 131072000 B L1 buffer across 64 banks, where each bank needs to store 2048000 B
backtrace:
 --- /home/ttuser/ssinghal/main/tt-metal/build_Release/lib/libtt_metal.so(+0x2d0df5) [0x7f145702bdf5]
 --- tt::tt_metal::BankManager::allocate_buffer(unsigned long, unsigned long, bool, CoreRangeSet const&, std::optional<unsigned int>)
 --- tt::tt_metal::Allocator::allocate_buffer(tt::tt_metal::Buffer*)
 --- tt::tt_metal::Buffer::allocate_impl()
 --- tt::tt_metal::Buffer::create(tt::tt_metal::IDevice*, unsigned long, unsigned long, tt::tt_metal::BufferType, tt::tt_metal::BufferShardingArgs const&, std::optional<bool>, std::optional<ttsl::StrongType<unsigned char, tt::tt_metal::SubDeviceIdTag> >)
 --- tt::tt_metal::distributed::MeshBuffer::create(std::variant<tt::tt_metal::distributed::ReplicatedBufferConfig, tt::tt_metal::distributed::ShardedBufferConfig> const&, tt::tt_metal::distributed::DeviceLocalBufferConfig const&, tt::tt_metal::distributed::MeshDevice*, std::optional<unsigned long>)
 --- tt::tt_metal::tensor_impl::allocate_mesh_buffer_on_device(tt::tt_metal::distributed::MeshDevice*, tt::tt_metal::TensorSpec const&)
 --- tt::tt_metal::Tensor tt::tt_metal::tensor_impl::to_device_mesh_tensor<bfloat16>(tt::tt_metal::Tensor const&, tt::tt_metal::distributed::MeshDevice*, tt::tt_metal::MemoryConfig const&, ttsl::StrongType<unsigned char, ttnn::QueueIdTag>)
 --- /home/ttuser/ssinghal/main/tt-metal/build_Release/lib/_ttnncpp.so(_ZN2tt8tt_metal11tensor_impl8dispatchIZNS1_29to_device_mesh_tensor_wrapperIJRKNS0_6TensorERPNS0_11distributed10MeshDeviceERKNS0_12MemoryConfigERN4ttsl10StrongTypeIhN4ttnn10QueueIdTagEEEEEEDaDpOT_EUlTyDpOT0_E_JS6_SA_SD_SJ_EEEDaNS0_8DataTypeEOT_SP_+0x39) [0x7f14579f6ff9]
 --- tt::tt_metal::tensor_ops::tensor_to_device(tt::tt_metal::Tensor const&, tt::tt_metal::distributed::MeshDevice*, tt::tt_metal::MemoryConfig const&, ttsl::StrongType<unsigned char, ttnn::QueueIdTag>)
 --- tt::tt_metal::Tensor tt::tt_metal::Tensor::from_span<bfloat16>(std::span<bfloat16 const, 18446744073709551615ul>, tt::tt_metal::TensorSpec const&, tt::tt_metal::distributed::MeshDevice*, ttsl::StrongType<unsigned char, ttnn::QueueIdTag>, bfloat16)
 --- /home/ttuser/ssinghal/main/tt-metal/ttnn/ttnn/_ttnn.so(+0x5eda43) [0x7f1458a75a43]
 --- /home/ttuser/ssinghal/main/tt-metal/ttnn/ttnn/_ttnn.so(+0x5eb124) [0x7f1458a73124]
 --- /home/ttuser/ssinghal/main/tt-metal/ttnn/ttnn/_ttnn.so(+0x5eae21) [0x7f1458a72e21]
 --- /home/ttuser/ssinghal/main/tt-metal/ttnn/ttnn/_ttnn.so(+0x517d27) [0x7f145899fd27]
 --- python_env/bin/python(+0x18ae52) [0x564a3ee28e52]
 --- python_env/bin/python(_PyObject_MakeTpCall+0x25b) [0x564a3ee1f77b]
 --- python_env/bin/python(+0x198bfb) [0x564a3ee36bfb]
 --- python_env/bin/python(_PyObject_Call+0x118) [0x564a3ee37768]
 --- python_env/bin/python(+0x19526b) [0x564a3ee3326b]
 --- python_env/bin/python(+0x181b1b) [0x564a3ee1fb1b]
 --- /home/ttuser/ssinghal/main/tt-metal/ttnn/ttnn/_ttnn.so(+0x51077b) [0x7f145899877b]
 --- python_env/bin/python(_PyObject_MakeTpCall+0x25b) [0x564a3ee1f77b]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x6907) [0x564a3ee19b77]
 --- python_env/bin/python(_PyFunction_Vectorcall+0x7c) [0x564a3ee296ac]
 --- python_env/bin/python(PyObject_Call+0x122) [0x564a3ee375c2]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x2a7b) [0x564a3ee15ceb]
 --- python_env/bin/python(_PyFunction_Vectorcall+0x7c) [0x564a3ee296ac]
 --- python_env/bin/python(_PyObject_FastCallDictTstate+0x16d) [0x564a3ee1e9fd]
 --- python_env/bin/python(_PyObject_Call_Prepend+0x5c) [0x564a3ee33a2c]
 --- python_env/bin/python(+0x29d854) [0x564a3ef3b854]
 --- python_env/bin/python(_PyObject_MakeTpCall+0x25b) [0x564a3ee1f77b]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x6907) [0x564a3ee19b77]
 --- python_env/bin/python(_PyFunction_Vectorcall+0x7c) [0x564a3ee296ac]
 --- python_env/bin/python(PyObject_Call+0x122) [0x564a3ee375c2]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x2a7b) [0x564a3ee15ceb]
 --- python_env/bin/python(_PyFunction_Vectorcall+0x7c) [0x564a3ee296ac]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x2a7b) [0x564a3ee15ceb]
 --- python_env/bin/python(_PyFunction_Vectorcall+0x7c) [0x564a3ee296ac]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x5633) [0x564a3ee188a3]
 --- python_env/bin/python(+0x198921) [0x564a3ee36921]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x5633) [0x564a3ee188a3]
 --- python_env/bin/python(_PyFunction_Vectorcall+0x7c) [0x564a3ee296ac]
 --- python_env/bin/python(_PyObject_FastCallDictTstate+0x16d) [0x564a3ee1e9fd]
 --- python_env/bin/python(_PyObject_Call_Prepend+0x5c) [0x564a3ee33a2c]
 --- python_env/bin/python(+0x29d854) [0x564a3ef3b854]
 --- python_env/bin/python(_PyObject_MakeTpCall+0x25b) [0x564a3ee1f77b]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x6907) [0x564a3ee19b77]
 --- python_env/bin/python(_PyFunction_Vectorcall+0x7c) [0x564a3ee296ac]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x807) [0x564a3ee13a77]
 --- python_env/bin/python(_PyFunction_Vectorcall+0x7c) [0x564a3ee296ac]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x2a7b) [0x564a3ee15ceb]
 --- python_env/bin/python(_PyFunction_Vectorcall+0x7c) [0x564a3ee296ac]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x5633) [0x564a3ee188a3]
 --- python_env/bin/python(+0x198921) [0x564a3ee36921]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x5633) [0x564a3ee188a3]
 --- python_env/bin/python(_PyFunction_Vectorcall+0x7c) [0x564a3ee296ac]
 --- python_env/bin/python(_PyObject_FastCallDictTstate+0x16d) [0x564a3ee1e9fd]
 --- python_env/bin/python(_PyObject_Call_Prepend+0x5c) [0x564a3ee33a2c]
 --- python_env/bin/python(+0x29d854) [0x564a3ef3b854]
 --- python_env/bin/python(PyObject_Call+0xbb) [0x564a3ee3755b]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x2a7b) [0x564a3ee15ceb]
 --- python_env/bin/python(_PyFunction_Vectorcall+0x7c) [0x564a3ee296ac]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x6c0) [0x564a3ee13930]
 --- python_env/bin/python(+0x198921) [0x564a3ee36921]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x1987) [0x564a3ee14bf7]
 --- python_env/bin/python(_PyFunction_Vectorcall+0x7c) [0x564a3ee296ac]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x2a7b) [0x564a3ee15ceb]
 --- python_env/bin/python(_PyFunction_Vectorcall+0x7c) [0x564a3ee296ac]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x6c0) [0x564a3ee13930]
 --- python_env/bin/python(_PyFunction_Vectorcall+0x7c) [0x564a3ee296ac]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x1987) [0x564a3ee14bf7]
 --- python_env/bin/python(_PyFunction_Vectorcall+0x7c) [0x564a3ee296ac]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x2a7b) [0x564a3ee15ceb]
 --- python_env/bin/python(_PyFunction_Vectorcall+0x7c) [0x564a3ee296ac]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x5633) [0x564a3ee188a3]
 --- python_env/bin/python(+0x198921) [0x564a3ee36921]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x5633) [0x564a3ee188a3]
 --- python_env/bin/python(_PyFunction_Vectorcall+0x7c) [0x564a3ee296ac]
 --- python_env/bin/python(_PyObject_FastCallDictTstate+0x16d) [0x564a3ee1e9fd]
 --- python_env/bin/python(_PyObject_Call_Prepend+0x5c) [0x564a3ee33a2c]
 --- python_env/bin/python(+0x29d854) [0x564a3ef3b854]
 --- python_env/bin/python(_PyObject_MakeTpCall+0x25b) [0x564a3ee1f77b]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x6907) [0x564a3ee19b77]
 --- python_env/bin/python(_PyFunction_Vectorcall+0x7c) [0x564a3ee296ac]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x2a7b) [0x564a3ee15ceb]
 --- python_env/bin/python(_PyFunction_Vectorcall+0x7c) [0x564a3ee296ac]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x5633) [0x564a3ee188a3]
 --- python_env/bin/python(+0x198921) [0x564a3ee36921]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x5633) [0x564a3ee188a3]
 --- python_env/bin/python(_PyFunction_Vectorcall+0x7c) [0x564a3ee296ac]
 --- python_env/bin/python(_PyObject_FastCallDictTstate+0x16d) [0x564a3ee1e9fd]
 --- python_env/bin/python(_PyObject_Call_Prepend+0x5c) [0x564a3ee33a2c]
 --- python_env/bin/python(+0x29d854) [0x564a3ef3b854]
 --- python_env/bin/python(_PyObject_MakeTpCall+0x25b) [0x564a3ee1f77b]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x6907) [0x564a3ee19b77]
 --- python_env/bin/python(_PyFunction_Vectorcall+0x7c) [0x564a3ee296ac])
ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape12] 2025-08-01 23:03:11.420 | warning  |          Always | Closing and re-initializing MetalContext with same parameters due to force_reinit flag. (metal_context.cpp:77)
2025-08-01 23:03:11.737 | warning  |           Metal | Opening subset of mmio devices slows down UMD read/write to remote chips. If opening more devices, consider using CreateDevices API. (device_pool.cpp:304)
SKIPPED (Type error: [1, 128, 640, 400] - __call__(): incompatible function arguments. The following argument types are supported:
    1. (self: ttnn._ttnn.operations.pool.max_pool2d_t, input_tensor: ttnn._ttnn.tensor.Tensor, batch_size: int, input_h: int, input_w: int, channels: int, kernel_size: Annotated[list[int], FixedSize(2)], stride: Annotated[list[int], FixedSize(2)], padding: Union[Annotated[list[int], FixedSize(2)], Annotated[list[int], FixedSize(4)]], dilation: Annotated[list[int], FixedSize(2)], ceil_mode: bool = False, *, memory_config: Optional[ttnn._ttnn.tensor.MemoryConfig] = None, applied_shard_scheme: Optional[ttnn._ttnn.tensor.TensorMemoryLayout] = None, in_place_halo: bool = False, queue_id: ttnn._ttnn.types.QueueId = QueueId(0)) -> ttnn._ttnn.tensor.Tensor

Invoked with: <ttnn._ttnn.operations.pool.max_pool2d_t object at 0x7f14560ca530>, ttnn.Tensor([[[[ 0.67188,  0.11328,  ...,  0.94531,  0.22656],
               [ 0.18359,  0.32812,  ...,  0.85547,  0.33594],
               ...,
               [ 0.61719,  0.43750,  ...,  0.80859,  0.14062],
               [ 0.56641,  0.15234,  ...,  0.86328,  0.27344]],

              [[ 0.77344,  0.31641,  ...,  0.89062,  0.10547],
               [ 0.77734,  0.37891,  ...,  0.13281,  0.61719],
               ...,
               [ 0.71875,  0.98828,  ...,  0.75391,  0.90625],
               [ 0.46875,  0.99609,  ...,  0.53516,  0.74219]],

              ...,

              [[ 0.59375,  0.04688,  ...,  0.05469,  0.72266],
               [ 0.76172,  0.75391,  ...,  0.16406,  0.35156],
               ...,
               [ 0.09375,  0.09375,  ...,  0.28125,  0.31250],
               [ 0.60547,  0.35547,  ...,  0.42969,  0.42578]],

              [[ 0.28906,  0.01953,  ...,  0.26172,  0.50781],
               [ 0.25781,  0.56641,  ...,  0.35156,  0.98828],
               ...,
               [ 0.36719,  0.07031,  ...,  0.48047,  0.65234],
               [ 0.83203,  0.42188,  ...,  0.62109,  0.96094]]]], shape=Shape([1, 640, 400, 128]), dtype=DataType::BFLOAT16, layout=Layout::TILE))

- generated xml file: /home/ttuser/ssinghal/main/tt-metal/generated/test_reports/most_recent_tests.xml -
============================== slowest durations ===============================
2.20s setup    ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape0]
1.13s call     ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape12]
0.57s call     ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape1]
0.56s call     ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape11]
0.56s call     ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape10]
0.38s setup    ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape9]
0.38s setup    ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape6]
0.38s setup    ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape10]
0.38s setup    ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape5]
0.38s setup    ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape4]
0.38s setup    ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape8]
0.38s setup    ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape7]
0.38s setup    ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape11]
0.36s setup    ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape1]
0.36s setup    ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape2]
0.33s setup    ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape3]
0.32s setup    ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape12]
0.27s call     ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape9]
0.26s call     ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape2]
0.13s call     ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape3]
0.06s call     ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape4]
0.05s call     ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape0]
0.04s call     ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape5]
0.01s call     ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape6]
0.01s teardown ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape4]
0.01s call     ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape7]
0.01s call     ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape8]
0.00s teardown ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape12]
0.00s teardown ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape9]
0.00s teardown ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape1]
0.00s teardown ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape10]
0.00s teardown ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape0]
0.00s teardown ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape5]
0.00s teardown ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape3]
0.00s teardown ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape6]
0.00s teardown ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape2]
0.00s teardown ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape8]
0.00s teardown ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape7]
0.00s teardown ssinghal/tests/test_maxpool2d.py::test_maxpool2d[input_shape11]
=========================== short test summary info ============================
SKIPPED [1] ssinghal/tests/test_maxpool2d.py:36: Type error: [1, 512, 40, 25] - __call__(): incompatible function arguments. The following argument types are supported:
    1. (self: ttnn._ttnn.operations.pool.max_pool2d_t, input_tensor: ttnn._ttnn.tensor.Tensor, batch_size: int, input_h: int, input_w: int, channels: int, kernel_size: Annotated[list[int], FixedSize(2)], stride: Annotated[list[int], FixedSize(2)], padding: Union[Annotated[list[int], FixedSize(2)], Annotated[list[int], FixedSize(4)]], dilation: Annotated[list[int], FixedSize(2)], ceil_mode: bool = False, *, memory_config: Optional[ttnn._ttnn.tensor.MemoryConfig] = None, applied_shard_scheme: Optional[ttnn._ttnn.tensor.TensorMemoryLayout] = None, in_place_halo: bool = False, queue_id: ttnn._ttnn.types.QueueId = QueueId(0)) -> ttnn._ttnn.tensor.Tensor

Invoked with: <ttnn._ttnn.operations.pool.max_pool2d_t object at 0x7f14560ca530>, ttnn.Tensor([[[[ 0.67188,  0.15234,  ...,  0.97656,  0.32812],
               [ 0.18359,  0.91406,  ...,  0.12891,  0.00391],
               ...,
               [ 0.67969,  0.39844,  ...,  0.55859,  0.92578],
               [ 0.34375,  0.07812,  ...,  0.20312,  0.99609]],

              [[ 0.31641,  0.66797,  ...,  0.26172,  0.39062],
               [ 0.64453,  0.46094,  ...,  0.08984,  0.71875],
               ...,
               [ 0.55469,  0.29297,  ...,  0.44141,  0.30078],
               [ 0.65234,  0.44531,  ...,  0.67188,  0.59375]],

              ...,

              [[ 0.28906,  0.76953,  ...,  0.88672,  0.15625],
               [ 0.32812,  0.12891,  ...,  0.62109,  0.31250],
               ...,
               [ 0.45703,  0.97656,  ...,  0.74219,  0.05859],
               [ 0.39062,  0.23828,  ...,  0.52734,  0.53125]],

              [[ 0.35156,  0.41406,  ...,  0.06641,  0.86328],
               [ 0.26562,  0.82422,  ...,  0.64062,  0.62891],
               ...,
               [ 0.59766,  0.23828,  ...,  0.06250,  0.07031],
               [ 0.59375,  0.70703,  ...,  0.36328,  0.42188]]]], shape=Shape([1, 40, 25, 512]), dtype=DataType::BFLOAT16, layout=Layout::TILE)
SKIPPED [1] ssinghal/tests/test_maxpool2d.py:36: Type error: [1, 256, 320, 200] - __call__(): incompatible function arguments. The following argument types are supported:
    1. (self: ttnn._ttnn.operations.pool.max_pool2d_t, input_tensor: ttnn._ttnn.tensor.Tensor, batch_size: int, input_h: int, input_w: int, channels: int, kernel_size: Annotated[list[int], FixedSize(2)], stride: Annotated[list[int], FixedSize(2)], padding: Union[Annotated[list[int], FixedSize(2)], Annotated[list[int], FixedSize(4)]], dilation: Annotated[list[int], FixedSize(2)], ceil_mode: bool = False, *, memory_config: Optional[ttnn._ttnn.tensor.MemoryConfig] = None, applied_shard_scheme: Optional[ttnn._ttnn.tensor.TensorMemoryLayout] = None, in_place_halo: bool = False, queue_id: ttnn._ttnn.types.QueueId = QueueId(0)) -> ttnn._ttnn.tensor.Tensor

Invoked with: <ttnn._ttnn.operations.pool.max_pool2d_t object at 0x7f14560ca530>, ttnn.Tensor([[[[ 0.67188,  0.65625,  ...,  0.18750,  0.63281],
               [ 0.18359,  0.55078,  ...,  0.77734,  0.89062],
               ...,
               [ 0.11719,  0.14844,  ...,  0.16016,  0.97656],
               [ 0.09375,  0.67578,  ...,  0.62500,  0.04297]],

              [[ 0.48828,  0.02734,  ...,  0.58984,  0.79688],
               [ 0.00781,  0.41797,  ...,  0.28516,  0.88672],
               ...,
               [ 0.61719,  0.89062,  ...,  0.00391,  0.42578],
               [ 0.56641,  0.01562,  ...,  0.71484,  0.59766]],

              ...,

              [[ 0.51562,  0.38281,  ...,  0.48438,  0.08594],
               [ 0.24219,  0.22266,  ...,  0.32812,  0.11328],
               ...,
               [ 0.35547,  0.00000,  ...,  0.39844,  0.91406],
               [ 0.07812,  0.32422,  ...,  0.37109,  0.55078]],

              [[ 0.69531,  0.67188,  ...,  0.87109,  0.11719],
               [ 0.28125,  0.83203,  ...,  0.94531,  0.42188],
               ...,
               [ 0.05469,  0.25781,  ...,  0.27344,  0.70312],
               [ 0.16016,  0.36719,  ...,  0.98438,  0.16016]]]], shape=Shape([1, 320, 200, 256]), dtype=DataType::BFLOAT16, layout=Layout::TILE)
SKIPPED [1] ssinghal/tests/test_maxpool2d.py:36: Type error: [1, 512, 160, 100] - __call__(): incompatible function arguments. The following argument types are supported:
    1. (self: ttnn._ttnn.operations.pool.max_pool2d_t, input_tensor: ttnn._ttnn.tensor.Tensor, batch_size: int, input_h: int, input_w: int, channels: int, kernel_size: Annotated[list[int], FixedSize(2)], stride: Annotated[list[int], FixedSize(2)], padding: Union[Annotated[list[int], FixedSize(2)], Annotated[list[int], FixedSize(4)]], dilation: Annotated[list[int], FixedSize(2)], ceil_mode: bool = False, *, memory_config: Optional[ttnn._ttnn.tensor.MemoryConfig] = None, applied_shard_scheme: Optional[ttnn._ttnn.tensor.TensorMemoryLayout] = None, in_place_halo: bool = False, queue_id: ttnn._ttnn.types.QueueId = QueueId(0)) -> ttnn._ttnn.tensor.Tensor

Invoked with: <ttnn._ttnn.operations.pool.max_pool2d_t object at 0x7f14560ca530>, ttnn.Tensor([[[[ 0.67188,  0.30859,  ...,  0.51953,  0.38281],
               [ 0.18359,  0.60156,  ...,  0.67969,  0.12500],
               ...,
               [ 0.20703,  0.23047,  ...,  0.73828,  0.98047],
               [ 0.54688,  0.94531,  ...,  0.11719,  0.17578]],

              [[ 0.47266,  0.77734,  ...,  0.84375,  0.00000],
               [ 0.66406,  0.66406,  ...,  0.29688,  0.62500],
               ...,
               [ 0.11719,  0.80859,  ...,  0.86328,  0.98828],
               [ 0.09375,  0.19922,  ...,  0.74219,  0.77734]],

              ...,

              [[ 0.09766,  0.90625,  ...,  0.85938,  0.38672],
               [ 0.05859,  0.21875,  ...,  0.57812,  0.56250],
               ...,
               [ 0.04297,  0.38672,  ...,  0.46875,  0.35547],
               [ 0.92969,  0.14453,  ...,  0.47656,  0.12109]],

              [[ 0.89453,  0.39062,  ...,  0.88281,  0.33984],
               [ 0.18750,  0.62891,  ...,  0.52344,  0.10156],
               ...,
               [ 0.07812,  0.47656,  ...,  0.91016,  0.66016],
               [ 0.71094,  0.76172,  ...,  0.08594,  0.26172]]]], shape=Shape([1, 160, 100, 512]), dtype=DataType::BFLOAT16, layout=Layout::TILE)
SKIPPED [1] ssinghal/tests/test_maxpool2d.py:36: Type error: [1, 1024, 80, 50] - __call__(): incompatible function arguments. The following argument types are supported:
    1. (self: ttnn._ttnn.operations.pool.max_pool2d_t, input_tensor: ttnn._ttnn.tensor.Tensor, batch_size: int, input_h: int, input_w: int, channels: int, kernel_size: Annotated[list[int], FixedSize(2)], stride: Annotated[list[int], FixedSize(2)], padding: Union[Annotated[list[int], FixedSize(2)], Annotated[list[int], FixedSize(4)]], dilation: Annotated[list[int], FixedSize(2)], ceil_mode: bool = False, *, memory_config: Optional[ttnn._ttnn.tensor.MemoryConfig] = None, applied_shard_scheme: Optional[ttnn._ttnn.tensor.TensorMemoryLayout] = None, in_place_halo: bool = False, queue_id: ttnn._ttnn.types.QueueId = QueueId(0)) -> ttnn._ttnn.tensor.Tensor

Invoked with: <ttnn._ttnn.operations.pool.max_pool2d_t object at 0x7f14560ca530>, ttnn.Tensor([[[[ 0.67188,  0.73047,  ...,  0.90234,  0.20703],
               [ 0.18359,  0.16797,  ...,  0.04688,  0.51172],
               ...,
               [ 0.55469,  0.71875,  ...,  0.71484,  0.19141],
               [ 0.65234,  0.87109,  ...,  0.23828,  0.76562]],

              [[ 0.12500,  0.86719,  ...,  0.34375,  0.26562],
               [ 0.75391,  0.01953,  ...,  0.65234,  0.62109],
               ...,
               [ 0.20703,  0.30859,  ...,  0.16016,  0.34375],
               [ 0.54688,  0.49609,  ...,  0.54297,  0.78906]],

              ...,

              [[ 0.16016,  0.23047,  ...,  0.55469,  0.39844],
               [ 0.07422,  0.45312,  ...,  0.08594,  0.17969],
               ...,
               [ 0.91016,  0.33984,  ...,  0.94141,  0.56250],
               [ 0.16016,  0.00391,  ...,  0.54297,  0.67578]],

              [[ 0.01172,  0.98047,  ...,  0.12109,  0.72266],
               [ 0.65234,  0.36328,  ...,  0.08594,  0.03906],
               ...,
               [ 0.13281,  0.59766,  ...,  0.87109,  0.99609],
               [ 0.29688,  0.54688,  ...,  0.60156,  0.57031]]]], shape=Shape([1, 80, 50, 1024]), dtype=DataType::BFLOAT16, layout=Layout::TILE)
SKIPPED [1] ssinghal/tests/test_maxpool2d.py:36: Type error: [1, 128, 160, 100] - __call__(): incompatible function arguments. The following argument types are supported:
    1. (self: ttnn._ttnn.operations.pool.max_pool2d_t, input_tensor: ttnn._ttnn.tensor.Tensor, batch_size: int, input_h: int, input_w: int, channels: int, kernel_size: Annotated[list[int], FixedSize(2)], stride: Annotated[list[int], FixedSize(2)], padding: Union[Annotated[list[int], FixedSize(2)], Annotated[list[int], FixedSize(4)]], dilation: Annotated[list[int], FixedSize(2)], ceil_mode: bool = False, *, memory_config: Optional[ttnn._ttnn.tensor.MemoryConfig] = None, applied_shard_scheme: Optional[ttnn._ttnn.tensor.TensorMemoryLayout] = None, in_place_halo: bool = False, queue_id: ttnn._ttnn.types.QueueId = QueueId(0)) -> ttnn._ttnn.tensor.Tensor

Invoked with: <ttnn._ttnn.operations.pool.max_pool2d_t object at 0x7f14560ca530>, ttnn.Tensor([[[[ 0.67188,  0.30859,  ...,  0.55078,  0.02734],
               [ 0.18359,  0.60156,  ...,  0.95312,  0.47656],
               ...,
               [ 0.20703,  0.23047,  ...,  0.56250,  0.53516],
               [ 0.54688,  0.94531,  ...,  0.90234,  0.73047]],

              [[ 0.47266,  0.77734,  ...,  0.56250,  0.28516],
               [ 0.66406,  0.66406,  ...,  0.82812,  0.05469],
               ...,
               [ 0.11719,  0.80859,  ...,  0.97656,  0.63672],
               [ 0.09375,  0.19922,  ...,  0.80859,  0.85938]],

              ...,

              [[ 0.09766,  0.90625,  ...,  0.95312,  0.93359],
               [ 0.05859,  0.21875,  ...,  0.35547,  0.06641],
               ...,
               [ 0.04297,  0.38672,  ...,  0.70703,  0.94531],
               [ 0.92969,  0.14453,  ...,  0.75391,  0.06250]],

              [[ 0.89453,  0.39062,  ...,  0.07422,  0.57812],
               [ 0.18750,  0.62891,  ...,  0.37500,  0.95312],
               ...,
               [ 0.07812,  0.47656,  ...,  0.42578,  0.16797],
               [ 0.71094,  0.76172,  ...,  0.00000,  0.03516]]]], shape=Shape([1, 160, 100, 128]), dtype=DataType::BFLOAT16, layout=Layout::TILE)
SKIPPED [1] ssinghal/tests/test_maxpool2d.py:36: Type error: [1, 256, 80, 50] - __call__(): incompatible function arguments. The following argument types are supported:
    1. (self: ttnn._ttnn.operations.pool.max_pool2d_t, input_tensor: ttnn._ttnn.tensor.Tensor, batch_size: int, input_h: int, input_w: int, channels: int, kernel_size: Annotated[list[int], FixedSize(2)], stride: Annotated[list[int], FixedSize(2)], padding: Union[Annotated[list[int], FixedSize(2)], Annotated[list[int], FixedSize(4)]], dilation: Annotated[list[int], FixedSize(2)], ceil_mode: bool = False, *, memory_config: Optional[ttnn._ttnn.tensor.MemoryConfig] = None, applied_shard_scheme: Optional[ttnn._ttnn.tensor.TensorMemoryLayout] = None, in_place_halo: bool = False, queue_id: ttnn._ttnn.types.QueueId = QueueId(0)) -> ttnn._ttnn.tensor.Tensor

Invoked with: <ttnn._ttnn.operations.pool.max_pool2d_t object at 0x7f14560ca530>, ttnn.Tensor([[[[ 0.67188,  0.73047,  ...,  0.95703,  0.53125],
               [ 0.18359,  0.16797,  ...,  0.00391,  0.90625],
               ...,
               [ 0.55469,  0.71875,  ...,  0.07031,  0.30859],
               [ 0.65234,  0.87109,  ...,  0.98438,  0.00781]],

              [[ 0.12500,  0.86719,  ...,  0.98828,  0.96094],
               [ 0.75391,  0.01953,  ...,  0.17969,  0.71094],
               ...,
               [ 0.20703,  0.30859,  ...,  0.16797,  0.59375],
               [ 0.54688,  0.49609,  ...,  0.60938,  0.58203]],

              ...,

              [[ 0.16016,  0.23047,  ...,  0.65625,  0.55859],
               [ 0.07422,  0.45312,  ...,  0.67969,  0.35156],
               ...,
               [ 0.91016,  0.33984,  ...,  0.00391,  0.19141],
               [ 0.16016,  0.00391,  ...,  0.47656,  0.06641]],

              [[ 0.01172,  0.98047,  ...,  0.42578,  0.08984],
               [ 0.65234,  0.36328,  ...,  0.81250,  0.37891],
               ...,
               [ 0.13281,  0.59766,  ...,  0.54688,  0.60547],
               [ 0.29688,  0.54688,  ...,  0.29688,  0.08203]]]], shape=Shape([1, 80, 50, 256]), dtype=DataType::BFLOAT16, layout=Layout::TILE)
SKIPPED [1] ssinghal/tests/test_maxpool2d.py:36: Type error: [1, 320, 40, 25] - __call__(): incompatible function arguments. The following argument types are supported:
    1. (self: ttnn._ttnn.operations.pool.max_pool2d_t, input_tensor: ttnn._ttnn.tensor.Tensor, batch_size: int, input_h: int, input_w: int, channels: int, kernel_size: Annotated[list[int], FixedSize(2)], stride: Annotated[list[int], FixedSize(2)], padding: Union[Annotated[list[int], FixedSize(2)], Annotated[list[int], FixedSize(4)]], dilation: Annotated[list[int], FixedSize(2)], ceil_mode: bool = False, *, memory_config: Optional[ttnn._ttnn.tensor.MemoryConfig] = None, applied_shard_scheme: Optional[ttnn._ttnn.tensor.TensorMemoryLayout] = None, in_place_halo: bool = False, queue_id: ttnn._ttnn.types.QueueId = QueueId(0)) -> ttnn._ttnn.tensor.Tensor

Invoked with: <ttnn._ttnn.operations.pool.max_pool2d_t object at 0x7f14560ca530>, ttnn.Tensor([[[[ 0.67188,  0.15234,  ...,  0.99219,  0.25000],
               [ 0.18359,  0.91406,  ...,  0.17188,  0.58203],
               ...,
               [ 0.67969,  0.39844,  ...,  0.26172,  0.34766],
               [ 0.34375,  0.07812,  ...,  0.19141,  0.98047]],

              [[ 0.31641,  0.66797,  ...,  0.35547,  0.34766],
               [ 0.64453,  0.46094,  ...,  0.64844,  0.23047],
               ...,
               [ 0.55469,  0.29297,  ...,  0.92578,  0.20703],
               [ 0.65234,  0.44531,  ...,  0.55469,  0.01172]],

              ...,

              [[ 0.28906,  0.76953,  ...,  0.78516,  0.13672],
               [ 0.32812,  0.12891,  ...,  0.98047,  0.09375],
               ...,
               [ 0.45703,  0.97656,  ...,  0.93750,  0.16797],
               [ 0.39062,  0.23828,  ...,  0.33203,  0.69531]],

              [[ 0.35156,  0.41406,  ...,  0.52344,  0.91797],
               [ 0.26562,  0.82422,  ...,  0.62891,  0.20703],
               ...,
               [ 0.59766,  0.23828,  ...,  0.19141,  0.10547],
               [ 0.59375,  0.70703,  ...,  0.32031,  0.33203]]]], shape=Shape([1, 40, 25, 320]), dtype=DataType::BFLOAT16, layout=Layout::TILE)
SKIPPED [1] ssinghal/tests/test_maxpool2d.py:36: Type error: [1, 256, 40, 25] - __call__(): incompatible function arguments. The following argument types are supported:
    1. (self: ttnn._ttnn.operations.pool.max_pool2d_t, input_tensor: ttnn._ttnn.tensor.Tensor, batch_size: int, input_h: int, input_w: int, channels: int, kernel_size: Annotated[list[int], FixedSize(2)], stride: Annotated[list[int], FixedSize(2)], padding: Union[Annotated[list[int], FixedSize(2)], Annotated[list[int], FixedSize(4)]], dilation: Annotated[list[int], FixedSize(2)], ceil_mode: bool = False, *, memory_config: Optional[ttnn._ttnn.tensor.MemoryConfig] = None, applied_shard_scheme: Optional[ttnn._ttnn.tensor.TensorMemoryLayout] = None, in_place_halo: bool = False, queue_id: ttnn._ttnn.types.QueueId = QueueId(0)) -> ttnn._ttnn.tensor.Tensor

Invoked with: <ttnn._ttnn.operations.pool.max_pool2d_t object at 0x7f14560ca530>, ttnn.Tensor([[[[ 0.67188,  0.15234,  ...,  0.10938,  0.19531],
               [ 0.18359,  0.91406,  ...,  0.14062,  0.41406],
               ...,
               [ 0.67969,  0.39844,  ...,  0.85547,  0.49609],
               [ 0.34375,  0.07812,  ...,  0.16406,  0.57812]],

              [[ 0.31641,  0.66797,  ...,  0.87109,  0.07812],
               [ 0.64453,  0.46094,  ...,  0.23047,  0.83984],
               ...,
               [ 0.55469,  0.29297,  ...,  0.50391,  0.57422],
               [ 0.65234,  0.44531,  ...,  0.96094,  0.01172]],

              ...,

              [[ 0.28906,  0.76953,  ...,  0.68359,  0.00000],
               [ 0.32812,  0.12891,  ...,  0.73828,  0.91016],
               ...,
               [ 0.45703,  0.97656,  ...,  0.03516,  0.76953],
               [ 0.39062,  0.23828,  ...,  0.87500,  0.42188]],

              [[ 0.35156,  0.41406,  ...,  0.87109,  0.86719],
               [ 0.26562,  0.82422,  ...,  0.48438,  0.22266],
               ...,
               [ 0.59766,  0.23828,  ...,  0.73438,  0.36719],
               [ 0.59375,  0.70703,  ...,  0.34375,  0.83203]]]], shape=Shape([1, 40, 25, 256]), dtype=DataType::BFLOAT16, layout=Layout::TILE)
SKIPPED [1] ssinghal/tests/test_maxpool2d.py:36: Type error: [1, 128, 40, 25] - __call__(): incompatible function arguments. The following argument types are supported:
    1. (self: ttnn._ttnn.operations.pool.max_pool2d_t, input_tensor: ttnn._ttnn.tensor.Tensor, batch_size: int, input_h: int, input_w: int, channels: int, kernel_size: Annotated[list[int], FixedSize(2)], stride: Annotated[list[int], FixedSize(2)], padding: Union[Annotated[list[int], FixedSize(2)], Annotated[list[int], FixedSize(4)]], dilation: Annotated[list[int], FixedSize(2)], ceil_mode: bool = False, *, memory_config: Optional[ttnn._ttnn.tensor.MemoryConfig] = None, applied_shard_scheme: Optional[ttnn._ttnn.tensor.TensorMemoryLayout] = None, in_place_halo: bool = False, queue_id: ttnn._ttnn.types.QueueId = QueueId(0)) -> ttnn._ttnn.tensor.Tensor

Invoked with: <ttnn._ttnn.operations.pool.max_pool2d_t object at 0x7f14560ca530>, ttnn.Tensor([[[[ 0.67188,  0.15234,  ...,  0.52344,  0.94141],
               [ 0.18359,  0.91406,  ...,  0.64453,  0.09375],
               ...,
               [ 0.67969,  0.39844,  ...,  0.15234,  0.85938],
               [ 0.34375,  0.07812,  ...,  0.05078,  0.47266]],

              [[ 0.31641,  0.66797,  ...,  0.68750,  0.22656],
               [ 0.64453,  0.46094,  ...,  0.30859,  0.31250],
               ...,
               [ 0.55469,  0.29297,  ...,  0.48438,  0.62891],
               [ 0.65234,  0.44531,  ...,  0.54688,  0.67188]],

              ...,

              [[ 0.28906,  0.76953,  ...,  0.89844,  0.42578],
               [ 0.32812,  0.12891,  ...,  0.83984,  0.41016],
               ...,
               [ 0.45703,  0.97656,  ...,  0.89453,  0.39062],
               [ 0.39062,  0.23828,  ...,  0.50000,  0.14453]],

              [[ 0.35156,  0.41406,  ...,  0.28906,  0.15234],
               [ 0.26562,  0.82422,  ...,  0.16406,  0.32812],
               ...,
               [ 0.59766,  0.23828,  ...,  0.02734,  0.25781],
               [ 0.59375,  0.70703,  ...,  0.19922,  0.36719]]]], shape=Shape([1, 40, 25, 128]), dtype=DataType::BFLOAT16, layout=Layout::TILE)
SKIPPED [1] ssinghal/tests/test_maxpool2d.py:36: Type error: [1, 32, 641, 401] - __call__(): incompatible function arguments. The following argument types are supported:
    1. (self: ttnn._ttnn.operations.pool.max_pool2d_t, input_tensor: ttnn._ttnn.tensor.Tensor, batch_size: int, input_h: int, input_w: int, channels: int, kernel_size: Annotated[list[int], FixedSize(2)], stride: Annotated[list[int], FixedSize(2)], padding: Union[Annotated[list[int], FixedSize(2)], Annotated[list[int], FixedSize(4)]], dilation: Annotated[list[int], FixedSize(2)], ceil_mode: bool = False, *, memory_config: Optional[ttnn._ttnn.tensor.MemoryConfig] = None, applied_shard_scheme: Optional[ttnn._ttnn.tensor.TensorMemoryLayout] = None, in_place_halo: bool = False, queue_id: ttnn._ttnn.types.QueueId = QueueId(0)) -> ttnn._ttnn.tensor.Tensor

Invoked with: <ttnn._ttnn.operations.pool.max_pool2d_t object at 0x7f14560ca530>, ttnn.Tensor([[[[ 0.67188,  0.76172,  ...,  0.92188,  0.10547],
               [ 0.18359,  0.42578,  ...,  0.26562,  0.83984],
               ...,
               [ 0.56641,  0.94531,  ...,  0.80469,  0.55078],
               [ 0.77344,  0.97656,  ...,  0.38281,  0.80859]],

              [[ 0.77734,  0.42578,  ...,  0.49609,  0.94531],
               [ 0.07031,  0.16016,  ...,  0.62891,  0.68750],
               ...,
               [ 0.25391,  0.48047,  ...,  0.11328,  0.78516],
               [ 0.75000,  0.16016,  ...,  0.14844,  0.96875]],

              ...,

              [[ 0.63672,  0.35547,  ...,  0.62891,  0.48828],
               [ 0.08594,  0.80469,  ...,  0.65234,  0.53516],
               ...,
               [ 0.91016,  0.96875,  ...,  0.40625,  0.80859],
               [ 0.55859,  0.12891,  ...,  0.23047,  0.60938]],

              [[ 0.11328,  0.56250,  ...,  0.83594,  0.25781],
               [ 0.85938,  0.52734,  ...,  0.14453,  0.76562],
               ...,
               [ 0.19531,  0.17969,  ...,  0.14062,  0.55859],
               [ 0.04688,  0.71875,  ...,  0.90625,  0.67188]]]], shape=Shape([1, 641, 401, 32]), dtype=DataType::BFLOAT16, layout=Layout::TILE)
SKIPPED [1] ssinghal/tests/test_maxpool2d.py:36: Type error: [1, 64, 640, 400] - __call__(): incompatible function arguments. The following argument types are supported:
    1. (self: ttnn._ttnn.operations.pool.max_pool2d_t, input_tensor: ttnn._ttnn.tensor.Tensor, batch_size: int, input_h: int, input_w: int, channels: int, kernel_size: Annotated[list[int], FixedSize(2)], stride: Annotated[list[int], FixedSize(2)], padding: Union[Annotated[list[int], FixedSize(2)], Annotated[list[int], FixedSize(4)]], dilation: Annotated[list[int], FixedSize(2)], ceil_mode: bool = False, *, memory_config: Optional[ttnn._ttnn.tensor.MemoryConfig] = None, applied_shard_scheme: Optional[ttnn._ttnn.tensor.TensorMemoryLayout] = None, in_place_halo: bool = False, queue_id: ttnn._ttnn.types.QueueId = QueueId(0)) -> ttnn._ttnn.tensor.Tensor

Invoked with: <ttnn._ttnn.operations.pool.max_pool2d_t object at 0x7f14560ca530>, ttnn.Tensor([[[[ 0.67188,  0.11328,  ...,  0.45312,  0.32812],
               [ 0.18359,  0.32812,  ...,  0.81250,  0.44922],
               ...,
               [ 0.61719,  0.43750,  ...,  0.09375,  0.03125],
               [ 0.56641,  0.15234,  ...,  0.65625,  0.72266]],

              [[ 0.77344,  0.31641,  ...,  0.77734,  0.93750],
               [ 0.77734,  0.37891,  ...,  0.77734,  0.94922],
               ...,
               [ 0.71875,  0.98828,  ...,  0.91016,  0.48047],
               [ 0.46875,  0.99609,  ...,  0.81641,  0.01562]],

              ...,

              [[ 0.59375,  0.04688,  ...,  0.25000,  0.71094],
               [ 0.76172,  0.75391,  ...,  0.91797,  0.87500],
               ...,
               [ 0.09375,  0.09375,  ...,  0.43750,  0.92969],
               [ 0.60547,  0.35547,  ...,  0.54297,  0.08594]],

              [[ 0.28906,  0.01953,  ...,  0.04688,  0.08594],
               [ 0.25781,  0.56641,  ...,  0.16797,  0.11328],
               ...,
               [ 0.36719,  0.07031,  ...,  0.76953,  0.70312],
               [ 0.83203,  0.42188,  ...,  0.50391,  0.16016]]]], shape=Shape([1, 640, 400, 64]), dtype=DataType::BFLOAT16, layout=Layout::TILE)
SKIPPED [1] ssinghal/tests/test_maxpool2d.py:31: OOM: [1, 64, 1280, 800] - TT_THROW @ /home/ttuser/ssinghal/main/tt-metal/tt_metal/impl/allocator/bank_manager.cpp:141: tt::exception
info:
Out of Memory: Not enough space to allocate 131072000 B L1 buffer across 64 banks, where each bank needs to store 2048000 B
backtrace:
 --- /home/ttuser/ssinghal/main/tt-metal/build_Release/lib/libtt_metal.so(+0x2d0df5) [0x7f145702bdf5]
 --- tt::tt_metal::BankManager::allocate_buffer(unsigned long, unsigned long, bool, CoreRangeSet const&, std::optional<unsigned int>)
 --- tt::tt_metal::Allocator::allocate_buffer(tt::tt_metal::Buffer*)
 --- tt::tt_metal::Buffer::allocate_impl()
 --- tt::tt_metal::Buffer::create(tt::tt_metal::IDevice*, unsigned long, unsigned long, tt::tt_metal::BufferType, tt::tt_metal::BufferShardingArgs const&, std::optional<bool>, std::optional<ttsl::StrongType<unsigned char, tt::tt_metal::SubDeviceIdTag> >)
 --- tt::tt_metal::distributed::MeshBuffer::create(std::variant<tt::tt_metal::distributed::ReplicatedBufferConfig, tt::tt_metal::distributed::ShardedBufferConfig> const&, tt::tt_metal::distributed::DeviceLocalBufferConfig const&, tt::tt_metal::distributed::MeshDevice*, std::optional<unsigned long>)
 --- tt::tt_metal::tensor_impl::allocate_mesh_buffer_on_device(tt::tt_metal::distributed::MeshDevice*, tt::tt_metal::TensorSpec const&)
 --- tt::tt_metal::Tensor tt::tt_metal::tensor_impl::to_device_mesh_tensor<bfloat16>(tt::tt_metal::Tensor const&, tt::tt_metal::distributed::MeshDevice*, tt::tt_metal::MemoryConfig const&, ttsl::StrongType<unsigned char, ttnn::QueueIdTag>)
 --- /home/ttuser/ssinghal/main/tt-metal/build_Release/lib/_ttnncpp.so(_ZN2tt8tt_metal11tensor_impl8dispatchIZNS1_29to_device_mesh_tensor_wrapperIJRKNS0_6TensorERPNS0_11distributed10MeshDeviceERKNS0_12MemoryConfigERN4ttsl10StrongTypeIhN4ttnn10QueueIdTagEEEEEEDaDpOT_EUlTyDpOT0_E_JS6_SA_SD_SJ_EEEDaNS0_8DataTypeEOT_SP_+0x39) [0x7f14579f6ff9]
 --- tt::tt_metal::tensor_ops::tensor_to_device(tt::tt_metal::Tensor const&, tt::tt_metal::distributed::MeshDevice*, tt::tt_metal::MemoryConfig const&, ttsl::StrongType<unsigned char, ttnn::QueueIdTag>)
 --- tt::tt_metal::Tensor tt::tt_metal::Tensor::from_span<bfloat16>(std::span<bfloat16 const, 18446744073709551615ul>, tt::tt_metal::TensorSpec const&, tt::tt_metal::distributed::MeshDevice*, ttsl::StrongType<unsigned char, ttnn::QueueIdTag>, bfloat16)
 --- /home/ttuser/ssinghal/main/tt-metal/ttnn/ttnn/_ttnn.so(+0x5eda43) [0x7f1458a75a43]
 --- /home/ttuser/ssinghal/main/tt-metal/ttnn/ttnn/_ttnn.so(+0x5eb124) [0x7f1458a73124]
 --- /home/ttuser/ssinghal/main/tt-metal/ttnn/ttnn/_ttnn.so(+0x5eae21) [0x7f1458a72e21]
 --- /home/ttuser/ssinghal/main/tt-metal/ttnn/ttnn/_ttnn.so(+0x517d27) [0x7f145899fd27]
 --- python_env/bin/python(+0x18ae52) [0x564a3ee28e52]
 --- python_env/bin/python(_PyObject_MakeTpCall+0x25b) [0x564a3ee1f77b]
 --- python_env/bin/python(+0x198bfb) [0x564a3ee36bfb]
 --- python_env/bin/python(_PyObject_Call+0x118) [0x564a3ee37768]
 --- python_env/bin/python(+0x19526b) [0x564a3ee3326b]
 --- python_env/bin/python(+0x181b1b) [0x564a3ee1fb1b]
 --- /home/ttuser/ssinghal/main/tt-metal/ttnn/ttnn/_ttnn.so(+0x51077b) [0x7f145899877b]
 --- python_env/bin/python(_PyObject_MakeTpCall+0x25b) [0x564a3ee1f77b]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x6907) [0x564a3ee19b77]
 --- python_env/bin/python(_PyFunction_Vectorcall+0x7c) [0x564a3ee296ac]
 --- python_env/bin/python(PyObject_Call+0x122) [0x564a3ee375c2]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x2a7b) [0x564a3ee15ceb]
 --- python_env/bin/python(_PyFunction_Vectorcall+0x7c) [0x564a3ee296ac]
 --- python_env/bin/python(_PyObject_FastCallDictTstate+0x16d) [0x564a3ee1e9fd]
 --- python_env/bin/python(_PyObject_Call_Prepend+0x5c) [0x564a3ee33a2c]
 --- python_env/bin/python(+0x29d854) [0x564a3ef3b854]
 --- python_env/bin/python(_PyObject_MakeTpCall+0x25b) [0x564a3ee1f77b]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x6907) [0x564a3ee19b77]
 --- python_env/bin/python(_PyFunction_Vectorcall+0x7c) [0x564a3ee296ac]
 --- python_env/bin/python(PyObject_Call+0x122) [0x564a3ee375c2]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x2a7b) [0x564a3ee15ceb]
 --- python_env/bin/python(_PyFunction_Vectorcall+0x7c) [0x564a3ee296ac]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x2a7b) [0x564a3ee15ceb]
 --- python_env/bin/python(_PyFunction_Vectorcall+0x7c) [0x564a3ee296ac]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x5633) [0x564a3ee188a3]
 --- python_env/bin/python(+0x198921) [0x564a3ee36921]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x5633) [0x564a3ee188a3]
 --- python_env/bin/python(_PyFunction_Vectorcall+0x7c) [0x564a3ee296ac]
 --- python_env/bin/python(_PyObject_FastCallDictTstate+0x16d) [0x564a3ee1e9fd]
 --- python_env/bin/python(_PyObject_Call_Prepend+0x5c) [0x564a3ee33a2c]
 --- python_env/bin/python(+0x29d854) [0x564a3ef3b854]
 --- python_env/bin/python(_PyObject_MakeTpCall+0x25b) [0x564a3ee1f77b]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x6907) [0x564a3ee19b77]
 --- python_env/bin/python(_PyFunction_Vectorcall+0x7c) [0x564a3ee296ac]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x807) [0x564a3ee13a77]
 --- python_env/bin/python(_PyFunction_Vectorcall+0x7c) [0x564a3ee296ac]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x2a7b) [0x564a3ee15ceb]
 --- python_env/bin/python(_PyFunction_Vectorcall+0x7c) [0x564a3ee296ac]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x5633) [0x564a3ee188a3]
 --- python_env/bin/python(+0x198921) [0x564a3ee36921]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x5633) [0x564a3ee188a3]
 --- python_env/bin/python(_PyFunction_Vectorcall+0x7c) [0x564a3ee296ac]
 --- python_env/bin/python(_PyObject_FastCallDictTstate+0x16d) [0x564a3ee1e9fd]
 --- python_env/bin/python(_PyObject_Call_Prepend+0x5c) [0x564a3ee33a2c]
 --- python_env/bin/python(+0x29d854) [0x564a3ef3b854]
 --- python_env/bin/python(PyObject_Call+0xbb) [0x564a3ee3755b]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x2a7b) [0x564a3ee15ceb]
 --- python_env/bin/python(_PyFunction_Vectorcall+0x7c) [0x564a3ee296ac]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x6c0) [0x564a3ee13930]
 --- python_env/bin/python(+0x198921) [0x564a3ee36921]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x1987) [0x564a3ee14bf7]
 --- python_env/bin/python(_PyFunction_Vectorcall+0x7c) [0x564a3ee296ac]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x2a7b) [0x564a3ee15ceb]
 --- python_env/bin/python(_PyFunction_Vectorcall+0x7c) [0x564a3ee296ac]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x6c0) [0x564a3ee13930]
 --- python_env/bin/python(_PyFunction_Vectorcall+0x7c) [0x564a3ee296ac]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x1987) [0x564a3ee14bf7]
 --- python_env/bin/python(_PyFunction_Vectorcall+0x7c) [0x564a3ee296ac]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x2a7b) [0x564a3ee15ceb]
 --- python_env/bin/python(_PyFunction_Vectorcall+0x7c) [0x564a3ee296ac]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x5633) [0x564a3ee188a3]
 --- python_env/bin/python(+0x198921) [0x564a3ee36921]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x5633) [0x564a3ee188a3]
 --- python_env/bin/python(_PyFunction_Vectorcall+0x7c) [0x564a3ee296ac]
 --- python_env/bin/python(_PyObject_FastCallDictTstate+0x16d) [0x564a3ee1e9fd]
 --- python_env/bin/python(_PyObject_Call_Prepend+0x5c) [0x564a3ee33a2c]
 --- python_env/bin/python(+0x29d854) [0x564a3ef3b854]
 --- python_env/bin/python(_PyObject_MakeTpCall+0x25b) [0x564a3ee1f77b]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x6907) [0x564a3ee19b77]
 --- python_env/bin/python(_PyFunction_Vectorcall+0x7c) [0x564a3ee296ac]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x2a7b) [0x564a3ee15ceb]
 --- python_env/bin/python(_PyFunction_Vectorcall+0x7c) [0x564a3ee296ac]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x5633) [0x564a3ee188a3]
 --- python_env/bin/python(+0x198921) [0x564a3ee36921]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x5633) [0x564a3ee188a3]
 --- python_env/bin/python(_PyFunction_Vectorcall+0x7c) [0x564a3ee296ac]
 --- python_env/bin/python(_PyObject_FastCallDictTstate+0x16d) [0x564a3ee1e9fd]
 --- python_env/bin/python(_PyObject_Call_Prepend+0x5c) [0x564a3ee33a2c]
 --- python_env/bin/python(+0x29d854) [0x564a3ef3b854]
 --- python_env/bin/python(_PyObject_MakeTpCall+0x25b) [0x564a3ee1f77b]
 --- python_env/bin/python(_PyEval_EvalFrameDefault+0x6907) [0x564a3ee19b77]
 --- python_env/bin/python(_PyFunction_Vectorcall+0x7c) [0x564a3ee296ac]
SKIPPED [1] ssinghal/tests/test_maxpool2d.py:36: Type error: [1, 128, 640, 400] - __call__(): incompatible function arguments. The following argument types are supported:
    1. (self: ttnn._ttnn.operations.pool.max_pool2d_t, input_tensor: ttnn._ttnn.tensor.Tensor, batch_size: int, input_h: int, input_w: int, channels: int, kernel_size: Annotated[list[int], FixedSize(2)], stride: Annotated[list[int], FixedSize(2)], padding: Union[Annotated[list[int], FixedSize(2)], Annotated[list[int], FixedSize(4)]], dilation: Annotated[list[int], FixedSize(2)], ceil_mode: bool = False, *, memory_config: Optional[ttnn._ttnn.tensor.MemoryConfig] = None, applied_shard_scheme: Optional[ttnn._ttnn.tensor.TensorMemoryLayout] = None, in_place_halo: bool = False, queue_id: ttnn._ttnn.types.QueueId = QueueId(0)) -> ttnn._ttnn.tensor.Tensor

Invoked with: <ttnn._ttnn.operations.pool.max_pool2d_t object at 0x7f14560ca530>, ttnn.Tensor([[[[ 0.67188,  0.11328,  ...,  0.94531,  0.22656],
               [ 0.18359,  0.32812,  ...,  0.85547,  0.33594],
               ...,
               [ 0.61719,  0.43750,  ...,  0.80859,  0.14062],
               [ 0.56641,  0.15234,  ...,  0.86328,  0.27344]],

              [[ 0.77344,  0.31641,  ...,  0.89062,  0.10547],
               [ 0.77734,  0.37891,  ...,  0.13281,  0.61719],
               ...,
               [ 0.71875,  0.98828,  ...,  0.75391,  0.90625],
               [ 0.46875,  0.99609,  ...,  0.53516,  0.74219]],

              ...,

              [[ 0.59375,  0.04688,  ...,  0.05469,  0.72266],
               [ 0.76172,  0.75391,  ...,  0.16406,  0.35156],
               ...,
               [ 0.09375,  0.09375,  ...,  0.28125,  0.31250],
               [ 0.60547,  0.35547,  ...,  0.42969,  0.42578]],

              [[ 0.28906,  0.01953,  ...,  0.26172,  0.50781],
               [ 0.25781,  0.56641,  ...,  0.35156,  0.98828],
               ...,
               [ 0.36719,  0.07031,  ...,  0.48047,  0.65234],
               [ 0.83203,  0.42188,  ...,  0.62109,  0.96094]]]], shape=Shape([1, 640, 400, 128]), dtype=DataType::BFLOAT16, layout=Layout::TILE)
============================= 13 skipped in 10.37s =============================
2025-08-01 23:03:13.298 | info     |          Device | Closing user mode device drivers (tt_cluster.cpp:406)
