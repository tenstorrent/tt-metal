2025-08-01 23:02:53.618 | DEBUG    | ttnn:<module>:83 - Initial ttnn.CONFIG:
Config{cache_path=/home/ttuser/.cache/ttnn,model_cache_path=/home/ttuser/.cache/ttnn/models,tmp_dir=/tmp/ttnn,enable_model_cache=false,enable_fast_runtime_mode=true,throw_exception_on_fallback=false,enable_logging=false,enable_graph_report=false,enable_detailed_buffer_report=false,enable_detailed_tensor_report=false,enable_comparison_mode=false,comparison_mode_should_raise_exception=false,comparison_mode_pcc=0.9999,root_report_path=generated/ttnn/reports,report_name=std::nullopt,std::nullopt}
2025-08-01 23:02:53.718 | info     |   SiliconDriver | Opened PCI device 0; KMD version: 2.0.0; API: 2; IOMMU: disabled (pci_device.cpp:197)
2025-08-01 23:02:53.721 | info     |   SiliconDriver | Opened PCI device 1; KMD version: 2.0.0; API: 2; IOMMU: disabled (pci_device.cpp:197)
2025-08-01 23:02:53.723 | info     |   SiliconDriver | Opened PCI device 2; KMD version: 2.0.0; API: 2; IOMMU: disabled (pci_device.cpp:197)
2025-08-01 23:02:53.726 | info     |   SiliconDriver | Opened PCI device 3; KMD version: 2.0.0; API: 2; IOMMU: disabled (pci_device.cpp:197)
2025-08-01 23:02:53.750 | info     |          Device | Opening user mode device driver (tt_cluster.cpp:192)
2025-08-01 23:02:53.751 | info     |   SiliconDriver | Opened PCI device 0; KMD version: 2.0.0; API: 2; IOMMU: disabled (pci_device.cpp:197)
2025-08-01 23:02:53.753 | info     |   SiliconDriver | Opened PCI device 1; KMD version: 2.0.0; API: 2; IOMMU: disabled (pci_device.cpp:197)
2025-08-01 23:02:53.755 | info     |   SiliconDriver | Opened PCI device 2; KMD version: 2.0.0; API: 2; IOMMU: disabled (pci_device.cpp:197)
2025-08-01 23:02:53.758 | info     |   SiliconDriver | Opened PCI device 3; KMD version: 2.0.0; API: 2; IOMMU: disabled (pci_device.cpp:197)
2025-08-01 23:02:53.783 | info     |   SiliconDriver | Opened PCI device 0; KMD version: 2.0.0; API: 2; IOMMU: disabled (pci_device.cpp:197)
2025-08-01 23:02:53.785 | info     |   SiliconDriver | Opened PCI device 1; KMD version: 2.0.0; API: 2; IOMMU: disabled (pci_device.cpp:197)
2025-08-01 23:02:53.787 | info     |   SiliconDriver | Opened PCI device 2; KMD version: 2.0.0; API: 2; IOMMU: disabled (pci_device.cpp:197)
2025-08-01 23:02:53.789 | info     |   SiliconDriver | Opened PCI device 3; KMD version: 2.0.0; API: 2; IOMMU: disabled (pci_device.cpp:197)
2025-08-01 23:02:53.812 | info     |   SiliconDriver | Harvesting mask for chip 3 is 0x210 (NOC0: 0x210, simulated harvesting mask: 0x0). (cluster.cpp:295)
2025-08-01 23:02:53.820 | info     |   SiliconDriver | Opened PCI device 0; KMD version: 2.0.0; API: 2; IOMMU: disabled (pci_device.cpp:197)
2025-08-01 23:02:53.875 | info     |   SiliconDriver | Harvesting mask for chip 2 is 0x204 (NOC0: 0x204, simulated harvesting mask: 0x0). (cluster.cpp:295)
2025-08-01 23:02:53.883 | info     |   SiliconDriver | Opened PCI device 1; KMD version: 2.0.0; API: 2; IOMMU: disabled (pci_device.cpp:197)
2025-08-01 23:02:53.885 | info     |   SiliconDriver | Harvesting mask for chip 1 is 0x202 (NOC0: 0x202, simulated harvesting mask: 0x0). (cluster.cpp:295)
2025-08-01 23:02:53.900 | info     |   SiliconDriver | Opened PCI device 2; KMD version: 2.0.0; API: 2; IOMMU: disabled (pci_device.cpp:197)
2025-08-01 23:02:53.901 | info     |   SiliconDriver | Harvesting mask for chip 0 is 0x300 (NOC0: 0x300, simulated harvesting mask: 0x0). (cluster.cpp:295)
2025-08-01 23:02:53.909 | info     |   SiliconDriver | Opened PCI device 3; KMD version: 2.0.0; API: 2; IOMMU: disabled (pci_device.cpp:197)
2025-08-01 23:02:53.911 | info     |   SiliconDriver | Harvesting mask for chip 7 is 0x210 (NOC0: 0x210, simulated harvesting mask: 0x0). (cluster.cpp:295)
2025-08-01 23:02:53.921 | info     |   SiliconDriver | Harvesting mask for chip 6 is 0x300 (NOC0: 0x300, simulated harvesting mask: 0x0). (cluster.cpp:295)
2025-08-01 23:02:53.930 | info     |   SiliconDriver | Harvesting mask for chip 5 is 0x300 (NOC0: 0x300, simulated harvesting mask: 0x0). (cluster.cpp:295)
2025-08-01 23:02:53.940 | info     |   SiliconDriver | Harvesting mask for chip 4 is 0x208 (NOC0: 0x208, simulated harvesting mask: 0x0). (cluster.cpp:295)
2025-08-01 23:02:53.949 | info     |   SiliconDriver | Opening local chip ids/pci ids: {0, 1, 2, 3}/[3, 2, 1, 0] and remote chip ids {4, 5, 6, 7} (cluster.cpp:157)
2025-08-01 23:02:53.952 | info     |   SiliconDriver | All devices in cluster running firmware version: 80.17.0 (cluster.cpp:138)
2025-08-01 23:02:53.952 | info     |   SiliconDriver | Software version 6.0.0, Ethernet FW version 6.14.0 (Device 0) (cluster.cpp:935)
2025-08-01 23:02:53.952 | info     |   SiliconDriver | Software version 6.0.0, Ethernet FW version 6.14.0 (Device 1) (cluster.cpp:935)
2025-08-01 23:02:53.952 | info     |   SiliconDriver | Software version 6.0.0, Ethernet FW version 6.14.0 (Device 2) (cluster.cpp:935)
2025-08-01 23:02:53.952 | info     |   SiliconDriver | Software version 6.0.0, Ethernet FW version 6.14.0 (Device 3) (cluster.cpp:935)
2025-08-01 23:02:53.952 | info     |   SiliconDriver | Software version 6.0.0, Ethernet FW version 6.14.0 (Device 4) (cluster.cpp:935)
2025-08-01 23:02:53.953 | info     |   SiliconDriver | Software version 6.0.0, Ethernet FW version 6.14.0 (Device 5) (cluster.cpp:935)
2025-08-01 23:02:53.954 | info     |   SiliconDriver | Software version 6.0.0, Ethernet FW version 6.14.0 (Device 6) (cluster.cpp:935)
2025-08-01 23:02:53.954 | info     |   SiliconDriver | Software version 6.0.0, Ethernet FW version 6.14.0 (Device 7) (cluster.cpp:935)
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-7.2.2, pluggy-1.6.0 -- /home/ttuser/ssinghal/main/tt-metal/python_env/bin/python
cachedir: .pytest_cache
benchmark: 4.0.0 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)
rootdir: /home/ttuser/ssinghal/main/tt-metal, configfile: pytest.ini
plugins: xdist-3.6.1, split-0.8.2, anyio-4.9.0, dash-2.15.0, timeout-2.2.0, benchmark-4.0.0, github-actions-annotate-failures-0.3.0
timeout: 300.0s
timeout method: signal
timeout func_only: False
collecting ... collected 8 items

ssinghal/tests/test_leakyrelu.py::test_leakyrelu[input_shape0] 2025-08-01 23:02:55.026 | warning  |           Metal | Opening subset of mmio devices slows down UMD read/write to remote chips. If opening more devices, consider using CreateDevices API. (device_pool.cpp:304)
SKIPPED (Type error: [1, 512, 40, 25] - __call__(): incompatible function arguments. The following argument types are supported:
    1. (self: ttnn._ttnn.operations.unary.leaky_relu_t, input_tensor: ttnn._ttnn.tensor.Tensor, negative_slope: float, *, memory_config: Optional[ttnn._ttnn.tensor.MemoryConfig] = None, output_tensor: Optional[ttnn._ttnn.tensor.Tensor] = None, queue_id: ttnn._ttnn.types.QueueId = QueueId(0)) -> ttnn._ttnn.tensor.Tensor

Invoked with: <ttnn._ttnn.operations.unary.leaky_relu_t object at 0x7f11feea30f0>, ttnn.Tensor([[[[ 0.67188,  0.15234,  ...,  0.97656,  0.32812],
               [ 0.18359,  0.91406,  ...,  0.12891,  0.00391],
               ...,
               [ 0.67969,  0.39844,  ...,  0.55859,  0.92578],
               [ 0.34375,  0.07812,  ...,  0.20312,  0.99609]],

              [[ 0.31641,  0.66797,  ...,  0.26172,  0.39062],
               [ 0.64453,  0.46094,  ...,  0.08984,  0.71875],
               ...,
               [ 0.55469,  0.29297,  ...,  0.44141,  0.30078],
               [ 0.65234,  0.44531,  ...,  0.67188,  0.59375]],

              ...,

              [[ 0.28906,  0.76953,  ...,  0.88672,  0.15625],
               [ 0.32812,  0.12891,  ...,  0.62109,  0.31250],
               ...,
               [ 0.45703,  0.97656,  ...,  0.74219,  0.05859],
               [ 0.39062,  0.23828,  ...,  0.52734,  0.53125]],

              [[ 0.35156,  0.41406,  ...,  0.06641,  0.86328],
               [ 0.26562,  0.82422,  ...,  0.64062,  0.62891],
               ...,
               [ 0.59766,  0.23828,  ...,  0.06250,  0.07031],
               [ 0.59375,  0.70703,  ...,  0.36328,  0.42188]]]], shape=Shape([1, 40, 25, 512]), dtype=DataType::BFLOAT16, layout=Layout::TILE))
ssinghal/tests/test_leakyrelu.py::test_leakyrelu[input_shape1] 2025-08-01 23:02:56.256 | warning  |          Always | Closing and re-initializing MetalContext with same parameters due to force_reinit flag. (metal_context.cpp:77)
2025-08-01 23:02:56.605 | warning  |           Metal | Opening subset of mmio devices slows down UMD read/write to remote chips. If opening more devices, consider using CreateDevices API. (device_pool.cpp:304)
SKIPPED (Type error: [1, 1024, 40, 25] - __call__(): incompatible function arguments. The following argument types are supported:
    1. (self: ttnn._ttnn.operations.unary.leaky_relu_t, input_tensor: ttnn._ttnn.tensor.Tensor, negative_slope: float, *, memory_config: Optional[ttnn._ttnn.tensor.MemoryConfig] = None, output_tensor: Optional[ttnn._ttnn.tensor.Tensor] = None, queue_id: ttnn._ttnn.types.QueueId = QueueId(0)) -> ttnn._ttnn.tensor.Tensor

Invoked with: <ttnn._ttnn.operations.unary.leaky_relu_t object at 0x7f11feea30f0>, ttnn.Tensor([[[[ 0.67188,  0.15234,  ...,  0.60156,  0.46875],
               [ 0.18359,  0.91406,  ...,  0.93359,  0.86719],
               ...,
               [ 0.67969,  0.39844,  ...,  0.61719,  0.09375],
               [ 0.34375,  0.07812,  ...,  0.90234,  0.16797]],

              [[ 0.31641,  0.66797,  ...,  0.44922,  0.19531],
               [ 0.64453,  0.46094,  ...,  0.30469,  0.42578],
               ...,
               [ 0.55469,  0.29297,  ...,  0.55859,  0.09375],
               [ 0.65234,  0.44531,  ...,  0.46484,  0.13281]],

              ...,

              [[ 0.28906,  0.76953,  ...,  0.48828,  0.08984],
               [ 0.32812,  0.12891,  ...,  0.19922,  0.37891],
               ...,
               [ 0.45703,  0.97656,  ...,  0.71094,  0.17969],
               [ 0.39062,  0.23828,  ...,  0.69141,  0.43359]],

              [[ 0.35156,  0.41406,  ...,  0.68359,  0.88672],
               [ 0.26562,  0.82422,  ...,  0.57812,  0.78906],
               ...,
               [ 0.59766,  0.23828,  ...,  0.69922,  0.60547],
               [ 0.59375,  0.70703,  ...,  0.46094,  0.08203]]]], shape=Shape([1, 40, 25, 1024]), dtype=DataType::BFLOAT16, layout=Layout::TILE))
ssinghal/tests/test_leakyrelu.py::test_leakyrelu[input_shape2] 2025-08-01 23:02:56.654 | warning  |          Always | Closing and re-initializing MetalContext with same parameters due to force_reinit flag. (metal_context.cpp:77)
2025-08-01 23:02:57.032 | warning  |           Metal | Opening subset of mmio devices slows down UMD read/write to remote chips. If opening more devices, consider using CreateDevices API. (device_pool.cpp:304)
SKIPPED (Type error: [1, 256, 40, 25] - __call__(): incompatible function arguments. The following argument types are supported:
    1. (self: ttnn._ttnn.operations.unary.leaky_relu_t, input_tensor: ttnn._ttnn.tensor.Tensor, negative_slope: float, *, memory_config: Optional[ttnn._ttnn.tensor.MemoryConfig] = None, output_tensor: Optional[ttnn._ttnn.tensor.Tensor] = None, queue_id: ttnn._ttnn.types.QueueId = QueueId(0)) -> ttnn._ttnn.tensor.Tensor

Invoked with: <ttnn._ttnn.operations.unary.leaky_relu_t object at 0x7f11feea30f0>, ttnn.Tensor([[[[ 0.67188,  0.15234,  ...,  0.10938,  0.19531],
               [ 0.18359,  0.91406,  ...,  0.14062,  0.41406],
               ...,
               [ 0.67969,  0.39844,  ...,  0.85547,  0.49609],
               [ 0.34375,  0.07812,  ...,  0.16406,  0.57812]],

              [[ 0.31641,  0.66797,  ...,  0.87109,  0.07812],
               [ 0.64453,  0.46094,  ...,  0.23047,  0.83984],
               ...,
               [ 0.55469,  0.29297,  ...,  0.50391,  0.57422],
               [ 0.65234,  0.44531,  ...,  0.96094,  0.01172]],

              ...,

              [[ 0.28906,  0.76953,  ...,  0.68359,  0.00000],
               [ 0.32812,  0.12891,  ...,  0.73828,  0.91016],
               ...,
               [ 0.45703,  0.97656,  ...,  0.03516,  0.76953],
               [ 0.39062,  0.23828,  ...,  0.87500,  0.42188]],

              [[ 0.35156,  0.41406,  ...,  0.87109,  0.86719],
               [ 0.26562,  0.82422,  ...,  0.48438,  0.22266],
               ...,
               [ 0.59766,  0.23828,  ...,  0.73438,  0.36719],
               [ 0.59375,  0.70703,  ...,  0.34375,  0.83203]]]], shape=Shape([1, 40, 25, 256]), dtype=DataType::BFLOAT16, layout=Layout::TILE))
ssinghal/tests/test_leakyrelu.py::test_leakyrelu[input_shape3] 2025-08-01 23:02:57.051 | warning  |          Always | Closing and re-initializing MetalContext with same parameters due to force_reinit flag. (metal_context.cpp:77)
2025-08-01 23:02:57.438 | warning  |           Metal | Opening subset of mmio devices slows down UMD read/write to remote chips. If opening more devices, consider using CreateDevices API. (device_pool.cpp:304)
SKIPPED (Type error: [1, 256, 80, 50] - __call__(): incompatible function arguments. The following argument types are supported:
    1. (self: ttnn._ttnn.operations.unary.leaky_relu_t, input_tensor: ttnn._ttnn.tensor.Tensor, negative_slope: float, *, memory_config: Optional[ttnn._ttnn.tensor.MemoryConfig] = None, output_tensor: Optional[ttnn._ttnn.tensor.Tensor] = None, queue_id: ttnn._ttnn.types.QueueId = QueueId(0)) -> ttnn._ttnn.tensor.Tensor

Invoked with: <ttnn._ttnn.operations.unary.leaky_relu_t object at 0x7f11feea30f0>, ttnn.Tensor([[[[ 0.67188,  0.73047,  ...,  0.95703,  0.53125],
               [ 0.18359,  0.16797,  ...,  0.00391,  0.90625],
               ...,
               [ 0.55469,  0.71875,  ...,  0.07031,  0.30859],
               [ 0.65234,  0.87109,  ...,  0.98438,  0.00781]],

              [[ 0.12500,  0.86719,  ...,  0.98828,  0.96094],
               [ 0.75391,  0.01953,  ...,  0.17969,  0.71094],
               ...,
               [ 0.20703,  0.30859,  ...,  0.16797,  0.59375],
               [ 0.54688,  0.49609,  ...,  0.60938,  0.58203]],

              ...,

              [[ 0.16016,  0.23047,  ...,  0.65625,  0.55859],
               [ 0.07422,  0.45312,  ...,  0.67969,  0.35156],
               ...,
               [ 0.91016,  0.33984,  ...,  0.00391,  0.19141],
               [ 0.16016,  0.00391,  ...,  0.47656,  0.06641]],

              [[ 0.01172,  0.98047,  ...,  0.42578,  0.08984],
               [ 0.65234,  0.36328,  ...,  0.81250,  0.37891],
               ...,
               [ 0.13281,  0.59766,  ...,  0.54688,  0.60547],
               [ 0.29688,  0.54688,  ...,  0.29688,  0.08203]]]], shape=Shape([1, 80, 50, 256]), dtype=DataType::BFLOAT16, layout=Layout::TILE))
ssinghal/tests/test_leakyrelu.py::test_leakyrelu[input_shape4] 2025-08-01 23:02:57.492 | warning  |          Always | Closing and re-initializing MetalContext with same parameters due to force_reinit flag. (metal_context.cpp:77)
2025-08-01 23:02:57.881 | warning  |           Metal | Opening subset of mmio devices slows down UMD read/write to remote chips. If opening more devices, consider using CreateDevices API. (device_pool.cpp:304)
SKIPPED (Type error: [1, 512, 80, 50] - __call__(): incompatible function arguments. The following argument types are supported:
    1. (self: ttnn._ttnn.operations.unary.leaky_relu_t, input_tensor: ttnn._ttnn.tensor.Tensor, negative_slope: float, *, memory_config: Optional[ttnn._ttnn.tensor.MemoryConfig] = None, output_tensor: Optional[ttnn._ttnn.tensor.Tensor] = None, queue_id: ttnn._ttnn.types.QueueId = QueueId(0)) -> ttnn._ttnn.tensor.Tensor

Invoked with: <ttnn._ttnn.operations.unary.leaky_relu_t object at 0x7f11feea30f0>, ttnn.Tensor([[[[ 0.67188,  0.73047,  ...,  0.07031,  0.29297],
               [ 0.18359,  0.16797,  ...,  0.07812,  0.96875],
               ...,
               [ 0.55469,  0.71875,  ...,  0.01172,  0.58984],
               [ 0.65234,  0.87109,  ...,  0.75000,  0.69531]],

              [[ 0.12500,  0.86719,  ...,  0.77734,  0.66797],
               [ 0.75391,  0.01953,  ...,  0.25781,  0.26953],
               ...,
               [ 0.20703,  0.30859,  ...,  0.53125,  0.66406],
               [ 0.54688,  0.49609,  ...,  0.07812,  0.41016]],

              ...,

              [[ 0.16016,  0.23047,  ...,  0.18750,  0.57812],
               [ 0.07422,  0.45312,  ...,  0.10156,  0.95312],
               ...,
               [ 0.91016,  0.33984,  ...,  0.81641,  0.37891],
               [ 0.16016,  0.00391,  ...,  0.67578,  0.31250]],

              [[ 0.01172,  0.98047,  ...,  0.88281,  0.40625],
               [ 0.65234,  0.36328,  ...,  0.48047,  0.03125],
               ...,
               [ 0.13281,  0.59766,  ...,  0.10156,  0.16797],
               [ 0.29688,  0.54688,  ...,  0.75391,  0.03516]]]], shape=Shape([1, 80, 50, 512]), dtype=DataType::BFLOAT16, layout=Layout::TILE))
ssinghal/tests/test_leakyrelu.py::test_leakyrelu[input_shape5] 2025-08-01 23:02:57.967 | warning  |          Always | Closing and re-initializing MetalContext with same parameters due to force_reinit flag. (metal_context.cpp:77)
2025-08-01 23:02:58.356 | warning  |           Metal | Opening subset of mmio devices slows down UMD read/write to remote chips. If opening more devices, consider using CreateDevices API. (device_pool.cpp:304)
SKIPPED (Type error: [1, 128, 80, 50] - __call__(): incompatible function arguments. The following argument types are supported:
    1. (self: ttnn._ttnn.operations.unary.leaky_relu_t, input_tensor: ttnn._ttnn.tensor.Tensor, negative_slope: float, *, memory_config: Optional[ttnn._ttnn.tensor.MemoryConfig] = None, output_tensor: Optional[ttnn._ttnn.tensor.Tensor] = None, queue_id: ttnn._ttnn.types.QueueId = QueueId(0)) -> ttnn._ttnn.tensor.Tensor

Invoked with: <ttnn._ttnn.operations.unary.leaky_relu_t object at 0x7f11feea30f0>, ttnn.Tensor([[[[ 0.67188,  0.73047,  ...,  0.91016,  0.32812],
               [ 0.18359,  0.16797,  ...,  0.43750,  0.28906],
               ...,
               [ 0.55469,  0.71875,  ...,  0.77734,  0.02344],
               [ 0.65234,  0.87109,  ...,  0.43359,  0.10938]],

              [[ 0.12500,  0.86719,  ...,  0.50781,  0.14453],
               [ 0.75391,  0.01953,  ...,  0.81250,  0.49219],
               ...,
               [ 0.20703,  0.30859,  ...,  0.00391,  0.21875],
               [ 0.54688,  0.49609,  ...,  0.22266,  0.68359]],

              ...,

              [[ 0.16016,  0.23047,  ...,  0.44922,  0.30859],
               [ 0.07422,  0.45312,  ...,  0.81641,  0.76172],
               ...,
               [ 0.91016,  0.33984,  ...,  0.27734,  0.72656],
               [ 0.16016,  0.00391,  ...,  0.15234,  0.80078]],

              [[ 0.01172,  0.98047,  ...,  0.13281,  0.15625],
               [ 0.65234,  0.36328,  ...,  0.93359,  0.31250],
               ...,
               [ 0.13281,  0.59766,  ...,  0.84766,  0.07031],
               [ 0.29688,  0.54688,  ...,  0.02734,  0.42188]]]], shape=Shape([1, 80, 50, 128]), dtype=DataType::BFLOAT16, layout=Layout::TILE))
ssinghal/tests/test_leakyrelu.py::test_leakyrelu[input_shape6] 2025-08-01 23:02:58.387 | warning  |          Always | Closing and re-initializing MetalContext with same parameters due to force_reinit flag. (metal_context.cpp:77)
2025-08-01 23:02:58.771 | warning  |           Metal | Opening subset of mmio devices slows down UMD read/write to remote chips. If opening more devices, consider using CreateDevices API. (device_pool.cpp:304)
SKIPPED (Type error: [1, 128, 160, 100] - __call__(): incompatible function arguments. The following argument types are supported:
    1. (self: ttnn._ttnn.operations.unary.leaky_relu_t, input_tensor: ttnn._ttnn.tensor.Tensor, negative_slope: float, *, memory_config: Optional[ttnn._ttnn.tensor.MemoryConfig] = None, output_tensor: Optional[ttnn._ttnn.tensor.Tensor] = None, queue_id: ttnn._ttnn.types.QueueId = QueueId(0)) -> ttnn._ttnn.tensor.Tensor

Invoked with: <ttnn._ttnn.operations.unary.leaky_relu_t object at 0x7f11feea30f0>, ttnn.Tensor([[[[ 0.67188,  0.30859,  ...,  0.55078,  0.02734],
               [ 0.18359,  0.60156,  ...,  0.95312,  0.47656],
               ...,
               [ 0.20703,  0.23047,  ...,  0.56250,  0.53516],
               [ 0.54688,  0.94531,  ...,  0.90234,  0.73047]],

              [[ 0.47266,  0.77734,  ...,  0.56250,  0.28516],
               [ 0.66406,  0.66406,  ...,  0.82812,  0.05469],
               ...,
               [ 0.11719,  0.80859,  ...,  0.97656,  0.63672],
               [ 0.09375,  0.19922,  ...,  0.80859,  0.85938]],

              ...,

              [[ 0.09766,  0.90625,  ...,  0.95312,  0.93359],
               [ 0.05859,  0.21875,  ...,  0.35547,  0.06641],
               ...,
               [ 0.04297,  0.38672,  ...,  0.70703,  0.94531],
               [ 0.92969,  0.14453,  ...,  0.75391,  0.06250]],

              [[ 0.89453,  0.39062,  ...,  0.07422,  0.57812],
               [ 0.18750,  0.62891,  ...,  0.37500,  0.95312],
               ...,
               [ 0.07812,  0.47656,  ...,  0.42578,  0.16797],
               [ 0.71094,  0.76172,  ...,  0.00000,  0.03516]]]], shape=Shape([1, 160, 100, 128]), dtype=DataType::BFLOAT16, layout=Layout::TILE))
ssinghal/tests/test_leakyrelu.py::test_leakyrelu[input_shape7] 2025-08-01 23:02:58.835 | warning  |          Always | Closing and re-initializing MetalContext with same parameters due to force_reinit flag. (metal_context.cpp:77)
2025-08-01 23:02:59.159 | warning  |           Metal | Opening subset of mmio devices slows down UMD read/write to remote chips. If opening more devices, consider using CreateDevices API. (device_pool.cpp:304)
SKIPPED (Type error: [1, 256, 160, 100] - __call__(): incompatible function arguments. The following argument types are supported:
    1. (self: ttnn._ttnn.operations.unary.leaky_relu_t, input_tensor: ttnn._ttnn.tensor.Tensor, negative_slope: float, *, memory_config: Optional[ttnn._ttnn.tensor.MemoryConfig] = None, output_tensor: Optional[ttnn._ttnn.tensor.Tensor] = None, queue_id: ttnn._ttnn.types.QueueId = QueueId(0)) -> ttnn._ttnn.tensor.Tensor

Invoked with: <ttnn._ttnn.operations.unary.leaky_relu_t object at 0x7f11feea30f0>, ttnn.Tensor([[[[ 0.67188,  0.30859,  ...,  0.40234,  0.11719],
               [ 0.18359,  0.60156,  ...,  0.91016,  0.34375],
               ...,
               [ 0.20703,  0.23047,  ...,  0.96875,  0.80078],
               [ 0.54688,  0.94531,  ...,  0.77344,  0.22656]],

              [[ 0.47266,  0.77734,  ...,  0.73438,  0.97266],
               [ 0.66406,  0.66406,  ...,  0.10156,  0.81641],
               ...,
               [ 0.11719,  0.80859,  ...,  0.13672,  0.34766],
               [ 0.09375,  0.19922,  ...,  0.39844,  0.65234]],

              ...,

              [[ 0.09766,  0.90625,  ...,  0.95703,  0.86328],
               [ 0.05859,  0.21875,  ...,  0.10156,  0.44141],
               ...,
               [ 0.04297,  0.38672,  ...,  0.71484,  0.70703],
               [ 0.92969,  0.14453,  ...,  0.31250,  0.66406]],

              [[ 0.89453,  0.39062,  ...,  0.74219,  0.39844],
               [ 0.18750,  0.62891,  ...,  0.39062,  0.17969],
               ...,
               [ 0.07812,  0.47656,  ...,  0.97266,  0.99609],
               [ 0.71094,  0.76172,  ...,  0.12109,  0.57031]]]], shape=Shape([1, 160, 100, 256]), dtype=DataType::BFLOAT16, layout=Layout::TILE))

- generated xml file: /home/ttuser/ssinghal/main/tt-metal/generated/test_reports/most_recent_tests.xml -
============================== slowest durations ===============================
2.12s setup    ssinghal/tests/test_leakyrelu.py::test_leakyrelu[input_shape0]
0.40s setup    ssinghal/tests/test_leakyrelu.py::test_leakyrelu[input_shape4]
0.39s setup    ssinghal/tests/test_leakyrelu.py::test_leakyrelu[input_shape5]
0.39s setup    ssinghal/tests/test_leakyrelu.py::test_leakyrelu[input_shape3]
0.39s setup    ssinghal/tests/test_leakyrelu.py::test_leakyrelu[input_shape6]
0.38s setup    ssinghal/tests/test_leakyrelu.py::test_leakyrelu[input_shape2]
0.35s setup    ssinghal/tests/test_leakyrelu.py::test_leakyrelu[input_shape1]
0.33s setup    ssinghal/tests/test_leakyrelu.py::test_leakyrelu[input_shape7]
0.12s call     ssinghal/tests/test_leakyrelu.py::test_leakyrelu[input_shape7]
0.08s call     ssinghal/tests/test_leakyrelu.py::test_leakyrelu[input_shape4]
0.06s call     ssinghal/tests/test_leakyrelu.py::test_leakyrelu[input_shape6]
0.05s call     ssinghal/tests/test_leakyrelu.py::test_leakyrelu[input_shape0]
0.04s call     ssinghal/tests/test_leakyrelu.py::test_leakyrelu[input_shape3]
0.04s call     ssinghal/tests/test_leakyrelu.py::test_leakyrelu[input_shape1]
0.02s call     ssinghal/tests/test_leakyrelu.py::test_leakyrelu[input_shape5]
0.01s call     ssinghal/tests/test_leakyrelu.py::test_leakyrelu[input_shape2]
0.00s teardown ssinghal/tests/test_leakyrelu.py::test_leakyrelu[input_shape5]
0.00s teardown ssinghal/tests/test_leakyrelu.py::test_leakyrelu[input_shape0]
0.00s teardown ssinghal/tests/test_leakyrelu.py::test_leakyrelu[input_shape3]
0.00s teardown ssinghal/tests/test_leakyrelu.py::test_leakyrelu[input_shape1]
0.00s teardown ssinghal/tests/test_leakyrelu.py::test_leakyrelu[input_shape4]
0.00s teardown ssinghal/tests/test_leakyrelu.py::test_leakyrelu[input_shape2]
0.00s teardown ssinghal/tests/test_leakyrelu.py::test_leakyrelu[input_shape6]
0.00s teardown ssinghal/tests/test_leakyrelu.py::test_leakyrelu[input_shape7]
=========================== short test summary info ============================
SKIPPED [1] ssinghal/tests/test_leakyrelu.py:36: Type error: [1, 512, 40, 25] - __call__(): incompatible function arguments. The following argument types are supported:
    1. (self: ttnn._ttnn.operations.unary.leaky_relu_t, input_tensor: ttnn._ttnn.tensor.Tensor, negative_slope: float, *, memory_config: Optional[ttnn._ttnn.tensor.MemoryConfig] = None, output_tensor: Optional[ttnn._ttnn.tensor.Tensor] = None, queue_id: ttnn._ttnn.types.QueueId = QueueId(0)) -> ttnn._ttnn.tensor.Tensor

Invoked with: <ttnn._ttnn.operations.unary.leaky_relu_t object at 0x7f11feea30f0>, ttnn.Tensor([[[[ 0.67188,  0.15234,  ...,  0.97656,  0.32812],
               [ 0.18359,  0.91406,  ...,  0.12891,  0.00391],
               ...,
               [ 0.67969,  0.39844,  ...,  0.55859,  0.92578],
               [ 0.34375,  0.07812,  ...,  0.20312,  0.99609]],

              [[ 0.31641,  0.66797,  ...,  0.26172,  0.39062],
               [ 0.64453,  0.46094,  ...,  0.08984,  0.71875],
               ...,
               [ 0.55469,  0.29297,  ...,  0.44141,  0.30078],
               [ 0.65234,  0.44531,  ...,  0.67188,  0.59375]],

              ...,

              [[ 0.28906,  0.76953,  ...,  0.88672,  0.15625],
               [ 0.32812,  0.12891,  ...,  0.62109,  0.31250],
               ...,
               [ 0.45703,  0.97656,  ...,  0.74219,  0.05859],
               [ 0.39062,  0.23828,  ...,  0.52734,  0.53125]],

              [[ 0.35156,  0.41406,  ...,  0.06641,  0.86328],
               [ 0.26562,  0.82422,  ...,  0.64062,  0.62891],
               ...,
               [ 0.59766,  0.23828,  ...,  0.06250,  0.07031],
               [ 0.59375,  0.70703,  ...,  0.36328,  0.42188]]]], shape=Shape([1, 40, 25, 512]), dtype=DataType::BFLOAT16, layout=Layout::TILE)
SKIPPED [1] ssinghal/tests/test_leakyrelu.py:36: Type error: [1, 1024, 40, 25] - __call__(): incompatible function arguments. The following argument types are supported:
    1. (self: ttnn._ttnn.operations.unary.leaky_relu_t, input_tensor: ttnn._ttnn.tensor.Tensor, negative_slope: float, *, memory_config: Optional[ttnn._ttnn.tensor.MemoryConfig] = None, output_tensor: Optional[ttnn._ttnn.tensor.Tensor] = None, queue_id: ttnn._ttnn.types.QueueId = QueueId(0)) -> ttnn._ttnn.tensor.Tensor

Invoked with: <ttnn._ttnn.operations.unary.leaky_relu_t object at 0x7f11feea30f0>, ttnn.Tensor([[[[ 0.67188,  0.15234,  ...,  0.60156,  0.46875],
               [ 0.18359,  0.91406,  ...,  0.93359,  0.86719],
               ...,
               [ 0.67969,  0.39844,  ...,  0.61719,  0.09375],
               [ 0.34375,  0.07812,  ...,  0.90234,  0.16797]],

              [[ 0.31641,  0.66797,  ...,  0.44922,  0.19531],
               [ 0.64453,  0.46094,  ...,  0.30469,  0.42578],
               ...,
               [ 0.55469,  0.29297,  ...,  0.55859,  0.09375],
               [ 0.65234,  0.44531,  ...,  0.46484,  0.13281]],

              ...,

              [[ 0.28906,  0.76953,  ...,  0.48828,  0.08984],
               [ 0.32812,  0.12891,  ...,  0.19922,  0.37891],
               ...,
               [ 0.45703,  0.97656,  ...,  0.71094,  0.17969],
               [ 0.39062,  0.23828,  ...,  0.69141,  0.43359]],

              [[ 0.35156,  0.41406,  ...,  0.68359,  0.88672],
               [ 0.26562,  0.82422,  ...,  0.57812,  0.78906],
               ...,
               [ 0.59766,  0.23828,  ...,  0.69922,  0.60547],
               [ 0.59375,  0.70703,  ...,  0.46094,  0.08203]]]], shape=Shape([1, 40, 25, 1024]), dtype=DataType::BFLOAT16, layout=Layout::TILE)
SKIPPED [1] ssinghal/tests/test_leakyrelu.py:36: Type error: [1, 256, 40, 25] - __call__(): incompatible function arguments. The following argument types are supported:
    1. (self: ttnn._ttnn.operations.unary.leaky_relu_t, input_tensor: ttnn._ttnn.tensor.Tensor, negative_slope: float, *, memory_config: Optional[ttnn._ttnn.tensor.MemoryConfig] = None, output_tensor: Optional[ttnn._ttnn.tensor.Tensor] = None, queue_id: ttnn._ttnn.types.QueueId = QueueId(0)) -> ttnn._ttnn.tensor.Tensor

Invoked with: <ttnn._ttnn.operations.unary.leaky_relu_t object at 0x7f11feea30f0>, ttnn.Tensor([[[[ 0.67188,  0.15234,  ...,  0.10938,  0.19531],
               [ 0.18359,  0.91406,  ...,  0.14062,  0.41406],
               ...,
               [ 0.67969,  0.39844,  ...,  0.85547,  0.49609],
               [ 0.34375,  0.07812,  ...,  0.16406,  0.57812]],

              [[ 0.31641,  0.66797,  ...,  0.87109,  0.07812],
               [ 0.64453,  0.46094,  ...,  0.23047,  0.83984],
               ...,
               [ 0.55469,  0.29297,  ...,  0.50391,  0.57422],
               [ 0.65234,  0.44531,  ...,  0.96094,  0.01172]],

              ...,

              [[ 0.28906,  0.76953,  ...,  0.68359,  0.00000],
               [ 0.32812,  0.12891,  ...,  0.73828,  0.91016],
               ...,
               [ 0.45703,  0.97656,  ...,  0.03516,  0.76953],
               [ 0.39062,  0.23828,  ...,  0.87500,  0.42188]],

              [[ 0.35156,  0.41406,  ...,  0.87109,  0.86719],
               [ 0.26562,  0.82422,  ...,  0.48438,  0.22266],
               ...,
               [ 0.59766,  0.23828,  ...,  0.73438,  0.36719],
               [ 0.59375,  0.70703,  ...,  0.34375,  0.83203]]]], shape=Shape([1, 40, 25, 256]), dtype=DataType::BFLOAT16, layout=Layout::TILE)
SKIPPED [1] ssinghal/tests/test_leakyrelu.py:36: Type error: [1, 256, 80, 50] - __call__(): incompatible function arguments. The following argument types are supported:
    1. (self: ttnn._ttnn.operations.unary.leaky_relu_t, input_tensor: ttnn._ttnn.tensor.Tensor, negative_slope: float, *, memory_config: Optional[ttnn._ttnn.tensor.MemoryConfig] = None, output_tensor: Optional[ttnn._ttnn.tensor.Tensor] = None, queue_id: ttnn._ttnn.types.QueueId = QueueId(0)) -> ttnn._ttnn.tensor.Tensor

Invoked with: <ttnn._ttnn.operations.unary.leaky_relu_t object at 0x7f11feea30f0>, ttnn.Tensor([[[[ 0.67188,  0.73047,  ...,  0.95703,  0.53125],
               [ 0.18359,  0.16797,  ...,  0.00391,  0.90625],
               ...,
               [ 0.55469,  0.71875,  ...,  0.07031,  0.30859],
               [ 0.65234,  0.87109,  ...,  0.98438,  0.00781]],

              [[ 0.12500,  0.86719,  ...,  0.98828,  0.96094],
               [ 0.75391,  0.01953,  ...,  0.17969,  0.71094],
               ...,
               [ 0.20703,  0.30859,  ...,  0.16797,  0.59375],
               [ 0.54688,  0.49609,  ...,  0.60938,  0.58203]],

              ...,

              [[ 0.16016,  0.23047,  ...,  0.65625,  0.55859],
               [ 0.07422,  0.45312,  ...,  0.67969,  0.35156],
               ...,
               [ 0.91016,  0.33984,  ...,  0.00391,  0.19141],
               [ 0.16016,  0.00391,  ...,  0.47656,  0.06641]],

              [[ 0.01172,  0.98047,  ...,  0.42578,  0.08984],
               [ 0.65234,  0.36328,  ...,  0.81250,  0.37891],
               ...,
               [ 0.13281,  0.59766,  ...,  0.54688,  0.60547],
               [ 0.29688,  0.54688,  ...,  0.29688,  0.08203]]]], shape=Shape([1, 80, 50, 256]), dtype=DataType::BFLOAT16, layout=Layout::TILE)
SKIPPED [1] ssinghal/tests/test_leakyrelu.py:36: Type error: [1, 512, 80, 50] - __call__(): incompatible function arguments. The following argument types are supported:
    1. (self: ttnn._ttnn.operations.unary.leaky_relu_t, input_tensor: ttnn._ttnn.tensor.Tensor, negative_slope: float, *, memory_config: Optional[ttnn._ttnn.tensor.MemoryConfig] = None, output_tensor: Optional[ttnn._ttnn.tensor.Tensor] = None, queue_id: ttnn._ttnn.types.QueueId = QueueId(0)) -> ttnn._ttnn.tensor.Tensor

Invoked with: <ttnn._ttnn.operations.unary.leaky_relu_t object at 0x7f11feea30f0>, ttnn.Tensor([[[[ 0.67188,  0.73047,  ...,  0.07031,  0.29297],
               [ 0.18359,  0.16797,  ...,  0.07812,  0.96875],
               ...,
               [ 0.55469,  0.71875,  ...,  0.01172,  0.58984],
               [ 0.65234,  0.87109,  ...,  0.75000,  0.69531]],

              [[ 0.12500,  0.86719,  ...,  0.77734,  0.66797],
               [ 0.75391,  0.01953,  ...,  0.25781,  0.26953],
               ...,
               [ 0.20703,  0.30859,  ...,  0.53125,  0.66406],
               [ 0.54688,  0.49609,  ...,  0.07812,  0.41016]],

              ...,

              [[ 0.16016,  0.23047,  ...,  0.18750,  0.57812],
               [ 0.07422,  0.45312,  ...,  0.10156,  0.95312],
               ...,
               [ 0.91016,  0.33984,  ...,  0.81641,  0.37891],
               [ 0.16016,  0.00391,  ...,  0.67578,  0.31250]],

              [[ 0.01172,  0.98047,  ...,  0.88281,  0.40625],
               [ 0.65234,  0.36328,  ...,  0.48047,  0.03125],
               ...,
               [ 0.13281,  0.59766,  ...,  0.10156,  0.16797],
               [ 0.29688,  0.54688,  ...,  0.75391,  0.03516]]]], shape=Shape([1, 80, 50, 512]), dtype=DataType::BFLOAT16, layout=Layout::TILE)
SKIPPED [1] ssinghal/tests/test_leakyrelu.py:36: Type error: [1, 128, 80, 50] - __call__(): incompatible function arguments. The following argument types are supported:
    1. (self: ttnn._ttnn.operations.unary.leaky_relu_t, input_tensor: ttnn._ttnn.tensor.Tensor, negative_slope: float, *, memory_config: Optional[ttnn._ttnn.tensor.MemoryConfig] = None, output_tensor: Optional[ttnn._ttnn.tensor.Tensor] = None, queue_id: ttnn._ttnn.types.QueueId = QueueId(0)) -> ttnn._ttnn.tensor.Tensor

Invoked with: <ttnn._ttnn.operations.unary.leaky_relu_t object at 0x7f11feea30f0>, ttnn.Tensor([[[[ 0.67188,  0.73047,  ...,  0.91016,  0.32812],
               [ 0.18359,  0.16797,  ...,  0.43750,  0.28906],
               ...,
               [ 0.55469,  0.71875,  ...,  0.77734,  0.02344],
               [ 0.65234,  0.87109,  ...,  0.43359,  0.10938]],

              [[ 0.12500,  0.86719,  ...,  0.50781,  0.14453],
               [ 0.75391,  0.01953,  ...,  0.81250,  0.49219],
               ...,
               [ 0.20703,  0.30859,  ...,  0.00391,  0.21875],
               [ 0.54688,  0.49609,  ...,  0.22266,  0.68359]],

              ...,

              [[ 0.16016,  0.23047,  ...,  0.44922,  0.30859],
               [ 0.07422,  0.45312,  ...,  0.81641,  0.76172],
               ...,
               [ 0.91016,  0.33984,  ...,  0.27734,  0.72656],
               [ 0.16016,  0.00391,  ...,  0.15234,  0.80078]],

              [[ 0.01172,  0.98047,  ...,  0.13281,  0.15625],
               [ 0.65234,  0.36328,  ...,  0.93359,  0.31250],
               ...,
               [ 0.13281,  0.59766,  ...,  0.84766,  0.07031],
               [ 0.29688,  0.54688,  ...,  0.02734,  0.42188]]]], shape=Shape([1, 80, 50, 128]), dtype=DataType::BFLOAT16, layout=Layout::TILE)
SKIPPED [1] ssinghal/tests/test_leakyrelu.py:36: Type error: [1, 128, 160, 100] - __call__(): incompatible function arguments. The following argument types are supported:
    1. (self: ttnn._ttnn.operations.unary.leaky_relu_t, input_tensor: ttnn._ttnn.tensor.Tensor, negative_slope: float, *, memory_config: Optional[ttnn._ttnn.tensor.MemoryConfig] = None, output_tensor: Optional[ttnn._ttnn.tensor.Tensor] = None, queue_id: ttnn._ttnn.types.QueueId = QueueId(0)) -> ttnn._ttnn.tensor.Tensor

Invoked with: <ttnn._ttnn.operations.unary.leaky_relu_t object at 0x7f11feea30f0>, ttnn.Tensor([[[[ 0.67188,  0.30859,  ...,  0.55078,  0.02734],
               [ 0.18359,  0.60156,  ...,  0.95312,  0.47656],
               ...,
               [ 0.20703,  0.23047,  ...,  0.56250,  0.53516],
               [ 0.54688,  0.94531,  ...,  0.90234,  0.73047]],

              [[ 0.47266,  0.77734,  ...,  0.56250,  0.28516],
               [ 0.66406,  0.66406,  ...,  0.82812,  0.05469],
               ...,
               [ 0.11719,  0.80859,  ...,  0.97656,  0.63672],
               [ 0.09375,  0.19922,  ...,  0.80859,  0.85938]],

              ...,

              [[ 0.09766,  0.90625,  ...,  0.95312,  0.93359],
               [ 0.05859,  0.21875,  ...,  0.35547,  0.06641],
               ...,
               [ 0.04297,  0.38672,  ...,  0.70703,  0.94531],
               [ 0.92969,  0.14453,  ...,  0.75391,  0.06250]],

              [[ 0.89453,  0.39062,  ...,  0.07422,  0.57812],
               [ 0.18750,  0.62891,  ...,  0.37500,  0.95312],
               ...,
               [ 0.07812,  0.47656,  ...,  0.42578,  0.16797],
               [ 0.71094,  0.76172,  ...,  0.00000,  0.03516]]]], shape=Shape([1, 160, 100, 128]), dtype=DataType::BFLOAT16, layout=Layout::TILE)
SKIPPED [1] ssinghal/tests/test_leakyrelu.py:36: Type error: [1, 256, 160, 100] - __call__(): incompatible function arguments. The following argument types are supported:
    1. (self: ttnn._ttnn.operations.unary.leaky_relu_t, input_tensor: ttnn._ttnn.tensor.Tensor, negative_slope: float, *, memory_config: Optional[ttnn._ttnn.tensor.MemoryConfig] = None, output_tensor: Optional[ttnn._ttnn.tensor.Tensor] = None, queue_id: ttnn._ttnn.types.QueueId = QueueId(0)) -> ttnn._ttnn.tensor.Tensor

Invoked with: <ttnn._ttnn.operations.unary.leaky_relu_t object at 0x7f11feea30f0>, ttnn.Tensor([[[[ 0.67188,  0.30859,  ...,  0.40234,  0.11719],
               [ 0.18359,  0.60156,  ...,  0.91016,  0.34375],
               ...,
               [ 0.20703,  0.23047,  ...,  0.96875,  0.80078],
               [ 0.54688,  0.94531,  ...,  0.77344,  0.22656]],

              [[ 0.47266,  0.77734,  ...,  0.73438,  0.97266],
               [ 0.66406,  0.66406,  ...,  0.10156,  0.81641],
               ...,
               [ 0.11719,  0.80859,  ...,  0.13672,  0.34766],
               [ 0.09375,  0.19922,  ...,  0.39844,  0.65234]],

              ...,

              [[ 0.09766,  0.90625,  ...,  0.95703,  0.86328],
               [ 0.05859,  0.21875,  ...,  0.10156,  0.44141],
               ...,
               [ 0.04297,  0.38672,  ...,  0.71484,  0.70703],
               [ 0.92969,  0.14453,  ...,  0.31250,  0.66406]],

              [[ 0.89453,  0.39062,  ...,  0.74219,  0.39844],
               [ 0.18750,  0.62891,  ...,  0.39062,  0.17969],
               ...,
               [ 0.07812,  0.47656,  ...,  0.97266,  0.99609],
               [ 0.71094,  0.76172,  ...,  0.12109,  0.57031]]]], shape=Shape([1, 160, 100, 256]), dtype=DataType::BFLOAT16, layout=Layout::TILE)
============================== 8 skipped in 5.22s ==============================
2025-08-01 23:02:59.666 | info     |          Device | Closing user mode device drivers (tt_cluster.cpp:406)
