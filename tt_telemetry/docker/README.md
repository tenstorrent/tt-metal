# TT-Metal Telemetry Monitoring with Prometheus + Grafana

This directory contains Docker Compose configuration for setting up a Prometheus + Grafana monitoring stack to scrape and visualize TT-Metal telemetry metrics.

## Prerequisites

- Docker and Docker Compose installed
- TT-Metal telemetry server(s) running on remote hosts, exposing metrics at `/api/metrics` endpoint

## Quick Start

### 1. Start the telemetry server(s)

Make sure your TT-Metal telemetry server is running on your target host(s):

```bash
# On the remote host (e.g., sjc-wh-05)
./build/tt_telemetry/tt_telemetry_server \
--port 53494 \
--fsd <path-to-fsd>
```

The server will expose metrics at `http://<host>:<port>/api/metrics`

### 2. Start the monitoring stack

Run Prometheus + Grafana locally (on your Mac or a designated monitoring host):

```bash
cd tt_telemetry/docker/monitoring

# Monitor a single remote host
./start-monitoring.sh sjc-wh-05:53494

# Monitor multiple remote hosts
./start-monitoring.sh sjc-wh-05:53494 sjc-wh-06:53494
```

### 3. Access the dashboards

- **Prometheus**: http://localhost:9090
  - View raw metrics, run PromQL queries
  - Check targets at http://localhost:9090/targets

- **Grafana**: http://localhost:3000
  - Default credentials: `admin` / `admin`
  - Prometheus datasource is pre-configured
  - Create custom dashboards to visualize your metrics

## Usage

### Stop the monitoring stack

```bash
docker compose down
```

### View logs

```bash
docker compose logs -f
```

### Restart with new targets

Simply run `start-monitoring.sh` again with new targets:

```bash
./start-monitoring.sh sjc-wh-07:53494 sjc-wh-08:53494
docker compose restart prometheus
```

## Architecture

```
┌──────────────────┐
│  TT Telemetry    │
│  Server(s)       │
│ :8080/api/metrics│
└────────┬─────────┘
         │
         │ HTTP scrape (every 15s)
         │
         ▼
┌──────────────────┐
│   Prometheus     │
│   :9090          │
│  (Time-series DB)│
└────────┬─────────┘
         │
         │ PromQL queries
         │
         ▼
┌──────────────────┐
│    Grafana       │
│    :3000         │
│ (Visualization)  │
└──────────────────┘
```

## Configuration Files

- `monitoring/docker-compose.yml` - Docker services configuration
- `monitoring/prometheus.yml` - Prometheus scrape configuration (generated by script)
- `monitoring/grafana-datasources.yml` - Grafana datasource provisioning
- `monitoring/start-monitoring.sh` - Helper script to start the stack

## Platform Support

This setup should work on:
- **macOS**: Uses `host.docker.internal` to access host machine
- **Linux**: Uses `host-gateway` for host access
- **Windows**: Should work with Docker Desktop

### Hostname Resolution on macOS

When running on macOS, you can provide unresolved hostnames to the monitoring script:

```bash
./start-monitoring.sh sjc-wh-05:53494 sjc-wh-02:53494
```

However, due to Docker's architecture on macOS (containers run inside a Linux VM with separate DNS), the script automatically resolves hostnames to IP addresses before configuring Prometheus. This means:

- ✅ You can use friendly hostnames when starting the monitoring stack
- ℹ️ The `instance` label in Prometheus will show resolved IPs (e.g., `10.229.36.45:53494`)
- ℹ️ Prometheus targets page will display IPs instead of hostnames
- ✅ Your metrics still contain the full `hostname` label from the telemetry server (e.g., `sjc-wh-05-special-kkfernandez-for-reservation-13353`)

**Why this happens:** Docker on macOS runs containers inside a Linux VM that doesn't share your Mac's DNS configuration. The script resolves hostnames on your Mac and passes IPs to Prometheus to ensure connectivity.

**For filtering/grouping:** Use the `hostname` label from your metrics rather than the `instance` label:

```promql
# Filter by hostname prefix
ASICTemperature{hostname=~"sjc-wh-05.*"}

# Group by hostname
avg(ASICTemperature) by (hostname)
```

## Customization

### Change scrape interval

Edit `start-monitoring.sh` and modify the `scrape_interval` in the generated config:

```yaml
global:
  scrape_interval: 10s  # Change from 15s to 10s
```

### Add custom Grafana dashboards

Mount a dashboard provisioning directory in `docker-compose.yml`:

```yaml
grafana:
  volumes:
    - ./dashboards:/etc/grafana/provisioning/dashboards
```

### Persist data across restarts

The setup already uses named volumes for persistence:
- `prometheus-data` - Prometheus time-series database
- `grafana-data` - Grafana dashboards and settings

To clear all data:

```bash
docker compose down -v
```

## Troubleshooting

### Prometheus can't reach telemetry server

1. Check if telemetry server is running:
   ```bash
   curl http://localhost:8080/api/metrics
   ```

2. Verify Prometheus targets are up:
   - Visit http://localhost:9090/targets
   - Check for error messages

3. For remote hosts, ensure they're accessible from your machine:
   ```bash
   curl http://remote-host:8080/api/metrics
   ```

### Grafana not showing data

1. Verify Prometheus datasource is configured:
   - Go to Configuration → Data Sources in Grafana
   - Test the Prometheus connection

2. Check if Prometheus has data:
   - Visit http://localhost:9090
   - Run a query like `{__name__=~".+"}`

### Permission issues on Linux

If you encounter permission errors:

```bash
sudo chown -R 472:472 grafana-data/
sudo chown -R 65534:65534 prometheus-data/
```

## Example Grafana Queries

Here are some example PromQL queries to get started:

- Show all metrics: `{__name__=~".+"}`
- Filter by metric prefix: `{__name__=~"tt_.*"}`
- Rate of change: `rate(your_metric_name[5m])`
- Aggregate by label: `sum by (unit) (your_metric_name)`
