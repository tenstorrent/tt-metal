from pathlib import Path
import sys
sys.path.insert(0, str(Path(__file__).parent))
sys.path.insert(0, str(Path(__file__).parent.parent))

import ttnn
import my_get_device
import utils
from models.common.utility_functions import (
    disable_persistent_kernel_cache,
    enable_persistent_kernel_cache,
)

import ttnn_supplemental

# Inject all ttnn_supplemental CCL operations into ttnn namespace
ttnn.MeshShardDirection = ttnn_supplemental.MeshShardDirection
ttnn.MeshShardType = ttnn_supplemental.MeshShardType
ttnn.mesh_shard = ttnn_supplemental.mesh_shard
ttnn.all_gather = ttnn_supplemental.all_gather
ttnn.reduce_scatter = ttnn_supplemental.reduce_scatter
ttnn.collective_permute = ttnn_supplemental.collective_permute
ttnn.point_to_point = ttnn_supplemental.point_to_point


def _main(v1): 
  v2 = v1[0]
  v3 = v1[1]
  v4 = v1[2]
  v5 = v1[3]
  v6 = v1[4]
  v7 = v1[5]
  v8 = v1[6]
  v9 = v1[7]
  v10 = v1[8]
  v11 = v1[9]
  v12 = v1[10]
  v13 = v1[11]
  v14 = v1[12]
  v15 = v1[13]
  v16 = v1[14]
  v17 = v1[15]
  v18 = v1[16]
  v19 = my_get_device.DeviceGetter.get_device()
  v20 = ttnn.full(shape=ttnn.Shape([]), fill_value=float('-inf'), dtype=ttnn.DataType.BFLOAT16, layout=ttnn.Layout.TILE, device=v19, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  v21 = ttnn.full(shape=ttnn.Shape([]), fill_value=0, dtype=ttnn.DataType.BFLOAT16, layout=ttnn.Layout.TILE, device=v19, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  v22 = ttnn.mesh_shard(v2, v19, ttnn.MeshShardDirection.FullToShard, ttnn.MeshShardType.Replicate, [1], [-1])
  ttnn.deallocate(v2, False)
  v23 = ttnn.mesh_shard(v3, v19, ttnn.MeshShardDirection.FullToShard, ttnn.MeshShardType.Replicate, [1], [-1])
  ttnn.deallocate(v3, False)
  v24 = ttnn.mesh_shard(v4, v19, ttnn.MeshShardDirection.FullToShard, ttnn.MeshShardType.Replicate, [1], [-1])
  ttnn.deallocate(v4, False)
  v25 = ttnn.mesh_shard(v5, v19, ttnn.MeshShardDirection.FullToShard, ttnn.MeshShardType.Replicate, [1], [-1])
  ttnn.deallocate(v5, False)
  v26 = ttnn.mesh_shard(v6, v19, ttnn.MeshShardDirection.FullToShard, ttnn.MeshShardType.Replicate, [1], [-1])
  ttnn.deallocate(v6, False)
  v27 = ttnn.mesh_shard(v7, v19, ttnn.MeshShardDirection.FullToShard, ttnn.MeshShardType.Replicate, [1], [-1])
  ttnn.deallocate(v7, False)
  v28 = ttnn.mesh_shard(v8, v19, ttnn.MeshShardDirection.FullToShard, ttnn.MeshShardType.Replicate, [1], [-1])
  ttnn.deallocate(v8, False)
  v29 = ttnn.mesh_shard(v9, v19, ttnn.MeshShardDirection.FullToShard, ttnn.MeshShardType.Replicate, [1], [-1])
  ttnn.deallocate(v9, False)
  v30 = ttnn.mesh_shard(v10, v19, ttnn.MeshShardDirection.FullToShard, ttnn.MeshShardType.Replicate, [1], [-1])
  ttnn.deallocate(v10, False)
  v31 = ttnn.mesh_shard(v11, v19, ttnn.MeshShardDirection.FullToShard, ttnn.MeshShardType.Replicate, [1], [-1])
  ttnn.deallocate(v11, False)
  v32 = ttnn.mesh_shard(v12, v19, ttnn.MeshShardDirection.FullToShard, ttnn.MeshShardType.Devices, [2], [-1, 0])
  ttnn.deallocate(v12, False)
  v33 = ttnn.mesh_shard(v13, v19, ttnn.MeshShardDirection.FullToShard, ttnn.MeshShardType.Devices, [1, 2], [-1, 1])
  ttnn.deallocate(v13, False)
  v34 = ttnn.mesh_shard(v14, v19, ttnn.MeshShardDirection.FullToShard, ttnn.MeshShardType.Devices, [2], [-1, 0])
  ttnn.deallocate(v14, False)
  v35 = ttnn.mesh_shard(v15, v19, ttnn.MeshShardDirection.FullToShard, ttnn.MeshShardType.Devices, [1, 2], [-1, 1])
  ttnn.deallocate(v15, False)
  v36 = ttnn.mesh_shard(v16, v19, ttnn.MeshShardDirection.FullToShard, ttnn.MeshShardType.Devices, [2], [-1, 0])
  ttnn.deallocate(v16, False)
  v37 = ttnn.mesh_shard(v17, v19, ttnn.MeshShardDirection.FullToShard, ttnn.MeshShardType.Devices, [1, 2], [-1, 1])
  ttnn.deallocate(v17, False)
  v38 = ttnn.mesh_shard(v18, v19, ttnn.MeshShardDirection.FullToShard, ttnn.MeshShardType.Devices, [2, 1, 1, 1], [-1, 0])
  ttnn.deallocate(v18, False)
  v39 = ttnn.to_layout(v38, ttnn.Layout.TILE, None, memory_config=None)
  ttnn.deallocate(v38, False)
  v40 = ttnn.to_device(v39, device=v19, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v39, False)
  v41 = ttnn.typecast(v40, ttnn.DataType.BFLOAT16, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v40, False)
  v42 = ttnn.reshape(v41, [1, 1, 200704, 3], memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v41, False)
  v43 = ttnn.to_device(v22, device=v19, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v22, False)
  v44 = ttnn.to_layout(v43, ttnn.Layout.TILE, None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v43, False)
  v45 = ttnn.reshape(v44, [1, 1, 1, 64], memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v44, False)
  v46 = ttnn.to_device(v23, device=v19, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v23, False)
  v47 = ttnn.to_layout(v46, ttnn.Layout.TILE, None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v46, False)
  v48 = ttnn.permute(v47, [3, 2, 0, 1], memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None), pad_value=0)
  ttnn.deallocate(v47, False)
  v49 = ttnn.to_layout(v48, ttnn.Layout.ROW_MAJOR, None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v48, False)
  v50 = ttnn.from_device(v49)
  ttnn.deallocate(v49, False)
  v51 = ttnn.to_layout(v45, ttnn.Layout.ROW_MAJOR, None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v45, False)
  v52 = ttnn.from_device(v51)
  ttnn.deallocate(v51, False)
  v53 = ttnn.to_layout(v42, ttnn.Layout.ROW_MAJOR, None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v42, False)
  v54 = ttnn.conv2d(input_tensor=v53, weight_tensor=v50, device=v19, in_channels=3, out_channels=64, batch_size=4, input_height=224, input_width=224, kernel_size=[11, 11], stride=[4, 4], padding=[0, 0, 0, 0], dilation=[1, 1], groups=1, bias_tensor=v52, conv_config=None, compute_config=None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v53, False)
  ttnn.deallocate(v52, False)
  ttnn.deallocate(v50, False)
  v55 = ttnn.reshape(v21, [1, 1, 1, 1], memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  v56 = ttnn.maximum(v54, v55, dtype=None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v55, False)
  ttnn.deallocate(v54, False)
  v57 = ttnn.to_layout(v56, ttnn.Layout.ROW_MAJOR, None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v56, False)
  v58 = ttnn.max_pool2d(v57, 4, 54, 54, 64, [3, 3], [2, 2], [0, 0], [1, 1], memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None), applied_shard_scheme=None, ceil_mode=False, in_place_halo=False)
  ttnn.deallocate(v57, False)
  v59 = ttnn.to_device(v24, device=v19, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v24, False)
  v60 = ttnn.to_layout(v59, ttnn.Layout.TILE, None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v59, False)
  v61 = ttnn.reshape(v60, [1, 1, 1, 192], memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v60, False)
  v62 = ttnn.to_device(v25, device=v19, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v25, False)
  v63 = ttnn.to_layout(v62, ttnn.Layout.TILE, None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v62, False)
  v64 = ttnn.permute(v63, [3, 2, 0, 1], memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None), pad_value=0)
  ttnn.deallocate(v63, False)
  v65 = ttnn.to_layout(v64, ttnn.Layout.ROW_MAJOR, None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v64, False)
  v66 = ttnn.from_device(v65)
  ttnn.deallocate(v65, False)
  v67 = ttnn.to_layout(v61, ttnn.Layout.ROW_MAJOR, None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v61, False)
  v68 = ttnn.from_device(v67)
  ttnn.deallocate(v67, False)
  v69 = ttnn.conv2d(input_tensor=v58, weight_tensor=v66, device=v19, in_channels=64, out_channels=192, batch_size=4, input_height=26, input_width=26, kernel_size=[5, 5], stride=[1, 1], padding=[2, 2, 2, 2], dilation=[1, 1], groups=1, bias_tensor=v68, conv_config=None, compute_config=None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v68, False)
  ttnn.deallocate(v66, False)
  ttnn.deallocate(v58, False)
  v70 = ttnn.reshape(v21, [1, 1, 1, 1], memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  v71 = ttnn.maximum(v69, v70, dtype=None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v70, False)
  ttnn.deallocate(v69, False)
  v72 = ttnn.to_layout(v71, ttnn.Layout.ROW_MAJOR, None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v71, False)
  v73 = ttnn.max_pool2d(v72, 4, 26, 26, 192, [3, 3], [2, 2], [0, 0], [1, 1], memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None), applied_shard_scheme=None, ceil_mode=False, in_place_halo=False)
  ttnn.deallocate(v72, False)
  v74 = ttnn.to_device(v26, device=v19, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v26, False)
  v75 = ttnn.to_layout(v74, ttnn.Layout.TILE, None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v74, False)
  v76 = ttnn.reshape(v75, [1, 1, 1, 384], memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v75, False)
  v77 = ttnn.to_device(v27, device=v19, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v27, False)
  v78 = ttnn.to_layout(v77, ttnn.Layout.TILE, None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v77, False)
  v79 = ttnn.permute(v78, [3, 2, 0, 1], memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None), pad_value=0)
  ttnn.deallocate(v78, False)
  v80 = ttnn.to_layout(v79, ttnn.Layout.ROW_MAJOR, None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v79, False)
  v81 = ttnn.from_device(v80)
  ttnn.deallocate(v80, False)
  v82 = ttnn.to_layout(v76, ttnn.Layout.ROW_MAJOR, None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v76, False)
  v83 = ttnn.from_device(v82)
  ttnn.deallocate(v82, False)
  v84 = ttnn.conv2d(input_tensor=v73, weight_tensor=v81, device=v19, in_channels=192, out_channels=384, batch_size=4, input_height=12, input_width=12, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1, 1, 1], dilation=[1, 1], groups=1, bias_tensor=v83, conv_config=None, compute_config=None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v83, False)
  ttnn.deallocate(v81, False)
  ttnn.deallocate(v73, False)
  v85 = ttnn.reshape(v21, [1, 1, 1, 1], memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  v86 = ttnn.maximum(v84, v85, dtype=None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v85, False)
  ttnn.deallocate(v84, False)
  v87 = ttnn.to_device(v28, device=v19, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v28, False)
  v88 = ttnn.to_layout(v87, ttnn.Layout.TILE, None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v87, False)
  v89 = ttnn.reshape(v88, [1, 1, 1, 256], memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v88, False)
  v90 = ttnn.to_device(v29, device=v19, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v29, False)
  v91 = ttnn.to_layout(v90, ttnn.Layout.TILE, None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v90, False)
  v92 = ttnn.permute(v91, [3, 2, 0, 1], memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None), pad_value=0)
  ttnn.deallocate(v91, False)
  v93 = ttnn.to_layout(v92, ttnn.Layout.ROW_MAJOR, None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v92, False)
  v94 = ttnn.from_device(v93)
  ttnn.deallocate(v93, False)
  v95 = ttnn.to_layout(v89, ttnn.Layout.ROW_MAJOR, None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v89, False)
  v96 = ttnn.from_device(v95)
  ttnn.deallocate(v95, False)
  v97 = ttnn.to_layout(v86, ttnn.Layout.ROW_MAJOR, None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v86, False)
  v98 = ttnn.conv2d(input_tensor=v97, weight_tensor=v94, device=v19, in_channels=384, out_channels=256, batch_size=4, input_height=12, input_width=12, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1, 1, 1], dilation=[1, 1], groups=1, bias_tensor=v96, conv_config=None, compute_config=None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v97, False)
  ttnn.deallocate(v96, False)
  ttnn.deallocate(v94, False)
  v99 = ttnn.reshape(v21, [1, 1, 1, 1], memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  v100 = ttnn.maximum(v98, v99, dtype=None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v99, False)
  ttnn.deallocate(v98, False)
  v101 = ttnn.to_device(v30, device=v19, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v30, False)
  v102 = ttnn.to_layout(v101, ttnn.Layout.TILE, None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v101, False)
  v103 = ttnn.reshape(v102, [1, 1, 1, 256], memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v102, False)
  v104 = ttnn.to_device(v31, device=v19, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v31, False)
  v105 = ttnn.to_layout(v104, ttnn.Layout.TILE, None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v104, False)
  v106 = ttnn.permute(v105, [3, 2, 0, 1], memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None), pad_value=0)
  ttnn.deallocate(v105, False)
  v107 = ttnn.to_layout(v106, ttnn.Layout.ROW_MAJOR, None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v106, False)
  v108 = ttnn.from_device(v107)
  ttnn.deallocate(v107, False)
  v109 = ttnn.to_layout(v103, ttnn.Layout.ROW_MAJOR, None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v103, False)
  v110 = ttnn.from_device(v109)
  ttnn.deallocate(v109, False)
  v111 = ttnn.to_layout(v100, ttnn.Layout.ROW_MAJOR, None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v100, False)
  v112 = ttnn.conv2d(input_tensor=v111, weight_tensor=v108, device=v19, in_channels=256, out_channels=256, batch_size=4, input_height=12, input_width=12, kernel_size=[3, 3], stride=[1, 1], padding=[1, 1, 1, 1], dilation=[1, 1], groups=1, bias_tensor=v110, conv_config=None, compute_config=None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v111, False)
  ttnn.deallocate(v110, False)
  ttnn.deallocate(v108, False)
  v113 = ttnn.reshape(v21, [1, 1, 1, 1], memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  v114 = ttnn.maximum(v112, v113, dtype=None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v113, False)
  ttnn.deallocate(v112, False)
  v115 = ttnn.to_layout(v114, ttnn.Layout.ROW_MAJOR, None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v114, False)
  v116 = ttnn.max_pool2d(v115, 4, 12, 12, 256, [3, 3], [2, 2], [0, 0], [1, 1], memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None), applied_shard_scheme=None, ceil_mode=False, in_place_halo=False)
  ttnn.deallocate(v115, False)
  v117 = ttnn.to_layout(v116, ttnn.Layout.TILE, None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v116, False)
  v118 = ttnn.reshape(v117, [1, 1, 4, 6400], memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v117, False)
  v119 = ttnn.all_gather(input=v118, mesh_device=v19, dim=2, cluster_axis=1, num_links=1, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v118, False)
  v120 = ttnn.reshape(v119, [8, 6400], memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v119, False)
  v121 = ttnn.to_device(v33, device=v19, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v33, False)
  v122 = ttnn.to_layout(v121, ttnn.Layout.TILE, None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v121, False)
  v123 = ttnn.matmul(v120, v122, transpose_a=False, transpose_b=False, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v122, False)
  ttnn.deallocate(v120, False)
  v124 = ttnn.to_device(v32, device=v19, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v32, False)
  v125 = ttnn.to_layout(v124, ttnn.Layout.TILE, None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v124, False)
  v126 = ttnn.reshape(v125, [1, 2048], memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v125, False)
  v127 = ttnn.add(v123, v126, dtype=ttnn.DataType.BFLOAT16, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v126, False)
  ttnn.deallocate(v123, False)
  v128 = ttnn.reshape(v21, [1, 1], memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  v129 = ttnn.maximum(v127, v128, dtype=None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v128, False)
  ttnn.deallocate(v127, False)
  v130 = ttnn.reshape(v129, [1, 1, 8, 2048], memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v129, False)
  v131 = ttnn.all_gather(input=v130, mesh_device=v19, dim=3, cluster_axis=1, num_links=1, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v130, False)
  v132 = ttnn.reshape(v131, [8, 4096], memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v131, False)
  v133 = ttnn.to_device(v35, device=v19, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v35, False)
  v134 = ttnn.to_layout(v133, ttnn.Layout.TILE, None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v133, False)
  v135 = ttnn.matmul(v132, v134, transpose_a=False, transpose_b=False, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v134, False)
  ttnn.deallocate(v132, False)
  v136 = ttnn.to_device(v34, device=v19, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v34, False)
  v137 = ttnn.to_layout(v136, ttnn.Layout.TILE, None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v136, False)
  v138 = ttnn.reshape(v137, [1, 2048], memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v137, False)
  v139 = ttnn.add(v135, v138, dtype=ttnn.DataType.BFLOAT16, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v138, False)
  ttnn.deallocate(v135, False)
  v140 = ttnn.reshape(v21, [1, 1], memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v21, False)
  v141 = ttnn.maximum(v139, v140, dtype=None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v140, False)
  ttnn.deallocate(v139, False)
  v142 = ttnn.reshape(v141, [1, 1, 8, 2048], memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v141, False)
  v143 = ttnn.all_gather(input=v142, mesh_device=v19, dim=3, cluster_axis=1, num_links=1, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v142, False)
  v144 = ttnn.reshape(v143, [8, 4096], memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v143, False)
  v145 = ttnn.to_device(v37, device=v19, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v37, False)
  v146 = ttnn.to_layout(v145, ttnn.Layout.TILE, None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v145, False)
  v147 = ttnn.matmul(v144, v146, transpose_a=False, transpose_b=False, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v146, False)
  ttnn.deallocate(v144, False)
  v148 = ttnn.to_device(v36, device=v19, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v36, False)
  v149 = ttnn.to_layout(v148, ttnn.Layout.TILE, None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v148, False)
  v150 = ttnn.reshape(v149, [1, 500], memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v149, False)
  v151 = ttnn.add(v147, v150, dtype=ttnn.DataType.BFLOAT16, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v150, False)
  ttnn.deallocate(v147, False)
  v152 = ttnn.reshape(v151, [1, 1, 8, 500], memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v151, False)
  v153 = ttnn.all_gather(input=v152, mesh_device=v19, dim=3, cluster_axis=1, num_links=1, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v152, False)
  v154 = ttnn.reshape(v153, [8, 1000], memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v153, False)
  v155 = ttnn.max(v154, [1], True, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  v156 = ttnn.reshape(v20, [1, 1], memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v20, False)
  v157 = ttnn.maximum(v156, v155, dtype=None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v156, False)
  ttnn.deallocate(v155, False)
  v158 = ttnn.neg(v157, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v157, False)
  v159 = ttnn.add(v154, v158, dtype=ttnn.DataType.BFLOAT16, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v158, False)
  ttnn.deallocate(v154, False)
  v160 = ttnn.exp(v159, fast_and_approximate_mode=False, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v159, False)
  v161 = ttnn.typecast(v160, ttnn.DataType.FLOAT32, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  v162 = ttnn.sum(v161, [1], True, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v161, False)
  v163 = ttnn.typecast(v162, ttnn.DataType.BFLOAT16, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v162, False)
  v164 = ttnn.divide(v160, v163, dtype=ttnn.DataType.BFLOAT16, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v163, False)
  ttnn.deallocate(v160, False)
  v165 = ttnn.to_layout(v164, ttnn.Layout.ROW_MAJOR, None, memory_config=ttnn.MemoryConfig(ttnn.TensorMemoryLayout.INTERLEAVED, ttnn.BufferType.DRAM, None))
  ttnn.deallocate(v164, False)
  v166 = ttnn.from_device(v165)
  ttnn.deallocate(v165, False)
  v167 = ttnn.mesh_shard(v166, v19, ttnn.MeshShardDirection.ShardToFull, ttnn.MeshShardType.Replicate, [1], [-1])
  ttnn.deallocate(v166, False)
  v168 = [v167]
  return v168

def create_inputs_for__main(): 
  v1 = ttnn.ones(shape=ttnn.Shape([64]), dtype=ttnn.DataType.BFLOAT16, layout=ttnn.Layout.ROW_MAJOR, device=None)
  v2 = ttnn.ones(shape=ttnn.Shape([11, 11, 3, 64]), dtype=ttnn.DataType.BFLOAT16, layout=ttnn.Layout.ROW_MAJOR, device=None)
  v3 = ttnn.ones(shape=ttnn.Shape([192]), dtype=ttnn.DataType.BFLOAT16, layout=ttnn.Layout.ROW_MAJOR, device=None)
  v4 = ttnn.ones(shape=ttnn.Shape([5, 5, 64, 192]), dtype=ttnn.DataType.BFLOAT16, layout=ttnn.Layout.ROW_MAJOR, device=None)
  v5 = ttnn.ones(shape=ttnn.Shape([384]), dtype=ttnn.DataType.BFLOAT16, layout=ttnn.Layout.ROW_MAJOR, device=None)
  v6 = ttnn.ones(shape=ttnn.Shape([3, 3, 192, 384]), dtype=ttnn.DataType.BFLOAT16, layout=ttnn.Layout.ROW_MAJOR, device=None)
  v7 = ttnn.ones(shape=ttnn.Shape([256]), dtype=ttnn.DataType.BFLOAT16, layout=ttnn.Layout.ROW_MAJOR, device=None)
  v8 = ttnn.ones(shape=ttnn.Shape([3, 3, 384, 256]), dtype=ttnn.DataType.BFLOAT16, layout=ttnn.Layout.ROW_MAJOR, device=None)
  v9 = ttnn.ones(shape=ttnn.Shape([256]), dtype=ttnn.DataType.BFLOAT16, layout=ttnn.Layout.ROW_MAJOR, device=None)
  v10 = ttnn.ones(shape=ttnn.Shape([3, 3, 256, 256]), dtype=ttnn.DataType.BFLOAT16, layout=ttnn.Layout.ROW_MAJOR, device=None)
  v11 = ttnn.ones(shape=ttnn.Shape([4096]), dtype=ttnn.DataType.BFLOAT16, layout=ttnn.Layout.ROW_MAJOR, device=None)
  v12 = ttnn.ones(shape=ttnn.Shape([6400, 4096]), dtype=ttnn.DataType.BFLOAT16, layout=ttnn.Layout.ROW_MAJOR, device=None)
  v13 = ttnn.ones(shape=ttnn.Shape([4096]), dtype=ttnn.DataType.BFLOAT16, layout=ttnn.Layout.ROW_MAJOR, device=None)
  v14 = ttnn.ones(shape=ttnn.Shape([4096, 4096]), dtype=ttnn.DataType.BFLOAT16, layout=ttnn.Layout.ROW_MAJOR, device=None)
  v15 = ttnn.ones(shape=ttnn.Shape([1000]), dtype=ttnn.DataType.BFLOAT16, layout=ttnn.Layout.ROW_MAJOR, device=None)
  v16 = ttnn.ones(shape=ttnn.Shape([4096, 1000]), dtype=ttnn.DataType.BFLOAT16, layout=ttnn.Layout.ROW_MAJOR, device=None)
  v17 = ttnn.ones(shape=ttnn.Shape([8, 224, 224, 3]), dtype=ttnn.DataType.INT32, layout=ttnn.Layout.ROW_MAJOR, device=None)
  v18 = [v1, v2, v3, v4, v5, v6, v7, v8, v9, v10, v11, v12, v13, v14, v15, v16, v17]
  return v18

def test_main(): 
  enable_persistent_kernel_cache()
  v1 = create_inputs_for__main()
  v2 = _main(v1)
  print(v2)
  v3 = 0
  return v3

if __name__ == '__main__':
  test_main()

