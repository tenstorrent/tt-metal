name: "[internal] Perf models impl"

on:
  workflow_call:
    inputs:
      build-artifact-name:
        required: true
        type: string
      wheel-artifact-name:
        required: true
        type: string
      docker-image:
        required: true
        type: string
      model:
        required: false
        type: string
        default: "all"
      extra-tag:
        required: false
        type: string
        default: "in-service"

jobs:
  models-perf:
    strategy:
      # Do not fail-fast because we need to ensure all tests go to completion
      # so we try not to get hanging machines
      fail-fast: false
      matrix:
        test-info: [
          {name: "N300 WH B0", model-group: "llm_javelin", timeout: 20, arch: wormhole_b0, runs-on: ["N300", "pipeline-perf", "bare-metal", "${{ inputs.extra-tag }}"], machine-type: "bare_metal"},
          {name: "N300 WH B0", model-group: "cnn_javelin", timeout: 10, arch: wormhole_b0, runs-on: ["N300", "pipeline-perf", "bare-metal", "${{ inputs.extra-tag }}"], machine-type: "bare_metal"},
          {name: "N300 WH B0", model-group: "other_magic_env", timeout: 45, arch: wormhole_b0, runs-on: ["N300", "pipeline-perf", "bare-metal", "${{ inputs.extra-tag }}"], machine-type: "bare_metal"},
          # Doesn't work on blackhole P150 {name: "P150 BH", model-group: "llm_javelin", timeout: 20, arch: blackhole, runs-on: ["P150", "pipeline-functional", "cloud-virtual-machine", "${{ inputs.extra-tag }}"], machine-type: "virtual_machine"},
          {name: "P150 BH", model-group: "cnn_javelin", timeout: 10, arch: blackhole, runs-on: ["P150", "pipeline-functional", "cloud-virtual-machine", "${{ inputs.extra-tag }}"], machine-type: "virtual_machine"},
          {name: "P150 BH", model-group: "other_magic_env", timeout: 45, arch: blackhole, runs-on: ["P150", "pipeline-perf", "bare-metal", "${{ inputs.extra-tag }}"], machine-type: "bare_metal"},
        ]

    name: "${{ matrix.test-info.model-group }} ${{ matrix.test-info.name }}"
    runs-on: ${{ matrix.test-info.runs-on }}
    container:
      image: ${{ inputs.docker-image || 'docker-image-unresolved!' }}
      env:
        TT_METAL_HOME: /work
        PYTHONPATH: /work
        LD_LIBRARY_PATH: /work/build/lib
        ARCH_NAME: ${{ matrix.test-info.arch }}
        LOGURU_LEVEL: INFO
        GITHUB_ACTIONS: true
        GTEST_OUTPUT: xml:/work/generated/test_reports/
        HF_HUB_CACHE: ${{ ((matrix.test-info.arch == 'wormhole_b0' || (matrix.test-info.arch == 'blackhole' && matrix.test-info.model-group == 'cnn_javelin')) && '/mnt/MLPerf/huggingface/hub') || '' }}
      volumes:
        - ${{ github.workspace }}/docker-job:/work # Subdir to workaround https://github.com/actions/runner/issues/691
        - /dev/hugepages-1G:/dev/hugepages-1G
        - /mnt/MLPerf:/mnt/MLPerf:ro
      options: "--device /dev/tenstorrent"
    defaults:
      run:
        shell: bash
        working-directory: /work # https://github.com/actions/runner/issues/878
    steps:
      - name: ⬇️  Setup Job
        uses: tenstorrent/tt-metal/.github/actions/setup-job@main
        timeout-minutes: 10
        with:
          build-artifact-name: ${{ inputs.build-artifact-name }}
          wheel-artifact-name: ${{ inputs.wheel-artifact-name }}
      - name: Run falcon7b model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          commands: pytest -n auto models/demos/falcon7b_common/tests -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model-group == 'llm_javelin' && (inputs.model == 'all' || inputs.model == 'falcon7b') }}
      - name: Run mamba model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          commands: pytest -n auto models/demos/wormhole/mamba/tests -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model-group == 'llm_javelin' }}
      - name: Run vanilla_unet model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          commands: pytest -n auto models/demos/vanilla_unet/tests/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model-group == 'cnn_javelin' && (inputs.model == 'all' || inputs.model == 'vanilla_unet') }}
      - name: Run functional_unet model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          commands: pytest -n auto models/experimental/functional_unet/tests -m models_performance_bare_metal --timeout=480
        if: ${{ !cancelled() && matrix.test-info.model-group == 'cnn_javelin' && (inputs.model == 'all' || inputs.model == 'functional_unet') }}
      - name: Run stable_diffusion model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          commands: pytest -n auto models/demos/${{ matrix.test-info.arch == 'blackhole' && 'blackhole' || 'wormhole' }}/stable_diffusion/tests -m models_performance_bare_metal --timeout=480
        if: ${{ !cancelled() && matrix.test-info.model-group == 'cnn_javelin' && (inputs.model == 'all' || inputs.model == 'stable_diffusion') }}
      - name: Run yolov10x model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          commands: pytest -n auto models/demos/yolov10x/tests/perf/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model-group == 'other_magic_env' && (inputs.model == 'all' || inputs.model == 'yolov10x') }}
      - name: Run sentence_bert model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          commands: pytest -n auto models/demos/sentence_bert/tests/perf/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model-group == 'other_magic_env' && (inputs.model == 'all' || inputs.model == 'sentence_bert') }}
      - name: Run resnet50 model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          commands: pytest -n auto models/demos/${{ matrix.test-info.arch == 'blackhole' && 'blackhole' || 'wormhole' }}/resnet50/tests/test_perf_e2e_resnet50.py -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model-group == 'other_magic_env' && (inputs.model == 'all' || inputs.model == 'resnet50') }}
      - name: Run yolov11 model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          commands: pytest -n auto models/demos/yolov11/tests/perf/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model-group == 'other_magic_env' && (inputs.model == 'all' || inputs.model == 'yolov11') }}
      - name: Run yolov11m model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          commands: pytest -n auto models/demos/yolov11m/tests/perf/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model-group == 'other_magic_env' && (inputs.model == 'all' || inputs.model == 'yolov11m') }}
      - name: Run bert_tiny model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          commands: pytest -n auto models/demos/wormhole/bert_tiny/tests/test_performance.py -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model-group == 'other_magic_env' && (inputs.model == 'all' || inputs.model == 'bert_tiny') }}
      - name: Run yolov4 model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          commands: pytest -n auto models/demos/yolov4/tests/perf/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model-group == 'other_magic_env' && (inputs.model == 'all' || inputs.model == 'yolov4') }}
      - name: Run yolov7 model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          commands: pytest -n auto models/demos/yolov7/tests/perf/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model-group == 'other_magic_env' && (inputs.model == 'all' || inputs.model == 'yolov7') }}
      - name: Run distilbert model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          commands: pytest -n auto models/demos/wormhole/distilbert/tests/test_perf_distilbert.py -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model-group == 'other_magic_env' && (inputs.model == 'all' || inputs.model == 'distilbert') }}
      - name: Run segformer model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          commands: pytest -n auto models/demos/segformer/tests/perf/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model-group == 'other_magic_env' && (inputs.model == 'all' || inputs.model == 'segformer') }}
      - name: Run metal_BERT_large_11 model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          commands: pytest -n auto models/demos/metal_BERT_large_11/tests/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model-group == 'other_magic_env' && (inputs.model == 'all' || inputs.model == 'metal_BERT_large_11') }}
      - name: Run yolov8s_world model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          commands: pytest -n auto models/demos/yolov8s_world/tests/perf/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model-group == 'other_magic_env' && (inputs.model == 'all' || inputs.model == 'yolov8s_world') }}
      - name: Run yolov8s model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          commands: pytest -n auto models/demos/yolov8s/tests/perf/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model-group == 'other_magic_env' && (inputs.model == 'all' || inputs.model == 'yolov8s') }}
      - name: Run yolov6l model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          commands: pytest -n auto models/demos/yolov6l/tests/perf/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model-group == 'other_magic_env' && (inputs.model == 'all' || inputs.model == 'yolov6l') }}
      - name: Run mobilenetv2 model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          commands: pytest -n auto models/demos/mobilenetv2/tests/perf/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model-group == 'other_magic_env' && (inputs.model == 'all' || inputs.model == 'mobilenetv2') }}
      - name: Run vgg_unet model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          commands: pytest -n auto models/demos/vgg_unet/tests/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model-group == 'other_magic_env' && (inputs.model == 'all' || inputs.model == 'vgg_unet') }}
      - name: Run yolov9c model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          commands: pytest -n auto models/demos/yolov9c/tests/perf/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model-group == 'other_magic_env' && (inputs.model == 'all' || inputs.model == 'yolov9c') }}
      - name: Run yolov8x model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          commands: pytest -n auto models/demos/yolov8x/tests/perf/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model-group == 'other_magic_env' && (inputs.model == 'all' || inputs.model == 'yolov8x') }}
      - name: Run swin_v2 model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          commands: pytest -n auto models/experimental/swin_v2/tests/perf/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model-group == 'other_magic_env' && (inputs.model == 'all' || inputs.model == 'swin_v2') }}
      - name: Run swin_s model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          commands: pytest -n auto models/experimental/swin_s/tests/perf/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model-group == 'other_magic_env' && (inputs.model == 'all' || inputs.model == 'swin_s') }}
      - name: Run yolov5x model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          commands: pytest -n auto models/demos/yolov5x/tests/perf/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model-group == 'other_magic_env' && (inputs.model == 'all' || inputs.model == 'yolov5x') }}
      - name: Run vovnet model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          commands: pytest -n auto models/experimental/vovnet/tests/perf/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model-group == 'other_magic_env' && (inputs.model == 'all' || inputs.model == 'vovnet') }}
      - name: Run yolov12x model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          commands: pytest -n auto models/demos/yolov12x/tests/perf/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model-group == 'other_magic_env' && (inputs.model == 'all' || inputs.model == 'yolov12x') }}
      - name: Run ufld_v2 model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          commands: pytest -n auto models/demos/ufld_v2/tests/perf/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model-group == 'other_magic_env' && (inputs.model == 'all' || inputs.model == 'ufld_v2') }}
      - name: Run efficientnetb0 model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          commands: pytest -n auto models/experimental/efficientnetb0/tests/perf/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model-group == 'other_magic_env' && (inputs.model == 'all' || inputs.model == 'efficientnetb0') }}
      - name: Merge all the generated reports
        timeout-minutes: 10
        run: |
          # Merge all the generated reports
          env python3 models/perf/merge_perf_results.py
        if: ${{ !cancelled() }}

      - name: Save environment data
        if: ${{ !cancelled() }}
        shell: bash
        env:
          ARCH_NAME: ${{ matrix.test-info.arch }}
        run: python3 .github/scripts/data_analysis/create_benchmark_with_environment_json.py

      - name: Upload benchmark data
        if: ${{ !cancelled() }}
        uses: tenstorrent/tt-metal/.github/actions/upload-data-via-sftp@main
        with:
          ssh-private-key: ${{ secrets.SFTP_BENCHMARK_WRITER_KEY }}
          sftp-batchfile: .github/actions/upload-data-via-sftp/benchmark_data_batchfile.txt
          username: ${{ secrets.SFTP_BENCHMARK_WRITER_USERNAME }}
          hostname: ${{ secrets.SFTP_BENCHMARK_WRITER_HOSTNAME }}
          path: /work

      # TODO: Fix the pipeline before enabling notifications.
      #- uses: tenstorrent/tt-metal/.github/actions/slack-report@main
      #  if: ${{ failure() }}
      #  with:
      #    slack_webhook_url: ${{ secrets.SLACK_METAL_INFRA_PIPELINE_STATUS_ALERT }}
      - name: Check perf report exists
        id: check-perf-report
        if: ${{ !cancelled() }}
        run: |
          ls -hal
          export PERF_REPORT_FILENAME=Models_Perf_$(date +%Y_%m_%d).csv
          ls -hal $PERF_REPORT_FILENAME
          FULL_REPORT_PATH="$(pwd)/$PERF_REPORT_FILENAME"
          echo "Full report location: $FULL_REPORT_PATH"
          echo "perf_report_filename=$PERF_REPORT_FILENAME" >> "$GITHUB_OUTPUT"
          echo "perf_report_full_path=$FULL_REPORT_PATH" >> "$GITHUB_OUTPUT"
      - name: Upload perf report
        if: ${{ !cancelled() && steps.check-perf-report.conclusion == 'success' }}
        uses: actions/upload-artifact@v4
        timeout-minutes: 10
        with:
          name: perf-report-csv-${{ matrix.test-info.model-group }}-${{ matrix.test-info.arch }}-${{ matrix.test-info.machine-type }}
          path: "${{ steps.check-perf-report.outputs.perf_report_full_path }}"
      - uses: tenstorrent/tt-metal/.github/actions/upload-artifact-with-job-uuid@main
        timeout-minutes: 10
        if: ${{ !cancelled() }}
        with:
          path: generated/test_reports/
          prefix: "test_reports_"
