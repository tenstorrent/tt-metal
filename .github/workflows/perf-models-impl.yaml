name: "[internal] Perf models impl"

on:
  workflow_call:
    inputs:
      build-artifact-name:
        required: true
        type: string
      wheel-artifact-name:
        required: true
        type: string
      docker-image:
        required: true
        type: string
      extra-tag:
        required: false
        type: string
        default: "in-service"
      models-to-run:
        required: false
        type: string
        default: "all"

jobs:
  create-test-matrix:
    runs-on: ubuntu-latest
    outputs:
      test_matrix: ${{ steps.ctm.outputs.test_matrix }}
      test_matrix_count: ${{ steps.ctm.outputs.test_matrix_count }}
    steps:
      - id: ctm
        shell: bash
        run: |
          set -euo pipefail

          # Define model configurations with their arch, model-group, and timeout mappings
          ALL_MODEL_CONFIGS='{
            "falcon7b": {"model-group": "llm_javelin", "timeout": 20, "archs": ["wormhole_b0"]},
            "mamba": {"model-group": "llm_javelin", "timeout": 20, "archs": ["wormhole_b0"]},
            "functional_unet": {"model-group": "cnn_javelin", "timeout": 10, "archs": ["wormhole_b0", "blackhole"]},
            "stable_diffusion": {"model-group": "cnn_javelin", "timeout": 10, "archs": ["wormhole_b0", "blackhole"]},
            "convnet_mnist": {"model-group": "other", "timeout": 5, "archs": ["wormhole_b0"], "special_archs": {"blackhole": "other_mlperf_required"}},
            "bert_tiny": {"model-group": "other", "timeout": 5, "archs": ["wormhole_b0"]},
            "squeezebert": {"model-group": "other", "timeout": 5, "archs": ["wormhole_b0"]},
            "roberta": {"model-group": "other", "timeout": 5, "archs": ["wormhole_b0"]},
            "sentence_bert": {"model-group": "other_magic_env", "timeout": 45, "archs": ["wormhole_b0", "blackhole"]},
            "resnet50": {"model-group": "other_magic_env", "timeout": 45, "archs": ["wormhole_b0", "blackhole"]},
            "yolov11": {"model-group": "other_magic_env", "timeout": 45, "archs": ["wormhole_b0", "blackhole"]},
            "yolov11m": {"model-group": "other_magic_env", "timeout": 45, "archs": ["wormhole_b0", "blackhole"]},
            "bert_tiny_wormhole": {"model-group": "other_magic_env", "timeout": 45, "archs": ["wormhole_b0", "blackhole"]},
            "yolov4": {"model-group": "other_magic_env", "timeout": 45, "archs": ["wormhole_b0", "blackhole"]},
            "yolov7": {"model-group": "other_magic_env", "timeout": 45, "archs": ["wormhole_b0", "blackhole"]},
            "distilbert": {"model-group": "other_magic_env", "timeout": 45, "archs": ["wormhole_b0", "blackhole"]},
            "segformer": {"model-group": "other_magic_env", "timeout": 45, "archs": ["wormhole_b0", "blackhole"]},
            "metal_BERT_large_11": {"model-group": "other_magic_env", "timeout": 45, "archs": ["wormhole_b0", "blackhole"]},
            "yolov8s_world": {"model-group": "other_magic_env", "timeout": 45, "archs": ["wormhole_b0", "blackhole"]},
            "yolov8s": {"model-group": "other_magic_env", "timeout": 45, "archs": ["wormhole_b0", "blackhole"]},
            "yolov6l": {"model-group": "other_magic_env", "timeout": 45, "archs": ["wormhole_b0", "blackhole"]},
            "mobilenetv2": {"model-group": "other_magic_env", "timeout": 45, "archs": ["wormhole_b0", "blackhole"]},
            "vgg_unet": {"model-group": "other_magic_env", "timeout": 45, "archs": ["wormhole_b0", "blackhole"]},
            "yolov9c": {"model-group": "other_magic_env", "timeout": 45, "archs": ["wormhole_b0", "blackhole"]},
            "vanilla_unet": {"model-group": "other_magic_env", "timeout": 45, "archs": ["wormhole_b0", "blackhole"]},
            "yolov8x": {"model-group": "other_magic_env", "timeout": 45, "archs": ["wormhole_b0", "blackhole"]},
            "swin_v2": {"model-group": "other_magic_env", "timeout": 45, "archs": ["wormhole_b0", "blackhole"]},
            "swin_s": {"model-group": "other_magic_env", "timeout": 45, "archs": ["wormhole_b0", "blackhole"]},
            "yolov5x": {"model-group": "other_magic_env", "timeout": 45, "archs": ["wormhole_b0", "blackhole"]},
            "vovnet": {"model-group": "other_magic_env", "timeout": 45, "archs": ["wormhole_b0", "blackhole"]},
            "yolov12x": {"model-group": "other_magic_env", "timeout": 45, "archs": ["wormhole_b0", "blackhole"]},
            "ufld_v2": {"model-group": "other_magic_env", "timeout": 45, "archs": ["wormhole_b0", "blackhole"]},
            "efficientnetb0": {"model-group": "other_magic_env", "timeout": 45, "archs": ["wormhole_b0", "blackhole"]}
          }'

          # Architecture-specific configuration mapping
          ARCH_CONFIGS='{
            "wormhole_b0": {
              "name": "N300 WH B0",
              "runs-on": ["N300", "pipeline-perf", "bare-metal", "${{ inputs.extra-tag }}"],
              "machine-type": "bare_metal"
            },
            "blackhole": {
              "name": "P150 BH",
              "runs-on": ["P150", "pipeline-perf", "bare-metal", "${{ inputs.extra-tag }}"],
              "machine-type": "bare_metal",
              "special_configs": {
                "other_mlperf_required": {
                  "runs-on": ["P150", "pipeline-functional", "cloud-virtual-machine", "${{ inputs.extra-tag }}"],
                  "machine-type": "virtual_machine"
                }
              }
            }
          }'

          SEL='${{ inputs.models-to-run }}'
          echo "SEL raw: ${SEL}"
          echo "${SEL}" | jq -e type && echo "Looks like valid JSON" || echo "Not JSON"

          # Extract all model names for "all" selection
          ALL_MODELS=$(jq -r 'keys[]' <<< "$ALL_MODEL_CONFIGS")

          # ---- Determine selected models ----
          if [ -z "${SEL}" ] || [ "${SEL}" = "all" ]; then
            SELECTED_MODELS="$(echo "$ALL_MODELS" | jq -R . | jq -s .)"
          else
            if echo "${SEL}" | jq -e type >/dev/null 2>&1; then
              SELECTED_MODELS="${SEL}"
            else
              echo "Not supported input format"
              exit 1
            fi
          fi

          # ---- Generate matrix entries for selected models ----
          MATRIX_ENTRIES='[]'

          for model in $(echo "$SELECTED_MODELS" | jq -r '.[]'); do
            if ! jq -e ".\"$model\"" <<< "$ALL_MODEL_CONFIGS" >/dev/null; then
              echo "Warning: Model '$model' not found in configuration, skipping"
              continue
            fi

            model_config=$(jq ".\"$model\"" <<< "$ALL_MODEL_CONFIGS")
            model_group=$(jq -r '."model-group"' <<< "$model_config")
            timeout=$(jq -r '.timeout' <<< "$model_config")
            archs=$(jq -r '.archs[]' <<< "$model_config")

            for arch in $archs; do
              arch_config=$(jq ".\"$arch\"" <<< "$ARCH_CONFIGS")
              name=$(jq -r '.name' <<< "$arch_config")
              runs_on=$(jq -c '."runs-on"' <<< "$arch_config")
              machine_type=$(jq -r '."machine-type"' <<< "$arch_config")

              # Check for special arch configurations (like convnet_mnist on blackhole)
              final_model_group="$model_group"
              final_runs_on="$runs_on"
              final_machine_type="$machine_type"

              if jq -e ".\"$model\".special_archs.\"$arch\"" <<< "$ALL_MODEL_CONFIGS" >/dev/null; then
                final_model_group=$(jq -r ".\"$model\".special_archs.\"$arch\"" <<< "$ALL_MODEL_CONFIGS")
                if jq -e ".\"$arch\".special_configs.\"$final_model_group\"" <<< "$ARCH_CONFIGS" >/dev/null; then
                  special_config=$(jq ".\"$arch\".special_configs.\"$final_model_group\"" <<< "$ARCH_CONFIGS")
                  final_runs_on=$(jq -c '."runs-on"' <<< "$special_config")
                  final_machine_type=$(jq -r '."machine-type"' <<< "$special_config")
                fi
              fi

              matrix_entry=$(jq -n \
                --arg model "$model" \
                --arg name "$name" \
                --arg model_group "$final_model_group" \
                --argjson timeout "$timeout" \
                --arg arch "$arch" \
                --argjson runs_on "$final_runs_on" \
                --arg machine_type "$final_machine_type" \
                '{
                  "model": $model,
                  "name": $name,
                  "model-group": $model_group,
                  "timeout": $timeout,
                  "arch": $arch,
                  "runs-on": $runs_on,
                  "machine-type": $machine_type
                }')

              MATRIX_ENTRIES=$(jq --argjson entry "$matrix_entry" '. + [$entry]' <<< "$MATRIX_ENTRIES")
            done
          done

          echo "test_matrix=$(echo $MATRIX_ENTRIES | tr -d '\n')" >> "$GITHUB_OUTPUT"

          MATRIX_COUNT="$(jq 'length' <<< "$MATRIX_ENTRIES")"
          echo "test_matrix_count=${MATRIX_COUNT}" >> "$GITHUB_OUTPUT"

  models-perf:
    needs: create-test-matrix
    if: ${{ needs.create-test-matrix.outputs.test_matrix_count != '0' }}
    strategy:
      # Do not fail-fast because we need to ensure all tests go to completion
      # so we try not to get hanging machines
      fail-fast: false
      matrix:
        test-info: ${{ fromJSON(needs.create-test-matrix.outputs.test_matrix) }}

    name: "${{ matrix.test-info.model }} ${{ matrix.test-info.name }}"
    defaults:
      run:
        shell: bash
    runs-on: ${{ matrix.test-info.runs-on }}
    env:
      DOCKER_IMAGE: ${{ inputs.docker-image }}
      DOCKER_PASSWORD: ${{ secrets.GITHUB_TOKEN }}
      DOCKER_OPTS: |
        -v /mnt/MLPerf:/mnt/MLPerf:ro
        -e TT_METAL_HOME=${{ github.workspace }}
        -e ARCH_NAME=${{ matrix.test-info.arch }}
        -e LD_LIBRARY_PATH=${{ github.workspace }}/build/lib
        -e GTEST_OUTPUT=xml:generated/test_reports/
        -e GITHUB_ACTIONS=true
        -e LOGURU_LEVEL=INFO
        ${{ (matrix.test-info.arch == 'wormhole_b0' || (matrix.test-info.arch == 'blackhole' && matrix.test-info.model-group == 'other_mlperf_required')) && '-e HF_HUB_CACHE=/mnt/MLPerf/huggingface/hub' || '' }}
      PIPELINE: model-perf
    steps:
      - name: ⬇️ Checkout
        uses: actions/checkout@v4
        with:
          submodules: recursive
      - name: ⬇️ Download Build
        uses: actions/download-artifact@634f93cb2916e3fdff6788551b99b062d0335ce0 # v5.0
        timeout-minutes: 10
        with:
          name: ${{ inputs.build-artifact-name }}
      - name: Extract files
        run: tar -xvf ttm_any.tar
      - name: ⬇️ Download Wheel
        uses: actions/download-artifact@634f93cb2916e3fdff6788551b99b062d0335ce0 # v5.0
        timeout-minutes: 10
        with:
          name: ${{ inputs.wheel-artifact-name }}
      - name: Run falcon7b model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: ./.github/actions/single-card-perf-test
        with:
          commands: pytest -n auto models/demos/falcon7b_common/tests -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model == 'falcon7b' }}
      - name: Run mamba model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: ./.github/actions/single-card-perf-test
        with:
          commands: pytest -n auto models/demos/wormhole/mamba/tests -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model == 'mamba' }}
      - name: Run functional_unet model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: ./.github/actions/single-card-perf-test
        with:
          commands: pytest -n auto models/experimental/functional_unet/tests -m models_performance_bare_metal --timeout=480
        if: ${{ !cancelled() && matrix.test-info.model == 'functional_unet' }}
      - name: Run stable_diffusion model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: ./.github/actions/docker-run
        with:
          docker_image: ${{ inputs.docker-image }}
          docker_password: ${{ secrets.GITHUB_TOKEN }}
          docker_opts: ${{ env.DOCKER_OPTS }}
          install_wheel: true
          run_args: pytest -n auto models/demos/${{ matrix.test-info.arch == 'blackhole' && 'blackhole' || 'wormhole' }}/stable_diffusion/tests -m models_performance_bare_metal --timeout=480
        if: ${{ !cancelled() && matrix.test-info.model == 'stable_diffusion' }}
      - name: Run covnet_mnist model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: ./.github/actions/single-card-perf-test
        with:
          commands: pytest -n auto models/demos/convnet_mnist/tests/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model == 'convnet_mnist' }}
      - name: Run bert_tiny model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: ./.github/actions/single-card-perf-test
        with:
          commands: pytest -n auto models/demos/bert_tiny/tests/test_performance.py -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model == 'bert_tiny' }}
      - name: Run squeezebert model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: ./.github/actions/single-card-perf-test
        with:
          commands: pytest -n auto models/demos/squeezebert/tests/test_performance.py -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model == 'squeezebert' }}
      - name: Run roberta model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: ./.github/actions/single-card-perf-test
        with:
          commands: pytest -n auto models/demos/roberta/tests/test_performance.py -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model == 'roberta' }}
      # issue: https://github.com/tenstorrent/tt-metal/issues/27745
      # - name: Run yolov10x model_perf test
      #   timeout-minutes: ${{ matrix.test-info.timeout }}
      #   uses: ./.github/actions/single-card-perf-test
      #   with:
      #     commands: pytest -n auto models/demos/yolov10x/tests/perf/ -m models_performance_bare_metal
      #  if: ${{ !cancelled() && matrix.test-info.model-group == 'other_magic_env' }}
      - name: Run sentence_bert model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: ./.github/actions/single-card-perf-test
        with:
          commands: pytest -n auto models/demos/sentence_bert/tests/perf/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model == 'sentence_bert' }}
      - name: Run resnet50 model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: ./.github/actions/single-card-perf-test
        with:
          commands: pytest -n auto models/demos/${{ matrix.test-info.arch == 'blackhole' && 'blackhole' || 'wormhole' }}/resnet50/tests/test_perf_e2e_resnet50.py -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model == 'resnet50' }}
      - name: Run yolov11 model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: ./.github/actions/single-card-perf-test
        with:
          commands: pytest -n auto models/demos/yolov11/tests/perf/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model == 'yolov11' }}
      - name: Run yolov11m model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: ./.github/actions/single-card-perf-test
        with:
          commands: pytest -n auto models/demos/yolov11m/tests/perf/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model == 'yolov11m' }}
      - name: Run bert_tiny_wormhole model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: ./.github/actions/single-card-perf-test
        with:
          commands: pytest -n auto models/demos/wormhole/bert_tiny/tests/test_performance.py -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model == 'bert_tiny_wormhole' }}
      - name: Run yolov4 model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: ./.github/actions/single-card-perf-test
        with:
          commands: pytest -n auto models/demos/yolov4/tests/perf/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model == 'yolov4' }}
      - name: Run yolov7 model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: ./.github/actions/single-card-perf-test
        with:
          commands: pytest -n auto models/demos/yolov7/tests/perf/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model == 'yolov7' }}
      - name: Run distilbert model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: ./.github/actions/single-card-perf-test
        with:
          commands: pytest -n auto models/demos/wormhole/distilbert/tests/test_perf_distilbert.py -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model == 'distilbert' }}
      - name: Run segformer model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: ./.github/actions/single-card-perf-test
        with:
          commands: pytest -n auto models/demos/segformer/tests/perf/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model == 'segformer' }}
      - name: Run metal_BERT_large_11 model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: ./.github/actions/single-card-perf-test
        with:
          commands: pytest -n auto models/demos/metal_BERT_large_11/tests/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model == 'metal_BERT_large_11' }}
      - name: Run yolov8s_world model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: ./.github/actions/single-card-perf-test
        with:
          commands: pytest -n auto models/demos/yolov8s_world/tests/perf/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model == 'yolov8s_world' }}
      - name: Run yolov8s model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: ./.github/actions/single-card-perf-test
        with:
          commands: pytest -n auto models/demos/yolov8s/tests/perf/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model == 'yolov8s' }}
      - name: Run yolov6l model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: ./.github/actions/single-card-perf-test
        with:
          commands: pytest -n auto models/demos/yolov6l/tests/perf/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model == 'yolov6l' }}
      - name: Run mobilenetv2 model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: ./.github/actions/single-card-perf-test
        with:
          commands: pytest -n auto models/demos/mobilenetv2/tests/perf/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model == 'mobilenetv2' }}
      - name: Run vgg_unet model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: ./.github/actions/single-card-perf-test
        with:
          commands: pytest -n auto models/demos/vgg_unet/tests/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model == 'vgg_unet' }}
      - name: Run yolov9c model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: ./.github/actions/single-card-perf-test
        with:
          commands: pytest -n auto models/demos/yolov9c/tests/perf/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model == 'yolov9c' }}
      - name: Run vanilla_unet model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: ./.github/actions/single-card-perf-test
        with:
          commands: pytest -n auto models/demos/vanilla_unet/tests/perf/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model == 'vanilla_unet' }}
      - name: Run yolov8x model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: ./.github/actions/single-card-perf-test
        with:
          commands: pytest -n auto models/demos/yolov8x/tests/perf/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model == 'yolov8x' }}
      - name: Run swin_v2 model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: ./.github/actions/single-card-perf-test
        with:
          commands: pytest -n auto models/experimental/swin_v2/tests/perf/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model == 'swin_v2' }}
      - name: Run swin_s model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: ./.github/actions/single-card-perf-test
        with:
          commands: pytest -n auto models/experimental/swin_s/tests/perf/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model == 'swin_s' }}
      - name: Run yolov5x model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: ./.github/actions/single-card-perf-test
        with:
          commands: pytest -n auto models/demos/yolov5x/tests/perf/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model == 'yolov5x' }}
      - name: Run vovnet model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: ./.github/actions/single-card-perf-test
        with:
          commands: pytest -n auto models/experimental/vovnet/tests/perf/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model == 'vovnet' }}
      - name: Run yolov12x model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: ./.github/actions/single-card-perf-test
        with:
          commands: pytest -n auto models/demos/yolov12x/tests/perf/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model == 'yolov12x' }}
      - name: Run ufld_v2 model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: ./.github/actions/single-card-perf-test
        with:
          commands: pytest -n auto models/demos/ufld_v2/tests/perf/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model == 'ufld_v2' }}
      - name: Run efficientnetb0 model_perf test
        timeout-minutes: ${{ matrix.test-info.timeout }}
        uses: ./.github/actions/single-card-perf-test
        with:
          commands: pytest -n auto models/experimental/efficientnetb0/tests/perf/ -m models_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.model == 'efficientnetb0' }}
      - name: Merge all the generated reports
        timeout-minutes: 10
        uses: ./.github/actions/docker-run
        with:
          docker_image: ${{ inputs.docker-image }}
          docker_password: ${{ secrets.GITHUB_TOKEN }}
          docker_opts: ${{ env.DOCKER_OPTS }}
          run_args: |
            # Merge all the generated reports
            env python3 models/perf/merge_perf_results.py CHECK
        if: ${{ !cancelled() }}

      # TODO: Fix the pipeline before enabling notifications.
      #- uses: tenstorrent/tt-metal/.github/actions/slack-report@main
      #  if: ${{ failure() }}
      #  with:
      #    slack_webhook_url: ${{ secrets.SLACK_METAL_INFRA_PIPELINE_STATUS_ALERT }}
      - name: Check perf report exists
        id: check-perf-report
        if: ${{ !cancelled() }}
        run: |
          ls -hal
          export PERF_REPORT_FILENAME=Models_Perf_$(date +%Y_%m_%d).csv
          ls -hal $PERF_REPORT_FILENAME
          echo "perf_report_filename=$PERF_REPORT_FILENAME" >> "$GITHUB_OUTPUT"
      - name: Upload perf report
        if: ${{ !cancelled() && steps.check-perf-report.conclusion == 'success' }}
        uses: actions/upload-artifact@v4
        timeout-minutes: 10
        with:
          name: perf-report-csv-${{ matrix.test-info.model-group }}-${{ matrix.test-info.arch }}-${{ matrix.test-info.machine-type }}
          path: "${{ steps.check-perf-report.outputs.perf_report_filename }}"
      - uses: tenstorrent/tt-metal/.github/actions/upload-artifact-with-job-uuid@main
        timeout-minutes: 10
        if: ${{ !cancelled() }}
        with:
          path: generated/test_reports/
          prefix: "test_reports_"
