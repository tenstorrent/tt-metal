name: "[internal] Single-card Device perf regressions impl"

on:
  workflow_call:
    inputs:
      os:
        required: false
        type: string
        default: "ubuntu-22.04"
      docker-image:
        required: true
        type: string
      build-artifact-name:
        required: true
        type: string
      wheel-artifact-name:
        required: true
        type: string
      extra-tag:
        required: false
        type: string
        default: "in-service"
      models-to-run:
        required: false
        type: string
        default: "all"

jobs:
  create-test-matrix:
    runs-on: ubuntu-latest
    outputs:
      test_matrix: ${{ steps.ctm.outputs.test_matrix }}
      test_matrix_count: ${{ steps.ctm.outputs.test_matrix_count }}
    steps:
      - id: ctm
        shell: bash
        run: |
          set -euo pipefail

          # Define model configurations with their test requirements
          ALL_MODEL_CONFIGS='{
            "non-civ2_tests": {
              "device_perf_model_name": "non-civ2_tests",
              "commands": "pytest models/demos/convnet_mnist/tests/ -m models_device_performance_bare_metal\npytest models/demos/mnist/tests -m models_device_performance_bare_metal\npytest models/demos/falcon7b_common/tests -m models_device_performance_bare_metal\npytest models/demos/segformer/tests/perf -m models_device_performance_bare_metal",
              "supported_configs": ["non-civ2"]
            },
            "yolov11": {
              "device_perf_model_name": "yolov11",
              "commands": "pytest models/demos/yolov11/tests/perf -m models_device_performance_bare_metal",
              "supported_configs": ["civ2-set1"]
            },
            "yolov11m": {
              "device_perf_model_name": "yolov11m",
              "commands": "pytest models/demos/yolov11m/tests/perf -m models_device_performance_bare_metal",
              "supported_configs": ["civ2-set1"]
            },
            "yolov10x": {
              "device_perf_model_name": "yolov10x",
              "commands": "pytest models/demos/yolov10x/tests/perf -m models_device_performance_bare_metal",
              "supported_configs": ["civ2-set1"]
            },
            "stable_diffusion": {
              "device_perf_model_name": "stable_diffusion",
              "commands": "pytest models/demos/{{ARCH_PATH}}/stable_diffusion/tests -m models_device_performance_bare_metal --timeout=600{{SDXL_EXTRA}}",
              "supported_configs": ["civ2-set1", "civ2-blackhole-set1"]
            },
            "distilbert": {
              "device_perf_model_name": "distilbert",
              "commands": "pytest models/demos/distilbert/tests -m models_device_performance_bare_metal\npytest models/demos/wormhole/distilbert/tests -m models_device_performance_bare_metal",
              "supported_configs": ["civ2-set1"]
            },
            "vgg": {
              "device_perf_model_name": "vgg",
              "commands": "pytest models/demos/vgg/tests/ -m models_device_performance_bare_metal\npytest models/demos/vgg_unet/tests/perf -m models_device_performance_bare_metal",
              "supported_configs": ["civ2-set1"]
            },
            "bert_tiny": {
              "device_perf_model_name": "bert_tiny",
              "commands": "pytest models/demos/bert_tiny/tests/ -m models_device_performance_bare_metal\npytest models/demos/wormhole/bert_tiny/tests -m models_device_performance_bare_metal",
              "supported_configs": ["civ2-set1"]
            },
            "squeezebert": {
              "device_perf_model_name": "squeezebert",
              "commands": "pytest models/demos/squeezebert/tests -m models_device_performance_bare_metal",
              "supported_configs": ["civ2-set1"]
            },
            "roberta": {
              "device_perf_model_name": "roberta",
              "commands": "pytest models/demos/roberta/tests/ -m models_device_performance_bare_metal",
              "supported_configs": ["civ2-set1"]
            },
            "resnet50": {
              "device_perf_model_name": "resnet50",
              "commands": "pytest models/demos/{{ARCH_PATH}}/resnet50/tests -m models_device_performance_bare_metal",
              "supported_configs": ["civ2-set1", "civ2-blackhole-set1"]
            },
            "ufld_v2": {
              "device_perf_model_name": "ufld_v2",
              "commands": "pytest models/demos/ufld_v2/tests/perf -m models_device_performance_bare_metal",
              "supported_configs": ["civ2-set1"]
            },
            "sentence_bert": {
              "device_perf_model_name": "sentence_bert",
              "commands": "pytest models/demos/sentence_bert/tests/perf -m models_device_performance_bare_metal",
              "supported_configs": ["civ2-set1"]
            },
            "functional_unet": {
              "device_perf_model_name": "functional_unet",
              "commands": "pytest models/experimental/functional_unet/tests/test_unet_perf.py -m models_device_performance_bare_metal",
              "supported_configs": ["civ2-set1", "civ2-blackhole-set1"]
            },
            "mamba": {
              "device_perf_model_name": "mamba",
              "commands": "pytest models/demos/wormhole/mamba/tests -m models_device_performance_bare_metal",
              "supported_configs": ["civ2-set2"]
            },
            "metal_BERT_large_11": {
              "device_perf_model_name": "metal_BERT_large_11",
              "commands": "# pytest models/demos/metal_BERT_large_11/tests -m models_device_performance_bare_metal",
              "supported_configs": ["civ2-set2"]
            },
            "yolov4": {
              "device_perf_model_name": "yolov4",
              "commands": "pytest models/demos/yolov4/tests -m models_device_performance_bare_metal",
              "supported_configs": ["civ2-set2"]
            },
            "mobilenetv2": {
              "device_perf_model_name": "mobilenetv2",
              "commands": "pytest models/demos/mobilenetv2/tests/perf -m models_device_performance_bare_metal",
              "supported_configs": ["civ2-set2"]
            },
            "yolov8": {
              "device_perf_model_name": "yolov8",
              "commands": "pytest models/demos/yolov8x/tests/perf -m models_device_performance_bare_metal\npytest models/demos/yolov8s/tests/perf -m models_device_performance_bare_metal\n# Skip for #27008\n# pytest models/demos/yolov8s_world/tests/perf -m models_device_performance_bare_metal",
              "supported_configs": ["civ2-set2"]
            },
            "yolov7": {
              "device_perf_model_name": "yolov7",
              "commands": "pytest models/demos/yolov7/tests/perf -m models_device_performance_bare_metal",
              "supported_configs": ["civ2-set2"]
            },
            "vit": {
              "device_perf_model_name": "vit",
              "commands": "pytest models/demos/wormhole/vit/demo/ -m models_device_performance_bare_metal",
              "supported_configs": ["civ2-set2"]
            },
            "yolov6l": {
              "device_perf_model_name": "yolov6l",
              "commands": "pytest models/demos/yolov6l/tests/perf -m models_device_performance_bare_metal",
              "supported_configs": ["civ2-set2"]
            },
            "yolov9c": {
              "device_perf_model_name": "yolov9c",
              "commands": "pytest models/demos/yolov9c/tests/perf -m models_device_performance_bare_metal",
              "supported_configs": ["civ2-set2"]
            },
            "vanilla_unet": {
              "device_perf_model_name": "vanilla_unet",
              "commands": "pytest models/demos/vanilla_unet/tests/perf -m models_device_performance_bare_metal",
              "supported_configs": ["civ2-set2"]
            },
            "swin_v2": {
              "device_perf_model_name": "swin_v2",
              "commands": "pytest models/experimental/swin_v2/tests/perf -m models_device_performance_bare_metal",
              "supported_configs": ["civ2-set2"]
            },
            "swin_s": {
              "device_perf_model_name": "swin_s",
              "commands": "pytest models/experimental/swin_s/tests/perf -m models_device_performance_bare_metal",
              "supported_configs": ["civ2-set2"]
            },
            "yolov5x": {
              "device_perf_model_name": "yolov5x",
              "commands": "pytest models/demos/yolov5x/tests/perf -m models_device_performance_bare_metal",
              "supported_configs": ["civ2-set2"]
            },
            "vovnet": {
              "device_perf_model_name": "VoVNet",
              "commands": "pytest models/experimental/vovnet/tests/perf -m models_device_performance_bare_metal",
              "supported_configs": ["civ2-set2"]
            },
            "yolov12x": {
              "device_perf_model_name": "yolov12x",
              "commands": "pytest models/demos/yolov12x/tests/perf -m models_device_performance_bare_metal",
              "supported_configs": ["civ2-set2"]
            },
            "efficientnetb0": {
              "device_perf_model_name": "efficientnetb0",
              "commands": "pytest models/experimental/efficientnetb0/tests/perf -m models_device_performance_bare_metal",
              "supported_configs": ["civ2-set2"]
            }
          }'

          # Define test configuration mappings
          TEST_CONFIGS='{
            "non-civ2": {
              "name": "N300 WH B0 not yet ported",
              "arch": "wormhole_b0",
              "runs-on": ["N300", "pipeline-perf", "bare-metal", "${{ inputs.extra-tag }}"],
              "machine-type": "bare_metal",
              "civ2-compatible": false,
              "timeout": 30,
              "job-set1": false
            },
            "civ2-set1": {
              "name": "N300 WH B0 Set 1",
              "arch": "wormhole_b0",
              "runs-on": ["tt-ubuntu-2204-n300-stable"],
              "machine-type": "CIv2",
              "civ2-compatible": true,
              "timeout": 120,
              "job-set1": true
            },
            "civ2-set2": {
              "name": "N300 WH B0 Set 2",
              "arch": "wormhole_b0",
              "runs-on": ["tt-ubuntu-2204-n300-stable"],
              "machine-type": "CIv2",
              "civ2-compatible": true,
              "timeout": 120,
              "job-set1": false
            },
            "civ2-blackhole-set1": {
              "name": "P150 BH",
              "arch": "blackhole",
              "runs-on": ["tt-ubuntu-2204-p150b-stable"],
              "machine-type": "CIv2",
              "civ2-compatible": true,
              "timeout": 120,
              "job-blackhole-set1": true
            }
          }'

          SEL='${{ inputs.models-to-run }}'
          echo "SEL raw: ${SEL}"
          echo "${SEL}" | jq -e type && echo "Looks like valid JSON" || echo "Not JSON"

          # Extract all model names for "all" selection
          ALL_MODELS=$(jq -r 'keys[]' <<< "$ALL_MODEL_CONFIGS")

          # ---- Determine selected models ----
          if [ -z "${SEL}" ] || [ "${SEL}" = "all" ]; then
            SELECTED_MODELS="$(echo "$ALL_MODELS" | jq -R . | jq -s .)"
          else
            if echo "${SEL}" | jq -e type >/dev/null 2>&1; then
              SELECTED_MODELS="${SEL}"
            else
              echo "Not supported input format"
              exit 1
            fi
          fi

          # ---- Generate matrix entries for selected models ----
          MATRIX_ENTRIES='[]'

          for model in $(echo "$SELECTED_MODELS" | jq -r '.[]'); do
            if ! jq -e ".\"$model\"" <<< "$ALL_MODEL_CONFIGS" >/dev/null; then
              echo "Warning: Model '$model' not found in configuration, skipping"
              continue
            fi

            model_config=$(jq ".\"$model\"" <<< "$ALL_MODEL_CONFIGS")
            device_perf_model_name=$(jq -r '.device_perf_model_name' <<< "$model_config")
            commands=$(jq -r '.commands' <<< "$model_config")
            supported_configs=$(jq -r '.supported_configs[]' <<< "$model_config")

            for config in $supported_configs; do
              if ! jq -e ".\"$config\"" <<< "$TEST_CONFIGS" >/dev/null; then
                echo "Warning: Config '$config' not found, skipping"
                continue
              fi

              test_config=$(jq ".\"$config\"" <<< "$TEST_CONFIGS")

              # Process arch-specific command substitutions
              arch=$(jq -r '.arch' <<< "$test_config")
              processed_commands="$commands"
              if [[ "$processed_commands" == *"{{ARCH_PATH}}"* ]]; then
                if [ "$arch" = "blackhole" ]; then
                  processed_commands="${processed_commands//\{\{ARCH_PATH\}\}/blackhole}"
                else
                  processed_commands="${processed_commands//\{\{ARCH_PATH\}\}/wormhole}"
                fi
              fi

              # Handle SDXL extra for stable_diffusion on wormhole_b0
              if [[ "$processed_commands" == *"{{SDXL_EXTRA}}"* ]]; then
                if [ "$arch" = "wormhole_b0" ]; then
                  processed_commands="${processed_commands//\{\{SDXL_EXTRA\}\}/\npytest models/experimental/stable_diffusion_xl_base/tests/test_sdxl_perf.py -m models_device_performance_bare_metal}"
                else
                  processed_commands="${processed_commands//\{\{SDXL_EXTRA\}\}/}"
                fi
              fi

              matrix_entry=$(jq -n \
                --arg model "$model" \
                --arg device_perf_model_name "$device_perf_model_name" \
                --arg commands "$processed_commands" \
                --argjson test_config "$test_config" \
                '{
                  "model": $model,
                  "device_perf_model_name": $device_perf_model_name,
                  "commands": $commands
                } + $test_config')

              MATRIX_ENTRIES=$(jq --argjson entry "$matrix_entry" '. + [$entry]' <<< "$MATRIX_ENTRIES")
            done
          done

          echo "test_matrix=$(echo $MATRIX_ENTRIES | tr -d '\n')" >> "$GITHUB_OUTPUT"

          MATRIX_COUNT="$(jq 'length' <<< "$MATRIX_ENTRIES")"
          echo "test_matrix_count=${MATRIX_COUNT}" >> "$GITHUB_OUTPUT"

  device-perf:
    needs: create-test-matrix
    if: ${{ needs.create-test-matrix.outputs.test_matrix_count != '0' }}
    strategy:
      # Do not fail-fast because we need to ensure all tests go to completion
      # so we try not to get hanging machines
      fail-fast: false
      matrix:
        test-info: ${{ fromJSON(needs.create-test-matrix.outputs.test_matrix) }}
    name: "${{ matrix.test-info.model }} - ${{ matrix.test-info.name }} device perf"
    runs-on: ${{ matrix.test-info.runs-on }}
    container:
      image: ${{ inputs.docker-image || 'docker-image-unresolved!' }}
      env:
        TT_METAL_HOME: /work
        PYTHONPATH: /work
        LD_LIBRARY_PATH: /work/build/lib
        ARCH_NAME: ${{ matrix.test-info.arch }}
        LOGURU_LEVEL: INFO
        GITHUB_ACTIONS: true
      volumes:
        - ${{ github.workspace }}/docker-job:/work # Subdir to workaround https://github.com/actions/runner/issues/691
        - /dev/hugepages-1G:/dev/hugepages-1G
        - /mnt/MLPerf:/mnt/MLPerf:ro
      options: "--device /dev/tenstorrent -e TT_GH_CI_INFRA"
    defaults:
      run:
        shell: bash
        working-directory: /work # https://github.com/actions/runner/issues/878
    steps:
      - name: ⬇️  Setup Job
        uses: tenstorrent/tt-metal/.github/actions/setup-job@main
        timeout-minutes: 10
        with:
          build-artifact-name: ${{ inputs.build-artifact-name }}
          wheel-artifact-name: ${{ inputs.wheel-artifact-name }}
      - name: Run performance tests
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        env:
          HF_HUB_CACHE: ${{ matrix.test-info.arch != 'blackhole' && '/mnt/MLPerf/huggingface/hub' || '' }}
          SDXL_DATASET_PATH: ${{ contains(matrix.test-info.commands, 'stable_diffusion') && '/mnt/MLPerf/ttnn/datasets/COCO_val2014_headshots' || '' }}
        with:
          device_perf_model_name: ${{ matrix.test-info.device_perf_model_name }}
          commands: ${{ matrix.test-info.commands }}
        if: ${{ !cancelled() }}
        timeout-minutes: ${{ matrix.test-info.timeout }}

      - name: Merge test reports
        id: generate-device-perf-report
        if: ${{ !cancelled() }}
        timeout-minutes: ${{ matrix.test-info.timeout }}
        env:
          TRACY_NO_INVARIANT_CHECK: 1
        run: |
          CLEAN_NAME=$(echo "${{ matrix.test-info.name }}" | tr ' ' '-')
          export DEVICE_PERF_REPORT_FILENAME=Models_Device_Perf_${{ matrix.test-info.test-type }}_${CLEAN_NAME}_$(date +%Y_%m_%d).csv
          cat Models_Device_Perf_$(date +%Y_%m_%d).csv > Models_Device_Perf_${{ matrix.test-info.test-type }}_${CLEAN_NAME}_$(date +%Y_%m_%d).csv
          cat Models_Device_Perf_${{ matrix.test-info.test-type }}_${CLEAN_NAME}_$(date +%Y_%m_%d).csv
          python3 models/perf/merge_device_perf_results.py $DEVICE_PERF_REPORT_FILENAME CHECK
          echo "device_perf_report_filename=$DEVICE_PERF_REPORT_FILENAME" >> "$GITHUB_OUTPUT"

      - name: Check device perf report exists
        id: check-device-perf-report
        if: ${{ !cancelled() }}
        run: |
          test -f ${{ steps.generate-device-perf-report.outputs.device_perf_report_filename }}

      - name: Upload device perf report
        timeout-minutes: 5
        if: ${{ !cancelled() && steps.check-device-perf-report.conclusion == 'success' }}
        uses: actions/upload-artifact@v4
        with:
          name: device-perf-report-csv-${{ matrix.test-info.test-type }}-${{ matrix.test-info.arch }}-${{ matrix.test-info.machine-type }}-${{ matrix.test-info.name }}
          path: /work/${{ steps.generate-device-perf-report.outputs.device_perf_report_filename }}

      - uses: tenstorrent/tt-metal/.github/actions/upload-artifact-with-job-uuid@main
        timeout-minutes: 10
        if: ${{ !cancelled() }}
        with:
          prefix: "test_reports_"

      - uses: tenstorrent/tt-metal/.github/actions/cleanup@main
        if: always()
