name: "[internal] Single-card Device perf regressions impl"

on:
  workflow_call:
    inputs:
      os:
        required: false
        type: string
        default: "ubuntu-22.04"
      docker-image:
        required: true
        type: string
      build-artifact-name:
        required: true
        type: string
      wheel-artifact-name:
        required: true
        type: string

jobs:
  device-perf:
    strategy:
      # Do not fail-fast because we need to ensure all tests go to completion
      # so we try not to get hanging machines
      fail-fast: false
      matrix:
        test-info: [
          {name: "N300 WH B0 not yet ported", arch: wormhole_b0, runs-on: ["N300", "pipeline-perf", "bare-metal", "in-service"], machine-type: "bare_metal", civ2-compatible: false, timeout: 30, test-type: "device_perf"},
          {name: "N300 WH B0", arch: wormhole_b0, runs-on: ["tt-beta-ubuntu-2204-n300-large-stable"], machine-type: "CIv2", civ2-compatible: true, timeout: 120, test-type: "device_perf"},
        ]
    name: "${{ matrix.test-info.name }} device perf"
    runs-on: ${{ matrix.test-info.runs-on }}
    container:
      image: ${{ inputs.docker-image || 'docker-image-unresolved!' }}
      env:
        TT_METAL_HOME: /work
        PYTHONPATH: /work
        LD_LIBRARY_PATH: /work/build/lib
        ARCH_NAME: ${{ matrix.test-info.arch }}
        LOGURU_LEVEL: INFO
        GITHUB_ACTIONS: true
      volumes:
        - ${{ github.workspace }}/docker-job:/work # Subdir to workaround https://github.com/actions/runner/issues/691
        - /dev/hugepages-1G:/dev/hugepages-1G
        - /mnt/MLPerf:/mnt/MLPerf:ro
      options: "--device /dev/tenstorrent"
    defaults:
      run:
        shell: bash
        working-directory: /work # https://github.com/actions/runner/issues/878
    steps:
      - name: ⬇️  Setup Job
        uses: tenstorrent/tt-metal/.github/actions/setup-job@main
        timeout-minutes: 10
        with:
          build-artifact-name: ${{ inputs.build-artifact-name }}
          wheel-artifact-name: ${{ inputs.wheel-artifact-name }}
      - name: non-civ2 tests
        if: ${{ !cancelled() && !matrix.test-info.civ2-compatible }}
        timeout-minutes: ${{ matrix.test-info.timeout }}
        env:
          TRACY_NO_INVARIANT_CHECK: 1
        run: |
          set -x
          export MAGIC_ENV=wormhole_b0_80_arch_eth_dispatch.yaml
          echo "Running tests that are not yet ported to CIv2"
          pytest models/demos/convnet_mnist/tests/ -m models_device_performance_bare_metal
          pytest models/demos/mnist/tests -m models_device_performance_bare_metal
          WH_ARCH_YAML=$MAGIC_ENV pytest models/demos/falcon7b_common/tests -m models_device_performance_bare_metal
          WH_ARCH_YAML=$MAGIC_ENV pytest models/demos/segformer/tests -m models_device_performance_bare_metal

          export DEVICE_PERF_REPORT_FILENAME=Models_Device_Perf_${{ matrix.test-info.test-type }}_non-civ2_tests_$(date +%Y_%m_%d).csv
          python3 models/perf/merge_device_perf_results.py $DEVICE_PERF_REPORT_FILENAME non-civ2
          echo "device_perf_report_filename=$DEVICE_PERF_REPORT_FILENAME" >> "$GITHUB_OUTPUT"

      - name: yolov11 tests
        if: ${{ !cancelled() && matrix.test-info.civ2-compatible }}
        timeout-minutes: ${{ matrix.test-info.timeout }}
        env:
          TRACY_NO_INVARIANT_CHECK: 1
        run: |
          set -x
          export MAGIC_ENV=wormhole_b0_80_arch_eth_dispatch.yaml
          WH_ARCH_YAML=$MAGIC_ENV pytest models/demos/yolov11/tests -m models_device_performance_bare_metal
          # WH_ARCH_YAML=$MAGIC_ENV pytest models/experimental/yolov11/tests -m models_device_performance_bare_metal

          export DEVICE_PERF_REPORT_FILENAME=${{ matrix.test-info.test-type }}_yolov11_$(date +%Y_%m_%d).csv
          python3 models/perf/merge_device_perf_results.py $DEVICE_PERF_REPORT_FILENAME yolov11
          echo "device_perf_report_filename=$DEVICE_PERF_REPORT_FILENAME" >> "$GITHUB_OUTPUT"

      # - name: stable_diffusion tests
      #   if: ${{ !cancelled() && matrix.test-info.civ2-compatible }}
      #   timeout-minutes: ${{ matrix.test-info.timeout }}
      #   env:
      #     TRACY_NO_INVARIANT_CHECK: 1
      #   run: |
      #     set -x
      #     export MAGIC_ENV=wormhole_b0_80_arch_eth_dispatch.yaml
      #     pytest models/demos/wormhole/stable_diffusion/tests -m models_device_performance_bare_metal --timeout=600
      #     # WH_ARCH_YAML=$MAGIC_ENV pytest models/experimental/stable_diffusion_xl_base/tests/test_sdxl_perf.py -m models_device_performance_bare_metal

      #     export DEVICE_PERF_REPORT_FILENAME=Models_Device_Perf_${{ matrix.test-info.test-type }}_stable_diffusion_$(date +%Y_%m_%d).csv
      #     python3 models/perf/merge_device_perf_results.py $DEVICE_PERF_REPORT_FILENAME stable_diffusion
      #     echo "device_perf_report_filename=$DEVICE_PERF_REPORT_FILENAME" >> "$GITHUB_OUTPUT"
      
      # - name: distilbert tests
      #   if: ${{ !cancelled() && matrix.test-info.civ2-compatible }}
      #   timeout-minutes: ${{ matrix.test-info.timeout }}
      #   env:
      #     TRACY_NO_INVARIANT_CHECK: 1
      #   run: |
      #     set -x
      #     export MAGIC_ENV=wormhole_b0_80_arch_eth_dispatch.yaml
      #     pytest models/demos/distilbert/tests -m models_device_performance_bare_metal
      #     WH_ARCH_YAML=$MAGIC_ENV pytest models/demos/wormhole/distilbert/tests -m models_device_performance_bare_metal

      #     export DEVICE_PERF_REPORT_FILENAME=Models_Device_Perf_${{ matrix.test-info.test-type }}_distilbert_$(date +%Y_%m_%d).csv
      #     python3 models/perf/merge_device_perf_results.py $DEVICE_PERF_REPORT_FILENAME
      #     echo "device_perf_report_filename=$DEVICE_PERF_REPORT_FILENAME" >> "$GITHUB_OUTPUT"

      # - name: vgg & vgg_unet tests
      #   if: ${{ !cancelled() && matrix.test-info.civ2-compatible }}
      #   timeout-minutes: ${{ matrix.test-info.timeout }}
      #   env:
      #     TRACY_NO_INVARIANT_CHECK: 1
      #   run: |
      #     set -x
      #     export MAGIC_ENV=wormhole_b0_80_arch_eth_dispatch.yaml
      #     pytest models/demos/vgg/tests/ -m models_device_performance_bare_metal
      #     # WH_ARCH_YAML=$MAGIC_ENV pytest models/demos/vgg_unet/tests -m models_device_performance_bare_metal

      #     export DEVICE_PERF_REPORT_FILENAME=Models_Device_Perf_${{ matrix.test-info.test-type }}_vgg_$(date +%Y_%m_%d).csv
      #     python3 models/perf/merge_device_perf_results.py $DEVICE_PERF_REPORT_FILENAME
      #     echo "device_perf_report_filename=$DEVICE_PERF_REPORT_FILENAME" >> "$GITHUB_OUTPUT"

      # - name: bert_tiny tests
      #   if: ${{ !cancelled() && matrix.test-info.civ2-compatible }}
      #   timeout-minutes: ${{ matrix.test-info.timeout }}
      #   env:
      #     TRACY_NO_INVARIANT_CHECK: 1
      #   run: |
      #     set -x
      #     export MAGIC_ENV=wormhole_b0_80_arch_eth_dispatch.yaml
      #     pytest models/demos/bert_tiny/tests/ -m models_device_performance_bare_metal
      #     WH_ARCH_YAML=$MAGIC_ENV pytest models/demos/wormhole/bert_tiny/tests -m models_device_performance_bare_metal

      #     export DEVICE_PERF_REPORT_FILENAME=Models_Device_Perf_${{ matrix.test-info.test-type }}_bert_tiny_$(date +%Y_%m_%d).csv
      #     python3 models/perf/merge_device_perf_results.py $DEVICE_PERF_REPORT_FILENAME
      #     echo "device_perf_report_filename=$DEVICE_PERF_REPORT_FILENAME" >> "$GITHUB_OUTPUT"

      # - name: squeezebert tests
      #   if: ${{ !cancelled() && matrix.test-info.civ2-compatible }}
      #   timeout-minutes: ${{ matrix.test-info.timeout }}
      #   env:
      #     TRACY_NO_INVARIANT_CHECK: 1
      #   run: |
      #     set -x
      #     export MAGIC_ENV=wormhole_b0_80_arch_eth_dispatch.yaml
      #     pytest models/demos/squeezebert/tests -m models_device_performance_bare_metal

      #     export DEVICE_PERF_REPORT_FILENAME=Models_Device_Perf_${{ matrix.test-info.test-type }}_squeezebert_$(date +%Y_%m_%d).csv
      #     python3 models/perf/merge_device_perf_results.py $DEVICE_PERF_REPORT_FILENAME
      #     echo "device_perf_report_filename=$DEVICE_PERF_REPORT_FILENAME" >> "$GITHUB_OUTPUT"

      # - name: roberta tests
      #   if: ${{ !cancelled() && matrix.test-info.civ2-compatible }}
      #   timeout-minutes: ${{ matrix.test-info.timeout }}
      #   env:
      #     TRACY_NO_INVARIANT_CHECK: 1
      #   run: |
      #     set -x
      #     export MAGIC_ENV=wormhole_b0_80_arch_eth_dispatch.yaml
      #     pytest models/demos/roberta/tests/ -m models_device_performance_bare_metal

      #     export DEVICE_PERF_REPORT_FILENAME=Models_Device_Perf_${{ matrix.test-info.test-type }}_roberta_$(date +%Y_%m_%d).csv
      #     python3 models/perf/merge_device_perf_results.py $DEVICE_PERF_REPORT_FILENAME
      #     echo "device_perf_report_filename=$DEVICE_PERF_REPORT_FILENAME" >> "$GITHUB_OUTPUT"

      # - name: resnet50 tests
      #   if: ${{ !cancelled() && matrix.test-info.civ2-compatible }}
      #   timeout-minutes: ${{ matrix.test-info.timeout }}
      #   env:
      #     TRACY_NO_INVARIANT_CHECK: 1
      #   run: |
      #     set -x
      #     export MAGIC_ENV=wormhole_b0_80_arch_eth_dispatch.yaml
      #     WH_ARCH_YAML=$MAGIC_ENV pytest models/demos/wormhole/resnet50/tests -m models_device_performance_bare_metal

      #     export DEVICE_PERF_REPORT_FILENAME=Models_Device_Perf_${{ matrix.test-info.test-type }}_resnet50_$(date +%Y_%m_%d).csv
      #     python3 models/perf/merge_device_perf_results.py $DEVICE_PERF_REPORT_FILENAME
      #     echo "device_perf_report_filename=$DEVICE_PERF_REPORT_FILENAME" >> "$GITHUB_OUTPUT"

      # - name: ufld_v2 tests
      #   if: ${{ !cancelled() && matrix.test-info.civ2-compatible }}
      #   timeout-minutes: ${{ matrix.test-info.timeout }}
      #   env:
      #     TRACY_NO_INVARIANT_CHECK: 1
      #   run: |
      #     set -x
      #     export MAGIC_ENV=wormhole_b0_80_arch_eth_dispatch.yaml
      #     WH_ARCH_YAML=$MAGIC_ENV pytest models/demos/ufld_v2/tests -m models_device_performance_bare_metal

      #     export DEVICE_PERF_REPORT_FILENAME=Models_Device_Perf_${{ matrix.test-info.test-type }}_ufld_v2_$(date +%Y_%m_%d).csv
      #     python3 models/perf/merge_device_perf_results.py $DEVICE_PERF_REPORT_FILENAME
      #     echo "device_perf_report_filename=$DEVICE_PERF_REPORT_FILENAME" >> "$GITHUB_OUTPUT"

      # - name: sentence_bert tests
      #   if: ${{ !cancelled() && matrix.test-info.civ2-compatible }}
      #   timeout-minutes: ${{ matrix.test-info.timeout }}
      #   env:
      #     TRACY_NO_INVARIANT_CHECK: 1
      #   run: |
      #     set -x
      #     export MAGIC_ENV=wormhole_b0_80_arch_eth_dispatch.yaml
      #     # WH_ARCH_YAML=$MAGIC_ENV pytest models/demos/sentence_bert/tests -m models_device_performance_bare_metal

      #     export DEVICE_PERF_REPORT_FILENAME=Models_Device_Perf_${{ matrix.test-info.test-type }}_sentence_bert_$(date +%Y_%m_%d).csv
      #     python3 models/perf/merge_device_perf_results.py $DEVICE_PERF_REPORT_FILENAME
      #     echo "device_perf_report_filename=$DEVICE_PERF_REPORT_FILENAME" >> "$GITHUB_OUTPUT"

      # - name: functional_unet tests
      #   if: ${{ !cancelled() && matrix.test-info.civ2-compatible }}
      #   timeout-minutes: ${{ matrix.test-info.timeout }}
      #   env:
      #     TRACY_NO_INVARIANT_CHECK: 1
      #   run: |
      #     set -x
      #     export MAGIC_ENV=wormhole_b0_80_arch_eth_dispatch.yaml
      #     WH_ARCH_YAML=$MAGIC_ENV pytest models/experimental/functional_unet/tests/test_unet_perf.py -m models_device_performance_bare_metal

      #     export DEVICE_PERF_REPORT_FILENAME=Models_Device_Perf_${{ matrix.test-info.test-type }}_functional_unet_$(date +%Y_%m_%d).csv
      #     python3 models/perf/merge_device_perf_results.py $DEVICE_PERF_REPORT_FILENAME
      #     echo "device_perf_report_filename=$DEVICE_PERF_REPORT_FILENAME" >> "$GITHUB_OUTPUT"

      # - name: mamba tests
      #   if: ${{ !cancelled() && matrix.test-info.civ2-compatible }}
      #   timeout-minutes: ${{ matrix.test-info.timeout }}
      #   env:
      #     TRACY_NO_INVARIANT_CHECK: 1
      #   run: |
      #     set -x
      #     export MAGIC_ENV=wormhole_b0_80_arch_eth_dispatch.yaml
      #     WH_ARCH_YAML=$MAGIC_ENV pytest models/demos/wormhole/mamba/tests -m models_device_performance_bare_metal

      #     export DEVICE_PERF_REPORT_FILENAME=Models_Device_Perf_${{ matrix.test-info.test-type }}_mamba_$(date +%Y_%m_%d).csv
      #     python3 models/perf/merge_device_perf_results.py $DEVICE_PERF_REPORT_FILENAME
      #     echo "device_perf_report_filename=$DEVICE_PERF_REPORT_FILENAME" >> "$GITHUB_OUTPUT"

      # - name: metal_BERT_large_11 tests
      #   if: ${{ !cancelled() && matrix.test-info.civ2-compatible }}
      #   timeout-minutes: ${{ matrix.test-info.timeout }}
      #   env:
      #     TRACY_NO_INVARIANT_CHECK: 1
      #   run: |
      #     set -x
      #     export MAGIC_ENV=wormhole_b0_80_arch_eth_dispatch.yaml
      #     WH_ARCH_YAML=$MAGIC_ENV pytest models/demos/metal_BERT_large_11/tests -m models_device_performance_bare_metal

      #     export DEVICE_PERF_REPORT_FILENAME=Models_Device_Perf_${{ matrix.test-info.test-type }}_metal_BERT_large_11_$(date +%Y_%m_%d).csv
      #     python3 models/perf/merge_device_perf_results.py $DEVICE_PERF_REPORT_FILENAME
      #     echo "device_perf_report_filename=$DEVICE_PERF_REPORT_FILENAME" >> "$GITHUB_OUTPUT"

      # - name: yolov4 tests
      #   if: ${{ !cancelled() && matrix.test-info.civ2-compatible }}
      #   timeout-minutes: ${{ matrix.test-info.timeout }}
      #   env:
      #     TRACY_NO_INVARIANT_CHECK: 1
      #   run: |
      #     set -x
      #     export MAGIC_ENV=wormhole_b0_80_arch_eth_dispatch.yaml
      #     WH_ARCH_YAML=$MAGIC_ENV pytest models/demos/yolov4/tests -m models_device_performance_bare_metal

      #     export DEVICE_PERF_REPORT_FILENAME=Models_Device_Perf_${{ matrix.test-info.test-type }}_yolov4_$(date +%Y_%m_%d).csv
      #     python3 models/perf/merge_device_perf_results.py $DEVICE_PERF_REPORT_FILENAME
      #     echo "device_perf_report_filename=$DEVICE_PERF_REPORT_FILENAME" >> "$GITHUB_OUTPUT"

      - name: mobilenetv2 tests
        if: ${{ !cancelled() && matrix.test-info.civ2-compatible }}
        timeout-minutes: ${{ matrix.test-info.timeout }}
        env:
          TRACY_NO_INVARIANT_CHECK: 1
        run: |
          set -x
          export MAGIC_ENV=wormhole_b0_80_arch_eth_dispatch.yaml
          # issue 24652: https://github.com/tenstorrent/tt-metal/issues/24652
          # WH_ARCH_YAML=$MAGIC_ENV pytest models/demos/mobilenetv2/tests -m models_device_performance_bare_metal

          export DEVICE_PERF_REPORT_FILENAME=Models_Device_Perf_${{ matrix.test-info.test-type }}_mobilenetv2_$(date +%Y_%m_%d).csv
          python3 models/perf/merge_device_perf_results.py $DEVICE_PERF_REPORT_FILENAME mobilenetv2
          echo "device_perf_report_filename=$DEVICE_PERF_REPORT_FILENAME" >> "$GITHUB_OUTPUT"

      - name: yolov8x tests
        if: ${{ !cancelled() && matrix.test-info.civ2-compatible }}
        timeout-minutes: ${{ matrix.test-info.timeout }}
        env:
          TRACY_NO_INVARIANT_CHECK: 1
        run: |
          set -x
          export MAGIC_ENV=wormhole_b0_80_arch_eth_dispatch.yaml
          # WH_ARCH_YAML=$MAGIC_ENV pytest models/demos/yolov8x/tests -m models_device_performance_bare_metal

          export DEVICE_PERF_REPORT_FILENAME=Models_Device_Perf_${{ matrix.test-info.test-type }}_yolov8x_$(date +%Y_%m_%d).csv
          python3 models/perf/merge_device_perf_results.py $DEVICE_PERF_REPORT_FILENAME yolov8x
          echo "device_perf_report_filename=$DEVICE_PERF_REPORT_FILENAME" >> "$GITHUB_OUTPUT"

      - name: yolov8s & yolov8s_world tests
        if: ${{ !cancelled() && matrix.test-info.civ2-compatible }}
        timeout-minutes: ${{ matrix.test-info.timeout }}
        env:
          TRACY_NO_INVARIANT_CHECK: 1
        run: |
          set -x
          export MAGIC_ENV=wormhole_b0_80_arch_eth_dispatch.yaml
          # WH_ARCH_YAML=$MAGIC_ENV pytest models/experimental/yolov8s/tests -m models_device_performance_bare_metal
          # WH_ARCH_YAML=$MAGIC_ENV pytest models/demos/yolov8s_world/tests -m models_device_performance_bare_metal

          export DEVICE_PERF_REPORT_FILENAME=Models_Device_Perf_${{ matrix.test-info.test-type }}_yolov8s_$(date +%Y_%m_%d).csv
          python3 models/perf/merge_device_perf_results.py $DEVICE_PERF_REPORT_FILENAME yolov8s
          echo "device_perf_report_filename=$DEVICE_PERF_REPORT_FILENAME" >> "$GITHUB_OUTPUT"

      - name: vanilla_unet tests
        if: ${{ !cancelled() && matrix.test-info.civ2-compatible }}
        timeout-minutes: ${{ matrix.test-info.timeout }}
        env:
          TRACY_NO_INVARIANT_CHECK: 1
        run: |
          set -x
          export MAGIC_ENV=wormhole_b0_80_arch_eth_dispatch.yaml
          WH_ARCH_YAML=$MAGIC_ENV pytest models/experimental/vanilla_unet/test -m models_device_performance_bare_metal

          export DEVICE_PERF_REPORT_FILENAME=Models_Device_Perf_${{ matrix.test-info.test-type }}_vanilla_unet_$(date +%Y_%m_%d).csv
          python3 models/perf/merge_device_perf_results.py $DEVICE_PERF_REPORT_FILENAME vanilla_unet
          echo "device_perf_report_filename=$DEVICE_PERF_REPORT_FILENAME" >> "$GITHUB_OUTPUT"

      - name: yolov10 tests
        if: ${{ !cancelled() && matrix.test-info.civ2-compatible }}
        timeout-minutes: ${{ matrix.test-info.timeout }}
        env:
          TRACY_NO_INVARIANT_CHECK: 1
        run: |
          set -x
          export MAGIC_ENV=wormhole_b0_80_arch_eth_dispatch.yaml
          # WH_ARCH_YAML=$MAGIC_ENV pytest models/experimental/yolov10/tests -m models_device_performance_bare_metal

          export DEVICE_PERF_REPORT_FILENAME=Models_Device_Perf_${{ matrix.test-info.test-type }}_yolov10_$(date +%Y_%m_%d).csv
          python3 models/perf/merge_device_perf_results.py $DEVICE_PERF_REPORT_FILENAME yolov10
          echo "device_perf_report_filename=$DEVICE_PERF_REPORT_FILENAME" >> "$GITHUB_OUTPUT"

      - name: yolov7 tests
        if: ${{ !cancelled() && matrix.test-info.civ2-compatible }}
        timeout-minutes: ${{ matrix.test-info.timeout }}
        env:
          TRACY_NO_INVARIANT_CHECK: 1
        run: |
          set -x
          export MAGIC_ENV=wormhole_b0_80_arch_eth_dispatch.yaml
          # WH_ARCH_YAML=$MAGIC_ENV pytest models/demos/yolov7/tests/perf/test_perf.py -m models_device_performance_bare_metal

          export DEVICE_PERF_REPORT_FILENAME=Models_Device_Perf_${{ matrix.test-info.test-type }}_yolov7_$(date +%Y_%m_%d).csv
          python3 models/perf/merge_device_perf_results.py $DEVICE_PERF_REPORT_FILENAME yolov7
          echo "device_perf_report_filename=$DEVICE_PERF_REPORT_FILENAME" >> "$GITHUB_OUTPUT"

      - name: vit tests
        if: ${{ !cancelled() && matrix.test-info.civ2-compatible }}
        timeout-minutes: ${{ matrix.test-info.timeout }}
        env:
          TRACY_NO_INVARIANT_CHECK: 1
        run: |
          set -x
          export MAGIC_ENV=wormhole_b0_80_arch_eth_dispatch.yaml
          WH_ARCH_YAML=$MAGIC_ENV pytest models/demos/wormhole/vit/demo/test_vit_device_perf.py -m models_device_performance_bare_metal

          export DEVICE_PERF_REPORT_FILENAME=Models_Device_Perf_${{ matrix.test-info.test-type }}_vit_$(date +%Y_%m_%d).csv
          python3 models/perf/merge_device_perf_results.py $DEVICE_PERF_REPORT_FILENAME vit
          echo "device_perf_report_filename=$DEVICE_PERF_REPORT_FILENAME" >> "$GITHUB_OUTPUT"

      - name: yolov6l tests
        if: ${{ !cancelled() && matrix.test-info.civ2-compatible }}
        timeout-minutes: ${{ matrix.test-info.timeout }}
        env:
          TRACY_NO_INVARIANT_CHECK: 1
        run: |
          set -x
          export MAGIC_ENV=wormhole_b0_80_arch_eth_dispatch.yaml
          WH_ARCH_YAML=$MAGIC_ENV pytest models/experimental/yolov6l/tests -m models_device_performance_bare_metal

          export DEVICE_PERF_REPORT_FILENAME=${{ matrix.test-info.test-type }}_yolov6l_$(date +%Y_%m_%d).csv
          python3 models/perf/merge_device_perf_results.py $DEVICE_PERF_REPORT_FILENAME yolov6l
          echo "device_perf_report_filename=$DEVICE_PERF_REPORT_FILENAME" >> "$GITHUB_OUTPUT"

      - name: Merge test reports
        id: generate-device-perf-report
        timeout-minutes: ${{ matrix.test-info.timeout }}
        env:
          TRACY_NO_INVARIANT_CHECK: 1
        run: |
          export DEVICE_PERF_REPORT_FILENAME=Models_Device_Perf_${{ matrix.test-info.test-type }}_$(date +%Y_%m_%d).csv
          python3 models/perf/merge_device_perf_results.py $DEVICE_PERF_REPORT_FILENAME
          echo "device_perf_report_filename=$DEVICE_PERF_REPORT_FILENAME" >> "$GITHUB_OUTPUT"

      - name: Check device perf report exists
        id: check-device-perf-report
        if: ${{ !cancelled() }}
        run: |
          ls -hal ${{ steps.generate-device-perf-report.outputs.device_perf_report_filename }}

      - name: Upload device perf report
        timeout-minutes: 5
        if: ${{ !cancelled() && steps.check-device-perf-report.conclusion == 'success' }}
        uses: actions/upload-artifact@v4
        with:
          name: device-perf-report-csv-${{ matrix.test-info.test-type }}-${{ matrix.test-info.arch }}-${{ matrix.test-info.machine-type }}
          path: /work/${{ steps.generate-device-perf-report.outputs.device_perf_report_filename }}

      - uses: tenstorrent/tt-metal/.github/actions/upload-artifact-with-job-uuid@main
        timeout-minutes: 10
        if: ${{ !cancelled() }}
        with:
          prefix: "test_reports_"

      - uses: tenstorrent/tt-metal/.github/actions/cleanup@main
        if: always()
