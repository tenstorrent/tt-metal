name: "[internal] Single-card Device perf regressions impl"

on:
  workflow_call:
    inputs:
      os:
        required: false
        type: string
        default: "ubuntu-22.04"
      docker-image:
        required: true
        type: string
      build-artifact-name:
        required: true
        type: string
      wheel-artifact-name:
        required: true
        type: string
      extra-tag:
        required: false
        type: string
        default: "in-service"
      requested-models:
        default: "all"
        type: string

jobs:
  define-models:
    runs-on: ubuntu-latest
    outputs:
      models-to-run: ${{ steps.compute-models.outputs.models-to-run }}
    steps:
      - name: Compute models to run
        id: compute-models
        run: |
          set -euo pipefail

          requested_models='${{ inputs.requested-models }}'
          echo "[info] requested-models: $requested_models"

          # Initialize models JSON with all false
          models_json='{
            "stable-diffusion-xl": false,
            "stable-diffusion-1-4": false,
            "distilbert": false,
            "vgg": false,
            "vgg-unet": false,
            "bert-tiny": false,
            "squeezebert": false,
            "resnet50": false,
            "ufld-v2": false,
            "sentence-bert": false,
            "functional-unet": false,
            "mamba": false,
            "metal-bert-large-11": false,
            "mobilenetv2": false,
            "vit": false,
            "vanilla-unet": false,
            "swin-v2": false,
            "swin-s": false,
            "vovnet": false,
            "efficientnetb0": false,
            "oft": false,
            "panoptic-deeplab": false,
            "non-civ2": false
          }'

          if [[ "$requested_models" == "all" ]]; then
            echo "[info] Running all models"
            models_json=$(echo "$models_json" | jq 'with_entries(.value = true)')
          else
            echo "[info] Processing specific model requests"
            models_json=$(echo "$requested_models" | jq --argjson models "$models_json" '
              reduce .[] as $req ($models;
                if has($req) then
                  .[$req] = true
                else
                  .
                end
              )')
          fi

          echo "[info] Final models selection:"
          echo "$models_json" | jq .

          # Output the JSON (compact format for GitHub Actions)
          echo "models-to-run=$(echo "$models_json" | jq -c .)" >> "$GITHUB_OUTPUT"

  generate-matrix:
    needs: define-models
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.generate-matrix.outputs.matrix }}
    steps:
      - name: Generate filtered matrix
        id: generate-matrix
        run: |
          set -euo pipefail

          models_json='${{ needs.define-models.outputs.models-to-run }}'
          echo "[info] Models to run: $models_json"

          # Define which models belong to each matrix group
          group_models='{
            "N300 WH B0 not yet ported": ["non-civ2"],
            "N300 WH B0 Set 1": ["stable-diffusion-xl", "stable-diffusion-1-4", "distilbert", "vgg", "bert-tiny", "squeezebert", "vgg-unet", "resnet50", "ufld-v2", "sentence-bert", "functional-unet", "vit"],
            "N300 WH B0 Set 2": ["mamba", "metal-bert-large-11", "mobilenetv2", "vanilla-unet", "swin-v2", "swin-s", "vovnet", "efficientnetb0"],
            "P150 BH": ["stable-diffusion-1-4", "vgg-unet", "resnet50", "ufld-v2", "sentence-bert", "functional-unet", "vit", "oft", "panoptic-deeplab"]
          }'

          # Original matrix definition
          original_matrix='[
            {"name": "N300 WH B0 not yet ported", "arch": "wormhole_b0", "runs-on": ["N300", "pipeline-perf", "bare-metal", "${{ inputs.extra-tag }}"], "machine-type": "bare_metal", "civ2-compatible": false, "timeout": 30, "job-set1": false},
            {"name": "N300 WH B0 Set 1", "arch": "wormhole_b0", "runs-on": ["tt-ubuntu-2204-n300-stable"], "machine-type": "CIv2", "civ2-compatible": true, "timeout": 120, "job-set1": true},
            {"name": "N300 WH B0 Set 2", "arch": "wormhole_b0", "runs-on": ["tt-ubuntu-2204-n300-stable"], "machine-type": "CIv2", "civ2-compatible": true, "timeout": 120, "job-set1": false},
            {"name": "P150 BH", "arch": "blackhole", "runs-on": ["tt-ubuntu-2204-p150b-stable"], "machine-type": "CIv2", "civ2-compatible": true, "timeout": 120, "job-blackhole-set1": true}
          ]'

          # Filter matrix based on selected models
          filtered_matrix=$(echo "$original_matrix" | jq --argjson models "$models_json" --argjson groups "$group_models" '[
            .[] | select(
              ($groups[.name] | map($models[.] // false) | any)
            )
          ]')

          echo "[info] Filtered matrix:"
          echo "$filtered_matrix" | jq .

          # Check if matrix is empty
          matrix_length=$(echo "$filtered_matrix" | jq 'length')
          echo "[info] Matrix length: $matrix_length"

          if [ "$matrix_length" -eq 0 ]; then
            echo "[warning] No matrix entries selected - using empty matrix"
            filtered_matrix='[]'
          fi

          # Output the filtered matrix
          echo "matrix={\"test-info\": $(echo "$filtered_matrix" | jq -c .)}" >> "$GITHUB_OUTPUT"

  device-perf:
    needs: [define-models, generate-matrix]
    if: ${{ fromJSON(needs.generate-matrix.outputs.matrix).test-info != '[]' && fromJSON(needs.generate-matrix.outputs.matrix).test-info != null }}
    strategy:
      # Do not fail-fast because we need to ensure all tests go to completion
      # so we try not to get hanging machines
      fail-fast: false
      matrix: ${{ fromJSON(needs.generate-matrix.outputs.matrix) }}
    name: "${{ matrix.test-info.name }} device perf"
    runs-on: ${{ matrix.test-info.runs-on }}
    container:
      image: ${{ inputs.docker-image || 'docker-image-unresolved!' }}
      env:
        TT_METAL_HOME: /work
        PYTHONPATH: /work
        LD_LIBRARY_PATH: /work/build/lib
        ARCH_NAME: ${{ matrix.test-info.arch }}
        LOGURU_LEVEL: INFO
        GITHUB_ACTIONS: true
      volumes:
        - ${{ github.workspace }}/docker-job:/work # Subdir to workaround https://github.com/actions/runner/issues/691
        - /dev/hugepages-1G:/dev/hugepages-1G
        - /mnt/MLPerf:/mnt/MLPerf:ro
      options: "--device /dev/tenstorrent -e TT_GH_CI_INFRA"
    defaults:
      run:
        shell: bash
        working-directory: /work # https://github.com/actions/runner/issues/878
    steps:
      - name: ðŸ§¬ Checkout Repository
        uses: actions/checkout@v4
        with:
          submodules: recursive
          path: docker-job
      - name: â¬‡ï¸  Setup Job
        uses: ./docker-job/.github/actions/setup-job
        timeout-minutes: 10
        with:
          build-artifact-name: ${{ inputs.build-artifact-name }}
          wheel-artifact-name: ${{ inputs.wheel-artifact-name }}
      - name: non-civ2 tests
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        env:
          HF_HUB_CACHE: /mnt/MLPerf/huggingface/hub
        with:
          device_perf_model_name: "non-civ2_tests"
          commands: |
            pytest models/demos/mnist/tests -m models_device_performance_bare_metal
            pytest models/demos/falcon7b_common/tests -m models_device_performance_bare_metal
            pytest models/demos/segformer/tests/perf -m models_device_performance_bare_metal
        if: ${{ !cancelled() && !matrix.test-info.civ2-compatible && fromJSON(needs.define-models.outputs.models-to-run)['non-civ2'] }}
        timeout-minutes: ${{ matrix.test-info.timeout }}

      - name: stable_diffusion_xl tests
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          device_perf_model_name: "stable_diffusion_xl"
          commands: |
            ${{ matrix.test-info.arch == 'wormhole_b0' && 'pytest models/experimental/stable_diffusion_xl_base/tests/test_sdxl_perf.py -m models_device_performance_bare_metal' || '' }}
        if: ${{ !cancelled() && matrix.test-info.civ2-compatible && (matrix.test-info.job-set1 || matrix.test-info.job-blackhole-set1) && fromJSON(needs.define-models.outputs.models-to-run)['stable-diffusion-xl'] }}
        timeout-minutes: ${{ matrix.test-info.timeout }}

      - name: stable_diffusion_1_4 tests
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          device_perf_model_name: "stable_diffusion_1_4"
          commands: |
            pytest models/demos/${{ matrix.test-info.arch == 'blackhole' && 'blackhole' || 'wormhole' }}/stable_diffusion/tests -m models_device_performance_bare_metal --timeout=600
        if: ${{ !cancelled() && matrix.test-info.civ2-compatible && (matrix.test-info.job-set1 || matrix.test-info.job-blackhole-set1) && fromJSON(needs.define-models.outputs.models-to-run)['stable-diffusion-1-4'] }}
        timeout-minutes: ${{ matrix.test-info.timeout }}

      - name: distilbert tests
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          device_perf_model_name: "distilbert"
          commands: |
            pytest models/demos/distilbert/tests -m models_device_performance_bare_metal
            pytest models/demos/wormhole/distilbert/tests -m models_device_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.civ2-compatible && matrix.test-info.job-set1 && fromJSON(needs.define-models.outputs.models-to-run)['distilbert'] }}
        timeout-minutes: ${{ matrix.test-info.timeout }}

      - name: vgg tests
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          device_perf_model_name: "vgg"
          commands: |
            pytest models/demos/vgg/tests/ -m models_device_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.civ2-compatible && matrix.test-info.job-set1 && fromJSON(needs.define-models.outputs.models-to-run)['vgg'] }}
        timeout-minutes: ${{ matrix.test-info.timeout }}

      - name: vgg_unet tests
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          device_perf_model_name: "vgg_unet"
          commands: |
            pytest models/demos/${{ matrix.test-info.arch == 'blackhole' && 'blackhole' || 'wormhole' }}/vgg_unet/tests/perf -m models_device_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.civ2-compatible && (matrix.test-info.job-set1 || matrix.test-info.job-blackhole-set1) && fromJSON(needs.define-models.outputs.models-to-run)['vgg-unet'] }}
        timeout-minutes: ${{ matrix.test-info.timeout }}

      - name: bert_tiny tests
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          device_perf_model_name: "bert_tiny"
          commands: |
            pytest models/demos/bert_tiny/tests/ -m models_device_performance_bare_metal
            pytest models/demos/wormhole/bert_tiny/tests -m models_device_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.civ2-compatible && matrix.test-info.job-set1 && fromJSON(needs.define-models.outputs.models-to-run)['bert-tiny'] }}
        timeout-minutes: ${{ matrix.test-info.timeout }}

      - name: squeezebert tests
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          device_perf_model_name: "squeezebert"
          commands: |
            pytest models/demos/squeezebert/tests -m models_device_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.civ2-compatible && matrix.test-info.job-set1 && fromJSON(needs.define-models.outputs.models-to-run)['squeezebert'] }}
        timeout-minutes: ${{ matrix.test-info.timeout }}


      - name: resnet50 tests
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          device_perf_model_name: "resnet50"
          commands: |
            pytest models/demos/${{ matrix.test-info.arch == 'blackhole' && 'blackhole' || 'wormhole' }}/resnet50/tests -m models_device_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.civ2-compatible && (matrix.test-info.job-set1 || matrix.test-info.job-blackhole-set1) && fromJSON(needs.define-models.outputs.models-to-run)['resnet50'] }}
        timeout-minutes: ${{ matrix.test-info.timeout }}

      - name: ufld_v2 tests
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          device_perf_model_name: "ufld_v2"
          commands: |
            pytest models/demos/${{ matrix.test-info.arch == 'blackhole' && 'blackhole' || 'wormhole' }}/ufld_v2/tests/perf -m models_device_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.civ2-compatible && (matrix.test-info.job-set1 || matrix.test-info.job-blackhole-set1) && fromJSON(needs.define-models.outputs.models-to-run)['ufld-v2'] }}
        timeout-minutes: ${{ matrix.test-info.timeout }}

      - name: sentence_bert tests
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          device_perf_model_name: "sentence_bert"
          commands: |
            pytest models/demos/${{ matrix.test-info.arch == 'blackhole' && 'blackhole' || 'wormhole' }}/sentence_bert/tests/perf -m models_device_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.civ2-compatible && (matrix.test-info.job-set1 || matrix.test-info.job-blackhole-set1) && fromJSON(needs.define-models.outputs.models-to-run)['sentence-bert'] }}
        timeout-minutes: ${{ matrix.test-info.timeout }}

      - name: functional_unet tests
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          device_perf_model_name: "functional_unet"
          commands: |
            pytest models/experimental/functional_unet/tests/test_unet_perf.py -m models_device_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.civ2-compatible && (matrix.test-info.job-set1 || matrix.test-info.job-blackhole-set1) && fromJSON(needs.define-models.outputs.models-to-run)['functional-unet'] }}
        timeout-minutes: ${{ matrix.test-info.timeout }}

      - name: mamba tests
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          device_perf_model_name: "mamba"
          commands: |
            pytest models/demos/wormhole/mamba/tests -m models_device_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.civ2-compatible && !matrix.test-info.job-set1 && !matrix.test-info.job-blackhole-set1 && fromJSON(needs.define-models.outputs.models-to-run)['mamba'] }}
        timeout-minutes: ${{ matrix.test-info.timeout }}

      - name: metal_BERT_large_11 tests
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          device_perf_model_name: "metal_BERT_large_11"
          commands: |
            # pytest models/demos/metal_BERT_large_11/tests -m models_device_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.civ2-compatible && !matrix.test-info.job-set1 && !matrix.test-info.job-blackhole-set1 && fromJSON(needs.define-models.outputs.models-to-run)['metal-bert-large-11'] }}
        timeout-minutes: ${{ matrix.test-info.timeout }}

      - name: mobilenetv2 tests
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          device_perf_model_name: "mobilenetv2"
          commands: |
            pytest models/demos/mobilenetv2/tests/perf -m models_device_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.civ2-compatible && !matrix.test-info.job-set1 && !matrix.test-info.job-blackhole-set1 && fromJSON(needs.define-models.outputs.models-to-run)['mobilenetv2'] }}
        timeout-minutes: ${{ matrix.test-info.timeout }}

      - name: vit tests
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          device_perf_model_name: "vit"
          commands: |
            pytest models/demos/${{ matrix.test-info.arch == 'blackhole' && 'blackhole' || 'wormhole' }}/vit/tests/ -m models_device_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.civ2-compatible && (matrix.test-info.job-set1 || matrix.test-info.job-blackhole-set1) && fromJSON(needs.define-models.outputs.models-to-run)['vit'] }}
        timeout-minutes: ${{ matrix.test-info.timeout }}

      - name: vanilla_unet tests
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          device_perf_model_name: "vanilla_unet"
          commands: |
            pytest models/demos/vanilla_unet/tests -m models_device_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.civ2-compatible && !matrix.test-info.job-set1 && !matrix.test-info.job-blackhole-set1 && fromJSON(needs.define-models.outputs.models-to-run)['vanilla-unet'] }}
        timeout-minutes: ${{ matrix.test-info.timeout }}

      - name: swin_v2 tests
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          device_perf_model_name: "swin_v2"
          commands: |
            pytest models/experimental/swin_v2/tests/perf -m models_device_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.civ2-compatible && !matrix.test-info.job-set1 && !matrix.test-info.job-blackhole-set1 && fromJSON(needs.define-models.outputs.models-to-run)['swin-v2'] }}
        timeout-minutes: ${{ matrix.test-info.timeout }}

      - name: swin_s tests
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          device_perf_model_name: "swin_s"
          commands: |
            pytest models/experimental/swin_s/tests/perf -m models_device_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.civ2-compatible && !matrix.test-info.job-set1 && !matrix.test-info.job-blackhole-set1 && fromJSON(needs.define-models.outputs.models-to-run)['swin-s'] }}
        timeout-minutes: ${{ matrix.test-info.timeout }}

      - name: vovnet tests
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          device_perf_model_name: "VoVNet"
          commands: |
            pytest models/experimental/vovnet/tests/perf -m models_device_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.civ2-compatible && !matrix.test-info.job-set1 && !matrix.test-info.job-blackhole-set1 && fromJSON(needs.define-models.outputs.models-to-run)['vovnet'] }}
        timeout-minutes: ${{ matrix.test-info.timeout }}

      - name: efficientnetb0 tests
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          device_perf_model_name: "efficientnetb0"
          commands: |
            pytest models/experimental/efficientnetb0/tests/perf -m models_device_performance_bare_metal
        if: ${{ !cancelled() && matrix.test-info.civ2-compatible && !matrix.test-info.job-set1 && !matrix.test-info.job-blackhole-set1 && fromJSON(needs.define-models.outputs.models-to-run)['efficientnetb0'] }}
        timeout-minutes: ${{ matrix.test-info.timeout }}

      - name: oft tests
        env:
          TT_METAL_CORE_GRID_OVERRIDE_TODEPRECATE: "4,3"
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          device_perf_model_name: "oft"
          commands: |
            pytest models/experimental/oft/tests/test_device_perf_oft.py -m models_device_performance_bare_metal --timeout=600
        if: ${{ !cancelled() && matrix.test-info.civ2-compatible &&  matrix.test-info.job-blackhole-set1 && fromJSON(needs.define-models.outputs.models-to-run)['oft'] }}

      - name: panoptic_deeplab tests (20 cores)
        env:
          TT_METAL_CORE_GRID_OVERRIDE_TODEPRECATE: "4,3"
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          device_perf_model_name: "panoptic_deeplab_20_cores"
          commands: |
            pytest models/experimental/panoptic_deeplab/tests/test_device_perf_pdl.py::test_device_perf_pdl_20_cores -m models_device_performance_bare_metal --timeout=600
        if: ${{ !cancelled() && matrix.test-info.civ2-compatible && matrix.test-info.job-blackhole-set1 && fromJSON(needs.define-models.outputs.models-to-run)['panoptic-deeplab'] }}

      - name: panoptic_deeplab tests (all cores)
        uses: tenstorrent/tt-metal/.github/actions/single-card-perf-test@main
        with:
          device_perf_model_name: "panoptic_deeplab_all_cores"
          commands: |
            pytest models/experimental/panoptic_deeplab/tests/test_device_perf_pdl.py::test_device_perf_pdl_all_cores -m models_device_performance_bare_metal --timeout=600
        if: ${{ !cancelled() && matrix.test-info.civ2-compatible && matrix.test-info.job-blackhole-set1 && fromJSON(needs.define-models.outputs.models-to-run)['panoptic-deeplab'] }}

      - name: Merge test reports
        id: generate-device-perf-report
        if: ${{ !cancelled() }}
        timeout-minutes: ${{ matrix.test-info.timeout }}
        env:
          TRACY_NO_INVARIANT_CHECK: 1
        run: |
          CLEAN_NAME=$(echo "${{ matrix.test-info.name }}" | tr ' ' '-')
          export DEVICE_PERF_REPORT_FILENAME=Models_Device_Perf_${{ matrix.test-info.test-type }}_${CLEAN_NAME}_$(date +%Y_%m_%d).csv
          cat Models_Device_Perf_$(date +%Y_%m_%d).csv > Models_Device_Perf_${{ matrix.test-info.test-type }}_${CLEAN_NAME}_$(date +%Y_%m_%d).csv
          cat Models_Device_Perf_${{ matrix.test-info.test-type }}_${CLEAN_NAME}_$(date +%Y_%m_%d).csv
          python3 models/perf/merge_device_perf_results.py $DEVICE_PERF_REPORT_FILENAME CHECK
          echo "device_perf_report_filename=$DEVICE_PERF_REPORT_FILENAME" >> "$GITHUB_OUTPUT"

      - name: Save environment data
        id: save-environment-data
        if: ${{ !cancelled() }}
        run: |
          if [ -d "generated/benchmark_data" ]; then
            echo "has_benchmark_data=true" >> $GITHUB_OUTPUT
            python3 .github/scripts/data_analysis/create_benchmark_with_environment_json.py
          else
            echo "::warning::Benchmark data directory 'generated/benchmark_data' does not exist"
            echo "has_benchmark_data=false" >> $GITHUB_OUTPUT
          fi

      - name: Upload benchmark data
        if: ${{ !cancelled() && steps.save-environment-data.conclusion == 'success' && steps.save-environment-data.outputs.has_benchmark_data == 'true' }}
        uses: tenstorrent/tt-metal/.github/actions/upload-data-via-sftp@main
        with:
          ssh-private-key: ${{ secrets.SFTP_BENCHMARK_WRITER_KEY }}
          sftp-batchfile: /work/.github/actions/upload-data-via-sftp/benchmark_data_batchfile.txt
          username: ${{ secrets.SFTP_BENCHMARK_WRITER_USERNAME }}
          hostname: ${{ secrets.SFTP_BENCHMARK_WRITER_HOSTNAME }}
          path: /work

      - name: Check device perf report exists
        id: check-device-perf-report
        if: ${{ !cancelled() }}
        run: |
          test -f ${{ steps.generate-device-perf-report.outputs.device_perf_report_filename }}

      - name: Clean test name for artifact
        run: |
          CLEAN_NAME=$(echo "${{ matrix.test-info.name }}" | tr ' ' '-')
          echo "ARTIFACT_NAME=device-perf-report-csv-${{ matrix.test-info.test-type }}-${{ matrix.test-info.arch }}-${{ matrix.test-info.machine-type }}-${CLEAN_NAME}" >> "$GITHUB_ENV"

      - name: Upload device perf report
        timeout-minutes: 5
        if: ${{ !cancelled() && steps.check-device-perf-report.conclusion == 'success' }}
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.ARTIFACT_NAME }}
          path: /work/${{ steps.generate-device-perf-report.outputs.device_perf_report_filename }}

      - uses: tenstorrent/tt-metal/.github/actions/upload-artifact-with-job-uuid@main
        timeout-minutes: 10
        if: ${{ !cancelled() }}
        with:
          prefix: "test_reports_"

      - uses: tenstorrent/tt-metal/.github/actions/cleanup@main
        if: always()
