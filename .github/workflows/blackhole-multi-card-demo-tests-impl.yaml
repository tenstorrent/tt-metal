name: "[internal] Blackhole Multi-card Demo tests impl"

on:
  workflow_call:
    inputs:
      build-artifact-name:
        required: true
        type: string
      wheel-artifact-name:
        required: true
        type: string
      docker-image:
        required: true
        type: string
      runner-label:
        required: false
        type: string
        default: "BH-LLMBox"
      extra-tag:
        required: false
        type: string
        default: "pipeline-perf"
      num_devices:
        required: false
        type: number
        default: 4
      regenerate-ttnn-cache:
        required: false
        type: boolean
        default: false

jobs:
  multi-card-demo-tests:
    strategy:
      fail-fast: false
      matrix:
        test-group:
          - name: "llama3.1-8b ${{ inputs.runner-label }} performance"
            arch: blackhole
            cmd: HF_MODEL=/localdev/blackhole_demos/huggingface_data/meta-llama/Llama-3.1-8B-Instruct TT_CACHE_PATH=/localdev/blackhole_demos/huggingface_data/meta-llama/Llama-3.1-8B-Instruct pytest models/tt_transformers/demo/simple_text_demo.py -k "performance and ci-32" --data_parallel 1
            owner_id: U08GELBB1AP # Ambrose Ling
          - name: "llama3.1-8b ${{ inputs.runner-label }} data-parallel=${{ inputs.num_devices }} performance"
            arch: blackhole
            cmd: HF_MODEL=/localdev/blackhole_demos/huggingface_data/meta-llama/Llama-3.1-8B-Instruct TT_CACHE_PATH=/localdev/blackhole_demos/huggingface_data/meta-llama/Llama-3.1-8B-Instruct pytest models/tt_transformers/demo/simple_text_demo.py -k "performance and ci-32" --data_parallel ${{ inputs.num_devices }}
            owner_id: U03PUAKE719 # Miguel Tairum
          - name: "llama3.1-8b ${{ inputs.runner-label }} data-parallel=${{ inputs.num_devices }} stress"
            arch: blackhole
            cmd: HF_MODEL=/localdev/blackhole_demos/huggingface_data/meta-llama/Llama-3.1-8B-Instruct TT_CACHE_PATH=/localdev/blackhole_demos/huggingface_data/meta-llama/Llama-3.1-8B-Instruct pytest models/tt_transformers/demo/simple_text_demo.py -k "performance-ci-stress-1" --data_parallel ${{ inputs.num_devices }} --max_generated_tokens 22000
            owner_id: U03PUAKE719 # Miguel Tairum
          - name: "llama3.1-8b ${{ inputs.runner-label }} batch-1 TP device perf decode"
            arch: blackhole
            cmd: HF_MODEL=/localdev/blackhole_demos/huggingface_data/meta-llama/Llama-3.1-8B-Instruct pytest models/tt_transformers/tests/test_device_perf.py -k "decode-llama3_8b-2-1024-2-10-1-1-False"
            owner_id: U08GELBB1AP # Ambrose Ling
          - name: "llama3.1-8b ${{ inputs.runner-label }} batch-1 TP device perf prefill"
            arch: blackhole
            cmd: HF_MODEL=/localdev/blackhole_demos/huggingface_data/meta-llama/Llama-3.1-8B-Instruct pytest models/tt_transformers/tests/test_device_perf.py -k "prefill-llama3_8b-2-1024-2-10-1-1-False"
            owner_id: U08GELBB1AP # Ambrose Ling
    name: ${{ matrix.test-group.name }}
    runs-on:
      - "in-service"
      - arch-blackhole
      - "${{ inputs.runner-label }}"
      - "${{ inputs.extra-tag }}"
    container:
      image: ${{ inputs.docker-image || 'docker-image-unresolved' }}
      env:
        ARCH_NAME: ${{ inputs.arch }}
        LOGURU_LEVEL: INFO
        LD_LIBRARY_PATH: /work/build/lib
        PYTHONPATH: /work
        TT_METAL_HOME: /work
        HF_TOKEN: ${{ secrets.HUGGINGFACE_TOKEN }}
      volumes:
        - ${{ github.workspace }}/docker-job:/work # Subdir to workaround https://github.com/actions/runner/issues/691
        - ${{ (!contains(inputs.runner-label, 'viommu') && '/dev/hugepages-1G:/dev/hugepages-1G') || '/no_hugepages' }}
        # If extra-tag is pipeline-yyz2-lfc, we don't need to mount the model cache volume
        # If extra-tag is pipeline-functional, we need to mount the model cache volume from /mnt/MLPerf/tt_dnn-models
        # If extra-tag is pipeline-perf, we need to mount the model cache volume from /localdev/blackhole_demos/huggingface_data because it's in CIv1 GH VLAN, so not on Cloud
        - "${{ inputs.extra-tag != 'pipeline-yyz2-lfc' && format('{0}:/localdev/blackhole_demos/huggingface_data{1}', inputs.extra-tag == 'pipeline-functional' && '/mnt/MLPerf/tt_dnn-models' || '/localdev/blackhole_demos/huggingface_data', inputs.regenerate-ttnn-cache == true && ':rw' || ':ro') || '/no_hf_cache' }}"
      options: "--device /dev/tenstorrent"
    defaults:
      run:
        shell: bash
        working-directory: /work # https://github.com/actions/runner/issues/878
    steps:
      - name: ⬇️  Setup Job
        uses: tenstorrent/tt-metal/.github/actions/setup-job@5b5c6ff5b54025e165d189371cda93d2b9ef6115
        timeout-minutes: 10
        with:
          build-artifact-name: ${{ inputs.build-artifact-name }}
          wheel-artifact-name: ${{ inputs.wheel-artifact-name }}
      - uses: tenstorrent/tt-metal/.github/actions/ensure-bh-links-online@main
        timeout-minutes: 10
        with:
          runner-label: ${{ inputs.runner-label }}
      - name: Download Llama model weights from LFC
        if: ${{ inputs.extra-tag == 'pipeline-yyz2-lfc' && contains(matrix.test-group.name, 'llama') }}
        timeout-minutes: 15
        run: |
          set -e
          mkdir -p /localdev/blackhole_demos/huggingface_data/meta-llama
          wget -r -nH -x --cut-dirs=5 -np --progress=dot:giga -R "index.html*" -P /localdev/blackhole_demos/huggingface_data/meta-llama http://yyz2-lfcache564.yyz2.tenstorrent.com/mldata/model_checkpoints/pytorch/huggingface/meta-llama/Llama-3.1-8B-Instruct/
      - name: Run demo regression tests
        timeout-minutes: 70
        run: |
          if [[ "${{ matrix.test-group.name }}" == *"llama"* ]]; then
            pip install -r /work/models/tt_transformers/requirements.txt
          fi
          ${{ matrix.test-group.cmd }}
      - name: Print tt-smi data on failure
        if: ${{ failure() }}
        run: |
          tt-smi -s
      - name: Save environment data
        id: save-environment-data
        if: ${{ !cancelled() }}
        timeout-minutes: 15
        env:
          ARCH_NAME: ${{ matrix.test-group.arch }}
        run: |
          if [ -d "generated/benchmark_data" ]; then
            echo "has_benchmark_data=true" >> $GITHUB_OUTPUT
            python3 .github/scripts/data_analysis/create_benchmark_with_environment_json.py
          else
            echo "::warning::Benchmark data directory 'generated/benchmark_data' does not exist"
            echo "has_benchmark_data=false" >> $GITHUB_OUTPUT
          fi

      - name: Upload benchmark data
        if: ${{ !cancelled() && steps.save-environment-data.conclusion == 'success' && steps.save-environment-data.outputs.has_benchmark_data == 'true' }}
        uses: tenstorrent/tt-metal/.github/actions/upload-data-via-sftp@main
        with:
          ssh-private-key: ${{ secrets.SFTP_BENCHMARK_WRITER_KEY }}
          sftp-batchfile: /work/.github/actions/upload-data-via-sftp/benchmark_data_batchfile.txt
          username: ${{ secrets.SFTP_BENCHMARK_WRITER_USERNAME }}
          hostname: ${{ secrets.SFTP_BENCHMARK_WRITER_HOSTNAME }}
          path: /work

      - uses: tenstorrent/tt-metal/.github/actions/upload-artifact-with-job-uuid@main
        timeout-minutes: 10
        if: ${{ !cancelled() }}
        with:
          prefix: "test_reports_"
      - uses: tenstorrent/tt-metal/.github/actions/slack-report@main
        if: ${{ failure() }}
        with:
          slack_webhook_url: ${{ secrets.SLACK_METAL_INFRA_PIPELINE_STATUS_ALERT }}
          owner: ${{ matrix.test-group.owner_id }}
      - uses: tenstorrent/tt-metal/.github/actions/cleanup@main
        if: always()
  multi-card-demo-tests-large:
    if: ${{ inputs.num_devices >= 4 }}
    strategy:
      fail-fast: false
      matrix:
        test-group:
          - name: "llama3.3-70b ${{ inputs.runner-label }} batch-32 performance"
            arch: blackhole
            cmd: HF_MODEL=/localdev/blackhole_demos/huggingface_data/meta-llama/Llama-3.3-70B-Instruct TT_CACHE_PATH=/localdev/blackhole_demos/huggingface_data/meta-llama/Llama-3.3-70B-Instruct pytest models/tt_transformers/demo/simple_text_demo.py -k "performance and ci-32"
            owner_id: U03PUAKE719 # Miguel Tairum
          - name: "llama3.3-70b ${{ inputs.runner-label }} batch-1 TP device perf prefill"
            arch: blackhole
            cmd: HF_MODEL=/localdev/blackhole_demos/huggingface_data/meta-llama/Llama-3.3-70B-Instruct pytest models/tt_transformers/tests/test_device_perf.py -k "prefill-llama3_70b-2-1024-2-10-1-1-False"
            owner_id: U08GELBB1AP # Ambrose Ling
          - name: "llama3.3-70b ${{ inputs.runner-label }} batch-1 TP device perf decode"
            arch: blackhole
            cmd: HF_MODEL=/localdev/blackhole_demos/huggingface_data/meta-llama/Llama-3.3-70B-Instruct pytest models/tt_transformers/tests/test_device_perf.py -k "decode-llama3_70b-2-1024-2-10-1-1-False"
            owner_id: U08GELBB1AP # Ambrose Ling
    name: ${{ matrix.test-group.name }}
    runs-on:
      - "in-service"
      - arch-blackhole
      - "${{ inputs.runner-label }}"
      - "${{ inputs.extra-tag }}"
    container:
      image: ${{ inputs.docker-image || 'docker-image-unresolved' }}
      env:
        ARCH_NAME: ${{ inputs.arch }}
        LOGURU_LEVEL: INFO
        LD_LIBRARY_PATH: /work/build/lib
        PYTHONPATH: /work
        TT_METAL_HOME: /work
        HF_TOKEN: ${{ secrets.HUGGINGFACE_TOKEN }}
      volumes:
        - ${{ github.workspace }}/docker-job:/work # Subdir to workaround https://github.com/actions/runner/issues/691
        - ${{ (!contains(inputs.runner-label, 'viommu') && '/dev/hugepages-1G:/dev/hugepages-1G') || '/no_hugepages' }}
        - "${{ inputs.extra-tag != 'pipeline-yyz2-lfc' && format('{0}:/localdev/blackhole_demos/huggingface_data{1}', inputs.extra-tag == 'pipeline-functional' && '/mnt/MLPerf/tt_dnn-models' || '/localdev/blackhole_demos/huggingface_data', inputs.regenerate-ttnn-cache == true && ':rw' || ':ro') || '/no_hf_cache' }}"
      options: "--device /dev/tenstorrent"
    defaults:
      run:
        shell: bash
        working-directory: /work # https://github.com/actions/runner/issues/878
    steps:
      - name: ⬇️  Setup Job
        uses: tenstorrent/tt-metal/.github/actions/setup-job@5b5c6ff5b54025e165d189371cda93d2b9ef6115
        timeout-minutes: 10
        with:
          build-artifact-name: ${{ inputs.build-artifact-name }}
          wheel-artifact-name: ${{ inputs.wheel-artifact-name }}
      - uses: tenstorrent/tt-metal/.github/actions/ensure-bh-links-online@main
        timeout-minutes: 10
        with:
          runner-label: ${{ inputs.runner-label }}
      - name: Run demo regression tests
        timeout-minutes: 70
        run: |
          if [[ "${{ matrix.test-group.name }}" == *"llama"* ]]; then
            pip install -r /work/models/tt_transformers/requirements.txt
          fi
          ${{ matrix.test-group.cmd }}

      - name: Save environment data
        id: save-environment-data
        if: ${{ !cancelled() }}
        timeout-minutes: 15
        env:
          ARCH_NAME: ${{ matrix.test-group.arch }}
        run: |
          if [ -d "generated/benchmark_data" ]; then
            echo "has_benchmark_data=true" >> $GITHUB_OUTPUT
            python3 .github/scripts/data_analysis/create_benchmark_with_environment_json.py
          else
            echo "::warning::Benchmark data directory 'generated/benchmark_data' does not exist"
            echo "has_benchmark_data=false" >> $GITHUB_OUTPUT
          fi

      - name: Upload benchmark data
        if: ${{ !cancelled() && steps.save-environment-data.conclusion == 'success' && steps.save-environment-data.outputs.has_benchmark_data == 'true' }}
        uses: tenstorrent/tt-metal/.github/actions/upload-data-via-sftp@main
        with:
          ssh-private-key: ${{ secrets.SFTP_BENCHMARK_WRITER_KEY }}
          sftp-batchfile: /work/.github/actions/upload-data-via-sftp/benchmark_data_batchfile.txt
          username: ${{ secrets.SFTP_BENCHMARK_WRITER_USERNAME }}
          hostname: ${{ secrets.SFTP_BENCHMARK_WRITER_HOSTNAME }}
          path: /work

      - uses: tenstorrent/tt-metal/.github/actions/upload-artifact-with-job-uuid@main
        timeout-minutes: 10
        if: ${{ !cancelled() }}
        with:
          prefix: "test_reports_"
      - uses: tenstorrent/tt-metal/.github/actions/slack-report@main
        if: ${{ failure() }}
        with:
          slack_webhook_url: ${{ secrets.SLACK_METAL_INFRA_PIPELINE_STATUS_ALERT }}
          owner: ${{ matrix.test-group.owner_id }}
      - uses: tenstorrent/tt-metal/.github/actions/cleanup@main
        if: always()
