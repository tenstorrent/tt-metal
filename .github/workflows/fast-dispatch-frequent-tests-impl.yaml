name: "[internal] Fast dispatch frequent tests impl"

on:
  workflow_call:
    inputs:
      build-artifact-name:
        required: true
        type: string
      wheel-artifact-name:
        required: true
        type: string
      docker-image:
        required: true
        type: string

jobs:
  fd-frequent:
    strategy:
      # Do not fail-fast because we need to ensure all tests go to completion
      # so we try not to get hanging machines
      fail-fast: false
      matrix:
        test-group:
          - name: "WH N300 pgm dispatch nightly"
            arch: wormhole_b0
            runs-on: ["cloud-virtual-machine", "N300", "in-service"]
            run-args: |
              mkdir -p generated/test_reports
              ./build/test/tt_metal/perf_microbenchmark/dispatch/test_pgm_dispatch --benchmark_out_format=json --benchmark_out=pgm_bench.json
              ./tests/tt_metal/tt_metal/perf_microbenchmark/dispatch/compare_pgm_dispatch_perf_ci.py pgm_bench.json
            timeout: 15
          - name: "WH N300 dispatch bandwidth nightly"
            arch: wormhole_b0
            runs-on: ["cloud-virtual-machine", "N300", "in-service"]
            run-args: |
              mkdir -p generated/test_reports
              ./build/test/tt_metal/perf_microbenchmark/dispatch/benchmark_rw_buffer --benchmark_out_format=json --benchmark_out=buffer_bench.json --benchmark_repetitions=11
              # Ignore times because they're not consistent across runs yet.
              ./tests/tt_metal/tt_metal/perf_microbenchmark/dispatch/compare_benchmark_rw_buffer.py buffer_bench.json --ignore-times
            timeout: 15
          - name: "WH N300 dispatch bandwidth IOMMU nightly"
            arch: wormhole_b0
            runs-on: ["tt-ubuntu-2204-N300-viommu-stable"]
            run-args: |
              mkdir -p generated/test_reports
              ./build/test/tt_metal/perf_microbenchmark/dispatch/benchmark_rw_buffer --benchmark_out_format=json --benchmark_out=buffer_bench.json --benchmark_repetitions=5
              # Ignore times because they're not consistent across runs yet.
              ./tests/tt_metal/tt_metal/perf_microbenchmark/dispatch/compare_benchmark_rw_buffer.py buffer_bench.json --ignore-times --golden tests/tt_metal/tt_metal/perf_microbenchmark/dispatch/benchmark_rw_buffer_n300_iommu_golden.json
            timeout: 25
          - name: "BH P150 pgm dispatch nightly"
            arch: blackhole
            runs-on: ["pipeline-perf", "P150", "in-service"]
            run-args: |
              mkdir -p generated/test_reports
              ./build/test/tt_metal/perf_microbenchmark/dispatch/test_pgm_dispatch --benchmark_out_format=json --benchmark_out=pgm_bench.json
              ./tests/tt_metal/tt_metal/perf_microbenchmark/dispatch/compare_pgm_dispatch_perf_ci.py -g tests/tt_metal/tt_metal/perf_microbenchmark/dispatch/pgm_dispatch_blackhole_golden.json pgm_bench.json
            timeout: 15
          - name: "BH P150 dispatch bandwidth nightly"
            arch: blackhole
            runs-on: ["pipeline-perf", "P150", "in-service"]
            run-args: |
              mkdir -p generated/test_reports
              ./build/test/tt_metal/perf_microbenchmark/dispatch/benchmark_rw_buffer --benchmark_out_format=json --benchmark_out=buffer_bench.json --benchmark_repetitions=11
              # We shouldn't fail the job for now as this benchmark is not yet stable
              ./tests/tt_metal/tt_metal/perf_microbenchmark/dispatch/compare_benchmark_rw_buffer.py --golden tests/tt_metal/tt_metal/perf_microbenchmark/dispatch/benchmark_rw_buffer_blackhole_golden.json buffer_bench.json --ignore-times
            timeout: 10
    name: ${{ matrix.test-group.name }}
    env:
      LOGURU_LEVEL: INFO
    runs-on: ${{ matrix.test-group.runs-on }}
    steps:
      - name: ⬇️ Checkout
        uses: actions/checkout@v4
        with:
          submodules: recursive
      - name: ⬇️ Download Build
        uses: actions/download-artifact@634f93cb2916e3fdff6788551b99b062d0335ce0 # v5.0
        timeout-minutes: 10
        with:
          name: ${{ inputs.build-artifact-name }}
      - name: Extract files
        run: tar --zstd -xvf ttm_any.tar.zst
      - name: ⬇️ Download Wheel
        uses: actions/download-artifact@634f93cb2916e3fdff6788551b99b062d0335ce0 # v5.0
        timeout-minutes: 10
        with:
          name: ${{ inputs.wheel-artifact-name }}
      - name: ${{ matrix.test-group.name }} tests
        timeout-minutes: ${{ matrix.test-group.timeout }}
        uses: ./.github/actions/docker-run
        with:
          docker_image: ${{ inputs.docker-image }}
          docker_password: ${{ secrets.GITHUB_TOKEN }}
          # we want to eventually get rid of TT_METAL_HOME, but
          # for these pgm dispatch things maybe not that big of a deal
          docker_opts: |
            -e TT_METAL_HOME=${{ github.workspace }}
            -e ARCH_NAME=${{ matrix.test-group.arch }}
            -e LD_LIBRARY_PATH=${{ github.workspace }}/build/lib
            -e GTEST_OUTPUT=xml:generated/test_reports/
          run_args: ${{ matrix.test-group.run-args }}
      - uses: tenstorrent/tt-metal/.github/actions/slack-report@main
        if: ${{ failure() }}
        with:
          slack_webhook_url: ${{ secrets.SLACK_METAL_INFRA_PIPELINE_STATUS_ALERT }}
          owner: U01Q0T3J3D0 # Paul Keller
      - uses: tenstorrent/tt-metal/.github/actions/upload-artifact-with-job-uuid@main
        timeout-minutes: 10
        if: ${{ !cancelled() }}
        with:
          path: generated/test_reports/
          prefix: "test_reports_"
      - name: Generate gtest annotations on failure
        uses: tenstorrent/tt-metal/.github/actions/generate-gtest-failure-message@main
        if: ${{ failure() }}
        with:
          test-report-path: generated/test_reports/
      - uses: tenstorrent/tt-metal/.github/actions/upload-artifact-with-job-uuid@main
        timeout-minutes: 10
        if: ${{ !cancelled() }}
        with:
          path: |
            pgm_bench.json
          prefix: "pgm_benchmarks_json_"
      - uses: tenstorrent/tt-metal/.github/actions/upload-artifact-with-job-uuid@main
        timeout-minutes: 10
        if: ${{ !cancelled() }}
        with:
          path: |
            buffer_bench.json
          prefix: "buffer_benchmarks_json_"
