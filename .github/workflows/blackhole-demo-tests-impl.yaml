name: "[internal] Blackhole Demo tests impl"

on:
  workflow_call:
    inputs:
      build-artifact-name:
        required: true
        type: string
      wheel-artifact-name:
        required: true
        type: string
      docker-image:
        required: true
        type: string
      runner-label:
        required: false
        type: string
        default: "BH"
      regenerate-ttnn-cache:
        required: false
        type: boolean
        default: false

jobs:
  single-card-demo-tests:
    if: ${{ inputs.runner-label == 'P100' || inputs.runner-label == 'P150' }}
    strategy:
      fail-fast: false
      matrix:
        test-group: [
          {
            name: "whisper performance",
            arch: blackhole,
            runs-on: ["in-service", "${{ inputs.runner-label }}", "pipeline-perf"],
            cmd: pytest models/demos/whisper/demo/demo.py --input-path="models/demos/whisper/demo/dataset/conditional_generation" -k "conditional_generation",
            owner_id: U05RWH3QUPM # Salar Hosseini
          },
          {
            name: "llama3-8b performance",
            arch: blackhole,
            runs-on: ["in-service", "${{ inputs.runner-label }}", "pipeline-perf"],
            # I think we can get rid of TT_CACHE_PATH here by using a NFS export
            cmd:  HF_MODEL=/localdev/blackhole_demos/huggingface_data/meta-llama/Llama-3.1-8B-Instruct TT_CACHE_PATH=/localdev/blackhole_demos/huggingface_data/meta-llama/Llama-3.1-8B-Instruct pytest models/tt_transformers/demo/simple_text_demo.py -k "performance-ci and not performance-ci-stress-1" --max_seq_len 131072,
            owner_id: U03PUAKE719 # Miguel Tairum
          },
          { # This should be moved to a BH perf regression pipeline in the future
            name: "unet-shallow performance",
            arch: blackhole,
            runs-on: ["in-service", "${{ inputs.runner-label }}", "pipeline-perf"],
            cmd: pytest -sv models/experimental/functional_unet/tests/test_unet_perf.py -k "test_unet_trace_perf and not test_unet_trace_perf_multi_device",
            owner_id: U06ECNVR0EN # Evan Smal
          }
        ]

    name: ${{ matrix.test-group.name }}
    runs-on: ${{ matrix.test-group.runs-on }}
    container:
      image: ${{ inputs.docker-image || 'docker-image-unresolved' }}
      env:
        ARCH_NAME: ${{ inputs.arch }}
        LOGURU_LEVEL: INFO
        LD_LIBRARY_PATH: /work/build/lib
        PYTHONPATH: /work
        TT_METAL_HOME: /work
        HF_TOKEN: ${{ secrets.HUGGINGFACE_TOKEN }}
      volumes:
        - ${{ github.workspace }}/docker-job:/work # Subdir to workaround https://github.com/actions/runner/issues/691
        - /dev/hugepages-1G:/dev/hugepages-1G
        - "/localdev/blackhole_demos/huggingface_data:/localdev/blackhole_demos/huggingface_data${{ inputs.regenerate-ttnn-cache == true && ':rw' || ':ro' }}"
      options: "--device /dev/tenstorrent -e TT_GH_CI_INFRA"
    defaults:
      run:
        shell: bash
        working-directory: /work # https://github.com/actions/runner/issues/878
    steps:
      - name: üß¨ Checkout Repository
        uses: actions/checkout@v4
        with:
          submodules: recursive
          path: docker-job
      - name: ‚¨áÔ∏è  Setup Job
        uses: ./docker-job/.github/actions/setup-job
        timeout-minutes: 10
        with:
          build-artifact-name: ${{ inputs.build-artifact-name }}
          wheel-artifact-name: ${{ inputs.wheel-artifact-name }}
      - name: Run demo regression tests
        timeout-minutes: 70
        run: |
          ${{ matrix.test-group.cmd }}
      - name: Save environment data
        id: save-environment-data
        if: ${{ !cancelled() }}
        timeout-minutes: 15
        env:
          ARCH_NAME: ${{ matrix.test-group.arch }}
        run: |
          if [ -d "generated/benchmark_data" ]; then
            echo "has_benchmark_data=true" >> $GITHUB_OUTPUT
            python3 .github/scripts/data_analysis/create_benchmark_with_environment_json.py
          else
            echo "::warning::Benchmark data directory 'generated/benchmark_data' does not exist"
            echo "has_benchmark_data=false" >> $GITHUB_OUTPUT
          fi

      - name: Upload benchmark data
        if: ${{ !cancelled() && steps.save-environment-data.conclusion == 'success' && steps.save-environment-data.outputs.has_benchmark_data == 'true' }}
        uses: tenstorrent/tt-metal/.github/actions/upload-data-via-sftp@main
        with:
          ssh-private-key: ${{ secrets.SFTP_BENCHMARK_WRITER_KEY }}
          sftp-batchfile: /work/.github/actions/upload-data-via-sftp/benchmark_data_batchfile.txt
          username: ${{ secrets.SFTP_BENCHMARK_WRITER_USERNAME }}
          hostname: ${{ secrets.SFTP_BENCHMARK_WRITER_HOSTNAME }}
          path: /work

      - uses: tenstorrent/tt-metal/.github/actions/upload-artifact-with-job-uuid@main
        timeout-minutes: 10
        if: ${{ !cancelled() }}
        with:
          prefix: "test_reports_"
      - uses: tenstorrent/tt-metal/.github/actions/slack-report@main
        if: ${{ failure() }}
        with:
          slack_webhook_url: ${{ secrets.SLACK_METAL_INFRA_PIPELINE_STATUS_ALERT }}
          owner: ${{ matrix.test-group.owner_id }}
      - uses: tenstorrent/tt-metal/.github/actions/cleanup@main
        if: always()
  single-card-p150-demo-tests:
    if: ${{ inputs.runner-label == 'p150b' }}
    strategy:
      # Do not fail-fast because we need to ensure all tests go to completion
      # so we try not to get hanging machines
      fail-fast: false
      matrix:
        test-group: [
            { # This test shall be executed on the BH with 20 cores
              name: "panoptic_deeplab demo - 20 cores",
              arch: blackhole,
              cmd: 'TT_METAL_CORE_GRID_OVERRIDE_TODEPRECATE="4, 3" pytest models/experimental/panoptic_deeplab/demo/demo.py::test_panoptic_deeplab_demo_pipeline',
              owner_id: U09LK84G4TF # Nikola Milicevic
            },
            { # This test shall be executed on the BH P150 on 110 cores
              name: "panoptic_deeplab demo - 110 cores",
              arch: blackhole,
              cmd: 'TT_METAL_CORE_GRID_OVERRIDE_TODEPRECATE="10, 9" pytest models/experimental/panoptic_deeplab/demo/demo.py::test_panoptic_deeplab_demo_pipeline',
              owner_id: U09LK84G4TF # Nikola Milicevic
            },
          ]
    name: ${{ matrix.test-group.name }}
    runs-on: ${{ format('tt-ubuntu-2204-{0}-viommu-stable', inputs.runner-label) }}
    container:
      image: harbor.ci.tenstorrent.net/${{ inputs.docker-image || 'docker-image-unresolved!'}}
      env:
        PYTHONPATH: /work
        LD_LIBRARY_PATH: /work/build/lib
        ARCH_NAME: blackhole
        LOGURU_LEVEL: INFO
      volumes:
        - ${{ github.workspace }}/docker-job:/work # Subdir to workaround https://github.com/actions/runner/issues/691
        - /dev/hugepages-1G:/dev/hugepages-1G
      options: "--device /dev/tenstorrent -e TT_GH_CI_INFRA"
    defaults:
      run:
        shell: bash
        working-directory: /work # https://github.com/actions/runner/issues/878
    steps:
      - name: üß¨ Checkout Repository
        uses: actions/checkout@v4
        with:
          submodules: recursive
          path: docker-job
      - name: ‚¨áÔ∏è  Setup Job
        uses: ./docker-job/.github/actions/setup-job
        timeout-minutes: 10
        with:
          build-artifact-name: ${{ inputs.build-artifact-name }}
          wheel-artifact-name: ${{ inputs.wheel-artifact-name }}

      - name: Run frequent reg tests scripts
        timeout-minutes: 180
        run: ${{ matrix.test-group.cmd }}

      - uses: tenstorrent/tt-metal/.github/actions/upload-artifact-with-job-uuid@main
        timeout-minutes: 10
        if: ${{ !cancelled() }}
        with:
          prefix: "test_reports_"

      - uses: tenstorrent/tt-metal/.github/actions/slack-report@main
        if: ${{ failure() }}
        with:
          slack_webhook_url: ${{ secrets.SLACK_WEBHOOK_URL }}
          owner: ${{ matrix.test-group.owner_id }}
