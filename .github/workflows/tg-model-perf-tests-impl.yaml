name: "[internal] TG model perf tests impl"

on:
  workflow_call:

jobs:
  tg-model-perf-tests:
    strategy:
      fail-fast: false
      matrix:
        test-group: [
          {
            name: "TG LLM model perf tests",
            model-type: "LLM",
            arch: wormhole_b0,
            runs-on: ["arch-wormhole_b0", "config-tg", "in-service", "bare-metal", "pipeline-perf"],
            cmd: './tests/scripts/run_tests.sh --tt-arch wormhole_b0 --pipeline-type llm_model_perf_tg_device --dispatch-mode ""'
          },
          {
            name: "TG CNN model perf tests",
            model-type: "CNN",
            arch: wormhole_b0,
            runs-on: ["arch-wormhole_b0", "config-tg", "in-service", "bare-metal", "pipeline-perf"],
            cmd: './tests/scripts/run_tests.sh --tt-arch wormhole_b0 --pipeline-type cnn_model_perf_tg_device --dispatch-mode ""'
          },
          { name: "TG CCL perf tests",
            arch: wormhole_b0,
            cmd: './tests/scripts/run_tests.sh --tt-arch wormhole_b0 --pipeline-type ccl_perf_tg_device --dispatch-mode ""',
            timeout: 75,
            tracy: true,
            runs-on: ["arch-wormhole_b0", "config-tg", "in-service", "bare-metal", "pipeline-perf"],
            owner_id: ULMEPM2MA
          }, # Sean Nijjar
          {
            name: "Llama TG Perf Unit Tests",
            model-type: "LLM",
            arch: wormhole_b0,
            cmd: './tests/scripts/run_tests.sh --tt-arch wormhole_b0 --pipeline-type llama_tg_perf_unit_tests --dispatch-mode ""',
            timeout: 900,
            tracy: true,
            runs-on: ["arch-wormhole_b0", "config-tg", "in-service", "bare-metal", "pipeline-perf"],
            owner_id: U071CKL4AFK
          }
        ]
    name: ${{ matrix.test-group.name }}
    env:
      ARCH_NAME: ${{ matrix.test-group.arch }}
      LOGURU_LEVEL: INFO
      LD_LIBRARY_PATH: ${{ github.workspace }}/build/lib
    runs-on: ${{ matrix.test-group.runs-on }}
    steps:
      - uses: tenstorrent/tt-metal/.github/actions/checkout-with-submodule-lfs@main
      - name: Enable performance mode
        run: |
          sudo cpupower frequency-set -g performance
      - uses: ./.github/actions/ensure-active-weka-mount
      - name: Set up dynamic env vars for build
        run: |
          echo "TT_METAL_HOME=$(pwd)" >> $GITHUB_ENV
          echo "PYTHONPATH=$(pwd)" >> $GITHUB_ENV
      - name: Download profiler build artifact
        uses: actions/download-artifact@v4
        with:
          name: TTMetal_build_any_profiler
      - name: Extract files
        run: tar -xvf ttm_any.tar
      - uses: ./.github/actions/install-python-deps
      - name: Run model perf regression tests
        timeout-minutes: 60
        run: |
          source ${{ github.workspace }}/python_env/bin/activate
          cd $TT_METAL_HOME
          export PYTHONPATH=$TT_METAL_HOME
          ${{ matrix.test-group.cmd }}
      - name: Save environment data
        if: ${{ (matrix.test-group.name == 'Llama TG Perf Unit Tests') && !cancelled() }}
        env:
          PYTHONPATH: ${{ github.workspace }}
        run: |
          source ${{ github.workspace }}/python_env/bin/activate
          python3 .github/scripts/data_analysis/create_benchmark_with_environment_json.py
      - name: Upload benchmark data
        if: ${{ (matrix.test-group.name == 'Llama TG Perf Unit Tests') && !cancelled() }}
        uses: ./.github/actions/upload-data-via-sftp
        with:
          ssh-private-key: ${{ secrets.SFTP_BENCHMARK_WRITER_KEY }}
          sftp-batchfile: .github/actions/upload-data-via-sftp/benchmark_data_batchfile.txt
          username: ${{ secrets.SFTP_BENCHMARK_WRITER_USERNAME }}
          hostname: ${{ secrets.SFTP_BENCHMARK_WRITER_HOSTNAME }}
      - name: Check perf report exists
        id: check-perf-report
        if: ${{ !cancelled() }}
        run: |
          TODAY=$(date +%Y_%m_%d)
          PERF_REPORT_FILENAME_MODELS="Models_Perf_${TODAY}.csv"
          PERF_REPORT_FILENAME_CCL_ALL_GATHER="CCL_all_gather_Perf_${TODAY}.csv"
          PERF_REPORT_FILENAME_CCL_REDUCE_SCATTER="CCL_reduce_scatter_Perf_${TODAY}.csv"
          if [ "${{ matrix.test-group.tracy }}" == "true" ]; then
            found_reports=false
            if [ -f "$PERF_REPORT_FILENAME_CCL_ALL_GATHER" ]; then
              echo "Found CCL AllGather Perf report: $PERF_REPORT_FILENAME_CCL_ALL_GATHER"
              echo "perf_report_filename_all_gather=$PERF_REPORT_FILENAME_CCL_ALL_GATHER" >> "$GITHUB_OUTPUT"
              found_reports=true
            fi
            if [ -f "$PERF_REPORT_FILENAME_CCL_REDUCE_SCATTER" ]; then
              echo "Found CCL ReduceScatter Perf report: $PERF_REPORT_FILENAME_CCL_REDUCE_SCATTER"
              echo "perf_report_filename_reduce_scatter=$PERF_REPORT_FILENAME_CCL_REDUCE_SCATTER" >> "$GITHUB_OUTPUT"
              found_reports=true
            fi
            if [ "$found_reports" = false ]; then
              echo "No CCL perf report found for today."
              exit 1
            fi
          else
            if [ -f "$PERF_REPORT_FILENAME_MODELS" ]; then
              echo "Found Models Perf report: $PERF_REPORT_FILENAME_MODELS"
              echo "perf_report_filename=$PERF_REPORT_FILENAME_MODELS" >> "$GITHUB_OUTPUT"
            else
              echo "No Models perf report found for today."
              exit 1
            fi
          fi
      - name: Upload Models perf report
        if: ${{ !cancelled() && steps.check-perf-report.conclusion == 'success' && !matrix.test-group.tracy}}
        uses: actions/upload-artifact@v4
        timeout-minutes: 10
        with:
          name: perf-report-csv-${{ matrix.test-group.model-type }}-${{ matrix.test-group.arch }}-${{ matrix.test-group.machine-type }}
          path: "${{ steps.check-perf-report.outputs.perf_report_filename }}"
      - name: Upload CCL perf report
        if: ${{ !cancelled() && steps.check-perf-report.conclusion == 'success' && matrix.test-group.tracy}}
        uses: actions/upload-artifact@v4
        timeout-minutes: 10
        with:
          name: perf-report-csv-${{ matrix.test-group.model-type }}-${{ matrix.test-group.arch }}-${{ matrix.test-group.model }}-bare-metal
          path:
            ${{ steps.check-perf-report.outputs.perf_report_filename_all_gather }}
      - uses: tenstorrent/tt-metal/.github/actions/upload-artifact-with-job-uuid@main
        timeout-minutes: 10
        if: ${{ !cancelled() }}
        with:
          path: |
            generated/test_reports/
          prefix: "test_reports_"
      - name: Disable performance mode
        if: always()
        run: |
          sudo cpupower frequency-set -g ondemand
