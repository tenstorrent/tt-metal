name: Uplift LLK Submodule

on:
  workflow_dispatch:
  workflow_call:
    inputs:
      workflow_timeout:
        description: 'Timeout for workflows in minutes'
        required: false
        type: number
        default: 120
      skip_draft:
        description: 'Skip creating PR as draft'
        required: false
        type: boolean
        default: false
  repository_dispatch:
    types: [trigger-llk-update]
  schedule:
    - cron: '0 0,12 * * *'

env:
  BRANCH_NAME: llk-submodule-uplift
  SUBMODULE_PATH: tt_metal/third_party/tt_llk

permissions:
  contents: write          # To push commits and create branches
  pull-requests: write     # To create and update pull requests
  actions: write           # To trigger other workflows
  issues: write            # To comment on PRs (PRs are a type of issue)
  checks: read             # To read workflow run status

jobs:
  llk-submodule-uplift:
    runs-on: ubuntu-latest
    outputs:
      pr-number: ${{ steps.create-pr.outputs.pull-request-number }}
      should-run-wormhole: ${{ steps.analyze-changes.outputs.should-run-wormhole }}
      should-run-blackhole: ${{ steps.analyze-changes.outputs.should-run-blackhole }}
      old-sha: ${{ steps.update-submodule.outputs.old-sha }}
      new-sha: ${{ steps.update-submodule.outputs.new-sha }}
      has-changes: ${{ steps.update-submodule.outputs.has-changes }}
      changed-files: ${{ steps.analyze-changes.outputs.changed-files }}
      commits-table: ${{ steps.analyze-changes.outputs.commits-table }}
    steps:
      - name: Checkout parent repo
        uses: actions/checkout@v4
        with:
          submodules: true
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0  # Ensure we get full history

      - name: Configure git
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "41898282+github-actions[bot]@users.noreply.github.com"

      - name: Update submodule
        id: update-submodule
        run: |
          cd ${{ env.SUBMODULE_PATH }}
          OLD_SHA=$(git rev-parse --short=7 HEAD)
          echo "old-sha=$OLD_SHA" >> $GITHUB_OUTPUT

          # Fetch full history to ensure we can see all commits
          git fetch --unshallow origin main 2>/dev/null || git fetch origin main
          git checkout main
          git pull origin main

          NEW_SHA=$(git rev-parse --short=7 HEAD)
          echo "new-sha=$NEW_SHA" >> $GITHUB_OUTPUT

          if [ "$OLD_SHA" = "$NEW_SHA" ]; then
            echo "has-changes=false" >> $GITHUB_OUTPUT
            echo "‚ö†Ô∏è No changes detected (SHA unchanged)"
          else
            echo "has-changes=true" >> $GITHUB_OUTPUT
            echo "‚úÖ Changes detected: $OLD_SHA -> $NEW_SHA"

            # Stage the submodule changes in the parent repo
            cd ../../..
            git add ${{ env.SUBMODULE_PATH }}
            echo "üìù Staged submodule changes"
          fi

      - name: Analyze changes and generate PR body
        id: analyze-changes
        if: steps.update-submodule.outputs.has-changes == 'true'
        run: |
          cd ${{ env.SUBMODULE_PATH }}
          OLD_SHA="${{ steps.update-submodule.outputs.old-sha }}"
          NEW_SHA="${{ steps.update-submodule.outputs.new-sha }}"

          # Get changed files once
          CHANGED_FILES=$(git diff --name-only ${OLD_SHA}..${NEW_SHA})
          echo "changed-files<<EOF" >> $GITHUB_OUTPUT
          echo "$CHANGED_FILES" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

          # Check for architecture-specific changes
          if echo "$CHANGED_FILES" | grep -q "^tt_llk_wormhole_b0/"; then
            echo "should-run-wormhole=true" >> $GITHUB_OUTPUT
            echo "‚úÖ Detected Wormhole changes"
          else
            echo "should-run-wormhole=false" >> $GITHUB_OUTPUT
          fi

          if echo "$CHANGED_FILES" | grep -q "^tt_llk_blackhole/"; then
            echo "should-run-blackhole=true" >> $GITHUB_OUTPUT
            echo "‚úÖ Detected Blackhole changes"
          else
            echo "should-run-blackhole=false" >> $GITHUB_OUTPUT
          fi

          # Generate commits table and save to GITHUB_OUTPUT
          COMMIT_COUNT=$(git log --oneline ${OLD_SHA}..${NEW_SHA} | wc -l)
          echo "Found $COMMIT_COUNT commits using ${OLD_SHA}..${NEW_SHA}"

          # Generate commits table content
          COMMITS_TABLE_CONTENT="| Commit | Message | Author | PR |"$'\n'
          COMMITS_TABLE_CONTENT+="|--------|---------|---------|-----|"$'\n'

          if [ "$COMMIT_COUNT" -gt 0 ]; then
            # Generate commits table content
            while IFS='|' read -r short_hash message author full_hash; do
              # Skip empty lines
              if [ -z "$short_hash" ]; then
                continue
              fi

              # Try to get the PR number from the commit message and clean the message
              pr_number=$(echo "$message" | grep -oE '\(#[0-9]+\)' | grep -oE '[0-9]+' | head -1)
              # Remove (#number) from the message for cleaner display
              clean_message=$(echo "$message" | sed 's/ *(#[0-9]\+) *$//')

              if [ -n "$pr_number" ]; then
                COMMITS_TABLE_CONTENT+="| [$short_hash](https://github.com/tenstorrent/tt-llk/commit/$full_hash) | $clean_message | $author | [#$pr_number](https://github.com/tenstorrent/tt-llk/pull/$pr_number) |"$'\n'
              else
                COMMITS_TABLE_CONTENT+="| [$short_hash](https://github.com/tenstorrent/tt-llk/commit/$full_hash) | $clean_message | $author | - |"$'\n'
              fi
            done < <(git log --pretty=tformat:"%h|%s|%an|%H" ${OLD_SHA}..${NEW_SHA})
          else
            echo "No commits found - this shouldn't happen if we detected changes"
            COMMITS_TABLE_CONTENT+="| (No commits found) | - | - | - |"$'\n'
          fi

          # Save commits table to GITHUB_OUTPUT
          echo "commits-table<<EOF" >> $GITHUB_OUTPUT
          echo "$COMMITS_TABLE_CONTENT" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

          # Generate simple initial PR body (will be updated later with full details)
          cat > ../../../llk_commit_log.txt << EOF
          ## üîÑ LLK Submodule Update

          Updating LLK submodule from \`$OLD_SHA\` to \`$NEW_SHA\`.

          *This PR body will be updated with detailed information shortly...*
          EOF

      - name: Create Pull Request
        id: create-pr
        if: steps.update-submodule.outputs.has-changes == 'true'
        uses: peter-evans/create-pull-request@v7
        with:
          token: ${{ secrets.TEMP_METAL_PAT }}
          commit-message: "chore: update LLK submodule to ${{ steps.update-submodule.outputs.new-sha }}"
          title: "chore: update LLK submodule to ${{ steps.update-submodule.outputs.new-sha }}"
          branch: ${{ env.BRANCH_NAME }}
          delete-branch: true
          body-path: llk_commit_log.txt
          add-paths: |
            ${{ env.SUBMODULE_PATH }}
          draft: ${{ !inputs.skip_draft }}
          labels: |
            llk-update
            automated

      - name: Update PR body with changes information
        if: steps.update-submodule.outputs.has-changes == 'true'
        env:
          GH_TOKEN: ${{ secrets.TEMP_METAL_PAT }}
        run: |
          PR_NUMBER="${{ steps.create-pr.outputs.pull-request-number }}"
          PR_URL="https://github.com/${{ github.repository }}/pull/$PR_NUMBER"
          OLD_SHA="${{ steps.update-submodule.outputs.old-sha }}"
          NEW_SHA="${{ steps.update-submodule.outputs.new-sha }}"

          # Get the changed files again for the updated body
          cd ${{ env.SUBMODULE_PATH }}
          CHANGED_FILES=$(git diff --name-only ${OLD_SHA}..${NEW_SHA})
          COMMIT_COUNT=$(git log --oneline ${OLD_SHA}..${NEW_SHA} | wc -l)
          FILE_COUNT=$(echo "$CHANGED_FILES" | wc -l)

          # Detect potential API breaking changes in C++ headers
          HEADER_CHANGES=$(echo "$CHANGED_FILES" | grep -E "\.(h|hpp)$")
          API_WARNINGS=""

          if [ -n "$HEADER_CHANGES" ]; then
            echo "üîç Analyzing C++ header changes for API compatibility..."
            # Check for potential breaking changes in headers
            while IFS= read -r header; do
              if [ -n "$header" ]; then
                # Look for common API breaking patterns in the diff
                DIFF_OUTPUT=$(git diff ${OLD_SHA}..${NEW_SHA} -- "$header" 2>/dev/null || echo "")

                # Check for potentially breaking function signature changes
                # Look for function definitions/declarations that changed
                REMOVED_FUNCTIONS=$(echo "$DIFF_OUTPUT" | grep -E "^-\s*(template\s*<|inline\s+|static\s+|extern\s+|virtual\s+)*\s*\w+.*\(" | head -5)
                ADDED_FUNCTIONS=$(echo "$DIFF_OUTPUT" | grep -E "^+\s*(template\s*<|inline\s+|static\s+|extern\s+|virtual\s+)*\s*\w+.*\(" | head -5)

                if [ -n "$REMOVED_FUNCTIONS" ] && [ -n "$ADDED_FUNCTIONS" ]; then
                  # Check for template parameter changes (breaking)
                  if echo "$DIFF_OUTPUT" | grep -qE "^-.*template\s*<.*>" && echo "$DIFF_OUTPUT" | grep -qE "^+.*template\s*<.*>"; then
                    API_WARNINGS="$API_WARNINGS\n- üö® **$header**: Template parameter changes detected (breaking)"
                  fi

                  # Check for argument order changes or type changes (breaking)
                  # This is a heuristic: if we see the same function name but different parameter patterns
                  while IFS= read -r removed_func; do
                    if [ -n "$removed_func" ]; then
                      # Extract function name (simplified)
                      FUNC_NAME=$(echo "$removed_func" | sed 's/^-[^(]*\s\+\([a-zA-Z_][a-zA-Z0-9_]*\)\s*(.*/\1/')
                      if [ -n "$FUNC_NAME" ] && echo "$ADDED_FUNCTIONS" | grep -q "$FUNC_NAME"; then
                        # Same function name exists in both removed and added - likely parameter change
                        API_WARNINGS="$API_WARNINGS\n- üö® **$header**: Function '$FUNC_NAME' signature changed (potentially breaking)"
                      fi
                    fi
                  done <<< "$REMOVED_FUNCTIONS"

                  # Check for simple extensions (non-breaking) - functions with same prefix but more params
                  # If all removed functions have corresponding added functions with same prefix, it might be safe extension
                  EXTENSION_SAFE=true
                  while IFS= read -r removed_func; do
                    if [ -n "$removed_func" ]; then
                      # Extract the part before the last parameter
                      FUNC_PREFIX=$(echo "$removed_func" | sed 's/^-//' | sed 's/,[^,]*)/)/g')
                      if [ -n "$FUNC_PREFIX" ] && ! echo "$ADDED_FUNCTIONS" | grep -q "$(echo "$FUNC_PREFIX" | sed 's/)/,.*)/g')"; then
                        EXTENSION_SAFE=false
                        break
                      fi
                    fi
                  done <<< "$REMOVED_FUNCTIONS"

                  if [ "$EXTENSION_SAFE" = "false" ]; then
                    API_WARNINGS="$API_WARNINGS\n- ‚ö†Ô∏è **$header**: Function signature changes detected (review required)"
                  fi
                fi

                # Check for removed functions/classes
                if echo "$DIFF_OUTPUT" | grep -qE "^-\s*(class|struct|enum|typedef|#define|inline|static|extern)"; then
                  API_WARNINGS="$API_WARNINGS\n- üö® **$header**: Removed declarations detected"
                fi

                # Check for namespace changes
                if echo "$DIFF_OUTPUT" | grep -q "^-.*namespace" || echo "$DIFF_OUTPUT" | grep -q "^+.*namespace"; then
                  API_WARNINGS="$API_WARNINGS\n- ‚ö†Ô∏è **$header**: Namespace changes detected"
                fi

                # Check for macro changes
                if echo "$DIFF_OUTPUT" | grep -qE "^-\s*#define" && echo "$DIFF_OUTPUT" | grep -qE "^+\s*#define"; then
                  API_WARNINGS="$API_WARNINGS\n- ‚ö†Ô∏è **$header**: Macro definition changes detected"
                fi
              fi
            done <<< "$HEADER_CHANGES"
          fi

          # Generate updated PR body with focus on API impact
          cat > ../../../updated_llk_commit_log.txt << EOF
          ## üîÑ LLK Submodule Update

          **Summary:** Updating LLK submodule from \`$OLD_SHA\` to \`$NEW_SHA\` ($COMMIT_COUNT commits, $FILE_COUNT files)

          $(if [ -n "$API_WARNINGS" ]; then echo "### üö® Potential API Impact"; echo -e "$API_WARNINGS"; echo ""; echo "**‚ö†Ô∏è Review Required**: Changes to C++ headers detected. Please verify compatibility with existing tt-metal code."; echo ""; fi)

          ### üèóÔ∏è Architecture Impact
          $(if echo "$CHANGED_FILES" | grep -q "^tt_llk_wormhole_b0/"; then echo "- **Wormhole**: Changes detected - will trigger all-post-commit tests"; fi)
          $(if echo "$CHANGED_FILES" | grep -q "^tt_llk_blackhole/"; then echo "- **Blackhole**: Changes detected - will trigger blackhole-post-commit tests"; fi)
          $(if ! echo "$CHANGED_FILES" | grep -q "^tt_llk_wormhole_b0/\|^tt_llk_blackhole/"; then echo "- **Cross-Architecture**: Changes affect common/shared components"; fi)

          ### üìù Commits Uplifted ($COMMIT_COUNT commits)
          ${{ steps.analyze-changes.outputs.commits-table }}

          ### üìÅ Files Changed ($FILE_COUNT files)
          <details>
          <summary>üìÅ View all changed files ($FILE_COUNT)</summary>

          \`\`\`
          $(echo "$CHANGED_FILES")
          \`\`\`
          </details>

          **Links:** [Compare Changes](https://github.com/tenstorrent/tt-llk/compare/$OLD_SHA...$NEW_SHA) | [LLK Repository](https://github.com/tenstorrent/tt-llk)

          ---
          *Auto-generated by LLK Auto-Uplift workflow. Test results will be posted below.*
          EOF

          # Update the PR body with the new content including PR link
          gh pr edit "$PR_NUMBER" --body-file ../../../updated_llk_commit_log.txt --repo "${{ github.repository }}"

          echo "‚úÖ Updated PR #$PR_NUMBER with PR link"

      - name: No changes summary
        if: steps.update-submodule.outputs.has-changes == 'false'
        run: |
          echo "üéâ LLK submodule is already up to date!"
          echo "Current SHA: ${{ steps.update-submodule.outputs.old-sha }}"

  trigger-and-monitor-workflows:
    needs: [llk-submodule-uplift]
    if: needs.llk-submodule-uplift.outputs.has-changes == 'true' && (needs.llk-submodule-uplift.outputs.should-run-wormhole == 'true' || needs.llk-submodule-uplift.outputs.should-run-blackhole == 'true')
    runs-on: ubuntu-latest
    steps:
      - name: Checkout for GitHub CLI
        uses: actions/checkout@v4

      - name: Trigger and monitor workflows
        env:
          GH_TOKEN: ${{ secrets.TEMP_METAL_PAT }}
        run: |
          set -euo pipefail
          TIMEOUT_MINUTES=${{ inputs.workflow_timeout || 120 }}

          # Build workflow list based on detected changes
          WORKFLOWS_TO_RUN=()

          if [ "${{ needs.llk-submodule-uplift.outputs.should-run-wormhole }}" == "true" ]; then
            WORKFLOWS_TO_RUN+=("all-post-commit-workflows.yaml")
          fi

          if [ "${{ needs.llk-submodule-uplift.outputs.should-run-blackhole }}" == "true" ]; then
            WORKFLOWS_TO_RUN+=("blackhole-post-commit.yaml")
          fi

          if [ ${#WORKFLOWS_TO_RUN[@]} -eq 0 ]; then
            echo "No workflows to trigger based on changes detected"
            exit 0
          fi

          echo "üöÄ Triggering ${#WORKFLOWS_TO_RUN[@]} workflow(s)..."

          # Trigger workflows and collect run IDs
          RUN_IDS=()
          for workflow in "${WORKFLOWS_TO_RUN[@]}"; do
            echo "Triggering $workflow..."

            # Get existing runs before triggering to establish baseline
            EXISTING_RUNS=$(gh run list --workflow "$workflow" --branch "${{ env.BRANCH_NAME }}" --limit 10 --json databaseId --jq '.[].databaseId' | tr '\n' ' ')
            echo "Existing runs before trigger: $EXISTING_RUNS"

            if gh workflow run "$workflow" --ref "${{ env.BRANCH_NAME }}" --repo "${{ github.repository }}"; then
              echo "‚úÖ Successfully triggered $workflow"

              # Wait for the new run to appear with retry logic
              RUN_ID=""
              for i in {1..12}; do
                # Get current runs and find the new one
                CURRENT_RUNS=$(gh run list --workflow "$workflow" --branch "${{ env.BRANCH_NAME }}" --limit 10 --json databaseId --jq '.[].databaseId')

                # Find the run that wasn't in the existing list
                for run_id in $CURRENT_RUNS; do
                  if [[ ! " $EXISTING_RUNS " =~ " $run_id " ]]; then
                    RUN_ID="$run_id"
                    break
                  fi
                done

                if [ -n "$RUN_ID" ] && [ "$RUN_ID" != "null" ]; then
                  break
                fi
                echo "Attempt $i: Waiting for new workflow run to appear..."
                sleep 10
              done

              if [ -n "$RUN_ID" ] && [ "$RUN_ID" != "null" ]; then
                RUN_IDS+=("$RUN_ID")
                echo "Monitoring run ID: $RUN_ID"

                # Comment on PR with workflow link
                RUN_URL="https://github.com/${{ github.repository }}/actions/runs/$RUN_ID"
                gh pr comment "${{ needs.llk-submodule-uplift.outputs.pr-number }}" \
                  --body "üîÑ **$workflow** triggered: [View run]($RUN_URL)" \
                  --repo "${{ github.repository }}"
              fi
            else
              echo "‚ùå Failed to trigger $workflow"
            fi
          done

          if [ ${#RUN_IDS[@]} -eq 0 ]; then
            echo "‚ùå No workflows were successfully triggered"
            exit 1
          fi

          # Monitor all runs
          echo "‚è≥ Monitoring ${#RUN_IDS[@]} workflow run(s)..."

          START_TIME=$(date +%s)
          TIMEOUT_SECONDS=$((TIMEOUT_MINUTES * 60))
          ALL_SUCCESS=true

          while [ ${#RUN_IDS[@]} -gt 0 ]; do
            # Check timeout
            CURRENT_TIME=$(date +%s)
            ELAPSED=$((CURRENT_TIME - START_TIME))

            if [ $ELAPSED -ge $TIMEOUT_SECONDS ]; then
              echo "‚è∞ Timeout reached after ${TIMEOUT_MINUTES} minutes"
              for run_id in "${RUN_IDS[@]}"; do
                RUN_URL="https://github.com/${{ github.repository }}/actions/runs/$run_id"
                gh pr comment "${{ needs.llk-submodule-uplift.outputs.pr-number }}" \
                  --body "‚è∞ **Workflow timed out** after ${TIMEOUT_MINUTES} minutes: [View run]($RUN_URL)" \
                  --repo "${{ github.repository }}"
              done
              ALL_SUCCESS=false
              break
            fi

            # Check status of all runs
            REMAINING_RUNS=()
            for run_id in "${RUN_IDS[@]}"; do
              STATUS=$(gh run view "$run_id" --json status --jq '.status // "unknown"' 2>/dev/null || echo "unknown")

              if [ "$STATUS" == "completed" ]; then
                CONCLUSION=$(gh run view "$run_id" --json conclusion --jq '.conclusion // "unknown"')
                RUN_URL="https://github.com/${{ github.repository }}/actions/runs/$run_id"

                if [ "$CONCLUSION" == "success" ]; then
                  echo "‚úÖ Run $run_id completed successfully"
                  gh pr comment "${{ needs.llk-submodule-uplift.outputs.pr-number }}" \
                    --body "‚úÖ **Workflow passed**: [View run]($RUN_URL)" \
                    --repo "${{ github.repository }}"
                else
                  echo "‚ùå Run $run_id failed with conclusion: $CONCLUSION"
                  gh pr comment "${{ needs.llk-submodule-uplift.outputs.pr-number }}" \
                    --body "‚ùå **Workflow failed** (conclusion: \`$CONCLUSION\`): [View run]($RUN_URL)" \
                    --repo "${{ github.repository }}"
                  ALL_SUCCESS=false
                fi
              else
                # Still running, keep monitoring
                REMAINING_RUNS+=("$run_id")
                echo "‚åõ Run $run_id status: $STATUS (${ELAPSED}s/${TIMEOUT_SECONDS}s)"
              fi
            done

            RUN_IDS=("${REMAINING_RUNS[@]}")

            # Wait before next check
            if [ ${#RUN_IDS[@]} -gt 0 ]; then
              sleep 60
            fi
          done

          if [ "$ALL_SUCCESS" == "true" ]; then
            echo "üéâ All workflows completed successfully"
          else
            echo "üí• One or more workflows failed or timed out"
            exit 1
          fi

  finalize:
    needs: [llk-submodule-uplift, trigger-and-monitor-workflows]
    if: always() && needs.llk-submodule-uplift.outputs.has-changes == 'true' && needs.llk-submodule-uplift.result == 'success' && (needs.trigger-and-monitor-workflows.result == 'success' || needs.trigger-and-monitor-workflows.result == 'skipped')
    runs-on: ubuntu-latest
    steps:
      - name: Auto-merge PR
        env:
          GH_TOKEN: ${{ secrets.TEMP_METAL_PAT }}
        run: |
          echo "üöÄ Finalizing PR merge..."

          PR_NUMBER="${{ needs.llk-submodule-uplift.outputs.pr-number }}"

          # Mark PR as ready if it was created as draft
          if [ "${{ inputs.skip_draft }}" != "true" ]; then
            echo "üìù Marking PR as ready for review..."
            if ! gh pr ready "$PR_NUMBER" --repo "${{ github.repository }}"; then
              echo "‚ö†Ô∏è Unable to mark PR as ready - may already be ready or have insufficient permissions"
            fi
          fi

          # Comment on PR that it's ready for review
          echo "üìù PR #$PR_NUMBER is ready for review and merge"
          gh pr comment "$PR_NUMBER" \
            --body "üéâ **LLK submodule update completed successfully!**
            All workflows have passed. This PR is ready for review and merge." \
            --repo "${{ github.repository }}" || echo "‚ö†Ô∏è Unable to comment on PR - insufficient permissions"

          echo "‚úÖ Workflow completed successfully - PR #$PR_NUMBER is ready for manual review"
