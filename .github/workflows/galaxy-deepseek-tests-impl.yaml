name: "[internal] Galaxy DeepSeek tests impl"

on:
  workflow_call:
    inputs:
      docker-image:
        required: true
        type: string
      build-artifact-name:
        required: true
        type: string
      wheel-artifact-name:
        required: true
        type: string
      extra-tag:
        required: false
        type: string
        default: "in-service"
      topology:
        required: false
        type: string
        default: "topology-6u"
      test-type:
        required: false
        type: string
        default: "all"

jobs:
  generate-matrix:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.generate.outputs.matrix }}
    steps:
      - name: Generate test matrix
        id: generate
        run: |
          all_tests=$(jq -n '[
            { "name": "(Galaxy) DeepSeek unit tests", "arch": "wormhole_b0", "model": "deepseek", "test-type": "unit", "timeout": 15, "owner_id": "U03HY7MK4BT" },
            { "name": "(Galaxy) DeepSeek module tests", "arch": "wormhole_b0", "model": "deepseek", "test-type": "module", "timeout": 150, "owner_id": "U03HY7MK4BT" }
          ]')

          # Filter matrix based on test-type selection
          if [ "${{ inputs.test-type }}" = "all" ]; then
            matrix="$all_tests"
          else
            matrix=$(echo "$all_tests" | jq -c "[.[] | select(.\"test-type\" == \"${{ inputs.test-type }}\")]")
          fi

          # Fail fast if the matrix is empty (invalid test-type selected)
          if [ "$(echo "$matrix" | jq length)" -eq 0 ]; then
            echo "Error: Invalid test-type selected: '${{ inputs.test-type }}'"
            exit 1
          fi
          echo "matrix=$(echo "$matrix" | jq -c .)" >> $GITHUB_OUTPUT

  galaxy-deepseek-tests:
    needs: generate-matrix
    name: ${{ matrix.test-group.name }}
    strategy:
      fail-fast: false
      matrix:
        test-group: ${{ fromJson(needs.generate-matrix.outputs.matrix) }}
    runs-on:
      - arch-wormhole_b0
      - ${{ inputs.topology }}
      - bare-metal
      - pipeline-functional
      - ${{ inputs.extra-tag }}
    container:
      image: ${{ inputs.docker-image }}
      env:
        TT_METAL_HOME: /work
        PYTHONPATH: /work
        LD_LIBRARY_PATH: /work/build/lib
        LOGURU_LEVEL: INFO
        ARCH_NAME: ${{ matrix.test-group.arch }}
        DEEPSEEK_V3_HF_MODEL: /mnt/MLPerf/tt_dnn-models/deepseek-ai/DeepSeek-R1-0528
        DEEPSEEK_V3_CACHE: /mnt/MLPerf/tt_dnn-models/deepseek-ai/DeepSeek-R1-0528-Cache/CI
        MESH_DEVICE: TG
      volumes:
        - ${{ github.workspace }}/docker-job:/work # Subdir to workaround https://github.com/actions/runner/issues/691
        - /dev/hugepages-1G:/dev/hugepages-1G
        - /mnt/MLPerf:/mnt/MLPerf:ro
      options: "--device /dev/tenstorrent"
    defaults:
      run:
        shell: bash
        working-directory: /work # https://github.com/actions/runner/issues/878
    steps:
      - name: ðŸ§¬ Checkout Repository
        uses: actions/checkout@v4
        with:
          submodules: recursive
          path: docker-job
      - name: â¬‡ï¸  Setup Job
        uses: ./docker-job/.github/actions/setup-job
        timeout-minutes: 10
        with:
          build-artifact-name: ${{ inputs.build-artifact-name }}
          wheel-artifact-name: ${{ inputs.wheel-artifact-name }}
      - name: Run DeepSeek unit tests
        if: ${{ matrix.test-group.test-type == 'unit' }}
        timeout-minutes: ${{ matrix.test-group.timeout }}
        run: |
          uv pip install -r models/demos/deepseek_v3/reference/deepseek/requirements.txt
          pytest models/demos/deepseek_v3/tests/unit --timeout 60 --durations=0
      - name: Validate weight cache
        if: ${{ matrix.test-group.test-type == 'module' }}
        timeout-minutes: 10
        run: |
          python3 models/demos/deepseek_v3/scripts/validate_weight_cache.py --root "$DEEPSEEK_V3_CACHE/tests_cache" || true
      - name: Run DeepSeek module tests
        if: ${{ matrix.test-group.test-type == 'module' }}
        timeout-minutes: ${{ matrix.test-group.timeout }}
        run: |
          uv pip install -r models/demos/deepseek_v3/reference/deepseek/requirements.txt
          pytest models/demos/deepseek_v3/tests --ignore=models/demos/deepseek_v3/tests/unit --timeout 600  --durations=0
      - uses: tenstorrent/tt-metal/.github/actions/slack-report@main
        if: ${{ failure() }}
        with:
          slack_webhook_url: ${{ secrets.SLACK_METAL_INFRA_PIPELINE_STATUS_ALERT }}
          owner: ${{ matrix.test-group.owner_id }}
      # - name: Save environment data
      #   id: save-environment-data
      #   if: ${{ !cancelled() }}
      #   run: |
      #     if [ -d "generated/benchmark_data" ]; then
      #       echo "has_benchmark_data=true" >> $GITHUB_OUTPUT
      #       python3 .github/scripts/data_analysis/create_benchmark_with_environment_json.py
      #     else
      #       echo "::warning::Benchmark data directory 'generated/benchmark_data' does not exist"
      #       echo "has_benchmark_data=false" >> $GITHUB_OUTPUT
      #     fi
      # - name: Upload benchmark data
      #   if: ${{ !cancelled() && steps.save-environment-data.conclusion == 'success' && steps.save-environment-data.outputs.has_benchmark_data == 'true' }}
      #   uses: tenstorrent/tt-metal/.github/actions/upload-data-via-sftp@main
      #   with:
      #     ssh-private-key: ${{ secrets.SFTP_BENCHMARK_WRITER_KEY }}
      #     sftp-batchfile: .github/actions/upload-data-via-sftp/benchmark_data_batchfile.txt
      #     username: ${{ secrets.SFTP_BENCHMARK_WRITER_USERNAME }}
      #     hostname: ${{ secrets.SFTP_BENCHMARK_WRITER_HOSTNAME }}
      #     path: /work
      - uses: tenstorrent/tt-metal/.github/actions/upload-artifact-with-job-uuid@main
        timeout-minutes: 10
        if: ${{ !cancelled() }}
        with:
          prefix: "test_reports_"
      - uses: tenstorrent/tt-metal/.github/actions/cleanup@main
