name: "[internal] Produce GitHub Merge Queue data"

on:
  # test on your branch
  push:
    branches:
      - ashah/merge-queue

  # test in PR
  pull_request:
    types: [opened, synchronize, reopened]

  workflow_dispatch:

  # runs after merge to main
  schedule:
    - cron: "*/5 * * * *"

permissions:
  contents: read
  pull-requests: read

jobs:
  produce-merge-queue:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      # ------------------------------------------------------------
      # Verify token works
      # ------------------------------------------------------------
      - name: Check GitHub API rate limit
        env:
          GH_TOKEN: ${{ github.token }}
        run: gh api rate_limit

      # ------------------------------------------------------------
      # Fetch REAL merge queue using GraphQL
      # ------------------------------------------------------------
      - name: Fetch merge queue
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          set -euo pipefail

          gh api graphql -f query='
          query {
            repository(owner: "tenstorrent", name: "tt-metal") {
              mergeQueue {
                entries(first: 100) {
                  nodes {
                    pullRequest {
                      number
                      title
                      author { login }
                      headRefOid
                    }
                  }
                }
              }
            }
          }
          ' > merge_queue_raw.json

          echo "[Info] Raw merge queue size:"
          jq '.data.repository.mergeQueue.entries.nodes | length' merge_queue_raw.json

      # ------------------------------------------------------------
      # Build snapshot JSON
      # ------------------------------------------------------------
      - name: Build merge queue snapshot
        run: |
          set -euo pipefail

          mkdir -p generated/merge_queue
          COLLECTED_AT=$(date -u +"%Y-%m-%dT%H:%M:%SZ")

          jq --arg repo "tenstorrent/tt-metal" --arg ts "$COLLECTED_AT" '
          {
            repository: $repo,
            collected_at: $ts,
            merge_queue: [
              .data.repository.mergeQueue.entries.nodes[].pullRequest | {
                merge_queue_id: null,
                pr_number: .number,
                pr_title: .title,
                pr_author_login: .author.login,
                head_sha: .headRefOid,
                state: "IN_QUEUE",
                queue_position: null,
                enqueued_at: null,
                estimated_time_to_merge_sec: null,
                collected_at: $ts
              }
            ]
          }
          ' merge_queue_raw.json \
            > generated/merge_queue/merge_queue_snapshot.json

          echo "[Info] Snapshot size:"
          jq '.merge_queue | length' generated/merge_queue/merge_queue_snapshot.json

      # ------------------------------------------------------------
      # Timestamp filename
      # ------------------------------------------------------------
      - name: Add timestamp to filename
        run: |
          TS=$(date -u +"%Y%m%dT%H%M%SZ")

          mv generated/merge_queue/merge_queue_snapshot.json \
             generated/merge_queue/${TS}_merge_queue_snapshot.json

          ls -lh generated/merge_queue

      # ------------------------------------------------------------
      # Upload via SFTP
      # ------------------------------------------------------------
      - name: Upload merge queue data via SFTP
        uses: ./.github/actions/upload-data-via-sftp
        with:
          ssh-private-key: ${{ secrets.SFTP_MERGE_QUEUE_WRITER_KEY }}
          username: ${{ secrets.SFTP_MERGE_QUEUE_WRITER_USERNAME }}
          hostname: ${{ secrets.SFTP_MERGE_QUEUE_WRITER_HOSTNAME }}
          sftp-batchfile: .github/actions/upload-data-via-sftp/merge_queue_data_batchfile.txt
