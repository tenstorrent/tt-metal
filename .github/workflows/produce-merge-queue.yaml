name: "[internal] Produce GitHub Merge Queue data"

on:
  push:
    branches:
      - ashah/merge-queue   

  workflow_dispatch:

  # Runs automatically every 5 minutes after merge to main
  schedule:
    - cron: "*/5 * * * *"

permissions:
  contents: read
  pull-requests: read

jobs:
  produce-merge-queue:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      # ------------------------------------------------------------
      # Fetch ALL open PR numbers (pagination prevents truncation)
      # ------------------------------------------------------------
      - name: Fetch open PR numbers
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          set -euo pipefail

          gh api --paginate \
            /repos/tenstorrent/tt-metal/pulls \
            | jq '.[].number' > pr_numbers.txt

      # ------------------------------------------------------------
      # Fetch FULL PR objects (mergeable_state is computed here)
      # ------------------------------------------------------------
      - name: Fetch PR details
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          set -euo pipefail

          gh api --paginate \
            /repos/tenstorrent/tt-metal/pulls \
            > pulls_full.json
      # ------------------------------------------------------------
      # Build merge queue snapshot with REAL state mapping
      # ------------------------------------------------------------
      - name: Build merge queue snapshot
        run: |
          set -euo pipefail

          mkdir -p generated/merge_queue
          COLLECTED_AT=$(date -u +"%Y-%m-%dT%H:%M:%SZ")

          jq --arg repo "tenstorrent/tt-metal" --arg ts "$COLLECTED_AT" '
          def map_state(ms):
            if ms == "clean" then "PASSED_GATE"
            elif ms == "blocked" then "IN_QUEUE"
            elif ms == "unstable" then "FAILED_GATE"
            elif ms == "dirty" then "FAILED_GATE"
            else "NOT_QUEUED"
            end;

          {
            repository: $repo,
            collected_at: $ts,
            merge_queue: [
              .[] | {
                merge_queue_id: null,
                pr_number: .number,
                pr_title: .title,
                pr_author_login: .user.login,
                head_sha: .head.sha,
                state: map_state(.mergeable_state),
                queue_position: null,
                enqueued_at: null,
                estimated_time_to_merge_sec: null,
                collected_at: $ts
              }
            ]
          }
          ' pulls_full.json > generated/merge_queue/merge_queue_snapshot.json

      # ------------------------------------------------------------
      # Timestamp filename (prevents overwrite + enables lineage)
      # ------------------------------------------------------------
      - name: Timestamp snapshot
        run: |
          TS=$(date -u +"%Y%m%dT%H%M%SZ")

          mv generated/merge_queue/merge_queue_snapshot.json \
             generated/merge_queue/${TS}_merge_queue_snapshot.json

      # ------------------------------------------------------------
      # Upload to SFTP (Airflow watches this)
      # ------------------------------------------------------------
      - name: Upload merge queue data via SFTP
        uses: ./.github/actions/upload-data-via-sftp
        with:
          ssh-private-key: ${{ secrets.SFTP_MERGE_QUEUE_WRITER_KEY }}
          username: ${{ secrets.SFTP_MERGE_QUEUE_WRITER_USERNAME }}
          hostname: ${{ secrets.SFTP_MERGE_QUEUE_WRITER_HOSTNAME }}
          sftp-batchfile: .github/actions/upload-data-via-sftp/merge_queue_data_batchfile.txt
