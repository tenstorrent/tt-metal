name: "[internal] vLLM nightly tests impl"

on:
  workflow_call:
    inputs:
      docker-image:
        required: true
        type: string
      wheel-artifact-name:
        required: true
        type: string
      build-artifact-name:
        required: true
        type: string
      vllm-commit:
        description: "vLLM branch or sha"
        required: false
        default: dev
        type: string
      model:
        description: "Model to test (or 'all' for all models)"
        required: false
        type: string
        default: "all"

jobs:
  generate-matrix:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.generate.outputs.matrix }}
    steps:
      - name: Generate test matrix
        id: generate
        run: |
          # Owner mapping:
          # Pavle Petrovic (U08E1JCDVNX), Salar Hosseini Khorasgani (U08CEGF78ET) - Llama models
          # Gongyu Wang (U07RY6B5FLJ) - Qwen models
          # Ambrose Ling (U08GELBB1AP) - BH tests
          # Tomasz Cheda (U091SNDA4TS) - Structured output tests
          # Radoica Draskic (U08BH66EXAL) - DP tests
          # Harry Andrews (U08TJ70UFRT), Stuti Raizada (U06F3ER8X9A) - GPT-OSS

          # Note: This matrix must be kept in sync with the original static matrix
          all_tests='[
            {
              "name": "[WH-T3K] Llama-3.1-8B-Instruct",
              "model": "meta-llama/Llama-3.1-8B-Instruct",
              "server-timeout": 10,
              "benchmark-timeout": 5,
              "runner-label": "config-t3000",
              "arch": "arch-wormhole_b0",
              "mesh-device": "T3K",
              "tt-llama-text-ver": "tt_transformers",
              "override-tt-config": "{\"fabric_config\": \"FABRIC_1D\"}",
              "multimodal": false,
              "co-owner-1-id": "U08E1JCDVNX",
              "co-owner-2-id": "U08CEGF78ET"
            },
            {
              "name": "[WH-T3K] Qwen2.5-VL-72B-Instruct",
              "model": "Qwen/Qwen2.5-VL-72B-Instruct",
              "server-timeout": 10,
              "benchmark-timeout": 10,
              "runner-label": "config-t3000",
              "arch": "arch-wormhole_b0",
              "mesh-device": "T3K",
              "tt-llama-text-ver": "tt_transformers",
              "override-tt-config": "{\"fabric_config\": \"FABRIC_1D\", \"trace_region_size\": 28467200}",
              "multimodal": true,
              "additional-server-args": "--max_model_len 2048",
              "co-owner-1-id": "U07RY6B5FLJ"
            },
            {
              "name": "[BH-DB] Llama-3.1-8B-Instruct",
              "model": "meta-llama/Llama-3.1-8B-Instruct",
              "server-timeout": 20,
              "benchmark-timeout": 5,
              "runner-label": "BH-DeskBox",
              "arch": "arch-blackhole",
              "mesh-device": "P150x2",
              "tt-llama-text-ver": "tt_transformers",
              "override-tt-config": "{\"data_parallel\": 2}",
              "multimodal": false,
              "owner_id": "U08GELBB1AP"
            },
            {
              "name": "[BH-LB] Llama-3.1-8B-Instruct v0 fallback structured-output",
              "model": "meta-llama/Llama-3.1-8B-Instruct",
              "server-timeout": 35,
              "benchmark-timeout": 10,
              "runner-label": "bh-loudbox",
              "arch": "arch-blackhole",
              "mesh-device": "P150x8",
              "tt-llama-text-ver": "tt_transformers",
              "override-tt-config": "{\"data_parallel\": 8, \"sample_on_device_mode\": \"decode_only\"}",
              "multimodal": false,
              "structured-output": true,
              "additional-server-args": "--num_scheduler_steps 1",
              "owner_id": "U091SNDA4TS"
            },
            {
              "name": "[WH-GLX] Llama-3.3-70B-Instruct multi-step",
              "model": "meta-llama/Llama-3.3-70B-Instruct",
              "server-timeout": 35,
              "benchmark-timeout": 10,
              "runner-label": "topology-6u",
              "arch": "arch-wormhole_b0",
              "mesh-device": "TG",
              "tt-llama-text-ver": "llama3_70b_galaxy",
              "override-tt-config": "{\"dispatch_core_axis\": \"col\", \"sample_on_device_mode\": \"all\", \"fabric_config\": \"FABRIC_1D_RING\", \"worker_l1_size\": 1344544, \"trace_region_size\": 184915840}",
              "multimodal": false,
              "co-owner-1-id": "U08E1JCDVNX",
              "co-owner-2-id": "U08CEGF78ET"
            },
            {
              "name": "[WH-GLX] Llama-3.3-70B-Instruct v0 structured-output",
              "model": "meta-llama/Llama-3.3-70B-Instruct",
              "server-timeout": 35,
              "benchmark-timeout": 10,
              "runner-label": "topology-6u",
              "arch": "arch-wormhole_b0",
              "mesh-device": "TG",
              "tt-llama-text-ver": "llama3_70b_galaxy",
              "override-tt-config": "{\"dispatch_core_axis\": \"col\", \"fabric_config\": \"FABRIC_1D_RING\", \"worker_l1_size\": 1344544, \"trace_region_size\": 184915840}",
              "multimodal": false,
              "structured-output": true,
              "additional-server-args": "--num_scheduler_steps 1",
              "owner_id": "U091SNDA4TS"
            },
            {
              "name": "[WH-GLX] Llama-3.3-70B-Instruct v0 fallback structured-output",
              "model": "meta-llama/Llama-3.3-70B-Instruct",
              "server-timeout": 35,
              "benchmark-timeout": 10,
              "runner-label": "topology-6u",
              "arch": "arch-wormhole_b0",
              "mesh-device": "TG",
              "tt-llama-text-ver": "llama3_70b_galaxy",
              "override-tt-config": "{\"dispatch_core_axis\": \"col\", \"sample_on_device_mode\": \"all\", \"fabric_config\": \"FABRIC_1D_RING\", \"worker_l1_size\": 1344544, \"trace_region_size\": 184915840}",
              "multimodal": false,
              "structured-output": true,
              "additional-server-args": "--num_scheduler_steps 1",
              "owner_id": "U091SNDA4TS"
            },
            {
              "name": "[WH-GLX] Llama-8B DP=16",
              "model": "meta-llama/Llama-3.1-8B-Instruct",
              "server-timeout": 10,
              "benchmark-timeout": 5,
              "runner-label": "topology-6u",
              "arch": "arch-wormhole_b0",
              "mesh-device": "TG",
              "override-tt-config": "{\"data_parallel\": 16, \"fabric_config\": \"FABRIC_1D_RING\"}",
              "tt-llama-text-ver": "tt_transformers",
              "multimodal": false,
              "co-owner-1-id": "U08E1JCDVNX",
              "co-owner-2-id": "U08BH66EXAL"
            },
            {
              "name": "[WH-T3K][v1] Gemma3-27B",
              "model": "google/gemma-3-27b-it",
              "server-timeout": 20,
              "benchmark-timeout": 5,
              "runner-label": "config-t3000",
              "arch": "arch-wormhole_b0",
              "mesh-device": "T3K",
              "override-tt-config": "{\"sample_on_device_mode\": \"decode_only\", \"fabric_config\": \"FABRIC_1D\", \"worker_l1_size\": 1344544, \"trace_region_size\": 50000000, \"l1_small_size\": 24576}",
              "tt-llama-text-ver": "tt_transformers",
              "multimodal": true,
              "use-vllm-v1": true,
              "co-owner-1-id": "U08E1JCDVNX",
              "co-owner-2-id": "U08BH66EXAL"
            },
            {
              "name": "[WH-GLX][v1] Gemma3-27B DP=4",
              "model": "google/gemma-3-27b-it",
              "server-timeout": 20,
              "benchmark-timeout": 5,
              "runner-label": "topology-6u",
              "arch": "arch-wormhole_b0",
              "mesh-device": "(4, 8)",
              "override-tt-config": "{\"sample_on_device_mode\": \"decode_only\", \"fabric_config\": \"FABRIC_1D_RING\", \"worker_l1_size\": 1344544, \"trace_region_size\": 50000000, \"l1_small_size\": 24576}",
              "additional-server-args": "--data_parallel_size 4 --max_num_seqs 32",
              "tt_mm_throttle_perf": 5,
              "tt-llama-text-ver": "tt_transformers",
              "multimodal": true,
              "use-vllm-v1": true,
              "co-owner-1-id": "U08E1JCDVNX",
              "co-owner-2-id": "U08BH66EXAL"
            },
            {
              "name": "[WH-GLX][v1] GPT-OSS-120B",
              "model": "openai/gpt-oss-120b",
              "server-timeout": 35,
              "benchmark-timeout": 10,
              "runner-label": "topology-6u",
              "arch": "arch-wormhole_b0",
              "mesh-device": "(4, 8)",
              "multimodal": false,
              "tt-llama-text-ver": "tt_transformers",
              "additional-server-args": "--max_num_seqs 1 --num_scheduler_steps 1",
              "use-vllm-v1": true,
              "structured-output": true,
              "co-owner-1-id": "U08TJ70UFRT",
              "co-owner-2-id": "U06F3ER8X9A"
            },
            {
              "name": "[WH-T3K][v1] Llama-3.1-8B-Instruct",
              "model": "meta-llama/Llama-3.1-8B-Instruct",
              "server-timeout": 10,
              "benchmark-timeout": 5,
              "runner-label": "config-t3000",
              "arch": "arch-wormhole_b0",
              "mesh-device": "T3K",
              "tt-llama-text-ver": "tt_transformers",
              "override-tt-config": "{\"fabric_config\": \"FABRIC_1D\"}",
              "use-vllm-v1": true,
              "structured-output": true,
              "multimodal": false,
              "co-owner-1-id": "U08E1JCDVNX",
              "co-owner-2-id": "U08CEGF78ET"
            },
            {
              "name": "[WH-T3K][v1] Llama-3.1-8B-Instruct (prefix caching)",
              "model": "meta-llama/Llama-3.1-8B-Instruct",
              "server-timeout": 10,
              "benchmark-timeout": 5,
              "runner-label": "config-t3000",
              "arch": "arch-wormhole_b0",
              "mesh-device": "T3K",
              "tt-llama-text-ver": "tt_transformers",
              "override-tt-config": "{\"fabric_config\": \"FABRIC_1D\"}",
              "use-vllm-v1": true,
              "multimodal": false,
              "additional-benchmark-args": "--random-prefix-len 128",
              "co-owner-1-id": "U08E1JCDVNX",
              "co-owner-2-id": "U08CEGF78ET"
            },
            {
              "name": "[WH-T3K][v1] Qwen2.5-VL-72B-Instruct",
              "model": "Qwen/Qwen2.5-VL-72B-Instruct",
              "server-timeout": 10,
              "benchmark-timeout": 10,
              "runner-label": "config-t3000",
              "arch": "arch-wormhole_b0",
              "mesh-device": "T3K",
              "tt-llama-text-ver": "tt_transformers",
              "override-tt-config": "{\"fabric_config\": \"FABRIC_1D\", \"trace_region_size\": 28467200}",
              "use-vllm-v1": true,
              "structured-output": true,
              "multimodal": true,
              "additional-server-args": "--max_model_len 2048",
              "co-owner-1-id": "U07RY6B5FLJ"
            },
            {
              "name": "[BH-LB][v1] Llama-3.1-8B-Instruct",
              "model": "meta-llama/Llama-3.1-8B-Instruct",
              "server-timeout": 35,
              "benchmark-timeout": 10,
              "runner-label": "bh-loudbox",
              "arch": "arch-blackhole",
              "mesh-device": "P150x8",
              "tt-llama-text-ver": "tt_transformers",
              "override-tt-config": "{\"data_parallel\": 8}",
              "additional-server-args": "--data_parallel_size 8",
              "use-vllm-v1": true,
              "structured-output": true,
              "multimodal": false,
              "owner_id": "U08GELBB1AP"
            },
            {
              "name": "[WH-GLX][v1] Llama-3.3-70B-Instruct device sampling",
              "model": "meta-llama/Llama-3.3-70B-Instruct",
              "server-timeout": 35,
              "benchmark-timeout": 10,
              "runner-label": "topology-6u",
              "arch": "arch-wormhole_b0",
              "mesh-device": "TG",
              "tt-llama-text-ver": "llama3_70b_galaxy",
              "override-tt-config": "{\"dispatch_core_axis\": \"col\", \"sample_on_device_mode\": \"all\", \"fabric_config\": \"FABRIC_1D_RING\", \"worker_l1_size\": 1344544, \"trace_region_size\": 184915840}",
              "additional-server-args": "--data_parallel_size 4 --max_num_seqs 8",
              "use-vllm-v1": true,
              "multimodal": false,
              "co-owner-1-id": "U08E1JCDVNX",
              "co-owner-2-id": "U08CEGF78ET"
            },
            {
              "name": "[WH-GLX][v1] Llama-3.3-70B-Instruct hostsample",
              "model": "meta-llama/Llama-3.3-70B-Instruct",
              "server-timeout": 35,
              "benchmark-timeout": 10,
              "runner-label": "topology-6u",
              "arch": "arch-wormhole_b0",
              "mesh-device": "TG",
              "tt-llama-text-ver": "llama3_70b_galaxy",
              "override-tt-config": "{\"dispatch_core_axis\": \"col\", \"fabric_config\": \"FABRIC_1D_RING\", \"worker_l1_size\": 1344544, \"trace_region_size\": 184915840}",
              "additional-server-args": "--data_parallel_size 4 --max_num_seqs 8",
              "use-vllm-v1": true,
              "structured-output": true,
              "multimodal": false,
              "co-owner-1-id": "U08E1JCDVNX",
              "co-owner-2-id": "U08CEGF78ET"
            },
            {
              "name": "[WH-GLX][v1] Llama-8B DP=16",
              "model": "meta-llama/Llama-3.1-8B-Instruct",
              "server-timeout": 10,
              "benchmark-timeout": 5,
              "runner-label": "topology-6u",
              "arch": "arch-wormhole_b0",
              "mesh-device": "TG",
              "override-tt-config": "{\"data_parallel\": 16, \"fabric_config\": \"FABRIC_1D_RING\"}",
              "tt-llama-text-ver": "tt_transformers",
              "additional-server-args": "--data_parallel_size 16",
              "use-vllm-v1": true,
              "structured-output": true,
              "multimodal": false,
              "co-owner-1-id": "U08E1JCDVNX",
              "co-owner-2-id": "U08BH66EXAL"
            },
            {
              "name": "[WH-T3K][v1] Multi-process reduce scatter test model",
              "model": "models/vllm_test_utils/t3000_multiproc_test",
              "server-timeout": 4,
              "benchmark-timeout": 4,
              "runner-label": "config-t3000",
              "arch": "arch-wormhole_b0",
              "mesh-device": "(2, 4)",
              "override-tt-config": "{\"rank_binding\": \"tests/tt_metal/distributed/config/2x4_multiprocess_rank_bindings.yaml\", \"mpi_args\": \"--allow-run-as-root --tag-output\", \"config_pkl_dir\": \"vllm\", \"register_test_models\": true}",
              "additional-server-args": "--data_parallel_size 8 --tokenizer meta-llama/Llama-3.1-8B-Instruct",
              "additional-benchmark-args": "--tokenizer meta-llama/Llama-3.1-8B-Instruct",
              "use-vllm-v1": true,
              "multimodal": false,
              "co-owner-1-id": "U08CEGF78ET"
            }
          ]'

          # Filter matrix based on model selection
          if [ "${{ inputs.model }}" = "all" ]; then
            matrix="$all_tests"
          else
            matrix=$(echo "$all_tests" | jq -c "[.[] | select(.model == \"${{ inputs.model }}\")]")
          fi

          echo "matrix=$(echo "$matrix" | jq -c .)" >> $GITHUB_OUTPUT

  vllm-tests:
    needs: generate-matrix
    strategy:
      fail-fast: false
      matrix:
        test-group: ${{ fromJson(needs.generate-matrix.outputs.matrix) }}
    name: ${{ matrix.test-group.name }}
    runs-on:
      - ${{ matrix.test-group.runner-label }}
      - ${{ matrix.test-group.arch }}
      - in-service
      - pipeline-functional
    container:
      image: ${{ inputs.docker-image }}
      env:
        TT_METAL_HOME: /work
        vllm_dir: /work/vllm
        VLLM_TARGET_DEVICE: "tt"
        PYTHONPATH: /work:/work/vllm
        LD_LIBRARY_PATH: /work/build/lib
        LOGURU_LEVEL: INFO
        HF_HUB_OFFLINE: 1
        HF_HUB_CACHE: /mnt/MLPerf/huggingface/hub
        TT_CACHE_HOME: /mnt/MLPerf/huggingface/tt_cache
        FILE_SERVER_PID: "./server.pid"
        FILE_SERVER_LOG: "./output/vllm_server.log"
        FILE_BENCHMARK_LOG: "./output/vllm_benchmark.log"
        FILE_BENCHMARK_STRUCTURED_OUTPUT_LOG: "./output/vllm_benchmark_structured_output.log"
        FILE_MULTIMODAL_TEST_LOG: "./output/vllm_multimodal_test.log"
      volumes:
        - ${{ github.workspace }}/docker-job:/work # Subdir to workaround https://github.com/actions/runner/issues/691
        - /dev/hugepages-1G:/dev/hugepages-1G
        - /mnt/MLPerf:/mnt/MLPerf:ro
      options: "--device /dev/tenstorrent"
    defaults:
      run:
        shell: bash
        working-directory: /work # https://github.com/actions/runner/issues/878
    steps:
      - name: ðŸ§¬ Checkout Repository
        uses: actions/checkout@v4
        with:
          submodules: recursive
          path: docker-job
      - name: â¬‡ï¸ Setup Metal
        uses: ./docker-job/.github/actions/setup-job
        timeout-minutes: 10
        with:
          build-artifact-name: ${{ inputs.build-artifact-name }}
          wheel-artifact-name: ${{ inputs.wheel-artifact-name }}

      - name: Ensure BH Eth links online
        if: ${{ contains(matrix.test-group.mesh-device, 'P150') }}
        uses: tenstorrent/tt-metal/.github/actions/ensure-bh-links-online@main
        timeout-minutes: 10
        with:
          runner-label: ${{ matrix.test-group.runner-label }}

      - name: â¬‡ï¸ Checkout vLLM
        uses: actions/checkout@v4
        with:
          repository: tenstorrent/vllm
          path: docker-job/vllm
          ref: ${{ inputs.vllm-commit }}
          fetch-depth: 0

      - name: ðŸ“€ Install vLLM
        run: |
          uv pip install vllm/ --extra-index-url https://download.pytorch.org/whl/cpu --index-strategy unsafe-best-match

      - name: ðŸ“‚ Create output directory
        run: |
          mkdir -p output

      - name: ðŸš€ Run server
        timeout-minutes: 1
        run: |
          OVERRIDE_TT_CONFIG_RAW='${{ matrix.test-group.override-tt-config }}'
          if [ -n "$OVERRIDE_TT_CONFIG_RAW" ]; then
            OVERRIDE_TT_CONFIG=(--override-tt-config "$OVERRIDE_TT_CONFIG_RAW")
          else
            OVERRIDE_TT_CONFIG=()
          fi

          if [ -n "${{ matrix.test-group.additional-server-args }}" ]; then
            ADDITIONAL_SERVER_ARGS=(${{ matrix.test-group.additional-server-args }})
          else
            ADDITIONAL_SERVER_ARGS=()
          fi

          export MESH_DEVICE="${{ matrix.test-group.mesh-device }}"
          if [ -n "${{ matrix.test-group.tt-llama-text-ver }}" ]; then
            export TT_LLAMA_TEXT_VER="${{ matrix.test-group.tt-llama-text-ver }}"
          fi

          # Keep TT cache separate from HF hub
          export HF_MODEL="${{ matrix.test-group.model }}"
          MODEL_NAME="${HF_MODEL/\//--}"
          export TT_CACHE_PATH="$TT_CACHE_HOME/$MODEL_NAME"

          # vLLM environment variables
          export VLLM_RPC_TIMEOUT=300000
          USE_V1="${{ matrix.test-group.use-vllm-v1 }}"
          if [[ "${USE_V1}" == "true" ]]; then
            export VLLM_USE_V1=1
          fi

          if [ -n "${{ matrix.test-group.tt_mm_throttle_perf }}" ]; then
            export TT_MM_THROTTLE_PERF="${{ matrix.test-group.tt_mm_throttle_perf }}"
          fi

          # Build the VLLM server arguments array
          declare -a VLLM_SERVER_ARGS
          VLLM_SERVER_ARGS+=(--model "$HF_MODEL")
          VLLM_SERVER_ARGS+=("${ADDITIONAL_SERVER_ARGS[@]}")
          VLLM_SERVER_ARGS+=("${OVERRIDE_TT_CONFIG[@]}")
          if [[ "${USE_V1}" == "true" ]]; then
            VLLM_SERVER_ARGS+=("--num_scheduler_steps" "1")
          fi

          echo "vLLM server args: ${VLLM_SERVER_ARGS[@]}"

          python3 vllm/examples/server_example_tt.py "${VLLM_SERVER_ARGS[@]}" > "${FILE_SERVER_LOG}" 2>&1 &

          # Store server's pid for cleanup
          echo $! > ${FILE_SERVER_PID}

      - name: â° Wait for server to be ready
        run: |
          echo "Waiting for server..."

          timeout_seconds=$(( ${{ matrix.test-group.server-timeout }} * 60 ))
          elapsed=0
          interval=20

          while [ $elapsed -lt $timeout_seconds ]; do
            if curl -sf http://localhost:8000/health; then
              echo "Server is up! ðŸš€ [$elapsed sec]"
              exit 0
            fi
            sleep $interval
            elapsed=$((elapsed + interval))
          done

          echo "âŒ Server did not become ready in time (${timeout_seconds}s)."
          echo "Check out the server log in a step below."
          exit 1

      - name: ðŸ“ Run benchmark
        timeout-minutes: ${{ matrix.test-group.benchmark-timeout }}
        run: |
          if [ -n "${{ matrix.test-group.additional-benchmark-args }}" ]; then
            ADDITIONAL_BENCHMARK_ARGS=(${{ matrix.test-group.additional-benchmark-args }})
          else
            ADDITIONAL_BENCHMARK_ARGS=()
          fi

          vllm bench serve \
            --backend vllm \
            --model ${{ matrix.test-group.model }} \
            --dataset-name random \
            --random-input-len 100 \
            --random-output-len 100 \
            --num-prompts 32 \
            --ignore-eos \
            --percentile-metrics ttft,tpot,itl,e2el \
            --save-result \
            --result-filename output/vllm_result.json \
            "${ADDITIONAL_BENCHMARK_ARGS[@]}" \
            2>&1 | tee ${FILE_BENCHMARK_LOG}

          # If the backend fails, the benchmark will still complete successfully but with all-zero results.
          # It will contain a warning message, though
          warning_message="All requests failed"
          if grep -q "$warning_message" "${FILE_BENCHMARK_LOG}"; then
            echo "âŒ All requests failed"
            echo "Check out the server log in a step below."
            exit 1
          fi
      - name: ðŸ“ Run structured output benchmark
        if: ${{ matrix.test-group.structured-output }}
        timeout-minutes: ${{ matrix.test-group.benchmark-timeout }}
        run: |
          if [ -n "${{ matrix.test-group.additional-benchmark-args }}" ]; then
            ADDITIONAL_BENCHMARK_ARGS=(${{ matrix.test-group.additional-benchmark-args }})
          else
            ADDITIONAL_BENCHMARK_ARGS=()
          fi

          python3 vllm/benchmarks/benchmark_serving_structured_output.py \
            --backend vllm \
            --model ${{ matrix.test-group.model }} \
            --num-prompts 32 \
            --percentile-metrics ttft,tpot,itl,e2el \
            --save-result \
            --result-filename output/vllm_result_structured.json \
            "${ADDITIONAL_BENCHMARK_ARGS[@]}" \
            2>&1 | tee ${FILE_BENCHMARK_STRUCTURED_OUTPUT_LOG}

          # The benchmark returns zero even if responses are not correct.
          success_message="correct_rate(%) 100.0"
          if grep -q "$success_message" "${FILE_BENCHMARK_STRUCTURED_OUTPUT_LOG}"; then
            echo "âœ… Structured output benchmark completed successfully"
          else
            echo "âŒ Structured output benchmark failed"
            echo "Check out the server log in a step below."
            exit 1
          fi

      - name: ðŸ–¼ï¸ Run multimodal test
        if: ${{ matrix.test-group.multimodal }}
        timeout-minutes: ${{ matrix.test-group.benchmark-timeout }}
        run: |
          curl http://localhost:8000/v1/chat/completions \
            -H "Content-Type: application/json" \
            -H "X-User-ID: vllm_test" \
            -d '{
              "model": "${{ matrix.test-group.model }}",
              "messages": [
                {
                  "role": "user",
                  "content": [
                    {
                      "type": "text",
                      "text": "Describe this image in 50 words."
                    },
                    {
                      "type": "image_url",
                      "image_url": {
                        "url": "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/cats.jpeg"
                      }
                    }
                  ]
                }
              ],
              "max_tokens": 512,
              "temperature": 0.0,
              "top_p": 0.9,
              "top_k": 10,
              "repetition_penalty": 1.0,
              "stream": false,
              "ignore_eos": false
          }' \
          2>&1 | tee ${FILE_MULTIMODAL_TEST_LOG}

          # If the test fails, the response will not contain the expected word
          keyword="cat"
          if ! grep -q -i "$keyword" "${FILE_MULTIMODAL_TEST_LOG}"; then
            echo "âŒ The keyword \"$keyword\" not found in the response"
            echo "Check out the server log in a step below."
            exit 1
          fi
      - name: ðŸ§¹ Cleanup server process
        if: always()
        run: |
          if [ -f "${FILE_SERVER_PID}" ]; then
            pid=$(cat "${FILE_SERVER_PID}")
            if kill -0 "$pid" 2>/dev/null; then
              kill "$pid"
              echo "âœ… Server process with PID $pid terminated."
              rm -f "${FILE_SERVER_PID}"
            else
              echo "âŒ Server process already down!"
              echo "Check out the server log in a step below."
              exit 1
            fi
          else
            echo "âŒ PID file not found. Server may not have started correctly."
            exit 1
          fi

      - name: Show server log
        if: always()
        continue-on-error: true
        run: |
          cat "${FILE_SERVER_LOG}"

      - name: Show report
        if: always()
        continue-on-error: true
        run: |
          cat output/vllm_result.json

      - name: Show structured output report
        if: ${{ always() && matrix.test-group.structured-output }}
        continue-on-error: true
        run: |
          cat output/vllm_result_structured.json

      - uses: ./.github/actions/slack-report
        if: ${{ failure() }}
        with:
          slack_webhook_url: ${{ secrets.SLACK_METAL_INFRA_PIPELINE_STATUS_ALERT }}
          owner: ${{ matrix.test-group.co-owner-1-id }}

      - uses: ./.github/actions/slack-report
        if: ${{ failure() }}
        with:
          slack_webhook_url: ${{ secrets.SLACK_METAL_INFRA_PIPELINE_STATUS_ALERT }}
          owner: ${{ matrix.test-group.co-owner-2-id }}

      - name: Set artifact prefix
        if: ${{ !cancelled() }}
        id: set-artifact-prefix
        run: |
          # Replace spaces with underscores
          SAFE_NAME=$(echo "${{ matrix.test-group.name }}" | tr ' ' '_')
          echo "prefix=vllm_output_${SAFE_NAME}_" >> $GITHUB_OUTPUT

      - uses: tenstorrent/tt-metal/.github/actions/upload-artifact-with-job-uuid@main
        timeout-minutes: 10
        if: ${{ !cancelled() }}
        with:
          path: docker-job/output/
          prefix: ${{ steps.set-artifact-prefix.outputs.prefix }}

      - uses: tenstorrent/tt-metal/.github/actions/cleanup@main
        if: always()
