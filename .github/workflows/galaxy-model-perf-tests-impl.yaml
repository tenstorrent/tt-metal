name: "[internal] Galaxy model perf tests impl"

on:
  workflow_call:
    inputs:
      build-artifact-name:
        required: true
        type: string
      wheel-artifact-name:
        required: true
        type: string
      docker-image:
        required: true
        type: string
      model:
        required: false
        type: string
        default: "all"
      extra-tag:
        required: false
        type: string
        default: "in-service"
      topology:
        required: false
        type: string
        default: "topology-6u"

jobs:
  generate-matrix:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
    steps:
      - name: Generate Matrix
        id: set-matrix
        run: |
          # Create matrix in two parts: disabled and active models
          DISABLED_MODELS=$(jq -n '[
            {
              "name": "Galaxy CNN model perf tests",
              "model-type": "CNN",
              "model-name": "cnn",
              "arch": "wormhole_b0",
              "save-perf-data": false,
              "timeout": 50,
              "cmd": "TT_METAL_CORE_GRID_OVERRIDE_TODEPRECATE=\"7,7\" pytest -n auto models/demos/ttnn_resnet/tests/test_perf_e2e_resnet50.py -m \"model_perf_tg\" && python3 models/perf/merge_perf_results.py --upper-threshold 1.10"
            }, # Pavle Josipovic
            {
              "name": "Galaxy Llama 70B model perf tests",
              "model-type": "Llama-70B",
              "model-name": "llama70b",
              "arch": "wormhole_b0",
              "save-perf-data": true,
              "timeout": 60,
              "cmd": "TT_METAL_KERNELS_EARLY_RETURN=1 TT_METAL_ENABLE_ERISC_IRAM=1 FAKE_DEVICE=TG LLAMA_DIR=/mnt/MLPerf/tt_dnn-models/llama/Llama3.3-70B-Instruct/ pytest -n auto models/demos/llama3_70b_galaxy/tests/test_decoder_device_perf.py::test_llama_TG_perf_device_non_overlapped_dispatch --timeout=600 && TT_METAL_ENABLE_ERISC_IRAM=1 FAKE_DEVICE=TG LLAMA_DIR=/mnt/MLPerf/tt_dnn-models/llama/Llama3.3-70B-Instruct/ pytest -n auto models/demos/llama3_70b_galaxy/tests/test_decoder_device_perf.py::test_llama_TG_perf_device --timeout=600",
              "owner_id": "U053W15B6JF"
            }, # Djordje Ivanovic
            {
              "name": "Llama Galaxy Perf Unit Tests",
              "model-name": "llama_unit_tests",
              "arch": "wormhole_b0",
              "cmd": "LLAMA_DIR=/mnt/MLPerf/tt_dnn-models/llama/Llama3.3-70B-Instruct/ pytest models/demos/llama3_70b_galaxy/tests/tg_perf_unit_tests",
              "timeout": 100,
              "tracy": true,
              "save-perf-data": true,
              "owner_id": "U053W15B6JF"
            }, # Djordje Ivanovic
            {
              "name": "Galaxy Llama 70B prefill perf tests",
              "model-type": "Llama-70B",
              "model-name": "llama70b_prefill",
              "arch": "wormhole_b0",
              "save-perf-data": true,
              "timeout": 60,
              "cmd": "FAKE_DEVICE=TG LLAMA_DIR=/mnt/MLPerf/tt_dnn-models/llama/Llama3.3-70B-Instruct/ pytest -n auto models/demos/llama3_70b_galaxy/tests/test_prefill_device_perf.py::test_llama_TG_perf_device --timeout=1000",
              "owner_id": "U03PUAKE719"
            }, # Miguel Tairum
            {
              "name": "Galaxy Sentence Bert tests",
              "arch": "wormhole_b0",
              "model-type": "sentence_bert",
              "model-name": "sentence_bert",
              "save-perf-data": false,
              "cmd": "pytest models/demos/tg/sentence_bert/tests/device_perf_test.py && python3 models/perf/merge_perf_results.py",
              "timeout": 30,
              "owner_id": "U088413NP0Q"
            } # Ashai Reddy
          ]' --compact-output)

          ACTIVE_MODELS=$(jq -n '[
            {
              "name": "Galaxy DiT SD3.5 model perf tests",
              "model-type": "SD3.5",
              "model-name": "sd35",
              "arch": "wormhole_b0",
              "save-perf-data": true,
              "timeout": 50,
              "cmd": "pytest models/experimental/tt_dit/tests/models/sd35/test_performance_sd35.py -k \"4x8cfg1sp0tp1\"",
              "owner_id": "U03FJB5TM5Y"
            }, # Colman Glagovich
            {
              "name": "Galaxy DiT Flux.1 model perf tests",
              "model-type": "Flux.1-Dev",
              "model-name": "flux1-dev",
              "arch": "wormhole_b0",
              "save-perf-data": true,
              "timeout": 50,
              "cmd": "HF_HUB_CACHE=/mnt/MLPerf/huggingface/hub pytest models/experimental/tt_dit/tests/models/flux1/test_performance_flux1.py -k \"wh_4x8sp0tp1\"",
              "owner_id": "U08TED0JM9D"
            }, # Samuel Adesoye
            {
              "name": "Galaxy DiT Motif model perf tests",
              "model-type": "Motif",
              "model-name": "motif",
              "arch": "wormhole_b0",
              "save-perf-data": true,
              "timeout": 15,
              "cmd": "HF_HUB_CACHE=/mnt/MLPerf/huggingface/hub pytest models/experimental/tt_dit/tests/models/motif/test_performance_motif.py -k \"4x8cfg1sp0tp1\"",
              "owner_id": "U08TED0JM9D"
            }, # Samuel Adesoye
            {
              "name": "Galaxy DiT Wan2.2 model perf tests",
              "model-type": "Wan2.2",
              "model-name": "wan2-2",
              "arch": "wormhole_b0",
              "save-perf-data": true,
              "timeout": 35,
              "cmd": "export TT_DIT_CACHE_DIR=\"/tmp/TT_DIT_CACHE\" && pytest models/experimental/tt_dit/tests/models/wan2_2/test_performance_wan.py -k \"wh_4x8sp1tp0 and resolution_720p\"",
              "owner_id": "U03FJB5TM5Y"
            }, # Colman Glagovich
            {
              "name": "Galaxy Mochi model perf tests",
              "model-type": "mochi",
              "model-name": "mochi",
              "arch": "wormhole_b0",
              "save-perf-data": true,
              "timeout": 50,
              "cmd": "export TT_DIT_CACHE_DIR=\"/tmp/TT_DIT_CACHE\" && export NO_PROMPT=1 && pytest models/experimental/tt_dit/tests/models/mochi/test_performance_mochi.py -k \"4x8sp1tp0 \"",
              "owner_id": "U09ELB03XRU"
            }, # Stephen Osborne
            {
              "name": "Galaxy DiT Qwen-Image model perf tests",
              "model-type": "QwenImage",
              "model-name": "qwenimage",
              "arch": "wormhole_b0",
              "save-perf-data": true,
              "timeout": 20,
              "cmd": "export TT_DIT_CACHE_DIR=\"/tmp/TT_DIT_CACHE\" && pytest models/experimental/tt_dit/tests/models/qwenimage/test_performance_qwenimage.py -k \"4x8\"",
              "owner_id": "U08TED0JM9D"
            } # Samuel Adesoye
          ]' --compact-output)

          # Combine both arrays into full matrix
          FULL_MATRIX=$ACTIVE_MODELS

          # Filter matrix based on model selection
          if [ "${{ inputs.model }}" = "all" ]; then
            echo "matrix=$FULL_MATRIX" >> $GITHUB_OUTPUT
          else
            FILTERED_MATRIX=$(echo "$FULL_MATRIX" | jq --arg model "${{ inputs.model }}" '[.[] | select(.["model-name"] == $model)]' --compact-output)
            echo "matrix=$FILTERED_MATRIX" >> $GITHUB_OUTPUT
          fi

  galaxy-model-perf-tests:
    needs: generate-matrix
    strategy:
      fail-fast: false
      matrix:
        test-group: ${{ fromJson(needs.generate-matrix.outputs.matrix) }}
    name: ${{ matrix.test-group.name }}
    env:
      ARCH_NAME: ${{ matrix.test-group.arch }}
      LOGURU_LEVEL: INFO
      LD_LIBRARY_PATH: ${{ github.workspace }}/build/lib
      TT_METAL_HOME: ${{ github.workspace }}
      PYTHONPATH: ${{ github.workspace }}
    runs-on:
      - arch-wormhole_b0
      - ${{ inputs.topology }}
      - ${{ inputs.extra-tag }}
    steps:
      - name: ⬇️ Checkout
        uses: actions/checkout@v4
        with:
          submodules: recursive
      - name: Enable performance mode
        run: |
          sudo cpupower frequency-set -g performance
      - uses: ./.github/actions/ensure-active-weka-mount
      - name: ⬇️ Download Build
        uses: actions/download-artifact@634f93cb2916e3fdff6788551b99b062d0335ce0 # v5.0
        timeout-minutes: 10
        with:
          name: ${{ inputs.build-artifact-name || 'build artifact not specified' }}
      - name: Extract files
        run: tar --zstd -xvf ttm_any.tar.zst
      - name: ⬇️ Download Wheel
        uses: actions/download-artifact@634f93cb2916e3fdff6788551b99b062d0335ce0 # v5.0
        timeout-minutes: 10
        with:
          name: ${{ inputs.wheel-artifact-name || 'wheel artifact not specified' }}
      - name: Run model perf regression tests
        timeout-minutes: ${{ matrix.test-group.timeout }}
        uses: ./.github/actions/docker-run
        env:
          LOGURU_LEVEL: INFO
        with:
          docker_image: ${{ inputs.docker-image }}
          docker_password: ${{ secrets.GITHUB_TOKEN }}
          docker_opts: |
            -e TT_METAL_HOME=${{ github.workspace }}
            -e ARCH_NAME=${{ matrix.test-group.arch }}
            -e LD_LIBRARY_PATH=${{ github.workspace }}/build/lib
            -v /mnt/MLPerf:/mnt/MLPerf:ro
          install_wheel: true
          run_args: |
            ${{ matrix.test-group.cmd }}
      - name: Check if benchmark data directory exists
        id: check-benchmark-data-directory
        if: ${{ matrix.test-group.save-perf-data && !cancelled() }}
        run: |
          if [ -d "generated/benchmark_data" ]; then
            echo "has_benchmark_data=true" >> $GITHUB_OUTPUT
          else
            echo "::warning::Benchmark data directory 'generated/benchmark_data' does not exist"
            echo "has_benchmark_data=false" >> $GITHUB_OUTPUT
          fi
      - name: Save environment data
        id: save-environment-data
        if: ${{ matrix.test-group.save-perf-data && !cancelled() && steps.check-benchmark-data-directory.outputs.has_benchmark_data == 'true' }}
        uses: ./.github/actions/docker-run
        with:
          docker_image: ${{ inputs.docker-image }}
          docker_password: ${{ secrets.GITHUB_TOKEN }}
          docker_opts: |
            -e TT_METAL_HOME=${{ github.workspace }}
            -e ARCH_NAME=${{ matrix.test-group.arch }}
            -e LD_LIBRARY_PATH=${{ github.workspace }}/build/lib
          install_wheel: true
          run_args: |
            python3 .github/scripts/data_analysis/create_benchmark_with_environment_json.py
      - name: Upload benchmark data
        if: ${{ matrix.test-group.save-perf-data && !cancelled() && steps.save-environment-data.conclusion == 'success' }}
        uses: ./.github/actions/upload-data-via-sftp
        with:
          ssh-private-key: ${{ secrets.SFTP_BENCHMARK_WRITER_KEY }}
          sftp-batchfile: .github/actions/upload-data-via-sftp/benchmark_data_batchfile.txt
          username: ${{ secrets.SFTP_BENCHMARK_WRITER_USERNAME }}
          hostname: ${{ secrets.SFTP_BENCHMARK_WRITER_HOSTNAME }}
      - name: Check perf report exists
        id: check-perf-report
        if: ${{ !(matrix.test-group.save-perf-data) && !cancelled() }}
        run: |
          TODAY=$(date +%Y_%m_%d)
          PERF_REPORT_FILENAME_MODELS="Models_Perf_${TODAY}.csv"
          PERF_REPORT_FILENAME_CCL_ALL_GATHER="CCL_all_gather_Perf_${TODAY}.csv"
          PERF_REPORT_FILENAME_CCL_REDUCE_SCATTER="CCL_reduce_scatter_Perf_${TODAY}.csv"
          if [ "${{ matrix.test-group.tracy }}" == "true" ]; then
            found_reports=false
            if [ -f "$PERF_REPORT_FILENAME_CCL_ALL_GATHER" ]; then
              echo "Found CCL AllGather Perf report: $PERF_REPORT_FILENAME_CCL_ALL_GATHER"
              echo "perf_report_filename_all_gather=$PERF_REPORT_FILENAME_CCL_ALL_GATHER" >> "$GITHUB_OUTPUT"
              found_reports=true
            fi
            if [ -f "$PERF_REPORT_FILENAME_CCL_REDUCE_SCATTER" ]; then
              echo "Found CCL ReduceScatter Perf report: $PERF_REPORT_FILENAME_CCL_REDUCE_SCATTER"
              echo "perf_report_filename_reduce_scatter=$PERF_REPORT_FILENAME_CCL_REDUCE_SCATTER" >> "$GITHUB_OUTPUT"
              found_reports=true
            fi
            if [ "$found_reports" = false ]; then
              echo "No CCL perf report found for today."
              exit 1
            fi
          else
            if [ -f "$PERF_REPORT_FILENAME_MODELS" ]; then
              echo "Found Models Perf report: $PERF_REPORT_FILENAME_MODELS"
              echo "perf_report_filename=$PERF_REPORT_FILENAME_MODELS" >> "$GITHUB_OUTPUT"
            else
              echo "No Models perf report found for today."
              exit 1
            fi
          fi
      - name: Upload Models perf report
        if: ${{ !cancelled() && steps.check-perf-report.conclusion == 'success' && !matrix.test-group.tracy }}
        uses: actions/upload-artifact@v4
        timeout-minutes: 10
        with:
          name: perf-report-csv-${{ matrix.test-group.model-type }}-${{ matrix.test-group.arch }}-${{ matrix.test-group.machine-type }}
          path: "${{ steps.check-perf-report.outputs.perf_report_filename }}"
      - name: Upload CCL perf report
        if: ${{ !cancelled() && steps.check-perf-report.conclusion == 'success' && matrix.test-group.tracy }}
        uses: actions/upload-artifact@v4
        timeout-minutes: 10
        with:
          name: perf-report-csv-${{ matrix.test-group.model-type }}-${{ matrix.test-group.arch }}-${{ matrix.test-group.model }}-bare-metal
          path:
            ${{ steps.check-perf-report.outputs.perf_report_filename_all_gather }}
      - uses: tenstorrent/tt-metal/.github/actions/slack-report@main
        if: ${{ failure() }}
        with:
          slack_webhook_url: ${{ secrets.SLACK_METAL_INFRA_PIPELINE_STATUS_ALERT }}
          owner: ${{ matrix.test-group.owner_id }}
      - uses: tenstorrent/tt-metal/.github/actions/upload-artifact-with-job-uuid@main
        timeout-minutes: 10
        if: ${{ !cancelled() }}
        with:
          path: generated/test_reports/
          prefix: "test_reports_"
      - name: Disable performance mode
        if: always()
        run: |
          sudo cpupower frequency-set -g ondemand
