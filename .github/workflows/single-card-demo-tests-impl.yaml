name: "[internal] Single-card Demo tests impl"

on:
  workflow_call:
    inputs:
      build-artifact-name:
        required: true
        type: string
      docker-image:
        required: true
        type: string
      wheel-artifact-name:
        required: true
        type: string
      arch:
        required: true
        type: string
      extra-tag:
        required: false
        type: string
        default: "in-service"
      requested-models:
        default: "all"
        type: string
      run-perf-tests:
        type: boolean
        default: true

jobs:
  define-demo-tests:
    runs-on: ubuntu-latest
    outputs:
      demo-tests: ${{ steps.compute-tests.outputs.demo-tests }}
    strategy:
      matrix:
        default-demo-tests:
          [[
            { name: "llama3", runner-label: "N150", performance: false, cmd: run_llama3_func, owner_id: U03PUAKE719}, # Miguel Tairum
            { name: "llama3", runner-label: "N300", performance: false, cmd: run_llama3_func, owner_id: U03PUAKE719}, # Miguel Tairum
            { name: "llama3", runner-label: "N300", performance: true, cmd: run_llama3_perf, owner_id: U03PUAKE719}, # Miguel Tairum
            { name: "qwen25_vl", runner-label: "N300", performance: true, cmd: run_qwen25_vl_perfunc, owner_id: U07RY6B5FLJ},  #Gongyu Wang
            { name: "ds_r1_qwen", runner-label: "N300", performance: false, cmd: run_ds_r1_qwen_func, owner_id: U07RY6B5FLJ, civ2-compatible: true},  #Gongyu Wang

          ]]
    steps:
      - name: Compute tests
        shell: bash
        id: compute-tests
        run: |
          set -euo pipefail

          echo "[info] Outputing default values"
          default_demo_tests='${{ toJSON(matrix.default-demo-tests) }}'
          echo $default_demo_tests
          echo "[info] Outputing default values via jq"
          echo $default_demo_tests | jq
          requested_demo_tests=$default_demo_tests

          requested_models=${{ toJSON(inputs.requested-models) }}
          echo "[info] requested-models: $requested_models"
          run_perf_tests=${{ inputs.run-perf-tests }}
          echo "[info] run-perf-tests: $run_perf_tests"

          if [[ "$requested_models" != "all" ]]; then
            requested_demo_tests=$(jq --argjson requested_models "$requested_models" '[.[] | select(.name | IN($requested_models[]))]' <<< "$requested_demo_tests")
            echo "[info] after filtering for requested models: $requested_demo_tests"
          fi

          # By default, test list includes perf tests. If we don't want to run perf tests,
          # filter them out
          if [[ "$run_perf_tests" == "false" ]]; then
            requested_demo_tests=$(jq '[.[] | select(.performance == false)]' <<< "$requested_demo_tests")
            echo "[info] after filtering filtering out perf tests: $requested_demo_tests"
          fi

          # Check that we have a valid test list that's not empty
          echo "$requested_demo_tests" | jq -e 'if type != "array" then error("Not a valid JSON array") elif length == 0 then error("Test list is empty") else . end' && echo "Valid test configs"

          echo "demo-tests=$(echo $requested_demo_tests | tr -d '\n')" >> "$GITHUB_OUTPUT"

          echo "[info] Showing GITHUB_OUTPUT"
          cat "$GITHUB_OUTPUT"

  single-card-demo-tests:
    needs: define-demo-tests
    strategy:
      fail-fast: false
      matrix:
        test-group: ${{ fromJSON(needs.define-demo-tests.outputs.demo-tests) }}
    name: ${{ matrix.test-group.name }}-${{ matrix.test-group.runner-label }}-${{ (matrix.test-group.performance && 'perf') || 'func' }}
    runs-on: >-
      ${{
        matrix.test-group.civ2-compatible == true
        && format('tt-ubuntu-2204-{0}-stable', matrix.test-group.runner-label)
        || (matrix.test-group.runner-label == 'N300' && matrix.test-group.performance)
          && fromJSON(format('["{0}", "{1}", "bare-metal", "pipeline-perf"]',
              matrix.test-group.runner-label,
              inputs.extra-tag
            ))
          || fromJSON(format('["{0}", "{1}", "cloud-virtual-machine"]',
              matrix.test-group.runner-label,
              inputs.extra-tag
            ))
      }}
    container:
      image: ${{ inputs.docker-image || 'docker-image-unresolved!' }}
      env:
        TT_METAL_HOME: /work
        PYTHONPATH: /work
        LD_LIBRARY_PATH: /work/build/lib
        ARCH_NAME: ${{ inputs.arch }}
        LOGURU_LEVEL: INFO
        GITHUB_ACTIONS: true
        GTEST_OUTPUT: xml:/work/generated/test_reports/
        HF_HUB_CACHE: ${{ (!matrix.test-group.civ2-compatible && '/mnt/MLPerf/huggingface/hub') || '' }}
        HTTP_PROXY: ${{ (matrix.test-group.civ2-compatible && env.HTTP_PROXY) || '' }}
        HTTPS_PROXY: ${{ (matrix.test-group.civ2-compatible && env.HTTPS_PROXY) || '' }}
        NO_PROXY: ${{ (matrix.test-group.civ2-compatible && env.NO_PROXY) || '' }}
      volumes:
        - ${{ github.workspace }}/docker-job:/work # Subdir to workaround https://github.com/actions/runner/issues/691
        - /dev/hugepages-1G:/dev/hugepages-1G
        - /mnt/MLPerf:/mnt/MLPerf:ro
      options: >-
        --device /dev/tenstorrent ${{ matrix.test-group.civ2-compatible == true && '-e TT_GH_CI_INFRA=1' || '' }} --cap-add=ALL --security-opt seccomp=unconfined --ulimit nproc=65536:65536 --ulimit nofile=65536:65536 --privileged -v /sys:/sys
    defaults:
      run:
        shell: bash
        working-directory: /work # https://github.com/actions/runner/issues/878
    steps:
      - name: ⬇️  Setup Job
        uses: tenstorrent/tt-metal/.github/actions/setup-job@main
        timeout-minutes: 10
        with:
          build-artifact-name: ${{ inputs.build-artifact-name }}
          wheel-artifact-name: ${{ inputs.wheel-artifact-name }}
      - name: Extract files
        run: tar --zstd -xvf ttm_any.tar.zst
      - name: ⬇️ Download Wheel
        uses: actions/download-artifact@634f93cb2916e3fdff6788551b99b062d0335ce0 # v5.0
        timeout-minutes: 10
        with:
          name: ${{ inputs.wheel-artifact-name }}
      - name: Check for invalid performance + civ2-compatible combination
        if: ${{ matrix.test-group.performance && matrix.test-group.civ2-compatible }}
        run: |
          echo "::error::Performance tests are not compatible with civ2-compatible tests"
          echo "::error::test-group.performance: ${{ matrix.test-group.performance }}"
          echo "::error::test-group.civ2-compatible: ${{ matrix.test-group.civ2-compatible }}"
          exit 1
      - name: Enable Performance mode
        if: ${{ matrix.test-group.runner-label == 'N300' && matrix.test-group.performance && !matrix.test-group.civ2-compatible }}
        uses: tenstorrent/tt-metal/.github/actions/set-cpu-governor@main
        with:
          governor: performance
      - name: Check Weka mount
        if: ${{ !matrix.test-group.civ2-compatible }}
        run: |
          if [ -d "/mnt/MLPerf" ] && mountpoint -q /mnt/MLPerf; then
            echo "CIv1: ✓ Weka is mounted at /mnt/MLPerf"
            ls -al /mnt/MLPerf/bit_error_tests
          else
            echo "CIv2: ✗ Weka is not mounted at /mnt/MLPerf"
            exit 1
          fi
      - name: Run demo regression tests
        timeout-minutes: 60
        shell: bash
        run: |
          source /work/tests/scripts/single_card/run_single_card_demo_tests.sh
          ${{ matrix.test-group.cmd }}
      - name: Save environment data
        if: ${{ matrix.test-group.runner-label == 'N300' && matrix.test-group.performance && !cancelled() && matrix.test-group.name != 'whisper' && matrix.test-group.name != 'mobilenetv2' }}
        shell: bash
        run: python3 .github/scripts/data_analysis/create_benchmark_with_environment_json.py
      - name: Upload benchmark data
        if: ${{ matrix.test-group.runner-label == 'N300' && matrix.test-group.performance && !cancelled() && matrix.test-group.name != 'whisper' && matrix.test-group.name != 'mobilenetv2' }}
        uses: ./.github/actions/upload-data-via-sftp
        with:
          ssh-private-key: ${{ secrets.SFTP_BENCHMARK_WRITER_KEY }}
          sftp-batchfile: .github/actions/upload-data-via-sftp/benchmark_data_batchfile.txt
          username: ${{ secrets.SFTP_BENCHMARK_WRITER_USERNAME }}
          hostname: ${{ secrets.SFTP_BENCHMARK_WRITER_HOSTNAME }}
          path: /work
      - uses: ./.github/actions/slack-report
        if: ${{ failure() }}
        with:
          slack_webhook_url: ${{ secrets.SLACK_METAL_INFRA_PIPELINE_STATUS_ALERT }}
          owner: ${{ matrix.test-group.owner_id }}
      - uses: tenstorrent/tt-metal/.github/actions/upload-artifact-with-job-uuid@main
        timeout-minutes: 10
        if: ${{ !cancelled() }}
        with:
          path: generated/test_reports/
          prefix: "test_reports_"
      - name: Disable Performance mode
        if: ${{ matrix.test-group.runner-label == 'N300' && matrix.test-group.performance && !matrix.test-group.civ2-compatible && always() }}
        uses: tenstorrent/tt-metal/.github/actions/set-cpu-governor@main
        with:
          governor: ondemand
