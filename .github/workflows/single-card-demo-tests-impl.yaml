name: "[internal] Single-card Demo tests impl"

on:
  workflow_call:
    inputs:
      build-artifact-name:
        required: true
        type: string
      docker-image:
        required: true
        type: string
      wheel-artifact-name:
        required: true
        type: string
      arch:
        required: true
        type: string
      extra-tag:
        required: false
        type: string
        default: "in-service"
      requested-models:
        default: "all"
        type: string
      run-perf-tests:
        type: boolean
        default: true
      mlperf-read-only:
        required: false
        type: boolean
        default: true
        description: "Set to false to allow write access to MLPerf mount"

jobs:
  define-demo-tests:
    runs-on: ubuntu-latest
    outputs:
      demo-tests: ${{ steps.compute-tests.outputs.demo-tests }}
    strategy:
      matrix:
        default-demo-tests:
          [[
            { name: "falcon7b", runner-label: "N150", performance: false, cmd: run_falcon7b_func, owner_id: U05RWH3QUPM}, # Salar Hosseini
            { name: "llama3", runner-label: "N150", performance: false, cmd: run_llama3_func, owner_id: U03PUAKE719}, # Miguel Tairum
            { name: "vgg", runner-label: "N150", performance: false, cmd: run_vgg_func, owner_id: U06Q7ESTFEV}, # Borys Bradel
            { name: "bert_tiny", runner-label: "N150", performance: false, cmd: run_bert_tiny_func, owner_id: U024A4EFV6U}, # Brian Liu
            { name: "bert", runner-label: "N150", performance: false, cmd: run_bert_func, owner_id: U024A4EFV6U}, # Brian Liu
            { name: "resnet", runner-label: "N150", performance: false, cmd: run_resnet_func, owner_id: U0837MYG788}, # Marko Radosavljevic
            { name: "resnet_ops_recording", runner-label: "N150", performance: false, cmd: run_resnet_with_ops_recording, owner_id: U0837MYG788}, # Marko Radosavljevic - ResNet with ops recording
            { name: "distilbert", runner-label: "N150", performance: false, cmd: run_distilbert_func, owner_id: U013121KDH9}, # Austin Ho
            { name: "mnist", runner-label: "N150", performance: false, cmd: run_mnist_func, owner_id: U06ECNVR0EN}, # Evan Smal
            { name: "squeezebert", runner-label: "N150", performance: false, cmd: run_squeezebert_func, owner_id: UBHPP2NDP}, # Joseph Chu
            { name: "stable_diffusion", runner-label: "N150", performance: false, cmd: run_stable_diffusion_func, owner_id: U045U3DEKM4}, # Mohamed Bahnas
            { name: "segformer", runner-label: "N150", performance: false, cmd: run_segformer_func, owner_id: U045U3DEKM4, civ2-compatible: true}, # Mohamed Bahnas (vguduruTT)
            { name: "sentence_bert", runner-label: "N150", performance: false, cmd: run_sentencebert_func, owner_id: U045U3DEKM4, civ2-compatible: true}, # Mohamed Bahnas
            { name: "mobilenetv2", runner-label: "N150", performance: false, cmd: run_mobilenetv2_perf, owner_id: U056BK5U81E, civ2-compatible: true}, # Dalar Vartanians
            { name: "ufld_v2", runner-label: "N150", performance: false, cmd: run_ufld_v2_func, owner_id: U056BK5U81E, civ2-compatible: true}, # Dalar Vartanians
            { name: "mnist_ops_recording", runner-label: "N150", performance: false, cmd: run_mnist_with_ops_recording, owner_id: U06ECNVR0EN, civ2-compatible: true}, # Evan Smal - MNIST with ops recording
            { name: "mobilenetv2_ops_recording", runner-label: "N150", performance: false, cmd: run_mobilenetv2_with_ops_recording, owner_id: U056BK5U81E, civ2-compatible: true}, # Dalar Vartanians - MobileNetV2 with ops recording
            { name: "ufld_v2_ops_recording", runner-label: "N150", performance: false, cmd: run_ufld_v2_with_ops_recording, owner_id: U056BK5U81E, civ2-compatible: true}, # Dalar Vartanians - UFLD V2 with ops recording
            { name: "swin_s", runner-label: "N150", performance: false, cmd: run_swin_s_demo, owner_id: U088413NP0Q, civ2-compatible: true}, # Ashai Reddy Ginuga (HariniMohan0102)
            { name: "vit", runner-label: "N150", performance: false, cmd: run_vit_demo, owner_id: U088413NP0Q, civ2-compatible: true}, # Ashai Reddy Ginuga
            { name: "vanilla_unet", runner-label: "N150", performance: false, cmd: run_vanilla_unet_demo, owner_id: U045U3DEKM4, civ2-compatible: true}, # Mohamed Bahnas (keerthana-r-mcw)
            { name: "vgg_unet", runner-label: "N150", performance: false, cmd: run_vgg_unet_demo, owner_id: U045U3DEKM4, civ2-compatible: true}, # Mohamed Bahnas (keerthana-r-mcw)
            { name: "resnet", runner-label: "N150", performance: true, cmd: run_resnet_stability, owner_id: U0837MYG788}, # Marko Radosavljevic
            { name: "sdxl", runner-label: "N150", performance: false, cmd: run_sdxl_func, owner_id: U0837MYG788}, # Marko Radosavljevic
            { name: "efficientnet_b0", runner-label: "N150", performance: false, cmd: run_efficientnet_b0_func, owner_id: U056BK5U81E, civ2-compatible: true}, # Dalar Vartanians
            { name: "vovnet", runner-label: "N150", performance: false, cmd: run_vovnet_demo, owner_id: U056BK5U81E, civ2-compatible: true}, # Dalar Vartanians
            { name: "swin_v2", runner-label: "N150", performance: false, cmd: run_swin_v2_demo, owner_id: U045U3DEKM4, civ2-compatible: true}, # Mohamed Bahnas
            { name: "swin_s", runner-label: "N300", performance: false, cmd: run_swin_s_demo, owner_id: U088413NP0Q, civ2-compatible: true}, # Ashai Reddy Ginuga (HariniMohan0102)
            { name: "vit", runner-label: "N300", performance: false, cmd: run_vit_demo, owner_id: U088413NP0Q, civ2-compatible: true}, # Ashai Reddy Ginuga
            { name: "falcon7b", runner-label: "N300", performance: false, cmd: run_falcon7b_func, owner_id: U05RWH3QUPM}, # Salar Hosseini
            { name: "llama3", runner-label: "N300", performance: false, cmd: run_llama3_func, owner_id: U03PUAKE719}, # Miguel Tairum
            { name: "vgg", runner-label: "N300", performance: false, cmd: run_vgg_func, owner_id: U06Q7ESTFEV}, # Borys Bradel
            { name: "bert_tiny", runner-label: "N300", performance: false, cmd: run_bert_tiny_func, owner_id: U024A4EFV6U}, # Brian Liu
            { name: "bert", runner-label: "N300", performance: false, cmd: run_bert_func, owner_id: U024A4EFV6U}, # Brian Liu
            { name: "resnet", runner-label: "N300", performance: false, cmd: run_resnet_func, owner_id: U0837MYG788}, # Marko Radosavljevic
            { name: "distilbert", runner-label: "N300", performance: false, cmd: run_distilbert_func, owner_id: U013121KDH9}, # Austin Ho
            { name: "mnist", runner-label: "N300", performance: false, cmd: run_mnist_func, owner_id: U06ECNVR0EN}, # Evan Smal
            { name: "squeezebert", runner-label: "N300", performance: false, cmd: run_squeezebert_func, owner_id: UBHPP2NDP}, #Joseph Chu
            { name: "mobilenetv2", runner-label: "N300", performance: false, cmd: run_mobilenetv2_perf, owner_id: U056BK5U81E, civ2-compatible: true}, # Dalar Vartanians
            { name: "ufld_v2", runner-label: "N300", performance: false, cmd: run_ufld_v2_func, owner_id: U056BK5U81E, civ2-compatible: true}, # Dalar Vartanians
            { name: "mistral7b", runner-label: "N150", performance: false, cmd: run_mistral7b_perf, owner_id: U0896VBAKFC}, # Pratikkumar Prajapati
            { name: "mistral7b", runner-label: "N300", performance: true, cmd: run_mistral7b_perf, owner_id: U0896VBAKFC}, # Pratikkumar Prajapati
            { name: "llama3", runner-label: "N300", performance: true, cmd: run_llama3_perf, owner_id: U03PUAKE719}, # Miguel Tairum
            { name: "falcon7b", runner-label: "N300", performance: true, cmd: run_falcon7b_perf, owner_id: U05RWH3QUPM}, # Salar Hosseini
            { name: "efficientnet_b0", runner-label: "N300", performance: false, cmd: run_efficientnet_b0_func, owner_id: U056BK5U81E, civ2-compatible: true}, # Dalar Vartanians
            { name: "whisper", runner-label: "N300", performance: true, cmd: run_whisper_perf, owner_id: U05RWH3QUPM}, # Salar Hosseini
  #          { name: "mamba", runner-label: "N300", performance: true, cmd: run_mamba_perf, owner_id: U06ECNVR0EN}, # Evan Smal
            { name: "segformer", runner-label: "N300", performance: false, cmd: run_segformer_func, owner_id: U045U3DEKM4, civ2-compatible: true}, # Mohamed Bahnas (vguduruTT)
            { name: "sentence_bert", runner-label: "N300", performance: false, cmd: run_sentencebert_func, owner_id: U045U3DEKM4, civ2-compatible: true}, # Mohamed Bahnas
            { name: "vanilla_unet", runner-label: "N300", performance: false, cmd: run_vanilla_unet_demo, owner_id: U045U3DEKM4, civ2-compatible: true}, # Mohamed Bahnas (keerthana-r-mcw)
            { name: "vgg_unet", runner-label: "N300", performance: false, cmd: run_vgg_unet_demo, owner_id: U045U3DEKM4, civ2-compatible: true}, # Mohamed Bahnas (keerthana-r-mcw)
            { name: "vovnet", runner-label: "N300", performance: false, cmd: run_vovnet_demo, owner_id: U056BK5U81E, civ2-compatible: true}, # Dalar Vartanians
            { name: "swin_v2", runner-label: "N300", performance: false, cmd: run_swin_v2_demo, owner_id: U045U3DEKM4, civ2-compatible: true}, # Mohamed Bahnas
            # Moved to t3k tests until OOM on single card runners resolved
            # { name: "qwen7b", runner-label: "N300", performance: false, cmd: run_qwen7b_func, owner_id: U03PUAKE719}, # Mark O'Connor
            { name: "qwen25_vl", runner-label: "N300", performance: true, cmd: run_qwen25_vl_perfunc, owner_id: U07RY6B5FLJ},  #Gongyu Wang
            { name: "ds_r1_qwen", runner-label: "N300", performance: false, cmd: run_ds_r1_qwen_func, owner_id: U07RY6B5FLJ, civ2-compatible: true},  #Gongyu Wang
            # { name: "gemma3", runner-label: "N150", performance: true, cmd: run_gemma3_perf, owner_id: U08TJ70UFRT},  # Harry Andrews TODO: Gemma3 N150 tests pulled due to OOM; will be addressed in future PR
            { name: "gemma3", runner-label: "N300", performance: true, cmd: run_gemma3_perf, owner_id: U08TJ70UFRT},  # Harry Andrews
            # { name: "phi4", runner-label: "N300", performance: false, cmd: run_phi4_func, owner_id: U094PKWHNJ0, civ2-compatible: true},  # Petar Milojevic
          ]]
    steps:
      - name: Compute tests
        shell: bash
        id: compute-tests
        run: |
          set -euo pipefail

          echo "[info] Outputing default values"
          default_demo_tests='${{ toJSON(matrix.default-demo-tests) }}'
          echo $default_demo_tests
          echo "[info] Outputing default values via jq"
          echo $default_demo_tests | jq
          requested_demo_tests=$default_demo_tests

          requested_models=${{ toJSON(inputs.requested-models) }}
          echo "[info] requested-models: $requested_models"
          run_perf_tests=${{ inputs.run-perf-tests }}
          echo "[info] run-perf-tests: $run_perf_tests"

          if [[ "$requested_models" != "all" ]]; then
            requested_demo_tests=$(jq --argjson requested_models "$requested_models" '[.[] | select(.name | IN($requested_models[]))]' <<< "$requested_demo_tests")
            echo "[info] after filtering for requested models: $requested_demo_tests"
          fi

          # By default, test list includes perf tests. If we don't want to run perf tests,
          # filter them out
          if [[ "$run_perf_tests" == "false" ]]; then
            requested_demo_tests=$(jq '[.[] | select(.performance == false)]' <<< "$requested_demo_tests")
            echo "[info] after filtering filtering out perf tests: $requested_demo_tests"
          fi

          # Check that we have a valid test list that's not empty
          echo "$requested_demo_tests" | jq -e 'if type != "array" then error("Not a valid JSON array") elif length == 0 then error("Test list is empty") else . end' && echo "Valid test configs"

          echo "demo-tests=$(echo $requested_demo_tests | tr -d '\n')" >> "$GITHUB_OUTPUT"

          echo "[info] Showing GITHUB_OUTPUT"
          cat "$GITHUB_OUTPUT"

  single-card-demo-tests:
    needs: define-demo-tests
    strategy:
      fail-fast: false
      matrix:
        test-group: ${{ fromJSON(needs.define-demo-tests.outputs.demo-tests) }}
    name: ${{ matrix.test-group.name }}-${{ matrix.test-group.runner-label }}-${{ (matrix.test-group.performance && 'perf') || 'func' }}
    runs-on: >-
      ${{
        matrix.test-group.civ2-compatible == true
        && format('tt-ubuntu-2204-{0}-stable', matrix.test-group.runner-label)
        || (matrix.test-group.runner-label == 'N300' && matrix.test-group.performance)
          && fromJSON(format('["{0}", "{1}", "bare-metal", "pipeline-perf"]',
              matrix.test-group.runner-label,
              inputs.extra-tag
            ))
          || fromJSON(format('["{0}", "{1}", "cloud-virtual-machine"]',
              matrix.test-group.runner-label,
              inputs.extra-tag
            ))
      }}
    container:
      image: ${{ inputs.docker-image || 'docker-image-unresolved!' }}
      env:
        TT_METAL_HOME: /work
        PYTHONPATH: /work
        LD_LIBRARY_PATH: /work/build/lib
        ARCH_NAME: ${{ inputs.arch }}
        LOGURU_LEVEL: INFO
        GITHUB_ACTIONS: true
        GTEST_OUTPUT: xml:/work/generated/test_reports/
        HF_HUB_CACHE: ${{ (!matrix.test-group.civ2-compatible && '/mnt/MLPerf/huggingface/hub') || '' }}
        HTTP_PROXY: ${{ (matrix.test-group.civ2-compatible && env.HTTP_PROXY) || '' }}
        HTTPS_PROXY: ${{ (matrix.test-group.civ2-compatible && env.HTTPS_PROXY) || '' }}
        NO_PROXY: ${{ (matrix.test-group.civ2-compatible && env.NO_PROXY) || '' }}
      volumes:
        - ${{ github.workspace }}/docker-job:/work # Subdir to workaround https://github.com/actions/runner/issues/691
        - /dev/hugepages-1G:/dev/hugepages-1G
        - /mnt/MLPerf:/mnt/MLPerf${{ inputs.mlperf-read-only && ':ro' || ':rw' }}
      options: >-
        --device /dev/tenstorrent ${{ matrix.test-group.civ2-compatible == true && '-e TT_GH_CI_INFRA=1' || '' }} --cap-add=ALL --security-opt seccomp=unconfined --ulimit nproc=65536:65536 --ulimit nofile=65536:65536 --privileged -v /sys:/sys
    defaults:
      run:
        shell: bash
        working-directory: /work # https://github.com/actions/runner/issues/878
    steps:
      - name: ðŸ§¬ Checkout Repository
        uses: actions/checkout@v4
        with:
          submodules: recursive
          path: docker-job
      - name: â¬‡ï¸  Setup Job
        uses: ./docker-job/.github/actions/setup-job
        timeout-minutes: 10
        with:
          build-artifact-name: ${{ inputs.build-artifact-name }}
          wheel-artifact-name: ${{ inputs.wheel-artifact-name }}
      - name: Check for invalid performance + civ2-compatible combination
        if: ${{ matrix.test-group.performance && matrix.test-group.civ2-compatible }}
        run: |
          echo "::error::Performance tests are not compatible with civ2-compatible tests"
          echo "::error::test-group.performance: ${{ matrix.test-group.performance }}"
          echo "::error::test-group.civ2-compatible: ${{ matrix.test-group.civ2-compatible }}"
          exit 1
      - name: Enable Performance mode
        if: ${{ matrix.test-group.runner-label == 'N300' && matrix.test-group.performance && !matrix.test-group.civ2-compatible }}
        uses: tenstorrent/tt-metal/.github/actions/set-cpu-governor@main
        with:
          governor: performance
      - name: Check Weka mount
        if: ${{ !matrix.test-group.civ2-compatible }}
        run: |
          if [ -d "/mnt/MLPerf" ] && mountpoint -q /mnt/MLPerf; then
            echo "CIv1: âœ“ Weka is mounted at /mnt/MLPerf"
            ls -al /mnt/MLPerf/bit_error_tests
          else
            echo "CIv2: âœ— Weka is not mounted at /mnt/MLPerf"
            exit 1
          fi
      - name: Run demo regression tests
        timeout-minutes: 120
        shell: bash
        run: |
          source /work/tests/scripts/single_card/run_single_card_demo_tests.sh
          ${{ matrix.test-group.cmd }}
      - name: Upload Tracy profiler reports (operations recording)
        if: ${{ !cancelled() && contains(matrix.test-group.cmd, 'ops_recording') }}
        uses: tenstorrent/tt-metal/.github/actions/upload-artifact-with-job-uuid@main
        timeout-minutes: 10
        with:
          path: generated/profiler/reports/
          prefix: "tracy_ops_"
      - name: Save environment data
        id: save-environment-data
        if: ${{ matrix.test-group.runner-label == 'N300' && matrix.test-group.performance && !cancelled() }}
        shell: bash
        run: |
          if [ -d "generated/benchmark_data" ]; then
            echo "has_benchmark_data=true" >> $GITHUB_OUTPUT
            python3 .github/scripts/data_analysis/create_benchmark_with_environment_json.py
          else
            echo "::warning::Benchmark data directory 'generated/benchmark_data' does not exist"
            echo "has_benchmark_data=false" >> $GITHUB_OUTPUT
          fi
      - name: Upload benchmark data
        if: ${{ !cancelled() && steps.save-environment-data.conclusion == 'success' && steps.save-environment-data.outputs.has_benchmark_data == 'true' }}
        uses: tenstorrent/tt-metal/.github/actions/upload-data-via-sftp@main
        with:
          ssh-private-key: ${{ secrets.SFTP_BENCHMARK_WRITER_KEY }}
          sftp-batchfile: .github/actions/upload-data-via-sftp/benchmark_data_batchfile.txt
          username: ${{ secrets.SFTP_BENCHMARK_WRITER_USERNAME }}
          hostname: ${{ secrets.SFTP_BENCHMARK_WRITER_HOSTNAME }}
          path: /work
      - uses: tenstorrent/tt-metal/.github/actions/slack-report@main
        if: ${{ failure() }}
        with:
          slack_webhook_url: ${{ secrets.SLACK_METAL_INFRA_PIPELINE_STATUS_ALERT }}
          owner: ${{ matrix.test-group.owner_id }}
      - uses: tenstorrent/tt-metal/.github/actions/upload-artifact-with-job-uuid@main
        timeout-minutes: 10
        if: ${{ !cancelled() }}
        with:
          path: generated/test_reports/
          prefix: "test_reports_"
      - name: Disable Performance mode
        if: ${{ matrix.test-group.runner-label == 'N300' && matrix.test-group.performance && !matrix.test-group.civ2-compatible && always() }}
        uses: tenstorrent/tt-metal/.github/actions/set-cpu-governor@main
        with:
          governor: ondemand

  aggregate-ops-recording:
    needs: single-card-demo-tests
    if: ${{ !cancelled() && contains(toJSON(needs.single-card-demo-tests), 'ops_recording') }}
    runs-on: ubuntu-latest
    steps:
      - name: Download all Tracy profiler reports
        uses: actions/download-artifact@v4
        with:
          pattern: tracy_ops_*
          path: all_tracy_reports
          merge-multiple: false

      - name: Aggregate operations from all models
        shell: bash
        run: |
          echo "=========================================="
          echo "Aggregating Operations from All Models"
          echo "=========================================="
          
          # Create output directory
          mkdir -p aggregated_ops
          
          # Find all ops_perf_results CSV files
          echo "Found Tracy reports:"
          find all_tracy_reports -name "ops_perf_results_*.csv" | head -50
          
          # Aggregate using Python
          python3 << 'EOF'
          import csv
          import os
          import json
          from pathlib import Path
          from collections import defaultdict
          
          all_ops = defaultdict(lambda: {"count": 0, "total_duration_ns": 0, "models": set()})
          model_ops = {}
          
          # Find all ops_perf_results CSV files
          for csv_path in Path("all_tracy_reports").rglob("ops_perf_results_*.csv"):
              # Extract model name from artifact folder structure
              parts = str(csv_path).split("/")
              model_name = parts[1] if len(parts) > 1 else csv_path.parent.name
              print(f"\nProcessing: {csv_path} (model: {model_name})")
              
              try:
                  with open(csv_path, 'r') as f:
                      reader = csv.DictReader(f)
                      ops_data = list(reader)
                  
                  # Aggregate by operation type
                  op_counts = defaultdict(lambda: {"count": 0, "total_duration_ns": 0})
                  
                  for op in ops_data:
                      op_type = op.get("OP TYPE", op.get("op_type", "unknown"))
                      
                      # Get duration
                      duration = 0
                      for col in ["DEVICE FW DURATION [ns]", "device_fw_duration", "KERNEL DURATION [ns]"]:
                          if col in op and op[col]:
                              try:
                                  duration = float(op[col])
                                  break
                              except:
                                  pass
                      
                      op_counts[op_type]["count"] += 1
                      op_counts[op_type]["total_duration_ns"] += duration
                      
                      all_ops[op_type]["count"] += 1
                      all_ops[op_type]["total_duration_ns"] += duration
                      all_ops[op_type]["models"].add(model_name)
                  
                  model_ops[model_name] = [
                      {"name": k, "count": v["count"], "duration_ns": v["total_duration_ns"]}
                      for k, v in op_counts.items()
                  ]
                  
                  print(f"  Found {len(op_counts)} unique operations from {len(ops_data)} total ops")
              except Exception as e:
                  print(f"  Error: {e}")
          
          # Write aggregated report
          with open("aggregated_ops/aggregated_operations.txt", "w") as f:
              f.write("=" * 100 + "\n")
              f.write("AGGREGATED TTNN OPERATIONS REPORT (via Tracy Profiler)\n")
              f.write("=" * 100 + "\n\n")
              
              f.write(f"Total unique operations: {len(all_ops)}\n")
              f.write(f"Models processed: {len(model_ops)}\n\n")
              
              f.write("=" * 100 + "\n")
              f.write("ALL OPERATIONS (sorted by frequency)\n")
              f.write("=" * 100 + "\n")
              f.write(f"{'Operation':<50} {'Count':<10} {'Total Duration (ms)':<20} {'Models'}\n")
              f.write("-" * 100 + "\n")
              
              for name, data in sorted(all_ops.items(), key=lambda x: x[1]["count"], reverse=True):
                  models_str = ", ".join(sorted(data["models"]))
                  dur_ms = data["total_duration_ns"] / 1_000_000
                  f.write(f"{name:<50} {data['count']:<10} {dur_ms:<20.4f} {models_str}\n")
              
              f.write("\n" + "=" * 100 + "\n")
              f.write("OPERATIONS BY MODEL\n")
              f.write("=" * 100 + "\n")
              
              for model, ops in sorted(model_ops.items()):
                  f.write(f"\n--- {model} ({len(ops)} unique ops) ---\n")
                  for op in sorted(ops, key=lambda x: x["count"], reverse=True)[:20]:
                      dur_ms = op["duration_ns"] / 1_000_000
                      f.write(f"  {op['name']}: {op['count']}x ({dur_ms:.2f}ms)\n")
          
          # Write JSON for programmatic access
          json_data = {
              "all_operations": {
                  k: {
                      "count": v["count"],
                      "total_duration_ns": v["total_duration_ns"],
                      "total_duration_ms": v["total_duration_ns"] / 1_000_000,
                      "models": list(v["models"])
                  }
                  for k, v in all_ops.items()
              },
              "by_model": model_ops
          }
          with open("aggregated_ops/aggregated_operations.json", "w") as f:
              json.dump(json_data, f, indent=2)
          
          print("\n" + "=" * 50)
          print(f"Aggregated {len(all_ops)} unique operations from {len(model_ops)} models")
          print("=" * 50)
          
          # Print summary
          print("\nTop 20 operations by frequency:")
          for i, (name, data) in enumerate(sorted(all_ops.items(), key=lambda x: x[1]["count"], reverse=True)[:20]):
              print(f"  {i+1}. {name}: {data['count']}x")
          EOF
          
          echo ""
          echo "=========================================="
          echo "Aggregation Complete"
          echo "=========================================="
          cat aggregated_ops/aggregated_operations.txt

      - name: Upload aggregated operations report
        uses: actions/upload-artifact@v4
        with:
          name: aggregated-ttnn-operations
          path: aggregated_ops/
