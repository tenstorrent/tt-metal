name: "Validate Test Count"

on:
  workflow_call:
    inputs:
      wheel-artifact-name:
        required: true
        type: string
  pull_request:
    paths:
      - 'tests/ttnn/unit_tests/operations/eltwise/**'
      - 'tests/ttnn/unit_tests/operations/conv/**'
      - 'tests/ttnn/unit_tests/operations/matmul/**'
      - 'tests/ttnn/unit_tests/operations/pool/**'
      - 'tests/ttnn/unit_tests/operations/fused/**'
      - 'tests/ttnn/unit_tests/operations/transformers/**'
      - 'tests/ttnn/unit_tests/operations/reduce/**'
      - 'tests/ttnn/unit_tests/tensor/**'
      - 'tests/ttnn/unit_tests/operations/debug/**'
      - 'tests/ttnn/unit_tests/base_functionality/**'
      - 'tests/ttnn/unit_tests/benchmarks/**'
jobs:
  check-test-count:
    runs-on: ubuntu-latest
    name: "Ensure no new tests added to locked directories"
    steps:
      - name: Checkout PR branch
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Download built wheel
        if: ${{ inputs.wheel-artifact-name != '' }}
        uses: actions/download-artifact@v4
        with:
          name: ${{ inputs.wheel-artifact-name }}
          path: ./wheels

      - name: Install tt-metal wheel and dependencies
        if: ${{ inputs.wheel-artifact-name != '' }}
        run: |
          pip install pytest torch numpy
          # Install other common test dependencies
          pip install multiprocess psutil loguru transformers
          pip install ./wheels/*.whl

      - name: Count and compare tests
        run: |          
          # Define locked directories to check (matching paths from workflow trigger)
          declare -a PATHS=(
            "tests/ttnn/unit_tests/operations/eltwise"
            "tests/ttnn/unit_tests/operations/conv"
            "tests/ttnn/unit_tests/operations/matmul"
            "tests/ttnn/unit_tests/operations/pool"
            "tests/ttnn/unit_tests/operations/fused"
            "tests/ttnn/unit_tests/operations/transformers"
            "tests/ttnn/unit_tests/operations/reduce"
            "tests/ttnn/unit_tests/tensor"
            "tests/ttnn/unit_tests/operations/debug"
            "tests/ttnn/unit_tests/base_functionality"
            "tests/ttnn/unit_tests/benchmarks"
          )
          
          # Function to count test functions using pytest
          count_tests() {
            local dir=$1
            echo "Collecting from: $dir" >&2
            output=$(pytest "$dir" --collect-only -q --noconftest 2>&1)
            echo "Pytest output:" >&2
            count=$(echo "$output" | tail -1 | grep -oE '[0-9]+' | head -1)
            if [ -z "$count" ]; then
              echo "0"
            else
              echo "$count"
            fi
          }
          
          # Count tests in PR branch
          echo "=== PR branch test counts ==="
          declare -A pr_counts
          for path in "${PATHS[@]}"; do
            count=$(count_tests "$path")
            pr_counts[$path]=$count
            echo "  $path: $count"
          done
          
          # Checkout base branch
          git fetch origin main
          git checkout origin/main
          
          # Count tests in base branch
          echo "=== Base branch test counts ==="
          declare -A base_counts
          for path in "${PATHS[@]}"; do
            count=$(count_tests "$path")
            base_counts[$path]=$count
            echo "  $path: $count"
          done
          
          # Compare and generate report
          FAILED=0
          
          echo "## Test Count Validation Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Directory | Base | PR | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-----------|------|-------|--------|" >> $GITHUB_STEP_SUMMARY
          
          for path in "${PATHS[@]}"; do
            pr_count=${pr_counts[$path]}
            base_count=${base_counts[$path]}
            
            if [ "$pr_count" -gt "$base_count" ]; then
              echo "| $path | $base_count | $pr_count | ❌ New tests added (+$((pr_count - base_count))) |" >> $GITHUB_STEP_SUMMARY
              echo "::error::New tests detected in $path/ ($base_count → $pr_count)"
              FAILED=1
            else
              echo "| $path | $base_count | $pr_count | ✅ No new tests |" >> $GITHUB_STEP_SUMMARY
            fi
          done
          
          if [ "$FAILED" -eq 1 ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "❌ **This PR adds new tests to APC.**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "These test directories are locked to maintain stable APC runtime." >> $GITHUB_STEP_SUMMARY
            echo "Please look into removing existing lower priority tests to add new tests." >> $GITHUB_STEP_SUMMARY
            exit 1
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "✅ **No new tests added - validation passed**" >> $GITHUB_STEP_SUMMARY

      - name: Comment on PR if validation fails
        if: failure() && github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: '❌ **Test Count Validation Failed**\n\nThis PR adds new tests in APC. A fixed test count to set to maintain stable APC runtime.\n\nIf you need to add new tests, please:\n1. Look through the current list of tests and check if a lower priority test can be removed to add your new test. \n2. Consider adding tests to the ttnn/nightly directory to run in L2-nightly pipeline \n3. Note down an explanation on why the new tests are necessary\n\nSee the workflow summary for details.'
            })
