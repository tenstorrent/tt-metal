name: "Validate Test Count"

on:
  workflow_dispatch:
  push:
    branches: [ "kkabilar-APC-limit" ]
  pull_request:
    paths:
      - 'tests/ttnn/unit_tests/operations/eltwise/**'
      - 'tests/ttnn/unit_tests/operations/conv/**'
      - 'tests/ttnn/unit_tests/operations/matmul/**'
      - 'tests/ttnn/unit_tests/operations/pool/**'
      - 'tests/ttnn/unit_tests/operations/fused/**'
      - 'tests/ttnn/unit_tests/operations/transformers/**'
      - 'tests/ttnn/unit_tests/operations/reduce/**'
      - 'tests/ttnn/unit_tests/operations/tensor/**'
      - 'tests/ttnn/unit_tests/operations/debug/**'
      - 'tests/ttnn/unit_tests/operations/base_functionality/**'
      - 'tests/ttnn/unit_tests/operations/benchmarks/**'
jobs:
  build:
    uses: ./.github/workflows/build-artifact.yaml
    permissions:
      packages: write
    secrets: inherit
    with:
      version: "22.04"
      toolchain: cmake/x86_64-linux-clang-17-libstdcpp-toolchain.cmake
      # Cannot do a Sanitizer build as that's not compatible with the downstream test.
      # Also cannot be Release if the other build was chosen to be Release as the GitHub artifact
      # name clashes.
      build-type: ${{ (inputs.build-type == 'Release' && 'Debug') || 'Release' }}
      build-wheel: true
      publish-artifact: false
      skip-tt-train: true
      distributed: false
      ref: ${{ github.event_name == 'pull_request' && github.event.pull_request.head.sha || '' }}
  check-test-count:
    needs: build
    runs-on: ubuntu-latest
    name: "Ensure no new tests added to locked directories"
    steps:
      - name: Checkout PR branch
        uses: actions/checkout@v4
        # Default fetch-depth: 1 - just PR branch

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Download built wheel
        if: ${{ needs.build.outputs.wheel-artifact-name != '' }}
        uses: actions/download-artifact@v4
        with:
          name: ${{ needs.build.outputs.wheel-artifact-name }}
          path: ./wheels

      - name: Install tt-metal wheel and dependencies
        if: ${{ needs.build.outputs.wheel-artifact-name != '' }}
        run: |
          pip install pytest torch numpy
          # Install other common test dependencies
          pip install multiprocess psutil loguru transformers
          pip install ./wheels/*.whl

      - name: Create stub modules for collection
        run: |
          # Create minimal stubs to satisfy imports during pytest collection
          mkdir -p models/common
          touch models/__init__.py
          touch models/common/__init__.py
          
          # Create stub utility_functions with minimal implementations
          cat > models/common/utility_functions.py << 'EOF'
          """Stub module for pytest collection - not used during collection"""
          import pytest
          
          # Comparison functions
          def comp_pcc(*args, **kwargs): pass
          def comp_allclose(*args, **kwargs): pass
          def comp_ulp(*args, **kwargs): pass
          def comp_equal(*args, **kwargs): pass
          def divup(*args, **kwargs): pass
          def roundup(*args, **kwargs): pass
          
          # Random/tensor functions
          def torch_random(*args, **kwargs): pass
          def torch2tt_tensor(*args, **kwargs): pass
          def tt2torch_tensor(*args, **kwargs): pass
          def ttl_complex_2_torch_complex(*args, **kwargs): pass
          
          # Device check functions
          def is_wormhole_b0(*args, **kwargs): return False
          def is_blackhole(*args, **kwargs): return False
          
          # Stub decorator
          def skip_for_slow_dispatch(func):
              return func
          EOF

      - name: Count and compare tests
        run: |
          # Add current directory to PYTHONPATH so models stub can be found
          export PYTHONPATH="${PYTHONPATH}:${PWD}"
          
          # Define locked directories to check
          DIRS="eltwise conv matmul pool fused transformers reduce tensor debug base_functionality benchmarks"
          
          # Function to count test functions using pytest
          count_tests() {
            local dir=$1
            echo "Collecting from: $dir" >&2
            output=$(pytest "$dir" --collect-only -q --noconftest 2>&1)
            echo "Pytest output:" >&2
            echo "$output" >&2
            count=$(echo "$output" | tail -1 | grep -oE '[0-9]+' | head -1)
            if [ -z "$count" ]; then
              echo "0"
            else
              echo "$count"
            fi
          }
          
          # Count tests in PR branch
          echo "=== PR branch test counts ==="
          declare -A pr_counts
          for dir in $DIRS; do
            count=$(count_tests "tests/ttnn/unit_tests/operations/$dir")
            pr_counts[$dir]=$count
            echo "  $dir: $count"
          done
          
          # Checkout base branch
          git fetch origin main
          git checkout origin/main
          
          # Count tests in base branch
          echo "=== Base branch test counts ==="
          declare -A base_counts
          for dir in $DIRS; do
            count=$(count_tests "tests/ttnn/unit_tests/operations/$dir")
            base_counts[$dir]=$count
            echo "  $dir: $count"
          done
          
          # Compare and generate report
          FAILED=0
          
          echo "## Test Count Validation Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Directory | Base | PR | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-----------|------|-------|--------|" >> $GITHUB_STEP_SUMMARY
          
          for dir in $DIRS; do
            pr_count=${pr_counts[$dir]}
            base_count=${base_counts[$dir]}
            
            if [ "$pr_count" -gt "$base_count" ]; then
              echo "| $dir | $base_count | $pr_count | ❌ New tests added (+$((pr_count - base_count))) |" >> $GITHUB_STEP_SUMMARY
              echo "::error::New tests detected in tests/ttnn/unit_tests/operations/$dir/ ($base_count → $pr_count)"
              FAILED=1
            else
              echo "| $dir | $base_count | $pr_count | ✅ No new tests |" >> $GITHUB_STEP_SUMMARY
            fi
          done
          
          if [ "$FAILED" -eq 1 ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "❌ **This PR adds new tests to locked directories.**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "These test directories are locked to maintain stable CI runtime." >> $GITHUB_STEP_SUMMARY
            echo "Please contact @tenstorrent/metalium-developers-infra for approval to add new tests." >> $GITHUB_STEP_SUMMARY
            exit 1
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "✅ **No new tests added - validation passed**" >> $GITHUB_STEP_SUMMARY

      - name: Comment on PR if validation fails
        if: failure()
        uses: actions/github-script@v7
        with:
          script: |
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: '❌ **Test Count Validation Failed**\n\nThis PR adds new tests to locked test directories. These directories have a fixed test count to maintain stable CI runtime.\n\nIf you need to add new tests, please:\n1. Contact @tenstorrent/metalium-developers-infra\n2. Explain why the new tests are necessary\n3. Consider adding tests to a different directory\n\nSee the workflow summary for details.'
            })
