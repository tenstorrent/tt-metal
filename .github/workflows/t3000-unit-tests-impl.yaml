name: "[internal] All Models Demo Tests Implementation"

on:
  workflow_call:
    inputs:
      device-type:
        required: true
        type: string
        description: "Device type: n150, n300, p100, p150, p300, WH-LB, BH-LB, BH-QB2, WH-6U, BH-6U"
      runner-label:
        required: true
        type: string
        description: "GitHub runner label"
      arch:
        required: true
        type: string
        description: "Architecture: wormhole_b0 or blackhole"
      docker-image:
        required: true
        type: string
      build-artifact-name:
        required: true
        type: string
      wheel-artifact-name:
        required: true
        type: string
      regenerate-ttnn-cache:
        required: false
        type: boolean
        default: false
      model-type:
        required: false
        type: string
        default: "all"
        description: "Model type filter: all, tt-transformers, or standalone"
      extra-tag:
        required: false
        type: string
        default: "in-service"
        description: "Extra tag for runner selection"

jobs:
  generate-test-matrix:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.generate.outputs.matrix }}
      model-config: ${{ steps.generate.outputs.model-config }}
    steps:
      - name: Generate test matrix
        id: generate
        run: |
          # Define device-compatible TT-Transformers models
          case "${{ inputs.device-type }}" in
            n150)
              tt_transformers_models='["llama3.1-8b", "llama3.2-1b", "llama3.2-3b", "mistral-7b", "phi-3-mini-128k"]'
              ;;
            n300)
              tt_transformers_models='["llama3.1-8b", "llama3.2-1b", "llama3.2-3b", "llama3.2-11b-vision", "mistral-7b", "qwen2.5-7b", "qwen2.5-coder-32b", "phi-3-mini-128k"]'
              ;;
            p100)
              tt_transformers_models='["llama3.1-8b", "llama3.2-1b", "llama3.2-3b", "llama3.2-11b-vision", "mistral-7b", "phi-3-mini-128k"]'
              ;;
            p150)
              tt_transformers_models='["llama3.1-8b", "llama3.2-1b", "llama3.2-3b", "llama3.2-11b-vision", "mistral-7b", "phi-3-mini-128k"]'
              ;;
            p300)
              tt_transformers_models='["llama3.1-8b", "llama3.2-1b", "llama3.2-3b", "llama3.2-11b-vision", "mistral-7b", "qwen2.5-7b", "qwen2.5-coder-32b", "qwen3-32b", "phi-3-mini-128k"]'
              ;;
            WH-LB)
              tt_transformers_models='["deepseek-r1-distill-llama-70b", "llama3.1-8b", "llama3.1-70b", "llama3.2-1b", "llama3.2-3b", "llama3.2-11b-vision", "llama3.2-90b-vision", "mistral-7b", "qwen2.5-7b", "qwen2.5-coder-32b", "qwen3-32b", "phi-3-mini-128k"]'
              ;;
            BH-LB)
              tt_transformers_models='["deepseek-r1-distill-llama-70b", "llama3.1-8b", "llama3.1-70b", "llama3.2-1b", "llama3.2-3b", "llama3.2-11b-vision", "llama3.2-90b-vision", "mistral-7b", "qwen2.5-7b", "qwen2.5-coder-32b", "qwen3-32b", "phi-3-mini-128k"]'
              ;;
            BH-QB2)
              tt_transformers_models='["deepseek-r1-distill-llama-70b", "llama3.1-8b", "llama3.1-70b", "llama3.2-1b", "llama3.2-3b", "llama3.2-11b-vision", "llama3.2-90b-vision", "mistral-7b", "qwen2.5-7b", "qwen2.5-coder-32b", "qwen2.5-72b", "qwen3-32b", "phi-3-mini-128k"]'
              ;;
            WH-6U)
              tt_transformers_models='["deepseek-r1-distill-llama-70b"]'
              ;;
            BH-6U)
              tt_transformers_models='["deepseek-r1-distill-llama-70b"]'
              ;;
          esac

          # Define device-compatible standalone models
          case "${{ inputs.device-type }}" in
            n150)
              standalone_models='["whisper", "stable-diffusion-wh", "resnet-50-wh", "vit-wh", "mobilenet-v2", "unet-vgg19-wh", "unet-vanilla", "segformer", "ufld-v2-wh", "bert-large", "sentence-bert-wh"]'
              ;;
            n300)
              standalone_models='["whisper", "stable-diffusion-wh", "resnet-50-wh", "vit-wh", "mobilenet-v2", "unet-vgg19-wh", "unet-vanilla", "segformer", "ufld-v2-wh", "bert-large", "sentence-bert-wh"]'
              ;;
            p100)
              standalone_models='["whisper", "stable-diffusion-bh", "resnet-50-bh", "vit-bh", "mobilenet-v2", "unet-vgg19-bh", "segformer", "ufld-v2-bh", "bert-large", "sentence-bert-bh"]'
              ;;
            p150)
              standalone_models='["whisper", "stable-diffusion-bh", "resnet-50-bh", "vit-bh", "mobilenet-v2", "unet-vgg19-bh", "segformer", "ufld-v2-bh", "bert-large", "sentence-bert-bh"]'
              ;;
            p300)
              standalone_models='["whisper", "stable-diffusion-bh", "resnet-50-bh", "vit-bh", "mobilenet-v2", "unet-vgg19-bh", "segformer", "ufld-v2-bh", "bert-large", "sentence-bert-bh"]'
              ;;
            WH-LB)
              standalone_models='["whisper", "stable-diffusion-wh", "resnet-50-ttnn", "vit-t3000", "mobilenet-v2", "unet-vgg19-wh", "unet-vanilla", "segformer", "ufld-v2-wh", "bert-large", "sentence-bert-wh"]'
              ;;
            BH-LB)
              standalone_models='["whisper", "stable-diffusion-bh", "resnet-50-bh", "vit-bh", "mobilenet-v2", "unet-vgg19-bh", "segformer", "ufld-v2-bh", "bert-large", "sentence-bert-bh"]'
              ;;
            BH-QB2)
              standalone_models='["whisper", "stable-diffusion-bh", "resnet-50-bh", "vit-bh", "mobilenet-v2", "unet-vgg19-bh", "segformer", "ufld-v2-bh", "bert-large", "sentence-bert-bh"]'
              ;;
            WH-6U)
              standalone_models='["whisper", "stable-diffusion-wh", "resnet-50-ttnn", "vit-t3000", "mobilenet-v2", "unet-vgg19-wh", "unet-vanilla", "segformer", "ufld-v2-wh", "bert-large", "sentence-bert-wh"]'
              ;;
            BH-6U)
              standalone_models='["whisper", "stable-diffusion-bh", "resnet-50-bh", "vit-bh", "mobilenet-v2", "unet-vgg19-bh", "segformer", "ufld-v2-bh", "bert-large", "sentence-bert-bh"]'
              ;;
          esac

          # Define model HuggingFace paths mapping
          declare -A model_paths
          model_paths["llama3.1-8b"]="meta-llama/Llama-3.1-8B-Instruct"
          model_paths["llama3.1-70b"]="meta-llama/Llama-3.1-70B-Instruct"
          model_paths["llama3.3-70b"]="meta-llama/Llama-3.3-70B-Instruct"
          model_paths["llama3.2-1b"]="meta-llama/Llama-3.2-1B"
          model_paths["llama3.2-3b"]="meta-llama/Llama-3.2-3B"
          model_paths["llama3.2-11b-vision"]="meta-llama/Llama-3.2-11B-Vision"
          model_paths["llama3.2-90b-vision"]="meta-llama/Llama-3.2-90B-Vision"
          model_paths["mistral-7b"]="mistralai/Mistral-7B-Instruct-v0.3"
          model_paths["qwen2.5-7b"]="Qwen/Qwen2.5-7B"
          model_paths["qwen2.5-coder-32b"]="Qwen/Qwen2.5-Coder-32B"
          model_paths["qwen2.5-72b"]="Qwen/Qwen2.5-72B"
          model_paths["qwen3-32b"]="Qwen/Qwen3-32B"
          model_paths["phi-3-mini-128k"]="microsoft/Phi-3-mini-128k-instruct"
          model_paths["deepseek-r1-distill-llama-70b"]="deepseek-ai/DeepSeek-R1-Distill-Llama-70B"

          # Define standalone model test configuration mapping
          declare -A standalone_test_paths
          declare -A standalone_test_args
          declare -A standalone_test_timeouts
          declare -A standalone_display_names

          # Audio models
          standalone_test_paths["whisper"]="models/demos/audio/whisper/demo/demo.py::test_demo_for_conditional_generation_dataset"
          standalone_test_args["whisper"]=""
          standalone_test_timeouts["whisper"]=30
          standalone_display_names["whisper"]="whisper"

          # Vision - Generative - Stable Diffusion variants
          standalone_test_paths["stable-diffusion-wh"]="models/demos/vision/generative/stable_diffusion/wormhole/demo/demo.py::test_demo"
          standalone_test_args["stable-diffusion-wh"]="--input-path=models/demos/vision/generative/stable_diffusion/wormhole/demo/input_data.json"
          standalone_test_timeouts["stable-diffusion-wh"]=30
          standalone_display_names["stable-diffusion-wh"]="stable-diffusion"

          standalone_test_paths["stable-diffusion-bh"]="models/demos/vision/generative/stable_diffusion/blackhole/tests/test_unet_2d_condition_model.py::test_unet_2d_condition_model_512x512"
          standalone_test_args["stable-diffusion-bh"]=""
          standalone_test_timeouts["stable-diffusion-bh"]=30
          standalone_display_names["stable-diffusion-bh"]="stable-diffusion"

          # Vision - Classification - ResNet-50 variants
          standalone_test_paths["resnet-50-wh"]="models/demos/vision/classification/resnet50/wormhole/demo/demo.py::test_demo_sample"
          standalone_test_args["resnet-50-wh"]=""
          standalone_test_timeouts["resnet-50-wh"]=20
          standalone_display_names["resnet-50-wh"]="resnet-50"

          standalone_test_paths["resnet-50-bh"]="models/demos/vision/classification/resnet50/blackhole/demo/demo.py::test_demo_sample"
          standalone_test_args["resnet-50-bh"]=""
          standalone_test_timeouts["resnet-50-bh"]=20
          standalone_display_names["resnet-50-bh"]="resnet-50"

          standalone_test_paths["resnet-50-ttnn"]="models/demos/vision/classification/resnet50/ttnn_resnet/tests/test_demo.py::test_demo_sample"
          standalone_test_args["resnet-50-ttnn"]=""
          standalone_test_timeouts["resnet-50-ttnn"]=20
          standalone_display_names["resnet-50-ttnn"]="resnet-50"

          # Vision - Classification - ViT variants
          standalone_test_paths["vit-wh"]="models/demos/vision/classification/vit/wormhole/tests/test_ttnn_optimized_sharded_vit_wh.py::test_vit"
          standalone_test_args["vit-wh"]=""
          standalone_test_timeouts["vit-wh"]=20
          standalone_display_names["vit-wh"]="vit"

          standalone_test_paths["vit-bh"]="models/demos/vision/classification/vit/blackhole/tests/test_ttnn_optimized_sharded_vit_bh.py::test_vit"
          standalone_test_args["vit-bh"]=""
          standalone_test_timeouts["vit-bh"]=20
          standalone_display_names["vit-bh"]="vit"

          standalone_test_paths["vit-t3000"]="models/demos/vision/classification/vit/t3000/demo/demo_vit_performant_imagenet_inference.py::test_run_vit_trace_2cqs_inference"
          standalone_test_args["vit-t3000"]=""
          standalone_test_timeouts["vit-t3000"]=20
          standalone_display_names["vit-t3000"]="vit"

          # Vision - Classification - MobileNet-V2
          standalone_test_paths["mobilenet-v2"]="models/demos/vision/classification/mobilenetv2/tests/pcc/test_mobilenetv2.py::test_mobilenetv2"
          standalone_test_args["mobilenet-v2"]=""
          standalone_test_timeouts["mobilenet-v2"]=20
          standalone_display_names["mobilenet-v2"]="mobilenet-v2"

          # Vision - Segmentation - UNet VGG19 variants
          standalone_test_paths["unet-vgg19-wh"]="models/demos/vision/segmentation/vgg_unet/wormhole/demo/demo.py::test_demo"
          standalone_test_args["unet-vgg19-wh"]=""
          standalone_test_timeouts["unet-vgg19-wh"]=20
          standalone_display_names["unet-vgg19-wh"]="unet-vgg19"

          standalone_test_paths["unet-vgg19-bh"]="models/demos/vision/segmentation/vgg_unet/blackhole/demo/demo.py::test_demo"
          standalone_test_args["unet-vgg19-bh"]=""
          standalone_test_timeouts["unet-vgg19-bh"]=20
          standalone_display_names["unet-vgg19-bh"]="unet-vgg19"

          # Vision - Segmentation - UNet Vanilla
          standalone_test_paths["unet-vanilla"]="models/demos/vision/segmentation/vanilla_unet/demo/demo.py::test_unet_demo_single_image"
          standalone_test_args["unet-vanilla"]=""
          standalone_test_timeouts["unet-vanilla"]=20
          standalone_display_names["unet-vanilla"]="unet-vanilla"

          # Vision - Segmentation - Segformer
          standalone_test_paths["segformer"]="models/demos/vision/segmentation/segformer/tests/pcc/test_segformer_for_semantic_segmentation.py"
          standalone_test_args["segformer"]=""
          standalone_test_timeouts["segformer"]=20
          standalone_display_names["segformer"]="segformer"

          # Vision - Segmentation - UFLD-V2 variants
          standalone_test_paths["ufld-v2-wh"]="models/demos/vision/segmentation/ufld_v2/wormhole/tests/pcc/test_ttnn_ufld_v2.py::test_ufld_v2_model"
          standalone_test_args["ufld-v2-wh"]=""
          standalone_test_timeouts["ufld-v2-wh"]=20
          standalone_display_names["ufld-v2-wh"]="ufld-v2"

          standalone_test_paths["ufld-v2-bh"]="models/demos/vision/segmentation/ufld_v2/blackhole/demo/demo.py::test_ufld_v2_demo"
          standalone_test_args["ufld-v2-bh"]=""
          standalone_test_timeouts["ufld-v2-bh"]=20
          standalone_display_names["ufld-v2-bh"]="ufld-v2"

          # NLP - BERT Large
          standalone_test_paths["bert-large"]="models/demos/metal_BERT_large_11/demo/demo.py::test_demo"
          standalone_test_args["bert-large"]=""
          standalone_test_timeouts["bert-large"]=20
          standalone_display_names["bert-large"]="bert-large"

          # NLP - Sentence BERT variants
          standalone_test_paths["sentence-bert-wh"]="models/demos/wormhole/sentence_bert/tests/pcc/test_ttnn_sentencebert_model.py::test_ttnn_sentence_bert_model"
          standalone_test_args["sentence-bert-wh"]=""
          standalone_test_timeouts["sentence-bert-wh"]=20
          standalone_display_names["sentence-bert-wh"]="sentence-bert"

          standalone_test_paths["sentence-bert-bh"]="models/demos/blackhole/sentence_bert/demo/demo.py::test_sentence_bert_demo_inference"
          standalone_test_args["sentence-bert-bh"]=""
          standalone_test_timeouts["sentence-bert-bh"]=20
          standalone_display_names["sentence-bert-bh"]="sentence-bert"

          # Define test configurations
          tests='[{"name":"Batch-1 CI","test_key":"performance and ci-1","extra_args":"","timeout":60,"owner_id":"U03PUAKE719"},{"name":"Batch-32 CI","test_key":"performance and ci-32","extra_args":"","timeout":60,"owner_id":"U03PUAKE719"},{"name":"Long Context 16K","test_key":"performance and ci-long-context-16k","extra_args":"","timeout":60,"owner_id":"U03PUAKE719"}]'

          # Generate matrix combining models and tests
          matrix='[]'

          # Process TT-Transformers models if requested
          if [[ "${{ inputs.model-type }}" == "all" || "${{ inputs.model-type }}" == "tt-transformers" ]]; then
            # Process TT-Transformers models with 4 test types each
            for model in $(echo "$tt_transformers_models" | jq -r '.[]'); do
              HF_MODEL="${model_paths[$model]}"

              # Determine cache path based on architecture
              if [[ "${{ inputs.arch }}" == "blackhole" ]]; then
                CACHE_PATH="/localdev/blackhole_demos/huggingface_data/${HF_MODEL}"
              else
                CACHE_PATH="/mnt/MLPerf/huggingface/tt_cache/${HF_MODEL}"
              fi

              # Add each test for this model to the matrix
              model_tests=$(echo "$tests" | jq -c --arg model "$model" --arg hf "$HF_MODEL" --arg cache "$CACHE_PATH" \
                '[.[] | . + {"model": $model, "hf_model": $hf, "cache_path": $cache, "model_type": "tt-transformers"}]')

              matrix=$(echo "$matrix" | jq -c --argjson new "$model_tests" '. + $new')
            done
          fi

          # Process standalone models if requested
          if [[ "${{ inputs.model-type }}" == "all" || "${{ inputs.model-type }}" == "standalone" ]]; then
            # Process standalone models with single demo test each
            for model_key in $(echo "$standalone_models" | jq -r '.[]'); do
              # Lookup test configuration from associative arrays
              test_path="${standalone_test_paths[$model_key]}"
              test_args="${standalone_test_args[$model_key]}"
              timeout="${standalone_test_timeouts[$model_key]}"
              display_name="${standalone_display_names[$model_key]}"

              # Determine cache path based on architecture
              if [[ "${{ inputs.arch }}" == "blackhole" ]]; then
                CACHE_PATH="/localdev/blackhole_demos/huggingface_data"
              else
                CACHE_PATH="/mnt/MLPerf/huggingface/tt_cache"
              fi

              # Add standalone model test to matrix using proper JSON construction
              matrix=$(echo "$matrix" | jq -c \
                --arg model "$display_name" \
                --arg test_path "$test_path" \
                --arg test_args "$test_args" \
                --arg cache "$CACHE_PATH" \
                --argjson timeout "$timeout" \
                '. + [{
                  "model": $model,
                  "name": "Demo Test",
                  "test_path": $test_path,
                  "test_args": $test_args,
                  "cache_path": $cache,
                  "timeout": $timeout,
                  "model_type": "standalone"
                }]')
            done
          fi

          echo "Generated matrix for device-type: ${{ inputs.device-type }}"
          echo "Matrix length: $(echo "$matrix" | jq 'length')"
          echo "matrix=$matrix" >> $GITHUB_OUTPUT

          # Generate model configuration metadata for chart generation
          # Only include models that match the model-type filter
          if [[ "${{ inputs.model-type }}" == "tt-transformers" ]]; then
            # Only TT-Transformers models
            model_config=$(jq -nc \
              --arg device "${{ inputs.device-type }}" \
              --argjson tt_models "$tt_transformers_models" \
              '{
                device: $device,
                tt_transformers: $tt_models,
                standalone_keys: []
              }')
          elif [[ "${{ inputs.model-type }}" == "standalone" ]]; then
            # Only standalone models
            model_config=$(jq -nc \
              --arg device "${{ inputs.device-type }}" \
              --argjson standalone_keys "$standalone_models" \
              '{
                device: $device,
                tt_transformers: [],
                standalone_keys: $standalone_keys
              }')
          else
            # All models
            model_config=$(jq -nc \
              --arg device "${{ inputs.device-type }}" \
              --argjson tt_models "$tt_transformers_models" \
              --argjson standalone_keys "$standalone_models" \
              '{
                device: $device,
                tt_transformers: $tt_models,
                standalone_keys: $standalone_keys
              }')
          fi

          echo "model-config=$model_config" >> $GITHUB_OUTPUT

  run-tests:
    needs: generate-test-matrix
    strategy:
      fail-fast: false
      matrix:
        test: ${{ fromJson(needs.generate-test-matrix.outputs.matrix) }}
    name: "${{ inputs.device-type }} - ${{ matrix.test.model }} - ${{ matrix.test.name }}"
    runs-on: >-
      ${{
        inputs.runner-label == 'topology-6u'
        && fromJSON(format('["{0}", "{1}", "{2}"]', inputs.arch == 'blackhole' && 'arch-blackhole' || 'arch-wormhole_b0', inputs.runner-label, inputs.extra-tag))
        || fromJSON(format('["{0}", "{1}"]', inputs.runner-label, inputs.extra-tag))
      }}
    container:
      image: ${{ inputs.docker-image }}
      env:
        TT_METAL_HOME: /work
        PYTHONPATH: /work
        LD_LIBRARY_PATH: /work/build/lib
        LOGURU_LEVEL: INFO
        ARCH_NAME: ${{ inputs.arch }}
        HF_MODEL: ${{ matrix.test.model_type == 'tt-transformers' && matrix.test.hf_model || '' }}
        TT_CACHE_PATH: ${{ matrix.test.cache_path }}
        HF_TOKEN: ${{ secrets.HUGGINGFACE_TOKEN }}
        HF_HUB_CACHE: ${{ inputs.arch == 'blackhole' && '/localdev/blackhole_demos/huggingface_data/hub' || '/mnt/MLPerf/huggingface/hub' }}
        HF_HOME: /tmp/hf_home
        SD_HF_DOWNLOAD_OVERRIDE: ${{ inputs.regenerate-ttnn-cache && '1' || '0' }}
        TT_CACHE_HOME: ${{ inputs.arch == 'blackhole' && '/localdev/blackhole_demos/huggingface_data/tt_cache' || '/mnt/MLPerf/huggingface/tt_cache' }}
      volumes:
        - ${{ github.workspace }}/docker-job:/work
        - /dev/hugepages-1G:/dev/hugepages-1G
        - ${{ inputs.arch == 'blackhole' && '/localdev/blackhole_demos/huggingface_data:/localdev/blackhole_demos/huggingface_data:rw' || format('/mnt/MLPerf:/mnt/MLPerf{0}', inputs.regenerate-ttnn-cache && ':rw' || ':ro') }}
      options: "--device /dev/tenstorrent"
    defaults:
      run:
        shell: bash
        working-directory: /work
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          submodules: recursive
          path: docker-job

      - name: ⬇️  Setup Job
        uses: ./docker-job/.github/actions/setup-job
        timeout-minutes: 10
        with:
          build-artifact-name: ${{ inputs.build-artifact-name }}
          wheel-artifact-name: ${{ inputs.wheel-artifact-name }}

      - name: Run ${{ matrix.test.name }} test
        timeout-minutes: ${{ matrix.test.timeout }}
        run: |
          echo "=========================================="
          echo "Running: ${{ matrix.test.name }}"
          echo "Device: ${{ inputs.device-type }}"
          echo "Model: ${{ matrix.test.model }}"
          echo "Model Type: ${{ matrix.test.model_type }}"
          echo "=========================================="

          # Sanitize test name for file naming (replace spaces with hyphens)
          TEST_NAME_SAFE="$(echo '${{ matrix.test.name }}' | tr ' ' '-')"

          # Check if we're not regenerating cache and should verify cache exists
          SKIP_IF_MISSING="${{ !inputs.regenerate-ttnn-cache }}"

          if [[ "${{ matrix.test.model_type }}" == "tt-transformers" ]]; then
            echo "HF_MODEL: ${{ matrix.test.hf_model }}"
            echo "TT_CACHE_PATH: ${{ matrix.test.cache_path }}"
            echo "Test Key: ${{ matrix.test.test_key }}"
            echo "Extra Args: ${{ matrix.test.extra_args }}"
            echo "=========================================="

            pytest models/tt_transformers/demo/simple_text_demo.py \
              -k "${{ matrix.test.test_key }}" \
              ${{ matrix.test.extra_args }} \
              --timeout 1000 \
              --junitxml=generated/test_results/results-${{ inputs.device-type }}-${{ matrix.test.model }}-${TEST_NAME_SAFE}.xml
          else
            echo "Test Path: ${{ matrix.test.test_path }}"
            echo "Test Args: ${{ matrix.test.test_args }}"
            echo "Working Directory: $(pwd)"
            echo "Test file exists: $(test -f ${{ matrix.test.test_path }} && echo 'YES' || echo 'NO')"
            echo "=========================================="

            # Run pytest with verbose output to see what's happening
            pytest --disable-warnings -v \
              ${{ matrix.test.test_path }} \
              ${{ matrix.test.test_args }} \
              --junitxml=generated/test_results/results-${{ inputs.device-type }}-${{ matrix.test.model }}-${TEST_NAME_SAFE}.xml || echo "pytest exit code: $?"
          fi

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ inputs.device-type }}-${{ matrix.test.model }}-${{ hashFiles(format('docker-job/generated/test_results/results-{0}-{1}-*.xml', inputs.device-type, matrix.test.model)) || github.run_number }}
          path: docker-job/generated/test_results/*.xml
          if-no-files-found: ignore

      - name: Save environment data
        id: save-environment-data
        if: ${{ !cancelled() }}
        timeout-minutes: 15
        env:
          ARCH_NAME: ${{ inputs.arch }}
        run: |
          if [ -d "generated/benchmark_data" ]; then
            echo "has_benchmark_data=true" >> $GITHUB_OUTPUT
            python3 .github/scripts/data_analysis/create_benchmark_with_environment_json.py
          fi

      - name: Upload benchmark data artifact
        if: ${{ !cancelled() && steps.save-environment-data.outputs.has_benchmark_data == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-data-${{ inputs.device-type }}-${{ matrix.test.model }}-${{ github.run_number }}-${{ strategy.job-index }}
          path: generated/benchmark_data

  generate-device-config:
    if: always()
    needs: [generate-test-matrix, run-tests]
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Export model configuration
        run: |
          # Get model config from matrix generation
          MODEL_CONFIG='${{ needs.generate-test-matrix.outputs.model-config }}'
          echo "$MODEL_CONFIG" > device-model-config.json

          # Extract standalone display names and test paths for chart generation
          DEVICE="${{ inputs.device-type }}"
          STANDALONE_KEYS=$(echo "$MODEL_CONFIG" | jq -r '.standalone_keys[]' 2>/dev/null || echo '[]')

          # Source the standalone model paths from the implementation
          source <(grep -E 'standalone_test_paths\[|standalone_test_args\[|standalone_display_names\[' .github/workflows/all-models-demo-tests-impl.yaml | sed 's/^[[:space:]]*//' | tr -d '\r')

          # Build JSON with display names and test commands
          DISPLAY_NAMES='[]'
          TEST_COMMANDS='{}'

          for key in $STANDALONE_KEYS; do
            # Get test path and args (using bash associative arrays wouldn't work in this context)
            # Instead, extract from the workflow file directly
            test_path=$(grep "standalone_test_paths\\[\"$key\"\\]=" .github/workflows/all-models-demo-tests-impl.yaml | sed -E 's/.*="(.*)"/\1/')
            test_args=$(grep "standalone_test_args\\[\"$key\"\\]=" .github/workflows/all-models-demo-tests-impl.yaml | sed -E 's/.*="(.*)"/\1/')
            display=$(grep "standalone_display_names\\[\"$key\"\\]=" .github/workflows/all-models-demo-tests-impl.yaml | sed -E 's/.*="(.*)"/\1/')

            if [ -n "$display" ] && [ -n "$test_path" ]; then
              DISPLAY_NAMES=$(echo "$DISPLAY_NAMES" | jq --arg name "$display" '. + [$name]')

              # Build pytest command
              if [ -n "$test_args" ]; then
                test_cmd="pytest --disable-warnings -v $test_path $test_args"
              else
                test_cmd="pytest --disable-warnings -v $test_path"
              fi

              TEST_COMMANDS=$(echo "$TEST_COMMANDS" | jq --arg model "$display" --arg cmd "$test_cmd" '. + {($model): $cmd}')
            fi
          done

          # Remove duplicates from display names (multiple variants map to same display name)
          DISPLAY_NAMES=$(echo "$DISPLAY_NAMES" | jq 'unique')

          # Create final config with display names and test commands
          FINAL_CONFIG=$(echo "$MODEL_CONFIG" | jq \
            --argjson standalone "$DISPLAY_NAMES" \
            --argjson test_commands "$TEST_COMMANDS" \
            '.standalone = $standalone | .standalone_test_commands = $test_commands | del(.standalone_keys)')
      - name: Upload device model configuration
        uses: actions/upload-artifact@v4
        with:
          name: model-config-${{ inputs.device-type }}
          path: device-model-config.json
          retention-days: 30
