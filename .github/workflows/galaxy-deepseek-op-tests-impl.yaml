name: "[internal] Galaxy DeepSeek tests impl"

on:
  workflow_call:
    inputs:
      docker-image:
        required: true
        type: string
      build-artifact-name:
        required: true
        type: string
      wheel-artifact-name:
        required: true
        type: string
      extra-tag:
        required: false
        type: string
        default: "in-service"
      topology:
        required: false
        type: string
        default: "topology-6u"

jobs:
  galaxy-deepseek-tests:
    name: ${{ matrix.test-group.name }}
    strategy:
      fail-fast: false
      matrix:
        test-group:
          - name: "(Galaxy) DeepSeek fused op tests"
            arch: wormhole_b0
            model: deepseek
            timeout: 150
            owner_id: U03HY7MK4BT
    runs-on:
      - arch-wormhole_b0
      - ${{ inputs.topology }}
      - bare-metal
      - pipeline-functional
      - ${{ inputs.extra-tag }}
    container:
      image: ${{ inputs.docker-image }}
      env:
        TT_METAL_HOME: /work
        PYTHONPATH: /work
        LD_LIBRARY_PATH: /work/build/lib
        LOGURU_LEVEL: INFO
        ARCH_NAME: ${{ matrix.test-group.arch }}
        DEEPSEEK_V3_HF_MODEL: /mnt/MLPerf/tt_dnn-models/deepseek-ai/DeepSeek-R1-0528
        DEEPSEEK_V3_CACHE: /mnt/MLPerf/tt_dnn-models/deepseek-ai/DeepSeek-R1-0528-Cache/CI
        MESH_DEVICE: TG
        # ADDED: Required for BenchmarkData to save to Superset
        CI: true
        GITHUB_ACTIONS: true
      volumes:
        - ${{ github.workspace }}/docker-job:/work # Subdir to workaround https://github.com/actions/runner/issues/691
        - /dev/hugepages-1G:/dev/hugepages-1G
        - /mnt/MLPerf:/mnt/MLPerf:rw
      options: "--device /dev/tenstorrent"
    defaults:
      run:
        shell: bash
        working-directory: /work # https://github.com/actions/runner/issues/878
    steps:
      - name: ðŸ§¬ Checkout Repository
        uses: actions/checkout@v4
        with:
          submodules: recursive
          path: docker-job
      - name: â¬‡ï¸  Setup Job
        uses: ./docker-job/.github/actions/setup-job
        timeout-minutes: 10
        with:
          build-artifact-name: ${{ inputs.build-artifact-name }}
          wheel-artifact-name: ${{ inputs.wheel-artifact-name }}
      - name: Validate weight cache
        timeout-minutes: 10
        run: |
          python3 models/demos/deepseek_v3/scripts/validate_weight_cache.py --root "$DEEPSEEK_V3_CACHE/tests_cache" || true

      - name: Run DeepSeek fused op unit tests (MLP - all ops)
        timeout-minutes: ${{ matrix.test-group.timeout }}
        run: |
          uv pip install -r models/demos/deepseek_v3/reference/deepseek/requirements.txt
          # Fused Op Tests: 1 decode (trace) + 2 prefill (eager: 128, 1024) per op
          # All tests log to Superset: mode, trace, program_cache, PCC, ATOL, RTOL, avg_us

          echo "=============================================="
          echo "LM HEAD fused op tests"
          echo "=============================================="
          echo "Running LM HEAD (decode seq_len=1, trace)..."
          pytest models/demos/deepseek_v3/tests/fused_op_unit_tests/lm_head/test_ds_fused_lm_head.py::test_ds_fused_lm_head -k "decode and 1 and trace and program_cache and not no_program_cache and real_weights" --timeout 600 --durations=0
          echo "Running LM HEAD (prefill seq_len=128, eager)..."
          pytest models/demos/deepseek_v3/tests/fused_op_unit_tests/lm_head/test_ds_fused_lm_head.py::test_ds_fused_lm_head -k "prefill and 128 and eager and program_cache and not no_program_cache and real_weights" --timeout 600 --durations=0
          echo "Running LM HEAD (prefill seq_len=1024, eager)..."
          pytest models/demos/deepseek_v3/tests/fused_op_unit_tests/lm_head/test_ds_fused_lm_head.py::test_ds_fused_lm_head -k "prefill and 1024 and eager and program_cache and not no_program_cache and real_weights" --timeout 600 --durations=0

          echo "=============================================="
          echo "MESH SCATTER fused op tests"
          echo "=============================================="
          echo "Running MESH SCATTER (decode seq_len=1, trace)..."
          pytest models/demos/deepseek_v3/tests/fused_op_unit_tests/lm_head/test_ds_fused_mesh_scatter.py::test_ds_fused_mesh_scatter -k "decode and 1 and row_3 and trace and program_cache and not no_program_cache" --timeout 600 --durations=0
          echo "Running MESH SCATTER (prefill seq_len=128, eager)..."
          pytest models/demos/deepseek_v3/tests/fused_op_unit_tests/lm_head/test_ds_fused_mesh_scatter.py::test_ds_fused_mesh_scatter -k "prefill and 128 and row_3 and eager and program_cache and not no_program_cache" --timeout 600 --durations=0
          echo "Running MESH SCATTER (prefill seq_len=1024, eager)..."
          pytest models/demos/deepseek_v3/tests/fused_op_unit_tests/lm_head/test_ds_fused_mesh_scatter.py::test_ds_fused_mesh_scatter -k "prefill and 1024 and row_3 and eager and program_cache and not no_program_cache" --timeout 600 --durations=0

          echo "=============================================="
          echo "RMS NORM fused op tests"
          echo "=============================================="
          echo "Running RMS NORM (decode seq_len=1, trace)..."
          pytest models/demos/deepseek_v3/tests/fused_op_unit_tests/rms_norm/test_ds_fused_rms_norm.py::test_ds_fused_rms_norm -k "decode and 1 and kv_lora_rank_512 and trace and program_cache and not no_program_cache and real_weights" --timeout 600 --durations=0
          echo "Running RMS NORM (prefill seq_len=128, eager)..."
          pytest models/demos/deepseek_v3/tests/fused_op_unit_tests/rms_norm/test_ds_fused_rms_norm.py::test_ds_fused_rms_norm -k "prefill and 128 and kv_lora_rank_512 and eager and program_cache and not no_program_cache and real_weights" --timeout 600 --durations=0
          echo "Running RMS NORM (prefill seq_len=1024, eager)..."
          pytest models/demos/deepseek_v3/tests/fused_op_unit_tests/rms_norm/test_ds_fused_rms_norm.py::test_ds_fused_rms_norm -k "prefill and 1024 and kv_lora_rank_512 and eager and program_cache and not no_program_cache and real_weights" --timeout 600 --durations=0

          echo "=============================================="
          echo "DISTRIBUTED NORM fused op tests"
          echo "=============================================="
          echo "Running DISTRIBUTED NORM (decode seq_len=1, trace)..."
          pytest models/demos/deepseek_v3/tests/fused_op_unit_tests/rms_norm/test_ds_fused_distributed_norm.py::test_ds_fused_distributed_norm -k "decode and 1 and trace and program_cache and not no_program_cache and real_weights" --timeout 600 --durations=0
          echo "Running DISTRIBUTED NORM (prefill seq_len=128, eager)..."
          pytest models/demos/deepseek_v3/tests/fused_op_unit_tests/rms_norm/test_ds_fused_distributed_norm.py::test_ds_fused_distributed_norm -k "prefill and 128 and eager and program_cache and not no_program_cache and real_weights" --timeout 600 --durations=0
          echo "Running DISTRIBUTED NORM (prefill seq_len=1024, eager)..."
          pytest models/demos/deepseek_v3/tests/fused_op_unit_tests/rms_norm/test_ds_fused_distributed_norm.py::test_ds_fused_distributed_norm -k "prefill and 1024 and eager and program_cache and not no_program_cache and real_weights" --timeout 600 --durations=0

          echo "=============================================="
          echo "MLP FF1/3 fused op tests"
          echo "=============================================="
          echo "Running MLP FF1/3 (decode seq_len=1, trace)..."
          pytest models/demos/deepseek_v3/tests/fused_op_unit_tests/mlp/ff1_3/test_ds_fused_ff1_3.py::test_ds_fused_ff1_3 -k "decode and 1 and trace and program_cache and not no_program_cache and real_weights" --timeout 600 --durations=0
          echo "Running MLP FF1/3 (prefill seq_len=128, eager)..."
          pytest models/demos/deepseek_v3/tests/fused_op_unit_tests/mlp/ff1_3/test_ds_fused_ff1_3.py::test_ds_fused_ff1_3 -k "prefill and 128 and eager and program_cache and not no_program_cache and real_weights" --timeout 600 --durations=0
          echo "Running MLP FF1/3 (prefill seq_len=1024, eager)..."
          pytest models/demos/deepseek_v3/tests/fused_op_unit_tests/mlp/ff1_3/test_ds_fused_ff1_3.py::test_ds_fused_ff1_3 -k "prefill and 1024 and eager and program_cache and not no_program_cache and real_weights" --timeout 600 --durations=0

          echo "=============================================="
          echo "MLP FF2 fused op tests"
          echo "=============================================="
          echo "Running MLP FF2 (decode seq_len=1, trace)..."
          pytest models/demos/deepseek_v3/tests/fused_op_unit_tests/mlp/ff2/test_ds_fused_ff2.py::test_ds_fused_ff2 -k "decode and 1 and trace and program_cache and not no_program_cache and real_weights" --timeout 600 --durations=0
          echo "Running MLP FF2 (prefill seq_len=128, eager)..."
          pytest models/demos/deepseek_v3/tests/fused_op_unit_tests/mlp/ff2/test_ds_fused_ff2.py::test_ds_fused_ff2 -k "prefill and 128 and eager and program_cache and not no_program_cache and real_weights" --timeout 600 --durations=0
          echo "Running MLP FF2 (prefill seq_len=1024, eager)..."
          pytest models/demos/deepseek_v3/tests/fused_op_unit_tests/mlp/ff2/test_ds_fused_ff2.py::test_ds_fused_ff2 -k "prefill and 1024 and eager and program_cache and not no_program_cache and real_weights" --timeout 600 --durations=0

          echo "=============================================="
          echo "MLP MUL fused op tests"
          echo "=============================================="
          echo "Running MLP MUL (decode seq_len=1, trace)..."
          pytest models/demos/deepseek_v3/tests/fused_op_unit_tests/mlp/mul/test_ds_fused_mul.py::test_ds_fused_mul -k "decode and 1 and trace and program_cache and not no_program_cache" --timeout 600 --durations=0
          echo "Running MLP MUL (prefill seq_len=128, eager)..."
          pytest models/demos/deepseek_v3/tests/fused_op_unit_tests/mlp/mul/test_ds_fused_mul.py::test_ds_fused_mul -k "prefill and 128 and eager and program_cache and not no_program_cache" --timeout 600 --durations=0
          echo "Running MLP MUL (prefill seq_len=1024, eager)..."
          pytest models/demos/deepseek_v3/tests/fused_op_unit_tests/mlp/mul/test_ds_fused_mul.py::test_ds_fused_mul -k "prefill and 1024 and eager and program_cache and not no_program_cache" --timeout 600 --durations=0

          echo "=============================================="
          echo "MLP REDUCE SCATTER fused op tests"
          echo "=============================================="
          echo "Running MLP REDUCE SCATTER (decode seq_len=1, trace)..."
          pytest models/demos/deepseek_v3/tests/fused_op_unit_tests/mlp/reduce_scatter/test_ds_fused_reduce_scatter_post_ff2.py::test_ds_fused_reduce_scatter_post_ff2 -k "decode and 1 and trace and program_cache and not no_program_cache" --timeout 600 --durations=0
          echo "Running MLP REDUCE SCATTER (prefill seq_len=128, eager)..."
          pytest models/demos/deepseek_v3/tests/fused_op_unit_tests/mlp/reduce_scatter/test_ds_fused_reduce_scatter_post_ff2.py::test_ds_fused_reduce_scatter_post_ff2 -k "prefill and 128 and eager and program_cache and not no_program_cache" --timeout 600 --durations=0
          echo "Running MLP REDUCE SCATTER (prefill seq_len=1024, eager)..."
          pytest models/demos/deepseek_v3/tests/fused_op_unit_tests/mlp/reduce_scatter/test_ds_fused_reduce_scatter_post_ff2.py::test_ds_fused_reduce_scatter_post_ff2 -k "prefill and 1024 and eager and program_cache and not no_program_cache" --timeout 600 --durations=0

          echo "=============================================="
          echo "MLP ALL GATHER fused op tests"
          echo "=============================================="
          echo "Running MLP ALL GATHER (decode seq_len=1, trace)..."
          pytest models/demos/deepseek_v3/tests/fused_op_unit_tests/mlp/all_gather/test_ds_fused_all_gather_preff1_3.py::test_ds_fused_all_gather_preff1_3 -k "decode and 1 and trace and program_cache and not no_program_cache" --timeout 600 --durations=0
          echo "Running MLP ALL GATHER (prefill seq_len=128, eager)..."
          pytest models/demos/deepseek_v3/tests/fused_op_unit_tests/mlp/all_gather/test_ds_fused_all_gather_preff1_3.py::test_ds_fused_all_gather_preff1_3 -k "prefill and 128 and eager and program_cache and not no_program_cache" --timeout 600 --durations=0
          echo "Running MLP ALL GATHER (prefill seq_len=1024, eager)..."
          pytest models/demos/deepseek_v3/tests/fused_op_unit_tests/mlp/all_gather/test_ds_fused_all_gather_preff1_3.py::test_ds_fused_all_gather_preff1_3 -k "prefill and 1024 and eager and program_cache and not no_program_cache" --timeout 600 --durations=0

          echo "=============================================="
          echo "EMBEDDING fused op tests"
          echo "=============================================="
          echo "Running EMBEDDING (decode seq_len=32, trace)..."
          pytest models/demos/deepseek_v3/tests/fused_op_unit_tests/embedding/embedding/test_ds_fused_embedding.py::test_ds_fused_embedding -k "decode and 32 and trace and program_cache and not no_program_cache and real_weights" --timeout 600 --durations=0
          echo "Running EMBEDDING (prefill seq_len=128, eager)..."
          pytest models/demos/deepseek_v3/tests/fused_op_unit_tests/embedding/embedding/test_ds_fused_embedding.py::test_ds_fused_embedding -k "prefill and 128 and eager and program_cache and not no_program_cache and real_weights" --timeout 600 --durations=0
          echo "Running EMBEDDING (prefill seq_len=1024, eager)..."
          pytest models/demos/deepseek_v3/tests/fused_op_unit_tests/embedding/embedding/test_ds_fused_embedding.py::test_ds_fused_embedding -k "prefill and 1024 and eager and program_cache and not no_program_cache and real_weights" --timeout 600 --durations=0

          echo "=============================================="
          echo "EMBEDDING ALL GATHER fused op tests"
          echo "=============================================="
          echo "Running EMBEDDING ALL GATHER (decode seq_len=32, trace)..."
          pytest models/demos/deepseek_v3/tests/fused_op_unit_tests/embedding/all_gather/test_ds_fused_all_gather_embedding.py::test_ds_fused_all_gather_embedding -k "decode and 32 and trace and program_cache and not no_program_cache" --timeout 600 --durations=0
          echo "Running EMBEDDING ALL GATHER (prefill seq_len=128, eager)..."
          pytest models/demos/deepseek_v3/tests/fused_op_unit_tests/embedding/all_gather/test_ds_fused_all_gather_embedding.py::test_ds_fused_all_gather_embedding -k "prefill and 128 and eager and program_cache and not no_program_cache" --timeout 600 --durations=0
          echo "Running EMBEDDING ALL GATHER (prefill seq_len=1024, eager)..."
          pytest models/demos/deepseek_v3/tests/fused_op_unit_tests/embedding/all_gather/test_ds_fused_all_gather_embedding.py::test_ds_fused_all_gather_embedding -k "prefill and 1024 and eager and program_cache and not no_program_cache" --timeout 600 --durations=0

          echo "=============================================="
          echo "All fused op tests completed!"
          echo "=============================================="
      - uses: tenstorrent/tt-metal/.github/actions/slack-report@main
        if: ${{ failure() }}
        with:
          slack_webhook_url: ${{ secrets.SLACK_METAL_INFRA_PIPELINE_STATUS_ALERT }}
          owner: ${{ matrix.test-group.owner_id }}
      # ENABLED: Save and upload benchmark data to Superset
      - name: Save environment data
        id: save-environment-data
        if: ${{ !cancelled() }}
        run: |
          if [ -d "generated/benchmark_data" ]; then
            echo "has_benchmark_data=true" >> $GITHUB_OUTPUT
            python3 .github/scripts/data_analysis/create_benchmark_with_environment_json.py
          else
            echo "::warning::Benchmark data directory 'generated/benchmark_data' does not exist"
            echo "has_benchmark_data=false" >> $GITHUB_OUTPUT
          fi
      - name: Upload benchmark data
        if: ${{ !cancelled() && steps.save-environment-data.conclusion == 'success' && steps.save-environment-data.outputs.has_benchmark_data == 'true' }}
        uses: tenstorrent/tt-metal/.github/actions/upload-data-via-sftp@main
        with:
          ssh-private-key: ${{ secrets.SFTP_BENCHMARK_WRITER_KEY }}
          sftp-batchfile: .github/actions/upload-data-via-sftp/benchmark_data_batchfile.txt
          username: ${{ secrets.SFTP_BENCHMARK_WRITER_USERNAME }}
          hostname: ${{ secrets.SFTP_BENCHMARK_WRITER_HOSTNAME }}
          path: /work
      - uses: tenstorrent/tt-metal/.github/actions/upload-artifact-with-job-uuid@main
        timeout-minutes: 10
        if: ${{ !cancelled() }}
        with:
          prefix: "test_reports_"
      - uses: tenstorrent/tt-metal/.github/actions/cleanup@main
