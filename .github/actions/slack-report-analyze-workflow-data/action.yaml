name: "Report Workflow Status to Slack"
description: "Report the workflow status to Slack to help identify breakages faster."
inputs:
  slack_webhook_url:
    description: "Webhook URL for the Slack channel to be posted to. Generated via slack app!"
    required: false
  channel_id:
    description: "Channel ID for the Slack channel (required if using Bot Token)"
    required: false
  regressed_workflows:
    description: "JSON array from analyze step output 'regressed_workflows'"
    required: true
  alert_all_message:
    description: "Optional Slack-ready alert text from analyze step output 'alert_all_message'"
    required: false
outputs:
  slack_ts:
    description: "The timestamp of the sent Slack message (only available when using Bot Token)"
    value: ${{ steps.slack_send.outputs.ts }}
runs:
  using: "composite"
  steps:
    - name: Build Slack message from regressions
      id: build
      shell: bash
      env:
        ALERT_RAW: ${{ inputs.alert_all_message }}
        REGRESSED_RAW: ${{ inputs.regressed_workflows }}
      run: |
        set -euo pipefail
        tmp_file="$(mktemp)"
        printf '%s' "$REGRESSED_RAW" > "$tmp_file"
        if ! jq -e . "$tmp_file" >/dev/null 2>&1; then
          echo "‚ö†Ô∏è Failed to parse regression list JSON. Skipping Slack notification."
          echo "has_regressions=false" >> "$GITHUB_OUTPUT"
          exit 0
        fi

        # Check if there are any regressions
        REGRESSION_COUNT=$(jq -r 'if (type=="array") then length else 0 end' "$tmp_file")
        if [ "$REGRESSION_COUNT" -eq 0 ]; then
          echo "‚úÖ No regressions detected. Skipping Slack notification (only posting when there are regressions)."
          echo "has_regressions=false" >> "$GITHUB_OUTPUT"
          exit 0
        fi
        echo "üìä Found $REGRESSION_COUNT regression(s). Preparing Slack notification..."
        echo "has_regressions=true" >> "$GITHUB_OUTPUT"

        # Slack has a 3000 character limit per text block
        # Be super conservative: use 1500 to ensure we stay well under the limit
        # This will naturally create more chunks (3+ messages) but ensures reliability
        MAX_BLOCK_TEXT_LENGTH=1500
        HEADER_PREFIX="‚ùå *Regressions (Pass ‚Üí Fail):*\n"

        # Function to format regression array to text (takes file path as argument)
        format_regressions() {
          local input_file="${1:-}"
          if [ -z "$input_file" ] || [ ! -f "$input_file" ]; then
            echo "Malformed regressions payload"
            return 0
          fi
          jq -r '
            def formatFailingJobs(jobs):
              if (jobs | type) == "array" and (jobs | length) > 0 then
                (jobs | map(
                  if (. | type) == "object" and .name then
                    (if .url and (.url | length) > 0 then
                      "    ‚Ä¢ <" + .url + "|" + .name + ">"
                    else
                      "    ‚Ä¢ " + .name
                    end) + (if (.owners | type) == "array" and (.owners | length) > 0 then
                      " " + (.owners | map(
                        if (.id // "") | startswith("S") then "<!subteam^" + .id + "|" + ((.name // "team")) + ">"
                        elif (.id // "") != "" then "<@" + .id + ">"
                        elif (.name // "") != "" then .name
                        else null end
                      ) | map(select(. != null)) | join(" "))
                    else "" end)
                  elif (. | type) == "string" then
                    "    ‚Ä¢ " + .
                  else
                    empty
                  end
                ) | join("\n"))
              else "" end;

            if (type=="array" and length > 0) then
              (map(
                "*" + .name + "*"
                + (if .workflow_url then " ‚Äî <" + .workflow_url + "|workflow>" else "" end)
                + (if .run_url then " ‚Äî <" + .run_url + "|run>" else "" end)
                + (if .commit_url and .commit_short then " ‚Äî <" + .commit_url + "|" + .commit_short + ">" else "" end)
                + (if (.failing_jobs | type) == "array" and (.failing_jobs | length) > 0 then
                    "\n" + formatFailingJobs(.failing_jobs)
                  else "" end)
              ) | join("\n"))
            else
              "Malformed regressions payload"
            end' "$input_file"
        }

        # Split regressions into chunks that fit within Slack's limit
        chunk_dir="$(mktemp -d)"
        chunk_index=0
        current_chunk="[]"

        # Process each regression
        for i in $(seq 0 $((REGRESSION_COUNT - 1))); do
          regression=$(jq -c ".[$i]" "$tmp_file")

          # Test if adding this regression would exceed the limit
          test_chunk=$(echo "$current_chunk" | jq -c ". + [$regression]")
          test_chunk_file="${chunk_dir}/test_${i}.json"
          echo "$test_chunk" > "$test_chunk_file"
          test_chunk_text=$(format_regressions "$test_chunk_file")
          test_full_text="${HEADER_PREFIX}${test_chunk_text}"
          test_length=$(printf '%s' "$test_full_text" | wc -c)

          # Reserve space for chunk indicator (we don't know total chunks yet, so be conservative)
          # Worst case: "*[Part 99/99]*\n" = ~18 chars, use 20 chars buffer
          CHUNK_INDICATOR_BUFFER=20
          test_length_with_indicator=$((test_length + CHUNK_INDICATOR_BUFFER))

          # If adding this regression would exceed the limit and we have regressions in current chunk, save it
          if [ "$test_length_with_indicator" -gt "$MAX_BLOCK_TEXT_LENGTH" ] && [ "$(echo "$current_chunk" | jq 'length')" -gt 0 ]; then
            echo "$current_chunk" > "${chunk_dir}/chunk_${chunk_index}.json"
            chunk_index=$((chunk_index + 1))
            current_chunk="[$regression]"
          else
            # Add regression to current chunk
            current_chunk="$test_chunk"
          fi
          rm -f "$test_chunk_file"
        done

        # Save the last chunk if it has any regressions
        if [ "$(echo "$current_chunk" | jq 'length')" -gt 0 ]; then
          echo "$current_chunk" > "${chunk_dir}/chunk_${chunk_index}.json"
          chunk_index=$((chunk_index + 1))
        fi

        TOTAL_CHUNKS=$chunk_index
        echo "total_chunks=$TOTAL_CHUNKS" >> "$GITHUB_OUTPUT"

        # Count total failing workflows from alert_all_message
        # The alert message format is: "*Alerts: failing workflows on main*\n‚Ä¢ Workflow Name <url|open> mentions jobs"
        # We count lines starting with "‚Ä¢ " to get the total number of failing workflows
        FAILING_WORKFLOWS_COUNT_MESSAGE=""
        if [ -n "${ALERT_RAW:-}" ]; then
          # Decode the alert message and count workflow lines
          decoded_alert=$(printf '%b' "$ALERT_RAW")
          total_failing_count=$(echo "$decoded_alert" | grep -E '^‚Ä¢ ' | wc -l | tr -d ' ')

          # Subtract regressions (already shown in detail) to get "other" failing workflows
          other_failing_count=$((total_failing_count - REGRESSION_COUNT))

          # Format the message (singular vs plural)
          if [ "$other_failing_count" -gt 0 ]; then
            if [ "$other_failing_count" -eq 1 ]; then
              FAILING_WORKFLOWS_COUNT_MESSAGE="1 other pipeline is failing"
            else
              FAILING_WORKFLOWS_COUNT_MESSAGE="$other_failing_count other pipelines are failing"
            fi
          fi
        fi

        # Build payloads for each chunk
        HEADER="Aggregate Workflow Data run: <https://github.com/${GITHUB_REPOSITORY}/actions/runs/${GITHUB_RUN_ID}|this run>"

        # Generate payloads for all chunks and store them
        # Temporarily disable exit on error so we create all payload files even if one fails
        set +e
        for i in $(seq 0 $((TOTAL_CHUNKS - 1))); do
          chunk_file="${chunk_dir}/chunk_${i}.json"
          if [ ! -f "$chunk_file" ]; then
            echo "‚ö†Ô∏è Chunk file not found: $chunk_file"
            continue
          fi

          chunk_text=$(format_regressions "$chunk_file" 2>/dev/null || echo "Error formatting regressions")
          if [ "$chunk_text" = "Error formatting regressions" ]; then
            echo "‚ö†Ô∏è Failed to format regressions for chunk $i"
          fi

          chunk_full_text="${HEADER_PREFIX}${chunk_text}"

          # Add chunk indicator if there are multiple chunks
          if [ "$TOTAL_CHUNKS" -gt 1 ]; then
            chunk_indicator="*[Part $((i + 1))/$TOTAL_CHUNKS]*\n"
            chunk_full_text="${chunk_indicator}${chunk_full_text}"
          else
            chunk_indicator=""
          fi

          # Verify the final text length doesn't exceed Slack's limit
          final_text_length=$(printf '%s' "$chunk_full_text" | wc -c)
          if [ "$final_text_length" -gt "$MAX_BLOCK_TEXT_LENGTH" ]; then
            echo "‚ö†Ô∏è Warning: Chunk $((i + 1)) text length ($final_text_length) exceeds our limit ($MAX_BLOCK_TEXT_LENGTH)"
            echo "This chunk may fail to send. Splitting further..."
            # This shouldn't happen with our conservative limit, but if it does, we need to handle it
          fi

          # Also verify the actual block text length in the payload (after JSON encoding)
          # Extract the body block text length from the payload to double-check
          body_block_text_length=$(echo "$PAYLOAD" | jq -r '.blocks[1].text.text // .blocks[1].text // ""' 2>/dev/null | wc -c || echo "0")
          if [ "$body_block_text_length" -gt 3000 ]; then
            echo "‚ö†Ô∏è CRITICAL: Chunk $((i + 1)) block text length ($body_block_text_length) exceeds Slack's 3000 char limit!"
            echo "This will definitely fail. The chunking logic needs to be more aggressive."
          fi

          # Add failing workflows count message only to the last chunk
          PAYLOAD=""
          if [ "$i" -eq $((TOTAL_CHUNKS - 1)) ] && [ -n "${FAILING_WORKFLOWS_COUNT_MESSAGE:-}" ]; then
            PAYLOAD=$(jq -cn \
              --arg header "$HEADER" \
              --arg body "$chunk_full_text" \
              --arg failing_count_msg "$FAILING_WORKFLOWS_COUNT_MESSAGE" \
              '
              {
                "text": ($header + "\n" + $body + "\n\n" + $failing_count_msg),
                "blocks": [
                  { "type": "section", "text": { "type": "mrkdwn", "text": $header } },
                  { "type": "section", "text": { "type": "mrkdwn", "text": $body } },
                  { "type": "section", "text": { "type": "mrkdwn", "text": $failing_count_msg } }
                ]
              }
            ' 2>/dev/null || echo "")
          else
            PAYLOAD=$(jq -cn \
              --arg header "$HEADER" \
              --arg body "$chunk_full_text" \
              '
              {
                "text": ($header + "\n" + $body),
                "blocks": [
                  { "type": "section", "text": { "type": "mrkdwn", "text": $header } },
                  { "type": "section", "text": { "type": "mrkdwn", "text": $body } }
                ]
              }
            ' 2>/dev/null || echo "")
          fi

          if [ -z "$PAYLOAD" ]; then
            echo "‚ö†Ô∏è Failed to create payload for chunk $i"
            continue
          fi

          # Store payload in a file for the send step
          payload_file="${GITHUB_WORKSPACE}/slack_payload_${i}.json"
          echo "$PAYLOAD" > "$payload_file"
          echo "Created payload file: $payload_file ($(wc -c < "$payload_file") bytes)"
        done
        set -e

        # Verify all payload files were created
        echo "Verifying payload files were created:"
        for i in $(seq 0 $((TOTAL_CHUNKS - 1))); do
          payload_file="${GITHUB_WORKSPACE}/slack_payload_${i}.json"
          if [ -f "$payload_file" ]; then
            echo "  ‚úÖ Payload $i exists ($(wc -c < "$payload_file") bytes)"
          else
            echo "  ‚ö†Ô∏è Payload $i MISSING!"
          fi
        done

        # Clean up temporary chunk files
        rm -rf "$chunk_dir"

    - name: Skip Slack notification (no regressions)
      if: steps.build.outputs.has_regressions != 'true'
      shell: bash
      run: echo "‚ÑπÔ∏è Skipping Slack notification because there are no regressions to report."

    - name: Report GitHub Pipeline Status to Slack (multiple messages if needed)
      if: steps.build.outputs.has_regressions == 'true'
      id: slack_send
      shell: bash
      env:
        SLACK_BOT_TOKEN: ${{ env.SLACK_BOT_TOKEN }}
        CHANNEL_ID: ${{ inputs.channel_id }}
        SLACK_WEBHOOK_URL: ${{ inputs.slack_webhook_url }}
        TOTAL_CHUNKS: ${{ steps.build.outputs.total_chunks }}
      run: |
        set -euo pipefail

        TOTAL_CHUNKS="${TOTAL_CHUNKS:-1}"
        echo "Sending $TOTAL_CHUNKS message(s) to Slack..."

        # Debug: List all payload files
        echo "Looking for payload files in ${GITHUB_WORKSPACE}:"
        ls -la "${GITHUB_WORKSPACE}"/slack_payload_*.json 2>/dev/null || echo "No payload files found yet"

        FIRST_TS=""
        SEND_ERRORS=0

        if [ -n "${SLACK_BOT_TOKEN:-}" ] && [ -n "${CHANNEL_ID:-}" ]; then
          # Using Bot Token method - supports threading
          # Temporarily disable exit on error for the loop so we can send all messages even if one fails
          set +e
          for i in $(seq 0 $((TOTAL_CHUNKS - 1))); do
            payload_file="${GITHUB_WORKSPACE}/slack_payload_${i}.json"
            if [ ! -f "$payload_file" ]; then
              echo "‚ö†Ô∏è Payload file not found: $payload_file"
              echo "Available files:"
              ls -la "${GITHUB_WORKSPACE}"/slack_payload_*.json 2>/dev/null || echo "None found"
              SEND_ERRORS=$((SEND_ERRORS + 1))
              continue
            fi

            PAYLOAD=$(cat "$payload_file" 2>/dev/null || echo "")
            if [ -z "$PAYLOAD" ]; then
              echo "‚ö†Ô∏è Failed to read payload file: $payload_file"
              SEND_ERRORS=$((SEND_ERRORS + 1))
              continue
            fi

            # Verify the block text length before sending
            # Check the body block (index 1) text length
            body_text=$(echo "$PAYLOAD" | jq -r '.blocks[1].text.text // .blocks[1].text // ""' 2>/dev/null || echo "")
            body_text_length=$(printf '%s' "$body_text" | wc -c)

            echo "Sending message part $((i + 1))/$TOTAL_CHUNKS..."
            echo "Payload file size: $(wc -c < "$payload_file" 2>/dev/null || echo 0) bytes"
            echo "Body block text length: $body_text_length characters (limit: 3000)"

            if [ "$body_text_length" -gt 3000 ]; then
              echo "‚ö†Ô∏è ERROR: Body text length ($body_text_length) exceeds Slack's 3000 character limit!"
              echo "This message will fail. Skipping to prevent API error."
              SEND_ERRORS=$((SEND_ERRORS + 1))
              continue
            fi

            # Build request body with channel and optional thread_ts
            REQUEST_BODY=""
            if [ -z "$FIRST_TS" ]; then
              REQUEST_BODY=$(echo "$PAYLOAD" | jq -c --arg channel "$CHANNEL_ID" '. + {channel: $channel}' 2>/dev/null || echo "")
            else
              REQUEST_BODY=$(echo "$PAYLOAD" | jq -c --arg channel "$CHANNEL_ID" --arg thread_ts "$FIRST_TS" '. + {channel: $channel, thread_ts: $thread_ts}' 2>/dev/null || echo "")
            fi

            if [ -z "$REQUEST_BODY" ]; then
              echo "‚ö†Ô∏è Failed to build request body for message part $((i + 1))"
              SEND_ERRORS=$((SEND_ERRORS + 1))
              continue
            fi

            RESPONSE=$(curl -s -X POST https://slack.com/api/chat.postMessage \
              -H "Authorization: Bearer $SLACK_BOT_TOKEN" \
              -H "Content-Type: application/json" \
              -d "$REQUEST_BODY" 2>/dev/null || echo '{"ok":false,"error":"curl_failed"}')

            # Extract timestamp for threading subsequent messages
            if [ -z "$FIRST_TS" ]; then
              FIRST_TS=$(echo "$RESPONSE" | jq -r '.ts // empty' 2>/dev/null || echo "")
              if [ -n "$FIRST_TS" ] && [ "$FIRST_TS" != "null" ] && [ "$FIRST_TS" != "" ]; then
                echo "ts=$FIRST_TS" >> "$GITHUB_OUTPUT"
                echo "First message timestamp: $FIRST_TS"
              fi
            fi

            # Check for errors
            OK_STATUS=$(echo "$RESPONSE" | jq -r '.ok // false' 2>/dev/null || echo "false")
            if [ "$OK_STATUS" != "true" ]; then
              ERROR_MSG=$(echo "$RESPONSE" | jq -r '.error // "unknown error"' 2>/dev/null || echo "failed to parse response")
              echo "‚ö†Ô∏è Failed to send Slack message part $((i + 1)): $ERROR_MSG"
              echo "Response: $RESPONSE"
              SEND_ERRORS=$((SEND_ERRORS + 1))
            else
              echo "‚úÖ Successfully sent message part $((i + 1))/$TOTAL_CHUNKS"
            fi
          done
          set -e

          if [ "$SEND_ERRORS" -gt 0 ]; then
            echo "‚ö†Ô∏è Warning: $SEND_ERRORS out of $TOTAL_CHUNKS messages failed to send"
          fi
        elif [ -n "${SLACK_WEBHOOK_URL:-}" ]; then
          # Using Webhook method (simpler but no threading support)
          # Temporarily disable exit on error for the loop
          set +e
          for i in $(seq 0 $((TOTAL_CHUNKS - 1))); do
            payload_file="${GITHUB_WORKSPACE}/slack_payload_${i}.json"
            if [ ! -f "$payload_file" ]; then
              echo "‚ö†Ô∏è Payload file not found: $payload_file"
              echo "Available files:"
              ls -la "${GITHUB_WORKSPACE}"/slack_payload_*.json 2>/dev/null || echo "None found"
              SEND_ERRORS=$((SEND_ERRORS + 1))
              continue
            fi

            PAYLOAD=$(cat "$payload_file" 2>/dev/null || echo "")
            if [ -z "$PAYLOAD" ]; then
              echo "‚ö†Ô∏è Failed to read payload file: $payload_file"
              SEND_ERRORS=$((SEND_ERRORS + 1))
              continue
            fi

            echo "Sending message part $((i + 1))/$TOTAL_CHUNKS via webhook..."
            echo "Payload file size: $(wc -c < "$payload_file" 2>/dev/null || echo 0) bytes"

            HTTP_CODE=$(curl -s -w "\n%{http_code}" -o /tmp/slack_response_${i}.txt -X POST "$SLACK_WEBHOOK_URL" \
              -H "Content-Type: application/json" \
              -d "$PAYLOAD" 2>/dev/null | tail -n1 || echo "000")

            if [ "$HTTP_CODE" != "200" ]; then
              echo "‚ö†Ô∏è Failed to send Slack message part $((i + 1)): HTTP $HTTP_CODE"
              cat "/tmp/slack_response_${i}.txt" 2>/dev/null || echo "No response body"
              SEND_ERRORS=$((SEND_ERRORS + 1))
            else
              echo "‚úÖ Successfully sent message part $((i + 1))/$TOTAL_CHUNKS"
            fi
            rm -f "/tmp/slack_response_${i}.txt"
          done
          set -e

          if [ "$SEND_ERRORS" -gt 0 ]; then
            echo "‚ö†Ô∏è Warning: $SEND_ERRORS out of $TOTAL_CHUNKS messages failed to send"
          fi
        else
          echo "‚ö†Ô∏è No Slack credentials provided (SLACK_BOT_TOKEN or SLACK_WEBHOOK_URL)"
          exit 1
        fi

        # Clean up payload files
        rm -f "${GITHUB_WORKSPACE}"/slack_payload_*.json
