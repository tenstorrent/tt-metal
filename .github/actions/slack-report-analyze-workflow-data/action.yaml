name: "Report Workflow Status to Slack"
description: "Report the workflow status to Slack to help identify breakages faster."
inputs:
  slack_webhook_url:
    description: "Webhook URL for the Slack channel to be posted to. Generated via slack app!"
    required: false
  channel_id:
    description: "Channel ID for the Slack channel (required if using Bot Token)"
    required: false
  regressed_workflows:
    description: "JSON array from analyze step output 'regressed_workflows'"
    required: true
  alert_all_message:
    description: "Optional Slack-ready alert text from analyze step output 'alert_all_message'"
    required: false
outputs:
  slack_ts:
    description: "The timestamp of the sent Slack message (only available when using Bot Token)"
    value: ${{ steps.slack_send.outputs.ts }}
runs:
  using: "composite"
  steps:
    - name: Build Slack message from regressions
      id: build
      shell: bash
      env:
        ALERT_RAW: ${{ inputs.alert_all_message }}
        REGRESSED_RAW: ${{ inputs.regressed_workflows }}
      run: |
        set -euo pipefail
        tmp_file="$(mktemp)"
        printf '%s' "$REGRESSED_RAW" > "$tmp_file"
        if ! jq -e . "$tmp_file" >/dev/null 2>&1; then
          echo "‚ö†Ô∏è Failed to parse regression list JSON. Skipping Slack notification."
          echo "has_regressions=false" >> "$GITHUB_OUTPUT"
          exit 0
        fi

        # Check if there are any regressions
        REGRESSION_COUNT=$(jq -r 'if (type=="array") then length else 0 end' "$tmp_file")
        if [ "$REGRESSION_COUNT" -eq 0 ]; then
          echo "‚úÖ No regressions detected. Skipping Slack notification (only posting when there are regressions)."
          echo "has_regressions=false" >> "$GITHUB_OUTPUT"
          exit 0
        fi
        echo "üìä Found $REGRESSION_COUNT regression(s). Preparing Slack notification..."
        echo "has_regressions=true" >> "$GITHUB_OUTPUT"

        # Slack has a 3000 character limit per text block
        MAX_BLOCK_TEXT_LENGTH=2900
        HEADER_PREFIX="‚ùå *Regressions (Pass ‚Üí Fail):*\n"

        # Function to format regression array to text (takes file path as argument)
        format_regressions() {
          local input_file="${1:-}"
          if [ -z "$input_file" ] || [ ! -f "$input_file" ]; then
            echo "Malformed regressions payload"
            return 0
          fi
          jq -r '
            def formatFailingJobs(jobs):
              if (jobs | type) == "array" and (jobs | length) > 0 then
                (jobs | map(
                  if (. | type) == "object" and .name then
                    (if .url and (.url | length) > 0 then
                      "    ‚Ä¢ <" + .url + "|" + .name + ">"
                    else
                      "    ‚Ä¢ " + .name
                    end) + (if (.owners | type) == "array" and (.owners | length) > 0 then
                      " " + (.owners | map(
                        if (.id // "") | startswith("S") then "<!subteam^" + .id + "|" + ((.name // "team")) + ">"
                        elif (.id // "") != "" then "<@" + .id + ">"
                        elif (.name // "") != "" then .name
                        else null end
                      ) | map(select(. != null)) | join(" "))
                    else "" end)
                  elif (. | type) == "string" then
                    "    ‚Ä¢ " + .
                  else
                    empty
                  end
                ) | join("\n"))
              else "" end;

            if (type=="array" and length > 0) then
              (map(
                "*" + .name + "*"
                + (if .workflow_url then " ‚Äî <" + .workflow_url + "|workflow>" else "" end)
                + (if .run_url then " ‚Äî <" + .run_url + "|run>" else "" end)
                + (if .commit_url and .commit_short then " ‚Äî <" + .commit_url + "|" + .commit_short + ">" else "" end)
                + (if (.failing_jobs | type) == "array" and (.failing_jobs | length) > 0 then
                    "\n" + formatFailingJobs(.failing_jobs)
                  else "" end)
              ) | join("\n"))
            else
              "Malformed regressions payload"
            end' "$input_file"
        }

        # Split regressions into chunks that fit within Slack's limit
        chunk_dir="$(mktemp -d)"
        chunk_index=0
        current_chunk="[]"

        # Process each regression
        for i in $(seq 0 $((REGRESSION_COUNT - 1))); do
          regression=$(jq -c ".[$i]" "$tmp_file")

          # Test if adding this regression would exceed the limit
          test_chunk=$(echo "$current_chunk" | jq -c ". + [$regression]")
          test_chunk_file="${chunk_dir}/test_${i}.json"
          echo "$test_chunk" > "$test_chunk_file"
          test_chunk_text=$(format_regressions "$test_chunk_file")
          test_full_text="${HEADER_PREFIX}${test_chunk_text}"
          test_length=$(printf '%s' "$test_full_text" | wc -c)

          # Reserve space for chunk indicator if we'll have multiple chunks
          # Estimate max: "*[Part 99/99]*\n" = ~20 chars
          CHUNK_INDICATOR_MAX=20
          test_length_with_indicator=$((test_length + CHUNK_INDICATOR_MAX))

          # If adding this regression would exceed the limit and we have regressions in current chunk, save it
          if [ "$test_length_with_indicator" -gt "$MAX_BLOCK_TEXT_LENGTH" ] && [ "$(echo "$current_chunk" | jq 'length')" -gt 0 ]; then
            echo "$current_chunk" > "${chunk_dir}/chunk_${chunk_index}.json"
            chunk_index=$((chunk_index + 1))
            current_chunk="[$regression]"
          else
            # Add regression to current chunk
            current_chunk="$test_chunk"
          fi
          rm -f "$test_chunk_file"
        done

        # Save the last chunk if it has any regressions
        if [ "$(echo "$current_chunk" | jq 'length')" -gt 0 ]; then
          echo "$current_chunk" > "${chunk_dir}/chunk_${chunk_index}.json"
          chunk_index=$((chunk_index + 1))
        fi

        TOTAL_CHUNKS=$chunk_index
        echo "total_chunks=$TOTAL_CHUNKS" >> "$GITHUB_OUTPUT"

        # Count total failing workflows from alert_all_message
        # The alert message format is: "*Alerts: failing workflows on main*\n‚Ä¢ Workflow Name <url|open> mentions jobs"
        # We count lines starting with "‚Ä¢ " to get the total number of failing workflows
        FAILING_WORKFLOWS_COUNT_MESSAGE=""
        if [ -n "${ALERT_RAW:-}" ]; then
          # Decode the alert message and count workflow lines
          decoded_alert=$(printf '%b' "$ALERT_RAW")
          total_failing_count=$(echo "$decoded_alert" | grep -E '^‚Ä¢ ' | wc -l | tr -d ' ')

          # Subtract regressions (already shown in detail) to get "other" failing workflows
          other_failing_count=$((total_failing_count - REGRESSION_COUNT))

          # Format the message (singular vs plural)
          if [ "$other_failing_count" -gt 0 ]; then
            if [ "$other_failing_count" -eq 1 ]; then
              FAILING_WORKFLOWS_COUNT_MESSAGE="1 other pipeline is failing"
            else
              FAILING_WORKFLOWS_COUNT_MESSAGE="$other_failing_count other pipelines are failing"
            fi
          fi
        fi

        # Build payloads for each chunk
        HEADER="Aggregate Workflow Data run: <https://github.com/${GITHUB_REPOSITORY}/actions/runs/${GITHUB_RUN_ID}|this run>"

        # Generate payloads for all chunks and store them
        for i in $(seq 0 $((TOTAL_CHUNKS - 1))); do
          chunk_file="${chunk_dir}/chunk_${i}.json"
          if [ ! -f "$chunk_file" ]; then
            echo "‚ö†Ô∏è Chunk file not found: $chunk_file"
            continue
          fi

          chunk_text=$(format_regressions "$chunk_file")
          chunk_full_text="${HEADER_PREFIX}${chunk_text}"

          # Add chunk indicator if there are multiple chunks
          if [ "$TOTAL_CHUNKS" -gt 1 ]; then
            chunk_full_text="*[Part $((i + 1))/$TOTAL_CHUNKS]*\n${chunk_full_text}"
          fi

          # Add failing workflows count message only to the last chunk
          if [ "$i" -eq $((TOTAL_CHUNKS - 1)) ] && [ -n "${FAILING_WORKFLOWS_COUNT_MESSAGE:-}" ]; then
            PAYLOAD=$(jq -cn \
              --arg header "$HEADER" \
              --arg body "$chunk_full_text" \
              --arg failing_count_msg "$FAILING_WORKFLOWS_COUNT_MESSAGE" \
              '
              {
                "text": ($header + "\n" + $body + "\n\n" + $failing_count_msg),
                "blocks": [
                  { "type": "section", "text": { "type": "mrkdwn", "text": $header } },
                  { "type": "section", "text": { "type": "mrkdwn", "text": $body } },
                  { "type": "section", "text": { "type": "mrkdwn", "text": $failing_count_msg } }
                ]
              }
            ')
          else
            PAYLOAD=$(jq -cn \
              --arg header "$HEADER" \
              --arg body "$chunk_full_text" \
              '
              {
                "text": ($header + "\n" + $body),
                "blocks": [
                  { "type": "section", "text": { "type": "mrkdwn", "text": $header } },
                  { "type": "section", "text": { "type": "mrkdwn", "text": $body } }
                ]
              }
            ')
          fi

          # Store payload in a file for the send step
          payload_file="${GITHUB_WORKSPACE}/slack_payload_${i}.json"
          echo "$PAYLOAD" > "$payload_file"
        done

        # Clean up temporary chunk files
        rm -rf "$chunk_dir"

    - name: Skip Slack notification (no regressions)
      if: steps.build.outputs.has_regressions != 'true'
      shell: bash
      run: echo "‚ÑπÔ∏è Skipping Slack notification because there are no regressions to report."

    - name: Report GitHub Pipeline Status to Slack (multiple messages if needed)
      if: steps.build.outputs.has_regressions == 'true'
      id: slack_send
      shell: bash
      env:
        SLACK_BOT_TOKEN: ${{ env.SLACK_BOT_TOKEN }}
        CHANNEL_ID: ${{ inputs.channel_id }}
        SLACK_WEBHOOK_URL: ${{ inputs.slack_webhook_url }}
        TOTAL_CHUNKS: ${{ steps.build.outputs.total_chunks }}
      run: |
        set -euo pipefail

        TOTAL_CHUNKS="${TOTAL_CHUNKS:-1}"
        echo "Sending $TOTAL_CHUNKS message(s) to Slack..."

        FIRST_TS=""

        if [ -n "${SLACK_BOT_TOKEN:-}" ] && [ -n "${CHANNEL_ID:-}" ]; then
          # Using Bot Token method - supports threading
          for i in $(seq 0 $((TOTAL_CHUNKS - 1))); do
            payload_file="${GITHUB_WORKSPACE}/slack_payload_${i}.json"
            if [ ! -f "$payload_file" ]; then
              echo "‚ö†Ô∏è Payload file not found: $payload_file"
              continue
            fi

            PAYLOAD=$(cat "$payload_file")
            echo "Sending message part $((i + 1))/$TOTAL_CHUNKS..."

            # Build request body with channel and optional thread_ts
            if [ -z "$FIRST_TS" ]; then
              REQUEST_BODY=$(echo "$PAYLOAD" | jq -c --arg channel "$CHANNEL_ID" '. + {channel: $channel}')
            else
              REQUEST_BODY=$(echo "$PAYLOAD" | jq -c --arg channel "$CHANNEL_ID" --arg thread_ts "$FIRST_TS" '. + {channel: $channel, thread_ts: $thread_ts}')
            fi

            RESPONSE=$(curl -s -X POST https://slack.com/api/chat.postMessage \
              -H "Authorization: Bearer $SLACK_BOT_TOKEN" \
              -H "Content-Type: application/json" \
              -d "$REQUEST_BODY")

            # Extract timestamp for threading subsequent messages
            if [ -z "$FIRST_TS" ]; then
              FIRST_TS=$(echo "$RESPONSE" | jq -r '.ts // empty')
              if [ -n "$FIRST_TS" ] && [ "$FIRST_TS" != "null" ]; then
                echo "ts=$FIRST_TS" >> "$GITHUB_OUTPUT"
              fi
            fi

            # Check for errors
            if [ "$(echo "$RESPONSE" | jq -r '.ok // false')" != "true" ]; then
              ERROR_MSG=$(echo "$RESPONSE" | jq -r '.error // "unknown error"')
              echo "‚ö†Ô∏è Failed to send Slack message part $((i + 1)): $ERROR_MSG"
              echo "$RESPONSE" | jq . || echo "$RESPONSE"
            else
              echo "‚úÖ Successfully sent message part $((i + 1))/$TOTAL_CHUNKS"
            fi
          done
        elif [ -n "${SLACK_WEBHOOK_URL:-}" ]; then
          # Using Webhook method (simpler but no threading support)
          for i in $(seq 0 $((TOTAL_CHUNKS - 1))); do
            payload_file="${GITHUB_WORKSPACE}/slack_payload_${i}.json"
            if [ ! -f "$payload_file" ]; then
              echo "‚ö†Ô∏è Payload file not found: $payload_file"
              continue
            fi

            PAYLOAD=$(cat "$payload_file")
            echo "Sending message part $((i + 1))/$TOTAL_CHUNKS via webhook..."

            HTTP_CODE=$(curl -s -w "\n%{http_code}" -o /tmp/slack_response_${i}.txt -X POST "$SLACK_WEBHOOK_URL" \
              -H "Content-Type: application/json" \
              -d "$PAYLOAD" | tail -n1)

            if [ "$HTTP_CODE" != "200" ]; then
              echo "‚ö†Ô∏è Failed to send Slack message part $((i + 1)): HTTP $HTTP_CODE"
              cat "/tmp/slack_response_${i}.txt" || true
            else
              echo "‚úÖ Successfully sent message part $((i + 1))/$TOTAL_CHUNKS"
            fi
            rm -f "/tmp/slack_response_${i}.txt"
          done
        else
          echo "‚ö†Ô∏è No Slack credentials provided (SLACK_BOT_TOKEN or SLACK_WEBHOOK_URL)"
          exit 1
        fi

        # Clean up payload files
        rm -f "${GITHUB_WORKSPACE}"/slack_payload_*.json
