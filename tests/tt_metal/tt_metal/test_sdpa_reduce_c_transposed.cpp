// SPDX-FileCopyrightText: Â© 2025 Tenstorrent AI ULC
//
// SPDX-License-Identifier: Apache-2.0

#include <algorithm>
#include <functional>
#include <random>

#include <tt-metalium/host_api.hpp>
#include <tt-metalium/tt_metal.hpp>
#include <tt-metalium/bfloat16.hpp>
#include "tt_metal/test_utils/deprecated/tensor.hpp"
#include <tt-metalium/tilize_utils.hpp>

using std::vector;
using namespace tt;
using std::string;

static void transpose_tiles_inplace_row_major(std::vector<bfloat16>& rm, uint32_t rows, uint32_t cols) {
    const uint32_t tile_h = 32;
    const uint32_t tile_w = 32;
    uint32_t tiles_h = rows / tile_h;
    uint32_t tiles_w = cols / tile_w;
    std::vector<bfloat16> copy = rm;
    for (uint32_t th = 0; th < tiles_h; ++th) {
        for (uint32_t tw = 0; tw < tiles_w; ++tw) {
            for (uint32_t i = 0; i < tile_h; ++i) {
                for (uint32_t j = 0; j < tile_w; ++j) {
                    uint32_t src_r = th * tile_h + i;
                    uint32_t src_c = tw * tile_w + j;
                    uint32_t dst_r = th * tile_h + j;
                    uint32_t dst_c = tw * tile_w + i;
                    rm[dst_r * cols + dst_c] = copy[src_r * cols + src_c];
                }
            }
        }
    }
}

static std::vector<bfloat16> golden_reduce_c_transposed(
    const std::vector<bfloat16>& qk_im_rm_transposed,
    const std::vector<bfloat16>& prev_max_first_col,
    uint32_t q_chunk_size,
    uint32_t k_chunk_size,
    bool do_eltwise_max) {
    const uint32_t rows = q_chunk_size * 32;
    const uint32_t cols = k_chunk_size * 32;
    const uint32_t stats_cols = 32;

    // Undo tile transpose to compute row-wise max on original orientation
    std::vector<bfloat16> qk_im_rm = qk_im_rm_transposed;
    transpose_tiles_inplace_row_major(qk_im_rm, rows, cols);

    std::vector<bfloat16> out(rows * stats_cols, static_cast<bfloat16>(0.0f));
    for (uint32_t r = 0; r < rows; ++r) {
        float row_max = -std::numeric_limits<float>::infinity();
        for (uint32_t c = 0; c < cols; ++c) {
            row_max = std::max(row_max, static_cast<float>(qk_im_rm[r * cols + c]));
        }
        if (do_eltwise_max) {
            row_max = std::max(row_max, static_cast<float>(prev_max_first_col[r]));
        }
        out[r * stats_cols + 0] = static_cast<bfloat16>(row_max);
    }

    // Re-apply tile transpose for the stats output (rows x 32)
    transpose_tiles_inplace_row_major(out, rows, 32);
    return out;
}

static float compare_first_col_mse(const std::vector<bfloat16>& result_rm, const std::vector<bfloat16>& golden_rm) {
    // Operates on row-major data, where each tile in the row-major data has been transposed.
    const uint32_t n_tiles = result_rm.size() / (32 * 32);
    const uint32_t rows = golden_rm.size() / 32;
    float mse = 0.0f;
    uint32_t start_idx = 0;
    for (uint32_t t = 0; t < n_tiles; ++t) {
        for (uint32_t r = 0; r < 32; ++r) {
            float a = static_cast<float>(result_rm[start_idx + r]);
            float b = static_cast<float>(golden_rm[start_idx + r]);
            float d = a - b;
            mse += d * d;
        }
        start_idx += 32 * 32;
    }
    mse /= rows;
    return mse;
}

static bool test_sdpa_reduce_c_transposed(
    tt_metal::IDevice* device,
    uint32_t q_chunk_size,
    uint32_t k_chunk_size,
    bool fp32_dest_acc_en,
    bool do_eltwise_max) {
    bool pass = true;

    auto slow_dispatch_mode = getenv("TT_METAL_SLOW_DISPATCH_MODE");
    TT_FATAL(slow_dispatch_mode, "This test only supports TT_METAL_SLOW_DISPATCH_MODE");

    log_info(
        LogTest,
        "Running sdpa_reduce_c_transposed test with q_chunk_size: {}, k_chunk_size: {}, "
        "fp32_dest_acc_en: {}, do_eltwise_max: {}",
        q_chunk_size,
        k_chunk_size,
        fp32_dest_acc_en,
        do_eltwise_max);

    tt_metal::Program program = tt_metal::CreateProgram();
    CoreCoord core = {0, 0};

    auto cb_df = tt::DataFormat::Float16_b;
    auto cb_tile_size = tt::tile_size(cb_df);

    uint32_t qk_im_num_tiles = q_chunk_size * k_chunk_size;
    uint32_t stats_num_tiles = q_chunk_size;

    auto qk_im_buffer_config = tt::tt_metal::ShardedBufferConfig{
        .device = device,
        .size = qk_im_num_tiles * cb_tile_size,
        .page_size = cb_tile_size,
        .buffer_type = tt::tt_metal::BufferType::L1,
        .buffer_layout = tt::tt_metal::TensorMemoryLayout::HEIGHT_SHARDED,
        .shard_parameters = tt::tt_metal::ShardSpecBuffer(
            CoreRangeSet(std::set<CoreRange>({CoreRange(core, core)})),
            {q_chunk_size * tt::constants::TILE_HEIGHT, k_chunk_size * tt::constants::TILE_WIDTH},
            tt::tt_metal::ShardOrientation::ROW_MAJOR,
            {tt::constants::TILE_HEIGHT, tt::constants::TILE_WIDTH},
            {q_chunk_size, k_chunk_size})};

    auto stats_buffer_config = tt::tt_metal::ShardedBufferConfig{
        .device = device,
        .size = stats_num_tiles * cb_tile_size,
        .page_size = cb_tile_size,
        .buffer_type = tt::tt_metal::BufferType::L1,
        .buffer_layout = tt::tt_metal::TensorMemoryLayout::HEIGHT_SHARDED,
        .shard_parameters = tt::tt_metal::ShardSpecBuffer(
            CoreRangeSet(std::set<CoreRange>({CoreRange(core, core)})),
            {stats_num_tiles * tt::constants::TILE_HEIGHT, tt::constants::TILE_WIDTH},
            tt::tt_metal::ShardOrientation::ROW_MAJOR,
            {tt::constants::TILE_HEIGHT, tt::constants::TILE_WIDTH},
            {stats_num_tiles, 1})};

    auto one_tile_buffer_config = tt::tt_metal::ShardedBufferConfig{
        .device = device,
        .size = cb_tile_size,
        .page_size = cb_tile_size,
        .buffer_type = tt::tt_metal::BufferType::L1,
        .buffer_layout = tt::tt_metal::TensorMemoryLayout::HEIGHT_SHARDED,
        .shard_parameters = tt::tt_metal::ShardSpecBuffer(
            CoreRangeSet(std::set<CoreRange>({CoreRange(core, core)})),
            {tt::constants::TILE_HEIGHT, tt::constants::TILE_WIDTH},
            tt::tt_metal::ShardOrientation::ROW_MAJOR,
            {tt::constants::TILE_HEIGHT, tt::constants::TILE_WIDTH},
            {1, 1})};

    auto qk_im_buffer = CreateBuffer(qk_im_buffer_config);
    auto prev_max_buffer = CreateBuffer(stats_buffer_config);
    auto out_max_buffer = CreateBuffer(stats_buffer_config);
    auto identity_scale_buffer = CreateBuffer(one_tile_buffer_config);

    auto cb_qk_im_id = tt::CBIndex::c_0;
    auto cb_qk_im_config = tt::tt_metal::CircularBufferConfig(qk_im_num_tiles * cb_tile_size, {{cb_qk_im_id, cb_df}})
                               .set_page_size(cb_qk_im_id, cb_tile_size)
                               .set_globally_allocated_address(*qk_im_buffer);
    tt_metal::CreateCircularBuffer(program, core, cb_qk_im_config);

    auto cb_prev_max_id = tt::CBIndex::c_1;
    auto cb_prev_max_config =
        tt::tt_metal::CircularBufferConfig(stats_num_tiles * cb_tile_size, {{cb_prev_max_id, cb_df}})
            .set_page_size(cb_prev_max_id, cb_tile_size)
            .set_globally_allocated_address(*prev_max_buffer);
    tt_metal::CreateCircularBuffer(program, core, cb_prev_max_config);

    auto cb_out_max_id = tt::CBIndex::c_2;
    auto cb_out_max_config =
        tt::tt_metal::CircularBufferConfig(stats_num_tiles * cb_tile_size, {{cb_out_max_id, cb_df}})
            .set_page_size(cb_out_max_id, cb_tile_size)
            .set_globally_allocated_address(*out_max_buffer);
    tt_metal::CreateCircularBuffer(program, core, cb_out_max_config);

    auto cb_identity_scale_id = tt::CBIndex::c_3;
    auto cb_identity_scale_config =
        tt::tt_metal::CircularBufferConfig(1 * cb_tile_size, {{cb_identity_scale_id, cb_df}})
            .set_page_size(cb_identity_scale_id, cb_tile_size)
            .set_globally_allocated_address(*identity_scale_buffer);
    tt_metal::CreateCircularBuffer(program, core, cb_identity_scale_config);

    std::vector<uint32_t> compute_kernel_args = {
        cb_qk_im_id,
        cb_prev_max_id,
        cb_out_max_id,
        cb_identity_scale_id,
        q_chunk_size,
        k_chunk_size,
        static_cast<uint32_t>(do_eltwise_max ? 1 : 0)};
    std::map<std::string, std::string> compute_defines;
    // unnecessary defines
    compute_defines["SUB_EXP_GRANULARITY"] = "0";
    compute_defines["LOG2_SUB_EXP_GRANULARITY"] = "0";
    compute_defines["STATS_GRANULARITY"] = "0";
    compute_defines["LOG2_STATS_GRANULARITY"] = "0";
    compute_defines["MUL_BCAST_GRANULARITY"] = "0";
    compute_defines["LOG2_MUL_BCAST_GRANULARITY"] = "0";
    compute_defines["DHT_GRANULARITY"] = "0";
    compute_defines["LOG2_DHT_GRANULARITY"] = "0";
    compute_defines["EXP_APPROX_MODE"] = "0";

    tt_metal::CreateKernel(
        program,
        "tests/tt_metal/tt_metal/test_kernels/misc/sdpa/reduce_c_transposed/compute.cpp",
        core,
        tt_metal::ComputeConfig{
            .math_fidelity = MathFidelity::HiFi2,
            .fp32_dest_acc_en = fp32_dest_acc_en,
            .math_approx_mode = false,
            .compile_args = compute_kernel_args,
            .defines = compute_defines});

    // Inputs: tile-transposed qk_im and prev_max
    SHAPE qk_im_shape = {1, 1, q_chunk_size * 32, k_chunk_size * 32};
    tt::deprecated::Tensor<bfloat16> qk_im_tensor = tt::deprecated::initialize_tensor<bfloat16>(
        qk_im_shape, tt::deprecated::Initialize::RANDOM, -50, 50, 0 /* seed */);

    std::vector<bfloat16> qk_rm = qk_im_tensor.get_values();
    transpose_tiles_inplace_row_major(qk_rm, q_chunk_size * 32, k_chunk_size * 32);
    auto qk_im_tilized = tilize_nfaces(qk_rm, q_chunk_size * 32, k_chunk_size * 32);
    auto qk_im_uint = pack_bfloat16_vec_into_uint32_vec(qk_im_tilized);
    tt_metal::detail::WriteToBuffer(qk_im_buffer, qk_im_uint);

    std::mt19937 rng(0);
    std::uniform_real_distribution<float> dist(25.0f, 65.0f);
    const uint32_t rows = q_chunk_size * 32;
    std::vector<bfloat16> prev_max_first_col(rows);
    std::vector<bfloat16> prev_max_rm(rows * 32, static_cast<bfloat16>(0.0f));
    for (uint32_t r = 0; r < rows; ++r) {
        float v = dist(rng);
        prev_max_first_col[r] = static_cast<bfloat16>(v);
        prev_max_rm[r * 32 + 0] = static_cast<bfloat16>(v);
    }
    // Transpose tiles of the stats matrix (rows x 32)
    transpose_tiles_inplace_row_major(prev_max_rm, rows, 32);
    auto prev_max_tilized = tilize_nfaces(prev_max_rm, rows, 32);
    auto prev_max_uint = pack_bfloat16_vec_into_uint32_vec(prev_max_tilized);
    tt_metal::detail::WriteToBuffer(prev_max_buffer, prev_max_uint);

    // identity scale tile of ones
    std::vector<bfloat16> scale_tile(
        tt::constants::TILE_HEIGHT * tt::constants::TILE_WIDTH, static_cast<bfloat16>(1.0f));
    auto scale_uint = pack_bfloat16_vec_into_uint32_vec(scale_tile);
    tt_metal::detail::WriteToBuffer(identity_scale_buffer, scale_uint);

    tt_metal::detail::LaunchProgram(device, program, true);

    std::vector<uint32_t> out_max_vec;
    tt_metal::detail::ReadFromBuffer(out_max_buffer, out_max_vec);
    auto out_max_bfp16 = unpack_uint32_vec_into_bfloat16_vec(out_max_vec);
    auto out_max_rm = untilize_nfaces(out_max_bfp16, rows, 32);

    auto golden_rm = golden_reduce_c_transposed(qk_rm, prev_max_first_col, q_chunk_size, k_chunk_size, do_eltwise_max);

    float mse = compare_first_col_mse(out_max_rm, golden_rm);

    if (mse > 0.0f) {
        log_error(LogTest, "reduce_c_transposed mse: {} > 0", mse);
        pass = false;
    }

    return pass;
}

int main(int argc, char** argv) {
    bool pass = true;
    char env[] = "TT_METAL_SLOW_DISPATCH_MODE=1";
    putenv(env);

    int device_id = 0;
    tt_metal::IDevice* device = tt_metal::CreateDevice(device_id);

    /**
     * Parameters to sweep over for correctness.
     */
    std::vector<uint32_t> q_chunk_sizes = {1};      //, 2, 4, 8};
    std::vector<uint32_t> k_chunk_sizes = {1};      //, 2, 4, 8, 16};
    std::vector<bool> fp32_dest_acc_ens = {false};  //, true};
    std::vector<bool> do_eltwise = {false};         //, true};

    /**
     * These parameters are the same as the SDPA sprint-2 perfomance test parameters.
     * Uncomment to measure perf of the test we care most about.
     */
    // std::vector<uint32_t> q_chunk_sizes = {8};
    // std::vector<uint32_t> k_chunk_sizes = {16};
    // std::vector<bool> fp32_dest_acc_ens = {false};
    // std::vector<bool> do_eltwise = {false, true};

    for (uint32_t q_chunk_size : q_chunk_sizes) {
        for (uint32_t k_chunk_size : k_chunk_sizes) {
            for (bool fp32_dest_acc_en : fp32_dest_acc_ens) {
                for (bool do_elt : do_eltwise) {
                    bool this_passed =
                        test_sdpa_reduce_c_transposed(device, q_chunk_size, k_chunk_size, fp32_dest_acc_en, do_elt);
                    if (!this_passed) {
                        log_error(
                            LogTest,
                            "Test Failed for q_chunk_size: {}, k_chunk_size: {}, fp32_dest_acc_en: {}, do_eltwise: {}",
                            q_chunk_size,
                            k_chunk_size,
                            fp32_dest_acc_en,
                            do_elt);
                    }
                    pass &= this_passed;
                }
            }
        }
    }

    pass &= tt_metal::CloseDevice(device);

    if (pass) {
        log_info(LogTest, "Test Passed");
    } else {
        TT_THROW("Test Failed");
    }

    TT_FATAL(pass, "Error");
}
