// SPDX-FileCopyrightText: Â© 2023 Tenstorrent Inc.
//
// SPDX-License-Identifier: Apache-2.0

#include <chrono>
#include <fmt/base.h>
#include <gtest/gtest.h>
#include <stddef.h>
#include <tt-metalium/bfloat16.hpp>
#include <tt-metalium/host_api.hpp>
#include <tt-metalium/tilize_utils.hpp>
#include <algorithm>
#include <bit>
#include <cstdint>
#include <initializer_list>
#include <iterator>
#include <map>
#include <memory>
#include <set>
#include <string>
#include <type_traits>
#include <utility>
#include <variant>
#include <vector>

#include <tt-metalium/assert.hpp>
#include <tt-metalium/base_types.hpp>
#include <tt-metalium/buffer.hpp>
#include <tt-metalium/buffer_types.hpp>
#include <tt-metalium/circular_buffer_config.hpp>
#include <tt-metalium/core_coord.hpp>
#include <tt-metalium/data_types.hpp>
#include "dispatch_fixture.hpp"
#include <tt-metalium/kernel_types.hpp>
#include <tt-metalium/logger.hpp>
#include "matmul_test_utils.hpp"
#include <tt-metalium/program.hpp>
#include <tt_stl/span.hpp>
#include <tt-metalium/tt_backend_api_types.hpp>
#include "tt_metal/test_utils/deprecated/tensor.hpp"
#include "tt_metal/test_utils/env_vars.hpp"
#include "umd/device/types/arch.h"
#include <tt-metalium/utils.hpp>

namespace tt {
namespace tt_metal {
class IDevice;
}  // namespace tt_metal
}  // namespace tt

namespace tt::tt_metal {

using std::vector;
using namespace tt;
using namespace tt::test_utils;
namespace unit_tests_common::matmul::test_matmul_X_tile {

struct MatmulTileStimuli {
    vector<bfloat16> t;  // Raw tensor values
    vector<uint32_t> a;  // Activations
    vector<uint32_t> w;  // Weights
};

struct MatmulTileConfig {
    uint32_t M, K, N;
    // Whether or not to add matmul result with bias:
    bool with_bias = false;
    // Whether or not to use *_init_short LLK API calls:
    bool test_init_short = false;
    // Whether or not to use *_with_dt LLK API init calls:
    bool with_dt = true;
    // Whether or not we want the result to be stored in DST in FP32:
    bool fp32_dest_acc_en = false;
    // Whether or not to sync full/half DST between MATH and PACK:
    bool dst_full_sync_en = false;
    string reader_kernel;
    string compute_kernel;
    vector<uint32_t> compute_kernel_args;
    MathFidelity math_fidelity = MathFidelity::HiFi4;
};

void create_test_stimuli(MatmulTileStimuli& stimuli, uint32_t M, uint32_t K, uint32_t N) {
    SHAPE shape = {1, 1, M * 32, K * 32};
    tt::deprecated::Tensor<bfloat16> tensor = tt::deprecated::initialize_tensor<bfloat16>(
        shape, tt::deprecated::Initialize::RANDOM, 0, 100, std::chrono::system_clock::now().time_since_epoch().count());
    stimuli.t = tensor.get_values();

    auto activations_tilized = tilize_swizzled(tensor.get_values(), M * 32, K * 32);
    auto activations_tile_layout =
        convert_layout_tile_swizzled_to_tile_nfaces(tt::stl::MakeConstSpan(activations_tilized));
    auto activations = pack_bfloat16_vec_into_uint32_vec(activations_tile_layout);
    auto activations_tile_transposed = tt::tt_metal::transpose_tiles(activations, M, K, 1);
    stimuli.a = activations_tile_transposed;

    auto identity = create_identity_matrix(K * 32, N * 32, std::min(K, N) * 32);
    auto identity_tilized = tilize_swizzled(identity, K * 32, N * 32);
    auto weights_tile_layout = convert_layout_tile_swizzled_to_tile_nfaces(tt::stl::MakeConstSpan(identity_tilized));
    auto weights = pack_bfloat16_vec_into_uint32_vec(weights_tile_layout);
    stimuli.w = weights;
}

// This function creates bit masks to model math fidelity phases. This will mask the result only.
void set_math_fid_masks(uint16_t& math_fid_mask, MathFidelity math_fidelity = MathFidelity::HiFi4) {
    auto arch = get_arch_from_string(get_umd_arch_name());
    switch (math_fidelity) {
        case MathFidelity::HiFi4:
        case MathFidelity::HiFi3: {
            break;
        }
        case MathFidelity::HiFi2:
        case MathFidelity::LoFi: {
            math_fid_mask = (arch == tt::ARCH::GRAYSKULL) ? 0xFFF8 : 0xFFFE;
            break;
        }
        default: {
            TT_THROW("Unsupported MathFidelity={}", math_fidelity);
            break;
        }
    }
}

void matmul_tile(
    tt_metal::DispatchFixture* fixture,
    tt_metal::IDevice* device,
    const MatmulTileConfig& cfg,
    vector<uint32_t> activations,
    vector<uint32_t> weights,
    vector<bfloat16> tensor_vals) {
    tt_metal::Program program = tt_metal::CreateProgram();
    CoreCoord core = {0, 0};

    // num_tile == M == N == K in the case of multi_tile, conveniently they were all the same!!
    // for single_tile case, num_tile = 1
    uint32_t M = cfg.M;
    uint32_t K = cfg.K;
    uint32_t N = cfg.N;
    uint32_t num_tiles = M * K;                      // only if M = K = N
    uint32_t single_tile_size_fp32 = 4 * 32 * 32;    // Single 32x32 tile size for Float32
    uint32_t single_tile_size_bfp16b = 2 * 32 * 32;  // Single 32x32 tile size for Float16_b / Uint16
    uint32_t single_tile_size_out0 = cfg.fp32_dest_acc_en ? single_tile_size_fp32 : single_tile_size_bfp16b;
    const size_t dram_buffer_size_bfp16b = num_tiles * single_tile_size_bfp16b;
    const size_t dram_buffer_size_out0 = num_tiles * single_tile_size_out0;

    tt_metal::InterleavedBufferConfig input_dram_config{
        .device = device,
        .size = dram_buffer_size_bfp16b,
        .page_size = dram_buffer_size_bfp16b,
        .buffer_type = tt_metal::BufferType::DRAM};
    tt_metal::InterleavedBufferConfig output_dram_config{
        .device = device,
        .size = dram_buffer_size_out0,
        .page_size = dram_buffer_size_out0,
        .buffer_type = tt_metal::BufferType::DRAM};

    auto src0_dram_buffer = CreateBuffer(input_dram_config);
    auto src1_dram_buffer = CreateBuffer(input_dram_config);
    auto dst_dram_buffer = CreateBuffer(output_dram_config);

    uint32_t num_input_tiles = 2 * M;

    uint32_t src0_cb_index = 0;
    tt_metal::CircularBufferConfig cb_src0_config =
        tt_metal::CircularBufferConfig(
            num_input_tiles * single_tile_size_bfp16b, {{src0_cb_index, tt::DataFormat::Float16_b}})
            .set_page_size(src0_cb_index, single_tile_size_bfp16b);
    auto cb_src0 = tt_metal::CreateCircularBuffer(program, core, cb_src0_config);

    uint32_t src1_cb_index = 1;
    tt_metal::CircularBufferConfig cb_src1_config =
        tt_metal::CircularBufferConfig(
            num_input_tiles * single_tile_size_bfp16b, {{src1_cb_index, tt::DataFormat::Float16_b}})
            .set_page_size(src1_cb_index, single_tile_size_bfp16b);
    auto cb_src1 = tt_metal::CreateCircularBuffer(program, core, cb_src1_config);

    std::shared_ptr<tt_metal::Buffer> src2_dram_buffer;
    std::shared_ptr<tt_metal::Buffer> dst1_dram_buffer;
    if (cfg.with_bias) {  // with_bias only when M, N, or K > 1
        tt_metal::InterleavedBufferConfig bias_config{
            .device = device,
            .size = single_tile_size_bfp16b * N,
            .page_size = single_tile_size_bfp16b * N,
            .buffer_type = tt_metal::BufferType::DRAM};
        src2_dram_buffer = CreateBuffer(bias_config);

        uint32_t src2_cb_index = 2;
        tt_metal::CircularBufferConfig cb_src2_config =
            tt_metal::CircularBufferConfig(
                num_input_tiles * single_tile_size_bfp16b, {{src2_cb_index, tt::DataFormat::Float16_b}})
                .set_page_size(src2_cb_index, single_tile_size_bfp16b);
        auto cb_src2 = tt_metal::CreateCircularBuffer(program, core, cb_src2_config);
    } else if (cfg.test_init_short) {  // This will be dummy input in uint16_t
        uint32_t in2_id = 2;
        uint32_t out1_id = 17;

        tt_metal::InterleavedBufferConfig dummy_config{
            .device = device,
            .size = single_tile_size_bfp16b * N,
            .page_size = single_tile_size_bfp16b * N,
            .buffer_type = tt_metal::BufferType::DRAM};

        // This will be srcB in uint16_t
        src2_dram_buffer = CreateBuffer(dummy_config);

        // This will be dummy output in uint16_t
        dst1_dram_buffer = CreateBuffer(dummy_config);

        tt_metal::CircularBufferConfig cb_src2_config =
            tt_metal::CircularBufferConfig(
                num_input_tiles * single_tile_size_bfp16b, {{in2_id, tt::DataFormat::UInt16}})
                .set_page_size(in2_id, single_tile_size_bfp16b);
        auto cb_src2 = tt_metal::CreateCircularBuffer(program, core, cb_src2_config);

        tt_metal::CircularBufferConfig cb_dst1_config =
            tt_metal::CircularBufferConfig(
                num_input_tiles * single_tile_size_bfp16b, {{out1_id, tt::DataFormat::UInt16}})
                .set_page_size(out1_id, single_tile_size_bfp16b);
        auto cb_dst1 = tt_metal::CreateCircularBuffer(program, core, cb_dst1_config);
    }

    uint32_t ouput_cb_index = 16;
    vector<uint32_t> reader_l1_args;
    if (cfg.M > 1 || cfg.N > 1 || cfg.K > 1) {
        uint32_t intermediate_cb_index = 24;
        std::map<uint8_t, tt::DataFormat> partials_and_out_data_format_spec = {
            {ouput_cb_index, (cfg.fp32_dest_acc_en ? tt::DataFormat::Float32 : tt::DataFormat::Float16_b)},
            {intermediate_cb_index, (cfg.fp32_dest_acc_en ? tt::DataFormat::Float32 : tt::DataFormat::Float16_b)}};

        CoreRangeSet cores(std::set<CoreRange>{CoreRange(core, core)});
        tt_metal::CircularBufferConfig cb_output_config =
            tt_metal::CircularBufferConfig(dram_buffer_size_out0, partials_and_out_data_format_spec)
                .set_page_size(ouput_cb_index, single_tile_size_out0)
                .set_page_size(intermediate_cb_index, single_tile_size_out0);
        auto cb_output = tt_metal::CreateCircularBuffer(program, core, cb_output_config);

        reader_l1_args = {
            src0_dram_buffer->address(),
            0,
            src1_dram_buffer->address(),
            0,
            (std::uint32_t)K,
            (std::uint32_t)M,
            (std::uint32_t)N,
            (std::uint32_t)(M * single_tile_size_bfp16b),
            (std::uint32_t)(N * single_tile_size_bfp16b),
            cfg.with_bias};
    } else {
        uint32_t num_output_tiles = 2;
        tt_metal::CircularBufferConfig cb_output_config =
            tt_metal::CircularBufferConfig(
                num_output_tiles * single_tile_size_out0,
                {{ouput_cb_index, (cfg.fp32_dest_acc_en ? tt::DataFormat::Float32 : tt::DataFormat::Float16_b)}})
                .set_page_size(ouput_cb_index, single_tile_size_out0);
        auto cb_output = tt_metal::CreateCircularBuffer(program, core, cb_output_config);

        reader_l1_args = {
            src0_dram_buffer->address(),
            0,
            src1_dram_buffer->address(),
            0,
            1,
            1,
            1,
            1 * single_tile_size_bfp16b,
            1 * single_tile_size_bfp16b};
    }

    std::map<string, string> compute_defines;

    compute_defines["WITH_DT"] = cfg.with_dt ? "1" : "0";
    compute_defines["TEST_INIT_SHORT"] = cfg.test_init_short ? "1" : "0";
    if (cfg.fp32_dest_acc_en) {
        compute_defines["DST_ACCUM_MODE"] = "1";
    }

    auto mm_reader_kernel = tt_metal::CreateKernel(
        program,
        cfg.reader_kernel,
        core,
        tt_metal::DataMovementConfig{
            .processor = tt_metal::DataMovementProcessor::RISCV_1, .noc = tt_metal::NOC::RISCV_1_default});

    auto unary_writer_kernel = tt_metal::CreateKernel(
        program,
        "tt_metal/kernels/dataflow/writer_unary.cpp",
        core,
        tt_metal::DataMovementConfig{
            .processor = tt_metal::DataMovementProcessor::RISCV_0, .noc = tt_metal::NOC::RISCV_0_default});

    auto mm_kernel = tt_metal::CreateKernel(
        program,
        cfg.compute_kernel,
        core,
        tt_metal::ComputeConfig{
            .math_fidelity = cfg.math_fidelity,
            .fp32_dest_acc_en = cfg.fp32_dest_acc_en,
            .dst_full_sync_en = cfg.dst_full_sync_en,
            .compile_args = cfg.compute_kernel_args,
            .defines = compute_defines});

    fixture->WriteBuffer(device, src0_dram_buffer, activations);
    fixture->WriteBuffer(device, src1_dram_buffer, weights);

    if (cfg.with_bias || cfg.test_init_short) {
        vector<uint32_t> bias(N * 512, 0);
        fixture->WriteBuffer(device, src2_dram_buffer, bias);

        vector<uint32_t> bias_args = {
            src2_dram_buffer->address(), 0, (std::uint32_t)N, (std::uint32_t)(N * single_tile_size_bfp16b)};

        for (uint32_t arg : bias_args) {
            reader_l1_args.push_back(arg);
        }
    }

    tt_metal::SetRuntimeArgs(program, mm_reader_kernel, core, reader_l1_args);

    tt_metal::SetRuntimeArgs(
        program,
        unary_writer_kernel,
        core,
        {dst_dram_buffer->address(), 0, num_tiles});  // this is M * N in the multi_tile case !!

    fixture->RunProgram(device, program);

    // This is tilized result, will not be modified
    std::vector<uint32_t> result_vec;
    fixture->ReadBuffer(device, dst_dram_buffer, result_vec);

    std::vector<bfloat16> golden = std::move(tensor_vals);
    std::vector<bfloat16> golden_tilized = tilize_swizzled(golden, M * 32, N * 32);
    std::vector<bfloat16> golden_tilized_single =
        convert_layout_tile_swizzled_to_tile_nfaces(tt::stl::MakeConstSpan(golden_tilized));

    std::vector<uint32_t> golden_packed(golden_tilized_single.size());
    uint16_t math_fid_mask = 0xFFFF;
    set_math_fid_masks(math_fid_mask, cfg.math_fidelity);
    for (auto i = 0; i < golden_tilized.size(); i++) {
        golden_tilized_single[i] = bfloat16(golden_tilized_single[i].to_uint16() & math_fid_mask);
        if (cfg.fp32_dest_acc_en) {
            golden_packed[i] = std::bit_cast<uint32_t>(golden_tilized_single[i].to_float());
        }
    }
    if (!cfg.fp32_dest_acc_en) {
        golden_packed = pack_bfloat16_vec_into_uint32_vec(golden_tilized_single);
    }

    EXPECT_EQ(golden_packed.size(), result_vec.size());
    EXPECT_EQ(golden_packed, result_vec);

    DeallocateBuffer(*src0_dram_buffer);
    DeallocateBuffer(*src1_dram_buffer);
    if (cfg.with_bias || cfg.test_init_short) {
        if (cfg.test_init_short) {
            DeallocateBuffer(*dst1_dram_buffer);
        }
        DeallocateBuffer(*src2_dram_buffer);
    }
    DeallocateBuffer(*dst_dram_buffer);

    tt::log_info(
        tt::LogTest,
        "Math Fidelity = {}, FP32_DestAcc = {}, DstSyncFull = {}",
        cfg.math_fidelity,
        cfg.fp32_dest_acc_en,
        cfg.dst_full_sync_en);
}
}  // namespace unit_tests_common::matmul::test_matmul_X_tile

using namespace tt::test_utils;
using namespace unit_tests_common::matmul::test_matmul_X_tile;

/* matmul_config.compute_kernel_args = {
    // block_tile_dim, within block, how many tiles are on the K dim
    // dst_tile_rows
    // dst_tile_cols
    // block_cnt, across blocks, how many tiles are on the K dim
    // in0_block_tile_cnt, M * block_tile_dim
    // in1_block_tile_cnt, N * block_tile_dim
    // out_block_tile_cnt
}
*/

TEST_F(DispatchFixture, TensixMatmulSingleTile) {
    for (uint8_t i = uint8_t(MathFidelity::LoFi); i <= uint8_t(MathFidelity::HiFi4); i++) {
        if (i == 1) {
            continue;
        }
        for (bool fp32_dest_acc_en : {true, false}) {
            if ((fp32_dest_acc_en) && (this->arch_ == tt::ARCH::GRAYSKULL)) {
                continue;
            }
            for (bool dst_full_sync_en : {true, false}) {
                MatmulTileConfig matmul_config = {
                    .M = 1,
                    .K = 1,
                    .N = 1,
                    .fp32_dest_acc_en = fp32_dest_acc_en,
                    .dst_full_sync_en = dst_full_sync_en,
                    .reader_kernel = "tests/tt_metal/tt_metal/test_kernels/dataflow/reader_matmul_blocked.cpp",
                    .compute_kernel = "tests/tt_metal/tt_metal/test_kernels/compute/matmul.cpp",
                    .compute_kernel_args = {1, 1, 1, 1, 1, 1, 1},
                    .math_fidelity = MathFidelity(i)};
                MatmulTileStimuli stimuli;
                create_test_stimuli(stimuli, 1, 1, 1);

                for (unsigned int id = 0; id < devices_.size(); id++) {
                    matmul_tile(this, devices_.at(id), matmul_config, stimuli.a, stimuli.w, stimuli.t);
                }
            }
        }
    }
}

TEST_F(DispatchFixture, TensixMatmulMultiTile) {
    for (uint8_t i = uint8_t(MathFidelity::LoFi); i <= uint8_t(MathFidelity::HiFi4); i++) {
        if (i == 1) {
            continue;
        }
        for (bool fp32_dest_acc_en : {true, false}) {
            if ((fp32_dest_acc_en) && (this->arch_ == tt::ARCH::GRAYSKULL)) {
                continue;
            }
            for (bool dst_full_sync_en : {true, false}) {
                uint32_t M = fp32_dest_acc_en ? 2 : 4;
                uint32_t N = fp32_dest_acc_en ? 2 : 4;
                uint32_t K = fp32_dest_acc_en ? 2 : 4;
                MatmulTileConfig matmul_config = {
                    .M = M,
                    .K = K,
                    .N = N,
                    .fp32_dest_acc_en = fp32_dest_acc_en,
                    .dst_full_sync_en = dst_full_sync_en,
                    .reader_kernel =
                        "tests/tt_metal/tt_metal/test_kernels/dataflow/reader_matmul_with_bias_blocked.cpp",
                    .compute_kernel = "tests/tt_metal/tt_metal/test_kernels/compute/matmul_with_bias.cpp",
                    .compute_kernel_args = {1, M, N, K, M, N, (M * N), matmul_config.with_bias},
                    .math_fidelity = MathFidelity(i)};
                MatmulTileStimuli stimuli;
                create_test_stimuli(stimuli, M, K, N);

                for (unsigned int id = 0; id < devices_.size(); id++) {
                    matmul_tile(this, devices_.at(id), matmul_config, stimuli.a, stimuli.w, stimuli.t);
                    log_info(LogTest, "Multi tile with no bias passed");
                    matmul_config.with_bias = true;
                    matmul_tile(this, devices_.at(id), matmul_config, stimuli.a, stimuli.w, stimuli.t);
                    log_info(LogTest, "Multi tile with bias passed");
                }
            }
        }
    }
}

TEST_F(DispatchFixture, TensixMatmulBlock) {
    for (uint8_t i = uint8_t(MathFidelity::LoFi); i <= uint8_t(MathFidelity::HiFi4); i++) {
        if (i == 1) {
            continue;
        }
        for (bool fp32_dest_acc_en : {true, false}) {
            if ((fp32_dest_acc_en) && (this->arch_ == tt::ARCH::GRAYSKULL)) {
                continue;
            }
            for (bool dst_full_sync_en : {true, false}) {
                uint32_t M = fp32_dest_acc_en ? 2 : 4;
                uint32_t N = fp32_dest_acc_en ? 2 : 4;
                uint32_t K = fp32_dest_acc_en ? 2 : 4;
                MatmulTileConfig matmul_config = {
                    .M = M,
                    .K = K,
                    .N = N,
                    .test_init_short = false,
                    .with_dt = false,
                    .fp32_dest_acc_en = fp32_dest_acc_en,
                    .dst_full_sync_en = dst_full_sync_en,
                    .reader_kernel =
                        "tests/tt_metal/tt_metal/test_kernels/dataflow/reader_matmul_with_bias_blocked.cpp",
                    .compute_kernel = "tests/tt_metal/tt_metal/test_kernels/compute/matmul_block.cpp",
                    .compute_kernel_args = {1, M, N, K, M, N, (M * N)},
                    .math_fidelity = MathFidelity(i)};
                MatmulTileStimuli stimuli;
                create_test_stimuli(stimuli, M, K, N);

                for (unsigned int id = 0; id < devices_.size(); id++) {
                    matmul_tile(this, devices_.at(id), matmul_config, stimuli.a, stimuli.w, stimuli.t);
                }
            }
        }
    }
}

TEST_F(DispatchFixture, TensixMatmulBlockInitShort) {
    for (uint8_t i = uint8_t(MathFidelity::LoFi); i <= uint8_t(MathFidelity::HiFi4); i++) {
        if (i == 1) {
            continue;
        }
        for (bool fp32_dest_acc_en : {true, false}) {
            if ((fp32_dest_acc_en) && (this->arch_ == tt::ARCH::GRAYSKULL)) {
                continue;
            }
            for (bool dst_full_sync_en : {true, false}) {
                uint32_t M = fp32_dest_acc_en ? 2 : 4;
                uint32_t N = fp32_dest_acc_en ? 2 : 4;
                uint32_t K = fp32_dest_acc_en ? 2 : 4;
                MatmulTileConfig matmul_config = {
                    .M = M,
                    .K = K,
                    .N = N,
                    .test_init_short = true,
                    .with_dt = false,
                    .fp32_dest_acc_en = fp32_dest_acc_en,
                    .dst_full_sync_en = dst_full_sync_en,
                    .reader_kernel =
                        "tests/tt_metal/tt_metal/test_kernels/dataflow/reader_matmul_with_bias_blocked.cpp",
                    .compute_kernel = "tests/tt_metal/tt_metal/test_kernels/compute/matmul_block.cpp",
                    .compute_kernel_args = {1, M, N, K, M, N, (M * N)},
                    .math_fidelity = MathFidelity(i)};
                MatmulTileStimuli stimuli;
                create_test_stimuli(stimuli, M, K, N);

                for (unsigned int id = 0; id < devices_.size(); id++) {
                    matmul_tile(this, devices_.at(id), matmul_config, stimuli.a, stimuli.w, stimuli.t);
                }
            }
        }
    }
}

TEST_F(DispatchFixture, TensixMatmulBlockInitShortWithDt) {
    for (uint8_t i = uint8_t(MathFidelity::LoFi); i <= uint8_t(MathFidelity::HiFi4); i++) {
        if (i == 1) {
            continue;
        }
        for (bool fp32_dest_acc_en : {true, false}) {
            if ((fp32_dest_acc_en) && (this->arch_ == tt::ARCH::GRAYSKULL)) {
                continue;
            }
            for (bool dst_full_sync_en : {true, false}) {
                uint32_t M = fp32_dest_acc_en ? 2 : 4;
                uint32_t N = fp32_dest_acc_en ? 2 : 4;
                uint32_t K = fp32_dest_acc_en ? 2 : 4;
                MatmulTileConfig matmul_config = {
                    .M = M,
                    .K = K,
                    .N = N,
                    .test_init_short = true,
                    .with_dt = true,
                    .fp32_dest_acc_en = fp32_dest_acc_en,
                    .dst_full_sync_en = dst_full_sync_en,
                    .reader_kernel =
                        "tests/tt_metal/tt_metal/test_kernels/dataflow/reader_matmul_with_bias_blocked.cpp",
                    .compute_kernel = "tests/tt_metal/tt_metal/test_kernels/compute/matmul_block.cpp",
                    .compute_kernel_args = {1, M, N, K, M, N, (M * N)},
                    .math_fidelity = MathFidelity(i)};
                MatmulTileStimuli stimuli;
                create_test_stimuli(stimuli, M, K, N);

                for (unsigned int id = 0; id < devices_.size(); id++) {
                    matmul_tile(this, devices_.at(id), matmul_config, stimuli.a, stimuli.w, stimuli.t);
                }
            }
        }
    }
}

}  // namespace tt::tt_metal
