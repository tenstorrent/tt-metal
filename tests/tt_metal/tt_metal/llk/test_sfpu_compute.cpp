// SPDX-FileCopyrightText: Â© 2023 Tenstorrent Inc.
//
// SPDX-License-Identifier: Apache-2.0

#include <chrono>
#include <fmt/base.h>
#include <gtest/gtest.h>
#include <stddef.h>
#include <stdint.h>
#include <tt-metalium/host_api.hpp>
#include <tt-metalium/tt_metal.hpp>
#include <algorithm>
#include <cmath>
#include <functional>
#include <map>
#include <memory>
#include <string>
#include <tuple>
#include <utility>
#include <variant>
#include <vector>

#include <tt-metalium/assert.hpp>
#include <tt-metalium/bfloat16.hpp>
#include <tt-metalium/buffer.hpp>
#include <tt-metalium/buffer_types.hpp>
#include <tt-metalium/circular_buffer_config.hpp>
#include <tt-metalium/core_coord.hpp>
#include <tt-metalium/data_types.hpp>
#include <tt-metalium/device.hpp>
#include "device_fixture.hpp"
#include "hostdevcommon/kernel_structs.h"
#include <tt-metalium/kernel_types.hpp>
#include <tt-metalium/logger.hpp>
#include <tt-metalium/program.hpp>
#include <tt_stl/span.hpp>
#include <tt-metalium/tt_backend_api_types.hpp>
#include "tt_metal/test_utils/comparison.hpp"
#include "tt_metal/test_utils/df/float32.hpp"
#include "tt_metal/test_utils/packing.hpp"
#include "tt_metal/test_utils/stimulus.hpp"
#include "umd/device/types/arch.h"
#include <tt-metalium/utils.hpp>

namespace tt::tt_metal {

using std::map;
using std::vector;
using namespace tt;
using namespace tt::test_utils;
using namespace tt::test_utils::df;

namespace unit_tests::sfpu_util {

const map<string, std::map<string, string>> sfpu_op_to_op_name = {
    // FIXME: #1157
    {"relu", {{"SFPU_OP_CHAIN_0", "relu_tile_init(); relu_tile(0);"}}},
    {"exponential", {{"SFPU_OP_CHAIN_0", "exp_tile_init(); exp_tile(0);"}}},
    {"reciprocal", {{"SFPU_OP_CHAIN_0", "recip_tile_init(); recip_tile(0);"}}},
    {"gelu", {{"SFPU_OP_CHAIN_0", "gelu_tile_init(); gelu_tile(0);"}}},
    {"sqrt", {{"SFPU_OP_CHAIN_0", "sqrt_tile_init(); sqrt_tile(0);"}}},
    {"sigmoid", {{"SFPU_OP_CHAIN_0", "sigmoid_tile_init(); sigmoid_tile(0);"}}},
    {"log", {{"SFPU_OP_CHAIN_0", "log_tile_init(); log_tile(0);"}}},
    {"tanh", {{"SFPU_OP_CHAIN_0", "tanh_tile_init(); tanh_tile(0);"}}},
    {"sign", {{"SFPU_OP_CHAIN_0", "sign_tile_init(); sign_tile(0);"}}},
};

bfloat16 sfpu_function(const string& op_name, const bfloat16& input) {
    if (op_name == "relu") {
        return bfloat16(fmaxf(input.to_float(), 0.0f));
    } else if (op_name == "exponential") {
        return bfloat16(std::exp(input.to_float()));
    } else if (op_name == "reciprocal") {
        return bfloat16(1 / input.to_float());
    } else if (op_name == "gelu") {
        static constexpr float alpha = M_2_SQRTPI * M_SQRT1_2;
        auto x = input.to_float();
        auto x3 = x * x * x;
        float result = x * 0.5 * (1.0 + tanhf(alpha * (x + 0.044715 * x3)));
        return bfloat16(result);
    } else if (op_name == "sqrt") {
        return bfloat16(sqrtf(input.to_float()));
    } else if (op_name == "sigmoid") {
        auto x = input.to_float();
        float result = 1 / (1 + std::exp(-x));
        return bfloat16(result);
    } else if (op_name == "log") {
        return bfloat16(logf(input.to_float()));
    } else if (op_name == "tanh") {
        return bfloat16(std::tanh(input.to_float()));
    } else if (op_name == "sign") {
        return bfloat16((0.0f < input.to_float()) ? 1.0f : ((input.to_float() < 0.0f) ? -1.0f : 0.0f));
    } else {
        TT_THROW("Unsupported op_name in test");
        return bfloat16(0.0f);
    }
}
vector<uint32_t> generate_packed_sfpu_input(const unsigned int numel, const string& op_name, const int seed) {
    if ((op_name == "sqrt") or (op_name == "log")) {
        return generate_packed_uniform_random_vector<uint32_t, bfloat16>(0.0001f, 4.0f, numel, seed);
    } else if ((op_name == "exponential") or (op_name == "gelu") or (op_name == "reciprocal")) {
        auto possible_values = vector<bfloat16>({-1.0f, -0.5f, 0.5f, 1.0f});
        return generate_packed_random_vector_from_vector<uint32_t, bfloat16>(possible_values, numel, seed);
    } else {
        return generate_packed_uniform_random_vector<uint32_t, bfloat16>(-1.0f, 1.0f, numel, seed);
    }
}

bool is_close_packed_sfpu_output(
    const std::vector<uint32_t>& vec_a, const std::vector<uint32_t>& vec_b, const string& op_name) {
    if (op_name == "tanh") {
        return is_close_packed_vectors<bfloat16, uint32_t>(
            vec_a, vec_b, [&](const bfloat16& a, const bfloat16& b) { return is_close(a, b, 0.175f, 0.1f); });
    } else if ((op_name == "gelu") or (op_name == "relu")) {
        return is_close_packed_vectors<bfloat16, uint32_t>(
            vec_a, vec_b, [&](const bfloat16& a, const bfloat16& b) { return is_close(a, b, 0.15f); });
    } else if ((op_name == "exponential")) {
        return is_close_packed_vectors<bfloat16, uint32_t>(
            vec_a, vec_b, [&](const bfloat16& a, const bfloat16& b) { return is_close(a, b, 0.1f, 0.1f); });
    } else if ((op_name == "log")) {
        return is_close_packed_vectors<bfloat16, uint32_t>(
            vec_a, vec_b, [&](const bfloat16& a, const bfloat16& b) { return is_close(a, b, 0.03f, 0.02f); });
    } else {
        return is_close_packed_vectors<bfloat16, uint32_t>(
            vec_a, vec_b, [&](const bfloat16& a, const bfloat16& b) { return is_close(a, b, 0.06f, 0.006f); });
    }
}

}  // namespace unit_tests::sfpu_util

namespace unit_tests::compute::sfpu {

struct SfpuConfig {
    size_t num_tiles = 0;
    size_t tile_byte_size = 0;
    tt::DataFormat l1_input_data_format = tt::DataFormat::Invalid;
    tt::DataFormat l1_output_data_format = tt::DataFormat::Invalid;
    CoreRangeSet cores = CoreRangeSet();
    std::string sfpu_op = "";
    bool approx_mode = true;
};

/// @brief Does Dram --> Reader --> CB --> Sfpu Compute --> CB --> Writer --> Dram. So far, enqueue APIs only added to
/// grayskull
/// @param device
/// @param test_config - Configuration of the test -- see struct
/// @return
bool run_sfpu_all_same_buffer(tt_metal::IDevice* device, const SfpuConfig& test_config) {
    const size_t byte_size = test_config.num_tiles * test_config.tile_byte_size;
    tt_metal::Program program = tt_metal::CreateProgram();
    tt::tt_metal::InterleavedBufferConfig dram_config{
        .device = device, .size = byte_size, .page_size = byte_size, .buffer_type = tt::tt_metal::BufferType::DRAM};

    auto input_dram_buffer = CreateBuffer(dram_config);
    uint32_t input_dram_byte_address = input_dram_buffer->address();
    auto output_dram_buffer = CreateBuffer(dram_config);
    uint32_t output_dram_byte_address = output_dram_buffer->address();

    vector<uint32_t> compute_kernel_args = {
        uint32_t(test_config.num_tiles),  // per_core_block_cnt
        1                                 // per_core_block_cnt
    };

    // Input
    std::vector<uint32_t> packed_input = sfpu_util::generate_packed_sfpu_input(
        byte_size / bfloat16::SIZEOF, test_config.sfpu_op, std::chrono::system_clock::now().time_since_epoch().count());

    // Golden output
    auto input = unpack_vector<bfloat16, uint32_t>(packed_input);
    std::vector<bfloat16> golden(input.size());
    std::transform(input.begin(), input.end(), golden.begin(), [&](const bfloat16& val) {
        return sfpu_util::sfpu_function(test_config.sfpu_op, val);
    });
    std::vector<uint32_t> packed_golden = pack_vector<uint32_t, bfloat16>(golden);

    // Same runtime args for every core
    vector<uint32_t> reader_rt_args = {
        (uint32_t)input_dram_byte_address,
        (uint32_t)0,
        (uint32_t)test_config.num_tiles,
    };

    vector<uint32_t> writer_rt_args = {
        (uint32_t)output_dram_byte_address,
        (uint32_t)0,
        (uint32_t)test_config.num_tiles,
    };

    for (const CoreRange& core_range : test_config.cores.ranges()) {
        tt_metal::CircularBufferConfig l1_input_cb_config =
            tt_metal::CircularBufferConfig(byte_size, {{tt::CBIndex::c_0, test_config.l1_input_data_format}})
                .set_page_size(tt::CBIndex::c_0, test_config.tile_byte_size);
        auto l1_input_cb = tt_metal::CreateCircularBuffer(program, core_range, l1_input_cb_config);

        tt_metal::CircularBufferConfig l1_output_cb_config =
            tt_metal::CircularBufferConfig(byte_size, {{tt::CBIndex::c_16, test_config.l1_output_data_format}})
                .set_page_size(tt::CBIndex::c_16, test_config.tile_byte_size);
        auto l1_output_cb = tt_metal::CreateCircularBuffer(program, core_range, l1_output_cb_config);

        auto reader_kernel = tt_metal::CreateKernel(
            program,
            "tt_metal/kernels/dataflow/reader_unary.cpp",
            test_config.cores,
            tt_metal::DataMovementConfig{
                .processor = tt_metal::DataMovementProcessor::RISCV_1, .noc = tt_metal::NOC::RISCV_1_default});

        auto writer_kernel = tt_metal::CreateKernel(
            program,
            "tt_metal/kernels/dataflow/writer_unary.cpp",
            test_config.cores,
            tt_metal::DataMovementConfig{
                .processor = tt_metal::DataMovementProcessor::RISCV_0, .noc = tt_metal::NOC::RISCV_0_default});

        std::map<string, string> sfpu_defines = sfpu_util::sfpu_op_to_op_name.at(test_config.sfpu_op);

        sfpu_defines["SFPU_OP_EXP_INCLUDE"] = "1";
        sfpu_defines["SFPU_OP_GELU_INCLUDE"] = "1";
        sfpu_defines["SFPU_OP_RECIP_INCLUDE"] = "1";
        sfpu_defines["SFPU_OP_SQRT_INCLUDE"] = "1";
        sfpu_defines["SFPU_OP_ERF_ERFC_INCLUDE"] = "1";
        sfpu_defines["SFPU_OP_ELU_INCLUDE"] = "1";
        sfpu_defines["SFPU_OP_NEG_INCLUDE"] = "1";
        sfpu_defines["SFPU_OP_RELU_FAMILY_INCLUDE"] = "1";
        sfpu_defines["SFPU_OP_COMPUTE_KERNEL_API_INCLUDE"] = "1";

        auto sfpu_kernel = tt_metal::CreateKernel(
            program,
            "tt_metal/kernels/compute/eltwise_sfpu.cpp",
            test_config.cores,
            tt_metal::ComputeConfig{
                .math_approx_mode = test_config.approx_mode,
                .compile_args = compute_kernel_args,
                .defines = sfpu_defines});

        for (const CoreCoord& core_coord : core_range) {
            SetRuntimeArgs(program, writer_kernel, core_coord, writer_rt_args);
            SetRuntimeArgs(program, reader_kernel, core_coord, reader_rt_args);
        }
    }

    std::vector<uint32_t> dest_buffer_data;
    tt_metal::detail::WriteToBuffer(input_dram_buffer, packed_input);
    tt_metal::detail::LaunchProgram(device, program);
    tt_metal::detail::ReadFromBuffer(output_dram_buffer, dest_buffer_data);

    return sfpu_util::is_close_packed_sfpu_output(dest_buffer_data, packed_golden, test_config.sfpu_op);
}

}  // namespace unit_tests::compute::sfpu
class SingleCoreSingleDeviceSfpuParameterizedFixture : public DeviceFixture,
                                                       public testing::WithParamInterface<std::tuple<size_t, string>> {
};
TEST_P(SingleCoreSingleDeviceSfpuParameterizedFixture, TensixSfpuCompute) {
    size_t num_tiles = std::get<0>(GetParam());
    string sfpu_op = std::get<1>(GetParam());

    CoreRange core_range({0, 0}, {0, 0});
    CoreRangeSet core_range_set({core_range});
    unit_tests::compute::sfpu::SfpuConfig test_config = {
        .num_tiles = num_tiles,
        .tile_byte_size = 2 * 32 * 32,
        .l1_input_data_format = tt::DataFormat::Float16_b,
        .l1_output_data_format = tt::DataFormat::Float16_b,
        .cores = core_range_set,
        .sfpu_op = sfpu_op,
        .approx_mode = false};
    log_info("Testing SFPU_OP={} num_tiles={}", sfpu_op, num_tiles);
    for (unsigned int id = 0; id < num_devices_; id++) {
        EXPECT_TRUE(run_sfpu_all_same_buffer(devices_.at(id), test_config));
    }
}

INSTANTIATE_TEST_SUITE_P(
    SingleCoreSfpuCompute,
    SingleCoreSingleDeviceSfpuParameterizedFixture,
    ::testing::Values(
        std::make_tuple(1, "relu"),
        std::make_tuple(1, "exponential"),
        std::make_tuple(1, "reciprocal"),
        std::make_tuple(1, "gelu"),
        std::make_tuple(1, "sqrt"),
        std::make_tuple(1, "sigmoid"),
        std::make_tuple(1, "log"),
        std::make_tuple(1, "tanh"),
        std::make_tuple(1, "sign"),
        std::make_tuple(4, "relu"),
        std::make_tuple(4, "exponential"),
        std::make_tuple(4, "reciprocal"),
        std::make_tuple(4, "gelu"),
        std::make_tuple(4, "sqrt"),
        std::make_tuple(4, "sigmoid"),
        std::make_tuple(4, "log"),
        std::make_tuple(4, "tanh"),
        std::make_tuple(4, "sign")));
class SingleCoreSingleDeviceSfpuParameterizedApproxFixture
    : public DeviceFixture,
      public testing::WithParamInterface<std::tuple<size_t, string>> {};

TEST_P(SingleCoreSingleDeviceSfpuParameterizedApproxFixture, TensixSfpuCompute) {
    size_t num_tiles = std::get<0>(GetParam());
    string sfpu_op = std::get<1>(GetParam());

    if (((arch_ == tt::ARCH::WORMHOLE_B0) and (sfpu_op == "relu")) or
        ((arch_ == tt::ARCH::WORMHOLE_B0) and (sfpu_op == "exponential")) or
        ((arch_ == tt::ARCH::WORMHOLE_B0) and (sfpu_op == "log"))) {
        GTEST_SKIP();
    } else {
        CoreRange core_range({0, 0}, {0, 0});
        CoreRangeSet core_range_set({core_range});
        unit_tests::compute::sfpu::SfpuConfig test_config = {
            .num_tiles = num_tiles,
            .tile_byte_size = 2 * 32 * 32,
            .l1_input_data_format = tt::DataFormat::Float16_b,
            .l1_output_data_format = tt::DataFormat::Float16_b,
            .cores = core_range_set,
            .sfpu_op = sfpu_op,
            .approx_mode = true};
        log_info("Testing SFPU_OP={} num_tiles={}", sfpu_op, num_tiles);
        for (unsigned int id = 0; id < num_devices_; id++) {
            EXPECT_TRUE(run_sfpu_all_same_buffer(devices_.at(id), test_config));
        }
    }
}
INSTANTIATE_TEST_SUITE_P(
    SingleCoreSfpuCompute,
    SingleCoreSingleDeviceSfpuParameterizedApproxFixture,
    ::testing::Values(
        std::make_tuple(1, "relu"),
        std::make_tuple(1, "exponential"),
        std::make_tuple(1, "reciprocal"),
        std::make_tuple(1, "gelu"),
        std::make_tuple(1, "sqrt"),
        std::make_tuple(1, "sigmoid"),
        std::make_tuple(1, "log"),
        std::make_tuple(1, "tanh"),
        std::make_tuple(1, "sign"),
        std::make_tuple(4, "relu"),
        std::make_tuple(4, "exponential"),
        std::make_tuple(4, "reciprocal"),
        std::make_tuple(4, "gelu"),
        std::make_tuple(4, "sqrt"),
        std::make_tuple(4, "sigmoid"),
        std::make_tuple(4, "log"),
        std::make_tuple(4, "tanh"),
        std::make_tuple(4, "sign")));

TEST_F(DeviceFixture, DISABLED_TensixMultiContinguousCoreSingleTileSfpuApproxCompute) {
    CoreRange core_range({0, 0}, {1, 0});
    CoreRangeSet core_range_set({core_range});
    unit_tests::compute::sfpu::SfpuConfig test_config = {
        .tile_byte_size = 2 * 32 * 32,
        .l1_input_data_format = tt::DataFormat::Float16_b,
        .l1_output_data_format = tt::DataFormat::Float16_b,
        .cores = core_range_set,
        .approx_mode = true};

    auto arch = this->arch_;

    if (arch != tt::ARCH::GRAYSKULL) {
        GTEST_SKIP();
    }

    CoreRangeSet core_set({core_range});
    test_config.cores = core_set;

    test_config.num_tiles = 1;
    test_config.sfpu_op = "relu";
    EXPECT_TRUE(run_sfpu_all_same_buffer(devices_.at(0), test_config));
    test_config.sfpu_op = "exponential";
    EXPECT_TRUE(run_sfpu_all_same_buffer(devices_.at(0), test_config));
    test_config.sfpu_op = "reciprocal";
    EXPECT_TRUE(run_sfpu_all_same_buffer(devices_.at(0), test_config));
    test_config.sfpu_op = "gelu";
    EXPECT_TRUE(run_sfpu_all_same_buffer(devices_.at(0), test_config));
    test_config.sfpu_op = "sqrt";
    EXPECT_TRUE(run_sfpu_all_same_buffer(devices_.at(0), test_config));
    test_config.sfpu_op = "sigmoid";
    EXPECT_TRUE(run_sfpu_all_same_buffer(devices_.at(0), test_config));
    test_config.sfpu_op = "log";
    EXPECT_TRUE(run_sfpu_all_same_buffer(devices_.at(0), test_config));
    test_config.sfpu_op = "tanh";
    EXPECT_TRUE(run_sfpu_all_same_buffer(devices_.at(0), test_config));
}

TEST_F(DeviceFixture, DISABLED_TensixMultiContinguousCoreMultiTileSfpuApproxCompute) {
    CoreRange core_range({0, 0}, {1, 0});
    CoreRangeSet core_range_set({core_range});
    unit_tests::compute::sfpu::SfpuConfig test_config = {
        .tile_byte_size = 2 * 32 * 32,
        .l1_input_data_format = tt::DataFormat::Float16_b,
        .l1_output_data_format = tt::DataFormat::Float16_b,
        .cores = core_range_set,
        .approx_mode = true};

    auto arch = this->arch_;

    if (arch != tt::ARCH::GRAYSKULL) {
        GTEST_SKIP();
    }

    CoreRangeSet core_set({core_range});
    test_config.cores = core_set;

    test_config.num_tiles = 4;

    test_config.sfpu_op = "relu";
    EXPECT_TRUE(run_sfpu_all_same_buffer(devices_.at(0), test_config));
    test_config.sfpu_op = "exponential";
    EXPECT_TRUE(run_sfpu_all_same_buffer(devices_.at(0), test_config));
    test_config.sfpu_op = "reciprocal";
    EXPECT_TRUE(run_sfpu_all_same_buffer(devices_.at(0), test_config));
    test_config.sfpu_op = "gelu";
    EXPECT_TRUE(run_sfpu_all_same_buffer(devices_.at(0), test_config));
    test_config.sfpu_op = "sqrt";
    EXPECT_TRUE(run_sfpu_all_same_buffer(devices_.at(0), test_config));
    test_config.sfpu_op = "sigmoid";
    EXPECT_TRUE(run_sfpu_all_same_buffer(devices_.at(0), test_config));
    test_config.sfpu_op = "log";
    EXPECT_TRUE(run_sfpu_all_same_buffer(devices_.at(0), test_config));
    test_config.sfpu_op = "tanh";
    EXPECT_TRUE(run_sfpu_all_same_buffer(devices_.at(0), test_config));
}
TEST_F(DeviceFixture, DISABLED_TensixAllCoreSingleTileSfpuApproxCompute) {
    unit_tests::compute::sfpu::SfpuConfig test_config = {
        .tile_byte_size = 2 * 32 * 32,
        .l1_input_data_format = tt::DataFormat::Float16_b,
        .l1_output_data_format = tt::DataFormat::Float16_b,
        .cores = CoreRangeSet(),
        .approx_mode = true};

    auto arch = this->arch_;

    if (arch != tt::ARCH::GRAYSKULL) {
        GTEST_SKIP();
    }

    int chip_id = 0;
    CoreCoord worker_grid_size = this->devices_.at(0)->logical_grid_size();
    CoreRange core_range({0, 0}, {worker_grid_size.x - 2, worker_grid_size.y - 2});

    CoreRangeSet core_set({core_range});
    test_config.cores = core_set;

    test_config.num_tiles = 1;
    test_config.sfpu_op = "relu";
    EXPECT_TRUE(run_sfpu_all_same_buffer(devices_.at(0), test_config));
    test_config.sfpu_op = "exponential";
    EXPECT_TRUE(run_sfpu_all_same_buffer(devices_.at(0), test_config));
    test_config.sfpu_op = "reciprocal";
    EXPECT_TRUE(run_sfpu_all_same_buffer(devices_.at(0), test_config));
    test_config.sfpu_op = "gelu";
    EXPECT_TRUE(run_sfpu_all_same_buffer(devices_.at(0), test_config));
    test_config.sfpu_op = "sqrt";
    EXPECT_TRUE(run_sfpu_all_same_buffer(devices_.at(0), test_config));
    test_config.sfpu_op = "sigmoid";
    EXPECT_TRUE(run_sfpu_all_same_buffer(devices_.at(0), test_config));
    test_config.sfpu_op = "log";
    EXPECT_TRUE(run_sfpu_all_same_buffer(devices_.at(0), test_config));
    test_config.sfpu_op = "tanh";
    EXPECT_TRUE(run_sfpu_all_same_buffer(devices_.at(0), test_config));
}
TEST_F(DeviceFixture, DISABLED_TensixAllCoreMultiTileSfpuApproxCompute) {
    unit_tests::compute::sfpu::SfpuConfig test_config = {
        .tile_byte_size = 2 * 32 * 32,
        .l1_input_data_format = tt::DataFormat::Float16_b,
        .l1_output_data_format = tt::DataFormat::Float16_b,
        .cores = CoreRangeSet(),
        .approx_mode = true};

    auto arch = this->arch_;

    if (arch != tt::ARCH::GRAYSKULL) {
        GTEST_SKIP();
    }

    int chip_id = 0;
    CoreCoord worker_grid_size = this->devices_.at(0)->logical_grid_size();
    CoreRange core_range({0, 0}, {worker_grid_size.x - 2, worker_grid_size.y - 2});

    CoreRangeSet core_set({core_range});
    test_config.cores = core_set;
    test_config.num_tiles = 4;
    test_config.sfpu_op = "relu";
    EXPECT_TRUE(run_sfpu_all_same_buffer(devices_.at(0), test_config));
    test_config.sfpu_op = "exponential";
    EXPECT_TRUE(run_sfpu_all_same_buffer(devices_.at(0), test_config));
    test_config.sfpu_op = "reciprocal";
    EXPECT_TRUE(run_sfpu_all_same_buffer(devices_.at(0), test_config));
    test_config.sfpu_op = "gelu";
    EXPECT_TRUE(run_sfpu_all_same_buffer(devices_.at(0), test_config));
    test_config.sfpu_op = "sqrt";
    EXPECT_TRUE(run_sfpu_all_same_buffer(devices_.at(0), test_config));
    test_config.sfpu_op = "sigmoid";
    EXPECT_TRUE(run_sfpu_all_same_buffer(devices_.at(0), test_config));
    test_config.sfpu_op = "log";
    EXPECT_TRUE(run_sfpu_all_same_buffer(devices_.at(0), test_config));
    test_config.sfpu_op = "tanh";
    EXPECT_TRUE(run_sfpu_all_same_buffer(devices_.at(0), test_config));
}

}  // namespace tt::tt_metal
