// SPDX-FileCopyrightText: Â© 2023 Tenstorrent Inc.
//
// SPDX-License-Identifier: Apache-2.0

#include <chrono>
#include <fmt/base.h>
#include <stdint.h>
#include <tt-metalium/host_api.hpp>
#include <tt-metalium/tt_align.hpp>
#include <tt-metalium/tt_metal.hpp>
#include <algorithm>
#include <cstdlib>
#include <ctime>
#include <exception>
#include <iomanip>
#include <map>
#include <memory>
#include <optional>
#include <sstream>
#include <string>
#include <utility>
#include <variant>
#include <vector>

#include <tt-metalium/allocator.hpp>
#include <tt-metalium/assert.hpp>
#include <tt-metalium/buffer_types.hpp>
#include "common.h"
#include <tt-metalium/core_coord.hpp>
#include <tt-metalium/data_types.hpp>
#include <tt-metalium/device.hpp>
#include "impl/dispatch/command_queue_common.hpp"
#include "impl/dispatch/dispatch_settings.hpp"
#include <tt-metalium/kernel_types.hpp>
#include "llrt.hpp"
#include <tt-metalium/logger.hpp>
#include <tt-metalium/metal_soc_descriptor.h>
#include <tt-metalium/program.hpp>
#include <tt_stl/span.hpp>
#include "test_common.hpp"
#include "impl/context/metal_context.hpp"
#include "tt_metal/impl/dispatch/kernels/cq_commands.hpp"
#include "umd/device/tt_core_coordinates.h"
#include <tt-metalium/utils.hpp>

constexpr uint32_t DEFAULT_ITERATIONS = 10000;
constexpr uint32_t DEFAULT_WARMUP_ITERATIONS = 100;
constexpr uint32_t DEFAULT_DISPATCH_BUFFER_LOG_PAGE_SIZE = 12;
constexpr uint32_t DEFAULT_DISPATCH_BUFFER_SIZE_BLOCKS = 4;
constexpr uint32_t DEFAULT_DISPATCH_BUFFER_SIZE_BYTES = 768 * 1024;
constexpr uint32_t DEFAULT_DISPATCH_BUFFER_BLOCK_SIZE_PAGES = DEFAULT_DISPATCH_BUFFER_SIZE_BYTES /
                                                              (1 << DEFAULT_DISPATCH_BUFFER_LOG_PAGE_SIZE) /
                                                              DEFAULT_DISPATCH_BUFFER_SIZE_BLOCKS;
constexpr uint32_t DEFAULT_PREFETCHER_BUFFER_SIZE_PAGES =
    DEFAULT_DISPATCH_BUFFER_SIZE_BYTES / (1 << DEFAULT_DISPATCH_BUFFER_LOG_PAGE_SIZE);
constexpr uint32_t MAX_XFER_SIZE_16B = 4 * 1024;
constexpr uint32_t MIN_XFER_SIZE_16B = 1;
constexpr uint32_t DEFAULT_PREFETCHER_PAGE_BATCH_SIZE = 1;

constexpr uint32_t DRAM_DATA_SIZE_BYTES = 16 * 1024 * 1024;
constexpr uint32_t DRAM_DATA_SIZE_WORDS = DRAM_DATA_SIZE_BYTES / sizeof(uint32_t);

constexpr uint32_t DEFAULT_PAGED_WRITE_PAGES = 4;
constexpr uint32_t MAX_PAGED_WRITE_ADDR = 512 * 1024;
constexpr uint32_t MIN_PAGED_WRITE_ADDR =
    512 * 1024;  // Disable randomization by default. 512 KB - 612 KB might be reasonable.

//////////////////////////////////////////////////////////////////////////////////////////
// Test dispatch program performance
//
// Times dispatching program to M cores, N processors, of various sizes, CBs, runtime args
//////////////////////////////////////////////////////////////////////////////////////////
using std::vector;
using namespace tt;

uint32_t iterations_g = DEFAULT_ITERATIONS;
uint32_t warmup_iterations_g = DEFAULT_WARMUP_ITERATIONS;
uint32_t prefetcher_iterations_g = 1;

uint32_t log_dispatch_buffer_page_size_g = DEFAULT_DISPATCH_BUFFER_LOG_PAGE_SIZE;
uint32_t dispatch_buffer_page_size_g = 1 << DEFAULT_DISPATCH_BUFFER_LOG_PAGE_SIZE;
uint32_t dispatch_buffer_block_size_pages_g = DEFAULT_DISPATCH_BUFFER_BLOCK_SIZE_PAGES;
uint32_t dispatch_buffer_size_blocks_g = DEFAULT_DISPATCH_BUFFER_SIZE_BLOCKS;
uint32_t dispatch_buffer_size_g = 0;
uint32_t prefetcher_buffer_size_g = 0;
uint32_t prefetcher_page_batch_size_g = DEFAULT_PREFETCHER_PAGE_BATCH_SIZE;
uint32_t max_xfer_size_bytes_g = MAX_XFER_SIZE_16B << 4;
uint32_t min_xfer_size_bytes_g = MIN_XFER_SIZE_16B << 4;
uint32_t test_type_g;

uint32_t max_paged_write_base_addr_g = MAX_PAGED_WRITE_ADDR;
uint32_t min_paged_write_base_addr_g = MIN_PAGED_WRITE_ADDR;
uint32_t num_pages_g = DEFAULT_PAGED_WRITE_PAGES;

bool debug_g;
bool fire_once_g;
bool use_coherent_data_g;
bool send_to_all_g;
bool perf_test_g;
uint32_t hugepage_issue_buffer_size_g;
uint32_t seed_g;

CoreCoord first_worker_g = {0, 1};
CoreRange all_workers_g = {
    first_worker_g,
    {first_worker_g.x + 1, first_worker_g.y + 1},
};

void init(int argc, char** argv) {
    std::vector<std::string> input_args(argv, argv + argc);

    if (test_args::has_command_option(input_args, "-h") || test_args::has_command_option(input_args, "--help")) {
        log_info(LogTest, "Usage:");
        log_info(
            LogTest,
            "    -t: test type, 0:uni_write 1:mcast_write 2:dram paged_write 3:l1 paged_write 4:packed_write "
            "5:packed_write_large (default {})",
            0);
        log_info(LogTest, "    -w: warm-up iterations before starting timer (default {}), ", DEFAULT_WARMUP_ITERATIONS);
        log_info(LogTest, "    -i: host iterations (default {})", DEFAULT_ITERATIONS);
        log_info(LogTest, "   -wx: right-most worker in grid (default {})", all_workers_g.end_coord.x);
        log_info(LogTest, "   -wy: bottom-most worker in grid (default {})", all_workers_g.end_coord.y);
        log_info(LogTest, "    -a: send to all workers (vs random) for 1-to-N cmds (default random)");
        log_info(LogTest, "   -pi: prefetcher iterations (looping on device) (default {})", 1);
        log_info(
            LogTest,
            "  -lps: log of page size of prefetch/dispatch buffer (default {})",
            DEFAULT_DISPATCH_BUFFER_LOG_PAGE_SIZE);
        log_info(
            LogTest, "   -bs: dispatcher block size in pages (default {})", DEFAULT_DISPATCH_BUFFER_BLOCK_SIZE_PAGES);
        log_info(LogTest, "    -b: dispatcher buffer size in blocks (default {})", DEFAULT_DISPATCH_BUFFER_SIZE_BLOCKS);
        log_info(LogTest, "  -pbs: prefetcher buffer size pages (default {})", DEFAULT_PREFETCHER_BUFFER_SIZE_PAGES);
        log_info(
            LogTest,
            " -ppbs: prefetcher page batch size (process pages in batches of N to reduce overhead) (default {})",
            DEFAULT_PREFETCHER_PAGE_BATCH_SIZE);
        log_info(
            LogTest,
            "    -f: prefetcher fire once, use to measure dispatcher perf w/ prefetcher out of the way (default "
            "disabled)");
        log_info(
            LogTest, "    -d: wrap all commands in debug commands and clear DRAM to known state (default disabled)");
        log_info(LogTest, "    -c: use coherent data as payload (default false)");
        log_info(LogTest, "   -np: paged-write number of pages (default {})", num_pages_g);
        log_info(LogTest, "    -s: seed for randomized testing");

        log_info(LogTest, "Random Test args:");
        log_info(LogTest, "  -max: max transfer size bytes (default {})", max_xfer_size_bytes_g);
        log_info(LogTest, "  -min: min transfer size bytes (default {})", min_xfer_size_bytes_g);
        log_info(LogTest, "  -max-addr: max paged-write dst base addr (default {})", max_paged_write_base_addr_g);
        log_info(LogTest, "  -min-addr: min paged-write dst base addr (default {})", min_paged_write_base_addr_g);

        exit(0);
    }

    warmup_iterations_g = test_args::get_command_option_uint32(input_args, "-w", DEFAULT_WARMUP_ITERATIONS);
    iterations_g = test_args::get_command_option_uint32(input_args, "-i", DEFAULT_ITERATIONS);
    prefetcher_iterations_g = test_args::get_command_option_uint32(input_args, "-pi", 1);
    test_type_g = test_args::get_command_option_uint32(input_args, "-t", 0);
    all_workers_g.end_coord.x = test_args::get_command_option_uint32(input_args, "-wx", all_workers_g.end_coord.x);
    all_workers_g.end_coord.y = test_args::get_command_option_uint32(input_args, "-wy", all_workers_g.end_coord.y);

    log_dispatch_buffer_page_size_g =
        test_args::get_command_option_uint32(input_args, "-lps", DEFAULT_DISPATCH_BUFFER_LOG_PAGE_SIZE);
    dispatch_buffer_page_size_g = 1 << log_dispatch_buffer_page_size_g;
    dispatch_buffer_block_size_pages_g =
        test_args::get_command_option_uint32(input_args, "-bs", DEFAULT_DISPATCH_BUFFER_BLOCK_SIZE_PAGES);
    dispatch_buffer_size_blocks_g =
        test_args::get_command_option_uint32(input_args, "-b", DEFAULT_DISPATCH_BUFFER_SIZE_BLOCKS);
    dispatch_buffer_size_g =
        dispatch_buffer_page_size_g * dispatch_buffer_block_size_pages_g * dispatch_buffer_size_blocks_g;
    log_debug(
        tt::LogTest,
        "Computed dispatch_buffer_size_g: {} from page_size: {} block_size_pages: {} blocks: {}",
        dispatch_buffer_size_g,
        dispatch_buffer_page_size_g,
        dispatch_buffer_block_size_pages_g,
        dispatch_buffer_size_blocks_g);

    prefetcher_page_batch_size_g =
        test_args::get_command_option_uint32(input_args, "-ppbs", DEFAULT_PREFETCHER_PAGE_BATCH_SIZE);

    uint32_t pbs_pages = test_args::get_command_option_uint32(input_args, "-pbs", DEFAULT_PREFETCHER_BUFFER_SIZE_PAGES);
    uint32_t terminate_cmd_pages = 1;
    // divide the batch size evenlly, one page for terminate
    pbs_pages = pbs_pages / prefetcher_page_batch_size_g * prefetcher_page_batch_size_g + terminate_cmd_pages;
    prefetcher_buffer_size_g = pbs_pages * dispatch_buffer_page_size_g;
    log_debug(
        tt::LogTest,
        "Computed prefetcher_buffer_size_g: {} from page_size: {} prefetch_buffer_pages: {}",
        prefetcher_buffer_size_g,
        dispatch_buffer_page_size_g,
        pbs_pages);

    max_xfer_size_bytes_g = test_args::get_command_option_uint32(input_args, "-max", max_xfer_size_bytes_g);
    min_xfer_size_bytes_g = test_args::get_command_option_uint32(input_args, "-min", min_xfer_size_bytes_g);
    max_paged_write_base_addr_g =
        test_args::get_command_option_uint32(input_args, "-max-addr", max_paged_write_base_addr_g);
    min_paged_write_base_addr_g =
        test_args::get_command_option_uint32(input_args, "-min-addr", min_paged_write_base_addr_g);

    send_to_all_g = test_args::has_command_option(input_args, "-a");

    fire_once_g = test_args::has_command_option(input_args, "-f");
    if (fire_once_g) {
        if (prefetcher_buffer_size_g != dispatch_buffer_size_g + terminate_cmd_pages) {
            log_info(LogTest, "Fire once overriding prefetcher buffer size");
            prefetcher_buffer_size_g = dispatch_buffer_size_g + terminate_cmd_pages * dispatch_buffer_page_size_g;
        }
    }

    use_coherent_data_g = test_args::has_command_option(input_args, "-c");

    debug_g = test_args::has_command_option(input_args, "-d");
    num_pages_g = test_args::get_command_option_uint32(input_args, "-np", num_pages_g);

    seed_g = test_args::get_command_option_uint32(input_args, "-s", 0);

    perf_test_g = (send_to_all_g && iterations_g == 1);  // XXXX find a better way?
}

// Keep these updated. One single place, for code to use.
bool is_paged_dram_test() { return (test_type_g == 2); }

bool is_paged_l1_test() { return (test_type_g == 3); }

bool is_paged_test() {
    bool is_paged_dram = is_paged_dram_test();
    bool is_paged_l1 = is_paged_l1_test();
    return (is_paged_dram || is_paged_l1);
}

// Unicast or Multicast Linear Write Test.
void gen_linear_or_packed_write_test(
    uint32_t& cmd_count,
    IDevice* device,
    vector<uint32_t>& dispatch_cmds,
    CoreRange worker_cores,
    DeviceData& device_data,
    uint32_t page_size,
    bool is_linear_multicast = false) {
    uint32_t total_size_bytes = 0;
    uint32_t buffer_size = prefetcher_buffer_size_g - page_size;  // for terminate
    bool is_linear_write = (test_type_g == 0 || test_type_g == 1);
    log_info(
        tt::LogTest,
        "Generating linear: {} multicast: {} Write Test with dispatch buffer page_size: {}",
        is_linear_write,
        is_linear_multicast,
        page_size);

    bool done = false;
    while (!done && total_size_bytes < buffer_size) {
        total_size_bytes += sizeof(CQDispatchCmd);
        if (debug_g) {
            total_size_bytes += sizeof(CQDispatchCmd);
        }

        uint32_t xfer_size_bytes = 0;

        // Test specific stuff starts here.
        switch (test_type_g) {
            case 0:
            case 1: {
                uint32_t xfer_size_16B = (std::rand() & (MAX_XFER_SIZE_16B - 1));
                if (total_size_bytes + (xfer_size_16B << 4) > buffer_size) {
                    xfer_size_16B = (buffer_size - total_size_bytes) >> 4;
                }

                xfer_size_bytes = xfer_size_16B << 4;
                if (xfer_size_bytes > max_xfer_size_bytes_g) {
                    xfer_size_bytes = max_xfer_size_bytes_g;
                }
                if (xfer_size_bytes < min_xfer_size_bytes_g) {
                    xfer_size_bytes = min_xfer_size_bytes_g;
                }

                if (is_linear_multicast) {
                    gen_dispatcher_multicast_write_cmd(
                        device, dispatch_cmds, worker_cores, device_data, xfer_size_bytes);
                } else {
                    gen_dispatcher_unicast_write_cmd(
                        device, dispatch_cmds, worker_cores.start_coord, device_data, xfer_size_bytes);
                }
                break;
            }
            case 4: gen_rnd_dispatcher_packed_write_cmd(device, dispatch_cmds, device_data); break;
            case 5:
                done = gen_rnd_dispatcher_packed_write_large_cmd(
                    device, worker_cores, dispatch_cmds, device_data, buffer_size - total_size_bytes);
                break;
        }

        uint32_t page_size_words = page_size / sizeof(uint32_t);
        dispatch_cmds.resize(
            (dispatch_cmds.size() + page_size_words - 1) / page_size_words * page_size_words);  // pad to page

        total_size_bytes = dispatch_cmds.size() * sizeof(uint32_t);
        cmd_count++;
    }

    gen_dispatcher_terminate_cmd(dispatch_cmds);
    uint32_t page_size_words = page_size / sizeof(uint32_t);
    dispatch_cmds.resize(
        (dispatch_cmds.size() + page_size_words - 1) / page_size_words * page_size_words);  // pad to page
    cmd_count++;
}

// DRAM or L1 Paged Write Test.
void gen_paged_write_test(
    uint32_t& cmd_count,
    bool is_dram,
    IDevice* device,
    vector<uint32_t>& dispatch_cmds,
    CoreRange worker_cores,
    DeviceData& device_data,
    uint32_t page_size) {
    uint32_t total_size_bytes = 0;
    uint32_t buffer_size = prefetcher_buffer_size_g - page_size;  // for terminate
    uint32_t start_page = 0;
    TT_ASSERT(is_paged_test());  // Ensure test-numbers kept up to date in this function.

    uint32_t xfer_size_16B = (std::rand() & (MAX_XFER_SIZE_16B - 1));
    if (total_size_bytes + (xfer_size_16B << 4) > buffer_size) {
        xfer_size_16B = (buffer_size - total_size_bytes) >> 4;
    }

    // Treat xfer size test in test as page write page size here. Keep consistend for all cmds.
    uint32_t page_size_bytes = xfer_size_16B << 4;
    if (page_size_bytes > max_xfer_size_bytes_g) {
        page_size_bytes = max_xfer_size_bytes_g;
    }
    if (page_size_bytes < min_xfer_size_bytes_g) {
        page_size_bytes = min_xfer_size_bytes_g;
    }

    log_info(
        tt::LogTest,
        "Generating Paged Write test to {} for dispatch buffer page_size: {} write_cmd_page_size: {} start_page: {}",
        is_dram ? "DRAM" : "L1",
        page_size,
        page_size_bytes,
        start_page);

    while (total_size_bytes < buffer_size) {
        total_size_bytes += sizeof(CQDispatchCmd);
        if (debug_g) {
            total_size_bytes += sizeof(CQDispatchCmd);
        }

        log_debug(
            tt::LogTest,
            "Generating paged write cmds (is_dram: {} for total_size_bytes: {} buffer_size: {} page_size_bytes: {})",
            is_dram,
            total_size_bytes,
            buffer_size,
            page_size_bytes);

        gen_dispatcher_paged_write_cmd(
            device, dispatch_cmds, device_data, is_dram, start_page, page_size_bytes, num_pages_g);

        // Offset start page by number of pages written, and use as next cmd start page to have writes to memory without
        // gaps
        start_page += num_pages_g;
        uint32_t page_size_words = page_size / sizeof(uint32_t);
        dispatch_cmds.resize(
            (dispatch_cmds.size() + page_size_words - 1) / page_size_words * page_size_words);  // pad to page

        total_size_bytes = dispatch_cmds.size() * sizeof(uint32_t);
        cmd_count++;
    }

    gen_dispatcher_terminate_cmd(dispatch_cmds);
    uint32_t page_size_words = page_size / sizeof(uint32_t);
    dispatch_cmds.resize(
        (dispatch_cmds.size() + page_size_words - 1) / page_size_words * page_size_words);  // pad to page
    cmd_count++;
}

// Generate Dispatcher Commands based on the type of test.
void gen_cmds(
    IDevice* device,
    vector<uint32_t>& dispatch_cmds,
    CoreRange worker_cores,
    DeviceData& device_data,
    uint32_t page_size) {
    uint32_t total_size_bytes = 0;
    uint32_t buffer_size = prefetcher_buffer_size_g - page_size;  // for terminate
    uint32_t cmd_count = 0;

    switch (test_type_g) {
        case 0:
            TT_FATAL(all_workers_g.size() == 1, "Should use single core for unicast write test");
            gen_linear_or_packed_write_test(cmd_count, device, dispatch_cmds, worker_cores, device_data, page_size);
            break;
        case 1:
            gen_linear_or_packed_write_test(
                cmd_count, device, dispatch_cmds, worker_cores, device_data, page_size, true);
            break;
        case 2:
        case 3:
            gen_paged_write_test(
                cmd_count, is_paged_dram_test(), device, dispatch_cmds, worker_cores, device_data, page_size);
            break;
        case 4:
            gen_linear_or_packed_write_test(cmd_count, device, dispatch_cmds, worker_cores, device_data, page_size);
            break;
        case 5:
            gen_linear_or_packed_write_test(cmd_count, device, dispatch_cmds, worker_cores, device_data, page_size);
            break;
    }

    log_info(LogTest, "Generated {} commands", cmd_count);
}

// Clear DRAM (helpful for paged write to DRAM debug to have a fresh slate)
void initialize_dram_banks(IDevice* device) {
    const auto& allocator = device->allocator();
    auto num_banks = allocator->get_num_banks(BufferType::DRAM);
    auto bank_size = allocator->get_bank_size(BufferType::DRAM);  // Or can hardcode to subset like 16MB.
    auto fill = std::vector<uint32_t>(bank_size / sizeof(uint32_t), 0xBADDF00D);

    for (int bank_id = 0; bank_id < num_banks; bank_id++) {
        log_info(
            tt::LogTest,
            "Initializing DRAM {} bytes for bank_id: {}",
            bank_size,
            bank_id);
        tt::tt_metal::detail::WriteToDeviceDRAMChannel(device, bank_id, 0, fill);
    }
}

int main(int argc, char** argv) {
    log_info(tt::LogTest, "test_dispatcher.cpp - Test Start");

    init(argc, argv);
    if (seed_g == 0) {
        seed_g = std::time(nullptr);
    }
    std::srand(seed_g);  // Seed the RNG
    log_info(LogTest, "Random seed: {}", seed_g);

    auto slow_dispatch_mode = getenv("TT_METAL_SLOW_DISPATCH_MODE");
    TT_FATAL(slow_dispatch_mode, "This test only supports TT_METAL_SLOW_DISPATCH_MODE");

    uint32_t dispatch_buffer_pages = dispatch_buffer_size_g / dispatch_buffer_page_size_g;
    bool paged_test = is_paged_test();

    bool pass = true;
    try {
        int device_id = 0;
        tt_metal::IDevice* device = tt_metal::CreateDevice(device_id);
        tt_metal::Program program = tt_metal::CreateProgram();

        CoreCoord spoof_prefetch_core = {0, 0};
        CoreCoord dispatch_core = {4, 0};

        CoreCoord phys_spoof_prefetch_core = device->worker_core_from_logical_core(spoof_prefetch_core);
        CoreCoord phys_dispatch_core = device->worker_core_from_logical_core(dispatch_core);

        uint32_t num_compute_cores =
            device->compute_with_storage_grid_size().x * device->compute_with_storage_grid_size().y;

        // Want different buffers on each core, instead use big buffer and self-manage it
        uint32_t dispatch_l1_unreserved_base =
            MetalContext::instance()
                .dispatch_mem_map(CoreType::WORKER)
                .get_device_command_queue_addr(CommandQueueDeviceAddrType::UNRESERVED);
        uint32_t l1_buf_base = tt::align(dispatch_l1_unreserved_base, dispatch_buffer_page_size_g);
        TT_ASSERT((l1_buf_base & (dispatch_buffer_page_size_g - 1)) == 0);

        // Make sure user doesn't exceed available L1 space with cmd line arguments.
        auto& soc_desc = tt::tt_metal::MetalContext::instance().get_cluster().get_soc_desc(device->id());
        if (prefetcher_buffer_size_g + l1_buf_base > soc_desc.worker_l1_size) {
            log_fatal(
                LogTest,
                "Prefetcher buffer size too large. {} exceeds l1_worker_size: {}",
                dispatch_buffer_size_g,
                soc_desc.worker_l1_size);
            exit(-1);
        }
        if (dispatch_buffer_size_g + l1_buf_base > soc_desc.worker_l1_size) {
            log_fatal(
                LogTest,
                "Dispatcher buffer size too large. {} exceeds l1_worker_size: {}",
                dispatch_buffer_size_g,
                soc_desc.worker_l1_size);
            exit(-1);
        }

        uint32_t dram_data_addr = l1_buf_base;
        uint32_t l1_data_addr = l1_buf_base;

        // Seperate Buffer space for paged write testing to not conflict with dispatch or prefetch buffers in L1
        if (paged_test) {
            // Seems like 16B alignment is required otherwise mismatches in readback. Linear writes only target 16B
            // aligned transfer sizes too. It's okay for these not to be, the random calc below will align final
            // address.
            if (max_paged_write_base_addr_g % 16 != 0) {
                log_warning(tt::LogTest, "max_paged_write_base_addr_g should be 16B aligned.");
            }
            if (min_paged_write_base_addr_g % 16 != 0) {
                log_warning(tt::LogTest, "min_paged_write_base_addr_g should be 16B aligned.");
            }

            // Need to be careful with write buffer address, especially for cases where L1 banks have negative offset
            // (occurs for storage cores) so find minmum required bank offset such that the negative offsets will not
            // cause underflow and bump up range to not be less.
            bool is_dram = is_paged_dram_test();
            uint32_t min_buffer_addr = get_min_required_buffer_addr(device, is_dram);

            // Just avoid hazard by bumping up min, max - and let user know with a warning.
            if (min_paged_write_base_addr_g < min_buffer_addr) {
                log_warning(
                    "min_paged_write_base_addr_g: {:x} is too low. Increasing to min_buffer_addr: {:x}",
                    min_paged_write_base_addr_g,
                    min_buffer_addr);
                min_paged_write_base_addr_g = min_buffer_addr;
            }
            if (max_paged_write_base_addr_g < min_buffer_addr ||
                max_paged_write_base_addr_g < min_paged_write_base_addr_g) {
                log_warning(
                    "max_paged_write_base_addr_g: {:x} is too low. Increasing to min_buffer_addr: {:x}",
                    max_paged_write_base_addr_g,
                    min_buffer_addr);
                max_paged_write_base_addr_g = min_buffer_addr;
            }

            auto range = 1 + max_paged_write_base_addr_g - min_paged_write_base_addr_g;
            // TODO: can we make these play better w/ the non-paged tests?
            dram_data_addr = ((min_paged_write_base_addr_g + (std::rand() % range)) >> 4) << 4;
            l1_data_addr = ((min_paged_write_base_addr_g + (std::rand() % range)) >> 4) << 4;
        }

        DeviceData device_data(
            device, all_workers_g, l1_data_addr, dram_data_addr, 0, paged_test, DRAM_DATA_SIZE_WORDS);

        if (is_paged_dram_test() && debug_g) {
            initialize_dram_banks(device);
        }

        // Generate commands once and write them to prefetcher core.
        vector<uint32_t> cmds;
        gen_cmds(device, cmds, all_workers_g, device_data, dispatch_buffer_page_size_g);
        llrt::write_hex_vec_to_core(device->id(), phys_spoof_prefetch_core, cmds, l1_buf_base);

        const uint32_t spoof_prefetch_core_sem_0_id =
            tt_metal::CreateSemaphore(program, {spoof_prefetch_core}, dispatch_buffer_pages);
        const uint32_t dispatch_core_sem_id = tt_metal::CreateSemaphore(program, {dispatch_core}, 0);
        TT_ASSERT(spoof_prefetch_core_sem_0_id == dispatch_core_sem_id);
        const uint32_t dispatch_cb_sem = spoof_prefetch_core_sem_0_id;

        const uint32_t spoof_prefetch_core_sem_1_id = tt_metal::CreateSemaphore(program, {spoof_prefetch_core}, 0);
        const uint32_t prefetch_sync_sem = spoof_prefetch_core_sem_1_id;

        const uint32_t host_completion_queue_wr_ptr =
            MetalContext::instance()
                .dispatch_mem_map(CoreType::WORKER)
                .get_host_command_queue_addr(CommandQueueHostAddrType::COMPLETION_Q_WR);
        const uint32_t dev_completion_queue_wr_ptr =
            MetalContext::instance()
                .dispatch_mem_map(CoreType::WORKER)
                .get_device_command_queue_addr(CommandQueueDeviceAddrType::COMPLETION_Q_WR);
        const uint32_t dev_completion_queue_rd_ptr =
            MetalContext::instance()
                .dispatch_mem_map(CoreType::WORKER)
                .get_device_command_queue_addr(CommandQueueDeviceAddrType::COMPLETION_Q_RD);

        std::vector<uint32_t> dispatch_compile_args = {
            l1_buf_base,
            log_dispatch_buffer_page_size_g,
            dispatch_buffer_size_g / dispatch_buffer_page_size_g,
            dispatch_cb_sem,
            dispatch_cb_sem,  // ugly, share an address
            dispatch_buffer_size_blocks_g,
            prefetch_sync_sem,
            // Hugepage compile args aren't used in this test since WriteHost is not tested here
            0,                  // command_queue_base_addr
            0,                  // completion_queue_base_addr
            0,                  // completion_queue_size
            0,                  // downstream_cb_base
            0,                  // downstream_cb_size
            0,                  // my_downstream_cb_sem_id
            0,                  // downstream_cb_sem_id
            0,                  // split_dispatch_page_preamble_size
            false,              // split_prefetcher
            0,                  // prefetch noc_xy
            0,                  // prefetch_local_downstream_sem_addr
            0,                  // prefetch_downstream_buffer_pages
            num_compute_cores,  // max_write_packed_cores
            0,
            DispatchSettings::DISPATCH_MESSAGE_ENTRIES,
            DispatchSettings::DISPATCH_GO_SIGNAL_NOC_DATA_ENTRIES,
            0,
            0,
            0,
            host_completion_queue_wr_ptr,
            dev_completion_queue_wr_ptr,
            dev_completion_queue_rd_ptr,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,     // unused for single device - used to "virtualize" the number of eth cores across devices
            0,     // unused for single device - used to "virtualize" the number of eth cores across devices
            0,     // unused for single device - used to "virtualize" the number of eth cores across devices
            true,  // is_dram_variant
            true,  // is_host_variant
        };
        std::vector<uint32_t> spoof_prefetch_compile_args = {
            l1_buf_base,
            log_dispatch_buffer_page_size_g,
            dispatch_buffer_pages,
            dispatch_cb_sem,
            l1_buf_base,
            (uint32_t)(cmds.size() * sizeof(uint32_t)) / dispatch_buffer_page_size_g,
            prefetcher_page_batch_size_g,
            prefetch_sync_sem,
        };

        std::map<string, string> prefetch_defines = {
            {"MY_NOC_X", std::to_string(phys_spoof_prefetch_core.x)},
            {"MY_NOC_Y", std::to_string(phys_spoof_prefetch_core.y)},
            {"DISPATCH_NOC_X", std::to_string(phys_dispatch_core.x)},
            {"DISPATCH_NOC_Y", std::to_string(phys_dispatch_core.y)},
            {"FD_CORE_TYPE", std::to_string(0)},  // todo, support dispatch on eth
        };
        if (fire_once_g) {
            prefetch_defines.insert(std::pair<string, string>("FIRE_ONCE", std::to_string(1)));
        }

        auto sp1 = tt_metal::CreateKernel(
            program,
            "tests/tt_metal/tt_metal/perf_microbenchmark/dispatch/kernels/spoof_prefetch.cpp",
            {spoof_prefetch_core},
            tt_metal::DataMovementConfig{
                .processor = tt_metal::DataMovementProcessor::RISCV_1,
                .noc = tt_metal::NOC::RISCV_0_default,
                .compile_args = spoof_prefetch_compile_args,
                .defines = prefetch_defines});
        vector<uint32_t> args;
        args.push_back(prefetcher_iterations_g);
        tt_metal::SetRuntimeArgs(program, sp1, spoof_prefetch_core, args);

        constexpr NOC my_noc_index = NOC::NOC_0;
        constexpr NOC dispatch_upstream_noc_index = NOC::NOC_1;

        configure_kernel_variant<true, true>(
            program,
            "tt_metal/impl/dispatch/kernels/cq_dispatch.cpp",
            dispatch_compile_args,
            dispatch_core,
            phys_dispatch_core,
            phys_spoof_prefetch_core,
            {0, 0},
            device,
            my_noc_index,
            dispatch_upstream_noc_index,
            my_noc_index);

        switch (test_type_g) {
            case 0: log_info(LogTest, "Running linear unicast test"); break;
            case 1: log_info(LogTest, "Running linear mcast test"); break;
            case 2:
            case 3: log_info(LogTest, "Running paged {} test", is_paged_dram_test() ? "DRAM" : "L1"); break;
            case 4: log_info(LogTest, "Running packed write unicast"); break;
            case 5: log_info(LogTest, "Running packed write large unicast"); break;
        }

        log_info(LogTest, "Worker grid {}", all_workers_g.str());
        log_info(LogTest, "Dispatch buffer size blocks {}", std::to_string(dispatch_buffer_size_blocks_g));
        log_info(LogTest, "Dispatch buffer block size pages {}", std::to_string(dispatch_buffer_block_size_pages_g));
        log_info(LogTest, "Dispatch buffer page size {}", std::to_string(dispatch_buffer_page_size_g));
        log_info(LogTest, "Dispatch buffer pages {}", std::to_string(dispatch_buffer_pages));
        log_info(
            LogTest, "Dispatch buffer size {}", std::to_string(dispatch_buffer_page_size_g * dispatch_buffer_pages));
        log_info(LogTest, "Dispatch buffer base {}", std::to_string(l1_buf_base));
        log_info(
            LogTest,
            "Dispatch buffer end {}",
            std::to_string(l1_buf_base + dispatch_buffer_page_size_g * dispatch_buffer_pages));
        log_info(LogTest, "Prefetcher CMD Buffer size {}", std::to_string(prefetcher_buffer_size_g));
        log_info(
            LogTest,
            "Worker result data total bytes written {}",
            std::to_string(device_data.size() * sizeof(uint32_t)));
        // Cache stuff
        for (int i = 0; i < warmup_iterations_g; i++) {
            tt_metal::detail::LaunchProgram(device, program);
        }

        auto start = std::chrono::system_clock::now();
        for (int i = 0; i < iterations_g; i++) {
            tt_metal::detail::LaunchProgram(device, program);
        }
        auto end = std::chrono::system_clock::now();

        pass &= device_data.validate(device);

        std::chrono::duration<double> elapsed_seconds = (end - start);
        uint32_t total_iterations = iterations_g * prefetcher_iterations_g;
        log_info(
            LogTest, "Ran in {}us (for total iterations: {})", elapsed_seconds.count() * 1000 * 1000, total_iterations);
        log_info(LogTest, "Ran in {}us per iteration", elapsed_seconds.count() * 1000 * 1000 / total_iterations);
        if (iterations_g > 0) {
            float total_words = device_data.size();
            total_words *= total_iterations;
            float bw = total_words * sizeof(uint32_t) / (elapsed_seconds.count() * 1024.0 * 1024.0 * 1024.0);
            std::stringstream ss;
            ss << std::fixed << std::setprecision(3) << bw;
            log_info(
                LogTest,
                "BW: {} GB/s (from total_words: {} size: {} MB via host_iter: {} prefetcher_iter: {} for num_cores: "
                "{})",
                ss.str(),
                total_words,
                total_words * sizeof(uint32_t) / (1024.0 * 1024.0),
                iterations_g,
                prefetcher_iterations_g,
                all_workers_g.size());
        } else {
            log_info(LogTest, "BW: -- GB/s (use -i 1 to report bandwidth)");
        }
        pass &= tt_metal::CloseDevice(device);
    } catch (const std::exception& e) {
        pass = false;
        log_fatal(e.what());
    }

    tt::tt_metal::MetalContext::instance().rtoptions().set_kernels_nullified(false);

    if (pass) {
        log_info(LogTest, "test_dispatcher.cpp - Test Passed");
        return 0;
    } else {
        log_fatal(LogTest, "test_dispatcher.cpp - Test Failed\n");
        return 1;
    }
}
