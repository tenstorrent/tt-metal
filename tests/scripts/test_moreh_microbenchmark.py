# SPDX-FileCopyrightText: Â© 2023 Tenstorrent AI ULC
#
# SPDX-License-Identifier: Apache-2.0

import os
import copy
import re
import csv
import time
import random
import toolz
import subprocess as sp
from pathlib import Path
from itertools import chain
from functools import partial
from loguru import logger
import pytest
import numpy as np
import sys

import tt_lib as ttl

from tt_metal.tools.profiler.common import PROFILER_LOGS_DIR, PROFILER_DEVICE_SIDE_LOG

profiler_log_path = PROFILER_LOGS_DIR / PROFILER_DEVICE_SIDE_LOG

from tt_metal.tools.profiler.process_device_log import import_log_run_stats
import tt_metal.tools.profiler.device_post_proc_config as device_post_proc_config


def run_moreh_single_test(test_name, test_entry):
    full_env = copy.deepcopy(os.environ)
    logger.info(f"========= RUNNING MOREH TEST - {test_name}")
    print(test_entry)
    result = sp.run(test_entry, shell=True, capture_output=True, env=full_env)
    print(result.stdout.decode("utf-8"))
    print(result.stderr.decode("utf-8"))
    return result


def capture_line_from_str_output(str_output, keyword):
    lines = str_output.strip().split("\n")
    for line in lines:
        if keyword in line:
            return line


def capture_terminal_line(log, keyword):
    str_output = log.stdout.decode("utf-8")

    return capture_line_from_str_output(str_output, keyword)


def capture_line_result(line, position):
    float_pattern = r"[-+]?\d*\.\d+|\d+"
    float_values = re.findall(float_pattern, line)
    float_values = [float(value) for value in float_values]
    return float_values[position]


def generate_csv(file_name, header, data):
    with open(file_name, mode="w", newline="") as file:
        writer = csv.writer(file)
        writer.writerow(header)
        writer.writerows(data)


def append_to_csv(file_path, header, data, write_header=True):
    file_exists = os.path.isfile(file_path)
    with open(file_path, "a", newline="") as csvfile:
        writer = csv.writer(csvfile)
        if not file_exists or write_header:
            writer.writerow(header)
        writer.writerows(data)


def profile_results():
    setup = device_post_proc_config.default_setup()
    setup.deviceInputLog = profiler_log_path
    setup.timerAnalysis = {
        "device_fw_duration": {
            "across": "device",
            "type": "session_first_last",
            "start": {"core": "ANY", "risc": "ANY", "zone_name": [f"{risc}-FW" for risc in setup.riscTypes]},
            "end": {"core": "ANY", "risc": "ANY", "zone_name": [f"{risc}-FW" for risc in setup.riscTypes]},
        },
    }
    devices_data = import_log_run_stats(setup)
    deviceID = list(devices_data["devices"].keys())[0]
    total_cycle = devices_data["devices"][deviceID]["cores"]["DEVICE"]["analysis"]["device_fw_duration"]["stats"][
        "Average"
    ]
    return total_cycle


def profile_results_kernel_duration():
    setup = device_post_proc_config.default_setup()
    setup.deviceInputLog = profiler_log_path
    setup.timerAnalysis = {
        "device_kernel_duration": {
            "across": "device",
            "type": "session_first_last",
            "start": {"core": "ANY", "risc": "ANY", "zone_name": [f"{risc}-KERNEL" for risc in setup.riscTypes]},
            "end": {"core": "ANY", "risc": "ANY", "zone_name": [f"{risc}-KERNEL" for risc in setup.riscTypes]},
        },
    }
    devices_data = import_log_run_stats(setup)
    deviceID = list(devices_data["devices"].keys())[0]
    total_cycle = devices_data["devices"][deviceID]["cores"]["DEVICE"]["analysis"]["device_kernel_duration"]["stats"][
        "Average"
    ]
    return total_cycle


def get_device_freq():
    setup = device_post_proc_config.default_setup()
    setup.deviceInputLog = profiler_log_path
    deviceData = import_log_run_stats(setup)
    freq = deviceData["deviceInfo"]["freq"]
    return freq


def profile_noc_results():
    setup = device_post_proc_config.test_noc()
    setup.deviceInputLog = profiler_log_path
    setup.timerAnalysis = {
        "NoC For Loop": {
            "across": "device",
            "type": "session_first_last",
            "start": {"core": "ANY", "risc": "ANY", "zone_name": [f"{risc}-KERNEL" for risc in setup.riscTypes]},
            "end": {"core": "ANY", "risc": "ANY", "zone_name": [f"{risc}-KERNEL" for risc in setup.riscTypes]},
        },
    }
    devices_data = import_log_run_stats(setup)
    deviceID = list(devices_data["devices"].keys())[0]
    min = devices_data["devices"][deviceID]["cores"]["DEVICE"]["analysis"]["NoC For Loop"]["stats"]["Min"]
    max = devices_data["devices"][deviceID]["cores"]["DEVICE"]["analysis"]["NoC For Loop"]["stats"]["Max"]
    return min, max


# pcie write
def test_write_device_l1(iter=1, buffer_type=0, size=2048):
    command = (
        "./build/test/tt_metal/perf_microbenchmark/old/pcie/test_rw_device_l1"
        + " "
        + "--iter "
        + str(iter)
        + " --buffer_type "
        + str(buffer_type)
        + " --size "
        + str(size)
    )
    result = run_moreh_single_test("pcie write to device l1", command)
    line = capture_terminal_line(result, "WriteToDeviceL1")
    bw = capture_line_result(line, -1)
    return bw


def test_write_device_dram_channel(iter=1, buffer_type=0, size=2048):
    command = (
        "./build/test/tt_metal/perf_microbenchmark/old/pcie/test_rw_device_dram"
        + " "
        + "--iter "
        + str(iter)
        + " --buffer_type "
        + str(buffer_type)
        + " --size "
        + str(size)
    )
    result = run_moreh_single_test("pcie write to device dram", command)
    line = capture_terminal_line(result, "WriteToDeviceDRAMChannel")
    bw = capture_line_result(line, -1)
    return bw


def test_write_buffer(iter=1, buffer_type=0, size=2048):
    command = (
        "./build/test/tt_metal/perf_microbenchmark/old/pcie/test_rw_buffer_old"
        + " "
        + "--iter "
        + str(iter)
        + " --buffer_type "
        + str(buffer_type)
        + " --size "
        + str(size)
    )
    result = run_moreh_single_test("pcie write to buffer", command)
    line = capture_terminal_line(result, "WriteToBuffer")
    bw = capture_line_result(line, -1)
    return bw


def test_enqueue_write_buffer(iter=1, buffer_type=0, size=2048, timeout=600):
    command = (
        "./build/test/tt_metal/perf_microbenchmark/old/pcie/test_enqueue_rw_buffer"
        + " "
        + "--iter "
        + str(iter)
        + " --buffer_type "
        + str(buffer_type)
        + " --size "
        + str(size)
    )
    result = run_moreh_single_test("pcie enqueue write to buffer", command)
    line = capture_terminal_line(result, "EnqueueWriteBuffer")
    bw = capture_line_result(line, -1)
    return bw


# pcie read
def test_read_device_l1(iter=1, buffer_type=0, size=2048):
    command = (
        "./build/test/tt_metal/perf_microbenchmark/old/pcie/test_rw_device_l1"
        + " "
        + "--iter "
        + str(iter)
        + " --buffer_type "
        + str(buffer_type)
        + " --size "
        + str(size)
    )
    result = run_moreh_single_test("pcie read from device l1", command)
    line = capture_terminal_line(result, "ReadFromDeviceL1")
    bw = capture_line_result(line, -1)
    return bw


def test_read_device_dram_channel(iter=1, buffer_type=0, size=2048):
    command = (
        "./build/test/tt_metal/perf_microbenchmark/old/pcie/test_rw_device_dram"
        + " "
        + "--iter "
        + str(iter)
        + " --buffer_type "
        + str(buffer_type)
        + " --size "
        + str(size)
    )
    result = run_moreh_single_test("pcie read from device dram", command)
    line = capture_terminal_line(result, "ReadFromDeviceDRAMChannel")
    bw = capture_line_result(line, -1)
    return bw


def test_read_buffer(iter=1, buffer_type=0, size=2048):
    command = (
        "./build/test/tt_metal/perf_microbenchmark/old/pcie/test_rw_buffer_old"
        + " "
        + "--iter "
        + str(iter)
        + " --buffer_type "
        + str(buffer_type)
        + " --size "
        + str(size)
    )
    result = run_moreh_single_test("pcie read from buffer", command)
    line = capture_terminal_line(result, "ReadFromBuffer")
    bw = capture_line_result(line, -1)
    return bw


def test_enqueue_read_buffer(iter=1, buffer_type=0, size=2048, timeout=600):
    command = (
        "./build/test/tt_metal/perf_microbenchmark/old/pcie/test_enqueue_rw_buffer"
        + " "
        + "--iter "
        + str(iter)
        + " --buffer_type "
        + str(buffer_type)
        + " --size "
        + str(size)
    )
    result = run_moreh_single_test("pcie enqueue read from buffer", command)
    line = capture_terminal_line(result, "EnqueueReadBuffer")
    bw = capture_line_result(line, -1)
    return bw


def run_dram_read_cmd(k, n, num_blocks, df, num_banks, bank_start_id):
    command = (
        "TT_METAL_DEVICE_PROFILER=1 ./build/test/tt_metal/perf_microbenchmark/8_dram_adjacent_core_read/test_dram_read"
        + " "
        + " --k "
        + str(k)
        + " --n "
        + str(n)
        + " --num-blocks "
        + str(num_blocks)
        + " --num-tests "
        + str(1)
        + " --data-type "
        + str(df)
        + " --num-banks "
        + str(num_banks)
        + " --bank-start-id "
        + str(bank_start_id)
        + " --bypass-check "
    )
    run_moreh_single_test("DRAM BW test multi-core", command)


def run_dram_read_l1_write_cmd(k, n, num_blocks, df, num_banks, bank_start_id):
    command = (
        "TT_METAL_DEVICE_PROFILER=1 ./build/test/tt_metal/perf_microbenchmark/9_dram_adjacent_read_remote_l1_write/test_dram_read_l1_write"
        + " "
        + " --k "
        + str(k)
        + " --n "
        + str(n)
        + " --num-blocks "
        + str(num_blocks)
        + " --num-tests "
        + str(1)
        + " --data-type "
        + str(df)
        + " --num-banks "
        + str(num_banks)
        + " --bank-start-id "
        + str(bank_start_id)
        + " --bypass-check "
    )
    run_moreh_single_test("DRAM BW test multi-core", command)


def run_dram_read_remote_cb_sync_cmd(
    k, n, num_blocks, cb_num_blocks, cb_padding, df, num_receivers, num_mixed_df_layers, use_sub_devices
):
    command = (
        "TT_METAL_DEVICE_PROFILER=1 ./build/test/tt_metal/perf_microbenchmark/10_dram_read_remote_cb_sync/test_dram_read_remote_cb"
        + " "
        + " --k "
        + str(k)
        + " --n "
        + str(n)
        + " --num-blocks "
        + str(num_blocks)
        + " --cb-num-blocks "
        + str(cb_num_blocks)
        + " --cb-padding "
        + str(cb_padding)
        + " --num-tests "
        + str(1)
        + " --data-type "
        + str(df)
        + " --num-receivers "
        + str(num_receivers)
        + " --num-mixed-df-layers "
        + str(num_mixed_df_layers)
        + (" --use-sub-devices " if use_sub_devices else "")
    )
    run_moreh_single_test("DRAM read remote CB sync single-core ", command)


def run_remote_cb_sync_matmul_single_core_cmd(
    m, k, n, num_blocks, cb_num_blocks, cb_padding, df, num_receivers, num_layers, use_sub_devices
):
    command = (
        "TT_METAL_DEVICE_PROFILER=1 ./build/test/tt_metal/perf_microbenchmark/11_remote_cb_sync_matmul_single_core/test_remote_cb_sync_matmul"
        + " "
        + " --m "
        + str(m)
        + " --k "
        + str(k)
        + " --n "
        + str(n)
        + " --num-blocks "
        + str(num_blocks)
        + " --cb-num-blocks "
        + str(cb_num_blocks)
        + " --cb-padding "
        + str(cb_padding)
        + " --num-tests "
        + str(1)
        + " --data-type "
        + str(df)
        + " --num-receivers "
        + str(num_receivers)
        + " --num-layers "
        + str(num_layers)
        + (" --use-sub-devices " if use_sub_devices else "")
    )
    run_moreh_single_test("DRAM read remote CB sync single-core ", command)


# noc
def test_noc_local(r=9, c=12, nt=256, cb=1):
    command = (
        "./build/test/tt_metal/perf_microbenchmark/old/noc/test_noc_read_local_l1"
        + " "
        + "--r "
        + str(r)
        + " --c "
        + str(c)
        + " --nt "
        + str(nt)
        + " --cb "
        + str(cb)
    )
    run_moreh_single_test("noc read local l1", command)


def test_noc_global_type_a(r=9, c=12, nt=256, cb=1):
    command = (
        "./build/test/tt_metal/perf_microbenchmark/old/noc/test_noc_read_global_l1"
        + " "
        + "--r "
        + str(r)
        + " --c "
        + str(c)
        + " --nt "
        + str(nt)
        + " --cb "
        + str(cb)
        + " --same_buffer_read 1 --one_buffer_share 1"
    )
    run_moreh_single_test("noc read global l1 (type a)", command)


def test_noc_global_type_b(r=9, c=12, nt=256, cb=1):
    command = (
        "./build/test/tt_metal/perf_microbenchmark/old/noc/test_noc_read_global_l1"
        + " "
        + "--r "
        + str(r)
        + " --c "
        + str(c)
        + " --nt "
        + str(nt)
        + " --cb "
        + str(cb)
        + " --same_buffer_read 1 --one_buffer_share 0"
    )
    run_moreh_single_test("noc read global l1 (type b)", command)


# matmul
def test_matmul_global(
    r=9, c=12, mt=72, nt=96, kt=24, per_core_mt=8, per_core_nt=8, l1_in0=0, l1_in1=0, l1_out=0, in0_block_w=4
):
    command = (
        "./build/test/tt_metal/perf_microbenchmark/old/matmul/matmul_global_l1"
        + " "
        + "--r "
        + str(r)
        + " --c "
        + str(c)
        + " --mt "
        + str(mt)
        + " --nt "
        + str(nt)
        + " --kt "
        + str(kt)
        + " --l1_in0 "
        + str(l1_in0)
        + " --l1_in1 "
        + str(l1_in1)
        + " --l1_out "
        + str(l1_out)
        + " --in0_block_w "
        + str(in0_block_w)
        + " --per_core_mt "
        + str(per_core_mt)
        + " --per_core_nt "
        + str(per_core_nt)
    )
    run_moreh_single_test("matmul global l1", command)


def test_matmul_local(r=9, c=12, mt=72, nt=96, kt=24):
    command = (
        "./build/test/tt_metal/perf_microbenchmark/old/matmul/matmul_local_l1"
        + " "
        + "--r "
        + str(r)
        + " --c "
        + str(c)
        + " --mt "
        + str(mt)
        + " --nt "
        + str(nt)
        + " --kt "
        + str(kt)
    )
    run_moreh_single_test("matmul local l1", command)


def test_matmul_single_core(
    m, n, k, dtype, fidel, matmul_block, num_blocks, packer_l1_acc, fp32_dest_acc, interm_cb_dtype, subblock_index
):
    command = (
        "TT_METAL_DEVICE_PROFILER=1 ./build/test/tt_metal/perf_microbenchmark/1_compute_mm/test_compute_mm"
        + " "
        + "--m "
        + str(m)
        + " --n "
        + str(n)
        + " --k "
        + str(k)
        + " --dtype "
        + str(dtype)
        + " --fidel "
        + str(fidel)
        + " --block "
        + str(matmul_block)
        + " --num-tests "
        + str(1)
        + " --fast-dispatch --bypass-check --one-core 1 "
        + " --num-blocks "
        + str(num_blocks)
        + " --packer "
        + str(packer_l1_acc)
        + " --fp32 "
        + str(fp32_dest_acc)
        + " --interm-cb "
        + str(interm_cb_dtype)
        + " --subblock-index "
        + str(subblock_index)
    )
    run_moreh_single_test("matmul single core sharded", command)


@pytest.mark.parametrize(
    "iteration, test_vector_small, test_vector_large",
    [(2, np.array([8192, 32768, 131072, 524288, 2097152, 8388608]), np.array([33554432, 134217728, 536870912]))],
)
def test_pcie_h2d_dram(iteration, test_vector_small, test_vector_large):
    file_name = PROFILER_LOGS_DIR / "moreh_old_H2D_DRAM_Bandwidth.csv"
    header = ["Transfer Size", "WriteToDeviceDRAMChannel", "WriteToBuffer", "EnqueueWriteBuffer"]
    data = []
    for test_point in test_vector_small:
        bw_wdd = test_write_device_dram_channel(iteration, 0, test_point)
        bw_wb = test_write_buffer(iteration, 0, test_point)
        bw_ewb = test_enqueue_write_buffer(iteration, 0, test_point)
        data_entry = [test_point, bw_wdd, bw_wb, bw_ewb]
        data.append(data_entry)
    for test_point in test_vector_large:
        bw_wdd = test_write_device_dram_channel(1, 0, test_point)
        bw_wb = test_write_buffer(1, 0, test_point)
        bw_ewb = test_enqueue_write_buffer(1, 0, test_point)
        data_entry = [test_point, bw_wdd, bw_wb, bw_ewb]
        data.append(data_entry)
    generate_csv(file_name, header, data)
    return


@pytest.mark.parametrize(
    "iteration, test_vector_small, test_vector_large",
    [(2, np.array([8192, 32768, 131072, 524288, 2097152, 8388608]), np.array([33554432, 134217728, 536870912]))],
)
def test_pcie_d2h_dram(iteration, test_vector_small, test_vector_large):
    file_name = PROFILER_LOGS_DIR / "moreh_old_D2H_DRAM_Bandwidth.csv"
    header = ["Transfer Size", "ReadFromDeviceDRAMChannel", "ReadFromBuffer", "EnqueueReadBuffer"]
    data = []
    for test_point in test_vector_small:
        bw_wdd = test_read_device_dram_channel(iteration, 0, test_point)
        bw_wb = test_read_buffer(iteration, 0, test_point)
        bw_ewb = test_enqueue_read_buffer(iteration, 0, test_point)
        data_entry = [test_point, bw_wdd, bw_wb, bw_ewb]
        data.append(data_entry)
    for test_point in test_vector_large:
        bw_wdd = test_read_device_dram_channel(1, 0, test_point)
        bw_wb = test_read_buffer(1, 0, test_point)
        bw_ewb = test_enqueue_read_buffer(1, 0, test_point)
        data_entry = [test_point, bw_wdd, bw_wb, bw_ewb]
        data.append(data_entry)
    generate_csv(file_name, header, data)
    return


@pytest.mark.parametrize(
    "arch, iteration, L1_size, test_vector",
    [
        ("grayskull", 2, 1048576, np.array([4096, 16384, 65536, 262144, 1048576, 4194304, 16777216])),
        ("wormhole_b0", 2, 1499136, np.array([4096, 16384, 65536, 262144, 1048576, 4194304, 16777216])),
        ("blackhole", 2, 1499136, np.array([4096, 16384, 65536, 262144, 1048576, 4194304, 16777216])),
    ],
)
def test_pcie_h2d_l1(arch, iteration, L1_size, test_vector):
    file_name = PROFILER_LOGS_DIR / "moreh_old_H2D_L1_Bandwidth.csv"
    header = ["Transfer Size", "WriteToDeviceL1", "WriteToBuffer", "EnqueueWriteBuffer"]
    data = []
    for test_point in test_vector:
        if test_point < L1_size:
            bw_wdd = test_write_device_l1(iteration, 1, test_point)
        else:
            bw_wdd = 0
        bw_wb = test_write_buffer(iteration, 1, test_point)
        bw_ewb = test_enqueue_write_buffer(iteration, 1, test_point)
        data_entry = [test_point, bw_wdd, bw_wb, bw_ewb]
        data.append(data_entry)
    generate_csv(file_name, header, data)
    return


@pytest.mark.parametrize(
    "arch, iteration, L1_size, test_vector",
    [
        ("grayskull", 2, 1048576, np.array([4096, 16384, 65536])),
        ("wormhole_b0", 2, 1499136, np.array([4096, 16384, 65536])),
        ("blackhole", 2, 1499136, np.array([4096, 16384, 65536])),
    ],
)
def test_pcie_d2h_l1(arch, iteration, L1_size, test_vector):
    file_name = PROFILER_LOGS_DIR / "moreh_old_D2H_L1_Bandwidth.csv"
    header = ["Transfer Size", "ReadFromDeviceL1", "ReadFromBuffer", "EnqueueReadBuffer"]
    data = []
    for test_point in test_vector:
        if test_point < L1_size:
            bw_wdd = test_read_device_l1(iteration, 1, test_point)
        else:
            bw_wdd = 0
        bw_wb = test_read_buffer(iteration, 1, test_point)
        bw_ewb = test_enqueue_read_buffer(iteration, 1, test_point)
        data_entry = [test_point, bw_wdd, bw_wb, bw_ewb]
        data.append(data_entry)
    generate_csv(file_name, header, data)
    return


@pytest.mark.parametrize(
    "arch, r, c, nt, test_vector",
    [
        ("grayskull", 9, 12, 256, np.array([1, 8, 16, 32])),
        ("wormhole_b0", 6, 6, 256, np.array([1, 8, 16, 32])),
    ],
)
def test_noc(arch, r, c, nt, test_vector):
    file_name = PROFILER_LOGS_DIR / "moreh_old_NoC_Read_Performance.csv"
    header = [
        "Requests",
        "Local L1 (min)",
        "Local L1 (max)",
        "Global L1 (type A) (min)",
        "Global L1 (type A) (max)",
        "Global L1 (type B) (min)",
        "Global L1 (type B) (max)",
    ]
    data = []
    for test_point in test_vector:
        test_noc_local(r, c, nt, test_point)
        min_1, max_1 = profile_noc_results()
        test_noc_global_type_a(r, c, nt, test_point)
        min_2, max_2 = profile_noc_results()
        test_noc_global_type_b(r, c, nt, test_point)
        min_3, max_3 = profile_noc_results()
        data.append([test_point, min_1, max_1, min_2, max_2, min_3, max_3])
    generate_csv(file_name, header, data)
    return


@pytest.mark.parametrize(
    "arch, freq, r, c, test_vector",
    [
        (
            "grayskull",
            1020,
            9,
            12,
            np.array([[4608, 6144, 6144], [3456, 3840, 1024], [3456, 3072, 1024], [2304, 3072, 768]]),
        ),
        ("wormhole_b0", 1000, 6, 6, np.array([[2304, 1920, 1024], [2304, 1536, 1024], [1536, 1536, 768]])),
    ],
)
def test_matmul_dram(arch, freq, r, c, test_vector):
    file_name = PROFILER_LOGS_DIR / "moreh_old_Matmul_DRAM.csv"
    header = ["M", "N", "K", "Cycles", "Time (ms)", "TFLOPS"]
    data = []
    for vec in test_vector:
        mt = int(vec[0] / 32)
        nt = int(vec[1] / 32)
        kt = int(vec[2] / 32)
        per_core_mt = int((mt - 1) / r) + 1
        per_core_nt = int((nt - 1) / c) + 1
        test_matmul_global(r, c, mt, nt, kt, per_core_mt, per_core_nt, 0, 0, 0, 2)
        cycle = profile_results()
        num_op = vec[0] * vec[1] * vec[2] * 2
        time = cycle / freq / 1000.0
        throughput = num_op / time / 1000.0 / 1000.0 / 1000.0
        data.append(vec + [cycle, time, throughput])
    generate_csv(file_name, header, data)
    return


@pytest.mark.parametrize(
    "arch, freq, test_vector, dtype, fidel, matmul_block, num_blocks, packer_l1_acc, fp32_dest_acc, interm_cb_dtype, subblock_index, baseline",
    [
        # ########################### 512 512 512 x 8 subblock 4 2 ################################
        ("wormhole_b0", 1000, np.array([[512, 512, 512]]), 0, 0, 1, 8, 0, 0, 0, 0, 717089.0),
        ("wormhole_b0", 1000, np.array([[512, 512, 512]]), 0, 1, 1, 8, 0, 0, 0, 0, 1233930.0),
        ("wormhole_b0", 1000, np.array([[512, 512, 512]]), 0, 0, 1, 8, 1, 0, 0, 0, 664492.0),
        ("wormhole_b0", 1000, np.array([[512, 512, 512]]), 0, 1, 1, 8, 1, 0, 0, 0, 1173029.0),
        # ########################### 512 512 256x8 subblock 4 2 ################################
        ("wormhole_b0", 1000, np.array([[512, 512, 256]]), 0, 0, 1, 8, 0, 0, 0, 0, 399068.0),
        ("wormhole_b0", 1000, np.array([[512, 512, 256]]), 0, 1, 1, 8, 0, 0, 0, 0, 658522.0),
        ("wormhole_b0", 1000, np.array([[512, 512, 256]]), 0, 0, 1, 8, 1, 0, 0, 0, 346350.0),
        ("wormhole_b0", 1000, np.array([[512, 512, 256]]), 0, 1, 1, 8, 1, 0, 0, 0, 597457.0),
        # ########################### 512 512 512 x 8 subblock 4 2 ################################
        ("blackhole", 800, np.array([[512, 512, 512]]), 0, 0, 1, 8, 0, 0, 0, 0, 717089.0),
        ("blackhole", 800, np.array([[512, 512, 512]]), 0, 1, 1, 8, 0, 0, 0, 0, 1233930.0),
        ("blackhole", 800, np.array([[512, 512, 512]]), 0, 0, 1, 8, 1, 0, 0, 0, 664492.0),
        ("blackhole", 800, np.array([[512, 512, 512]]), 0, 1, 1, 8, 1, 0, 0, 0, 1173029.0),
        # ########################### 512 512 256x8 subblock 4 2 ################################
        ("blackhole", 800, np.array([[512, 512, 256]]), 0, 0, 1, 8, 0, 0, 0, 0, 399068.0),
        ("blackhole", 800, np.array([[512, 512, 256]]), 0, 1, 1, 8, 0, 0, 0, 0, 658522.0),
        ("blackhole", 800, np.array([[512, 512, 256]]), 0, 0, 1, 8, 1, 0, 0, 0, 346350.0),
        ("blackhole", 800, np.array([[512, 512, 256]]), 0, 1, 1, 8, 1, 0, 0, 0, 597457.0),
    ],
)
def test_matmul_single_core_sharded(
    arch,
    freq,
    test_vector,
    dtype,
    fidel,
    matmul_block,
    num_blocks,
    packer_l1_acc,
    fp32_dest_acc,
    interm_cb_dtype,
    subblock_index,
    baseline,
):
    file_name = PROFILER_LOGS_DIR / "moreh_single_core_Matmul_Sharded.csv"
    header = ["Kernel Duration (Cycles)"]
    kernel_durations_cycle = []
    for vec in test_vector:
        m = int(vec[0])
        n = int(vec[1])
        k = int(vec[2])
        test_matmul_single_core(
            m,
            n,
            k,
            dtype,
            fidel,
            matmul_block,
            num_blocks,
            packer_l1_acc,
            fp32_dest_acc,
            interm_cb_dtype,
            subblock_index,
        )
        cycle = profile_results_kernel_duration()
        dev_freq = get_device_freq()
        logger.info("cycle: " + str(cycle))
        num_op = vec[0] * vec[1] * vec[2] * 2
        time = cycle / dev_freq / 1000.0
        throughput = num_op / time / 1000.0 / 1000.0 / 1000.0
        kernel_durations_cycle.append([cycle])

    max_diff = 0.01

    percentage_diff = np.abs(kernel_durations_cycle[0][0] - baseline) / baseline
    is_within_range = percentage_diff < max_diff
    if is_within_range == False:
        logger.info(
            "Diff is too large! kernel duration: {}, baseline: {}, diff: {}",
            kernel_durations_cycle[0][0],
            baseline,
            percentage_diff,
        )

    write_header = not os.path.exists(file_name)
    append_to_csv(file_name, header, kernel_durations_cycle, write_header)
    assert is_within_range


@pytest.mark.parametrize(
    "arch, freq, test_vector, num_tests, nblock, data_format, num_banks, bank_start_id",
    [
        ("wormhole_b0", 1000, np.array([32768, 12 * 128]), 1, 8, 0, 12, 0),
        ("wormhole_b0", 1000, np.array([32768, 12 * 128]), 1, 8, 1, 12, 0),
        ("wormhole_b0", 1000, np.array([2048, 3840]), 1, 4, 1, 12, 0),  # Padded FF1 shapes for llama 70b on TG
        ("blackhole", 800, np.array([32768, 8 * 128]), 1, 8, 0, 8, 0),
        ("blackhole", 800, np.array([32768, 8 * 128]), 1, 8, 1, 8, 0),
        ("blackhole", 800, np.array([2048, 3840]), 1, 4, 1, 8, 0),  # Padded FF1 shapes for llama 70b on TG
    ],
)
def test_dram_read_all_core(arch, freq, test_vector, num_tests, nblock, data_format, num_banks, bank_start_id):
    data = []
    cycle_list = []
    time_list = []
    throughput_list = []
    for _ in range(num_tests):
        k = int(test_vector[0])
        n = int(test_vector[1])
        if data_format == 0:
            input_size = k * n * 1088 // 1024
        elif data_format == 1:
            input_size = k * n * 2048 // 1024
        run_dram_read_cmd(k, n, nblock, data_format, num_banks, bank_start_id)
        cycle = profile_results_kernel_duration()
        time = cycle / freq / 1000.0 / 1000.0
        throughput = input_size / cycle
        logger.info("DRAM read cycle: " + str(cycle))
        logger.info("DRAM read time: " + str(time))
        logger.info("DRAM read throughput: " + str(throughput))
        cycle_list.append(cycle)
        time_list.append(time)
        throughput_list.append(throughput)
    cycle = sum(cycle_list) / len(cycle_list)
    time = sum(time_list) / len(time_list)
    throughput = sum(throughput_list) / len(throughput_list)
    logger.info("DRAM read cycle: " + str(cycle))
    logger.info("DRAM read time: " + str(time))
    logger.info("DRAM read throughput: " + str(throughput))
    data.append([throughput])
    # check within range
    dev_freq = get_device_freq()
    bw_lower_bound = 260.0 * dev_freq / 1000.0
    bw_upper_bound = bw_lower_bound + 10.0
    assert bw_lower_bound <= throughput
    assert throughput <= bw_upper_bound


@pytest.mark.parametrize(
    "arch, test_vector, num_tests, nblock, data_format, num_banks, bank_start_id, bw_target",
    [
        ("grayskull", np.array([32768 * 2, 8 * 128]), 1, 64, 1, 8, 0, None),
        ("wormhole_b0", np.array([32768 * 2, 12 * 128]), 1, 64, 2, 12, 0, None),
        ("blackhole", np.array([32768 * 8, 8 * 128]), 1, 256, 2, 8, 0, None),
        # FF1/FF3 shapes for TG llama 70b
        (
            "wormhole_b0",
            np.array([2048, 3840]),
            1,
            16,
            0,
            12,
            0,
            240,
        ),  # 244 GB/s
        (
            "blackhole",
            np.array([2048, 3840]),
            1,
            16,
            0,
            8,
            0,
            240,
        ),  # 244 GB/s
        # FF2 shapes for TG llama 70b
        (
            "wormhole_b0",
            np.array([3584, 2304]),
            1,
            28,
            1,
            12,
            0,
            250,
        ),  # 255 GB/s
        (
            "blackhole",
            np.array([3584, 2304]),
            1,
            28,
            1,
            8,
            0,
            250,
        ),  # 255 GB/s
        # Dense Out shapes for TG llama 70b
        (
            "wormhole_b0",
            np.array([1024, 2304]),
            1,
            8,
            1,
            12,
            0,
            220,
        ),  # 226 GB/s
        (
            "blackhole",
            np.array([1024, 2304]),
            1,
            8,
            1,
            8,
            0,
            220,
        ),  # 226 GB/s
        # QKV shapes for TG llama 70b
        (
            "wormhole_b0",
            np.array([2048, 1536]),
            1,
            16,
            1,
            12,
            0,
            225,
        ),  # 232 GB/s
        (
            "blackhole",
            np.array([2048, 1536]),
            1,
            16,
            1,
            8,
            0,
            225,
        ),  # 232 GB/ss
    ],
)
def test_dram_read_l1_write_core(
    arch, test_vector, num_tests, nblock, data_format, num_banks, bank_start_id, bw_target
):
    data = []
    cycle_list = []
    time_list = []
    throughput_list = []
    for _ in range(num_tests):
        k = int(test_vector[0])
        n = int(test_vector[1])
        if data_format == 0:  # BFP4
            input_size = k * n * (512 + 64) // 1024
        elif data_format == 1:  # BFP8
            input_size = k * n * 1088 // 1024
        elif data_format == 2:  # BFLOAT16
            input_size = k * n * 2048 // 1024
        run_dram_read_l1_write_cmd(k, n, nblock, data_format, num_banks, bank_start_id)
        cycle = profile_results_kernel_duration()
        dev_freq = get_device_freq()
        time = cycle / dev_freq / 1000.0 / 1000.0
        throughput = input_size / cycle * dev_freq / 1000.0
        cycle_list.append(cycle)
        time_list.append(time)
        throughput_list.append(throughput)
    cycle = sum(cycle_list) / len(cycle_list)
    time = sum(time_list) / len(time_list)
    throughput = sum(throughput_list) / len(throughput_list)
    logger.info("DRAM read cycle: " + str(cycle))
    logger.info("DRAM read time: " + str(time))
    logger.info("DRAM read throughput: " + str(throughput))
    data.append([throughput])
    # check within range
    if arch == "grayskull":
        bw_lower_bound = 70.0  # Equals 85 GB/s with 1200 MHz
    elif arch == "wormhole_b0":
        bw_lower_bound = 260.0
    elif arch == "blackhole":
        bw_lower_bound = 340.0
    if bw_target is not None:
        bw_lower_bound = bw_target
    bw_lower_bound = (
        bw_lower_bound * dev_freq / 1000.0
    )  # Adjust for device frequency; target is based on max device frequency
    assert bw_lower_bound <= throughput
    bw_upper_bound = bw_lower_bound + 10.0
    assert throughput <= bw_upper_bound


@pytest.mark.parametrize(
    "arch, test, test_vector, num_tests, nblock, cb_nblock, cb_padding, data_format, num_receivers, num_mixed_df_layers",
    [
        # single layer single receiver test
        ("wormhole_b0", None, np.array([32768, 128]), 1, 64, 5, 256, 1, 1, 1),
        # single layer multi receiver test
        ("wormhole_b0", None, np.array([32768, 128]), 1, 64, 3, 256, 1, 2, 1),
        # multi layer multi receiver test
        ("wormhole_b0", None, np.array([32768, 256]), 1, 64, 5, 256, 1, 4, 15),
        # Matmul test does not support mixed data format, just test for either bfp8 or fp16
        # single layer single receiver test
        ("wormhole_b0", "Matmul", np.array([32, 4096, 128]), 1, 8, 10, 256, 0, 1, 1),
        ("wormhole_b0", "Matmul", np.array([32, 2048, 128]), 1, 8, 10, 256, 1, 1, 1),
        # # single layer multi receiver test
        ("wormhole_b0", "Matmul", np.array([32, 2048, 128]), 1, 8, 10, 256, 1, 2, 1),
        # # multi layer multi receiver test
        ("wormhole_b0", "Matmul", np.array([32, 2048, 128]), 1, 8, 10, 256, 1, 2, 15),
        # single layer single receiver test
        ("blackhole", None, np.array([32768, 128]), 1, 64, 5, 256, 1, 1, 1),
        # single layer multi receiver test
        ("blackhole", None, np.array([32768, 128]), 1, 64, 3, 256, 1, 2, 1),
        # multi layer multi receiver test
        ("blackhole", None, np.array([32768, 256]), 1, 64, 5, 256, 1, 4, 15),
        # Matmul test does not support mixed data format, just test for either bfp8 or fp16
        # single layer single receiver test
        ("blackhole", "Matmul", np.array([32, 4096, 128]), 1, 8, 10, 256, 0, 1, 1),
        ("blackhole", "Matmul", np.array([32, 2048, 128]), 1, 8, 10, 256, 1, 1, 1),
        # # single layer multi receiver test
        ("blackhole", "Matmul", np.array([32, 2048, 128]), 1, 8, 10, 256, 1, 2, 1),
        # # multi layer multi receiver test
        ("blackhole", "Matmul", np.array([32, 2048, 128]), 1, 8, 10, 256, 1, 2, 15),
    ],
)
@pytest.mark.parametrize(
    "use_sub_devices",
    [False, True],
)
def test_dram_read_remote_cb_sync(
    arch,
    test,
    test_vector,
    num_tests,
    nblock,
    cb_nblock,
    cb_padding,
    data_format,
    num_receivers,
    num_mixed_df_layers,
    use_sub_devices,
):
    data = []
    cycle_list = []
    time_list = []
    throughput_list = []
    for _ in range(num_tests):
        if test == None:
            k = int(test_vector[0])
            n = int(test_vector[1])
        elif test == "Matmul":
            m = int(test_vector[0])
            k = int(test_vector[1])
            n = int(test_vector[2])
        input_size = 0
        if data_format == 0:
            input_size += k * n * 1088 // 1024
        elif data_format == 1:
            input_size += k * n * 2048 // 1024
        if test == None:
            for i in range(num_mixed_df_layers - 1):
                if i % 2 == 0:
                    input_size += k * n * 1088 // 1024
                else:
                    input_size += k * n * 2048 // 1024
            run_dram_read_remote_cb_sync_cmd(
                k, n, nblock, cb_nblock, cb_padding, data_format, num_receivers, num_mixed_df_layers, use_sub_devices
            )
        elif test == "Matmul":
            input_size = input_size * num_mixed_df_layers
            run_remote_cb_sync_matmul_single_core_cmd(
                m, k, n, nblock, cb_nblock, cb_padding, data_format, num_receivers, num_mixed_df_layers, use_sub_devices
            )
        cycle = profile_results_kernel_duration()
        time = cycle / get_device_freq() / 1000.0 / 1000.0
        throughput = input_size / cycle * get_device_freq() / 1000.0
        cycle_list.append(cycle)
        time_list.append(time)
        throughput_list.append(throughput)
    cycle = sum(cycle_list) / len(cycle_list)
    time = sum(time_list) / len(time_list)
    throughput = sum(throughput_list) / len(throughput_list)
    logger.info("DRAM read cycle: " + str(cycle))
    logger.info("DRAM read time: " + str(time))
    logger.info("DRAM read throughput: " + str(throughput))
    data.append([throughput])
    # check within range
    bw_lower_bound = 0.0
    if test == None:
        if arch == "wormhole_b0":
            bw_lower_bound = 21.5
    elif test == "Matmul":
        if arch == "wormhole_b0":
            bw_lower_bound = 18.0
    bw_upper_bound = bw_lower_bound + 4.0
    if use_sub_devices:
        pytest.xfail("Tests using sub-devices is not correctly set up for BW measurements")
    assert bw_lower_bound <= throughput
    assert throughput <= bw_upper_bound


@pytest.mark.parametrize(
    "arch, freq, r, c, test_vector_global, test_vector_local",
    [
        ("grayskull", 1020, 9, 12, np.array([[3456, 3072, 1024], [2304, 3072, 768]]), np.array([[2304, 3072, 768]])),
        ("wormhole_b0", 1000, 6, 6, np.array([[2304, 1536, 1024], [1536, 1536, 768]]), np.array([[1536, 1536, 768]])),
        ("blackhole", 800, 6, 6, np.array([[2304, 1536, 1024], [1536, 1536, 768]]), np.array([[1536, 1536, 768]])),
    ],
)
def test_matmul_l1(arch, freq, r, c, test_vector_global, test_vector_local):
    file_name = PROFILER_LOGS_DIR / "moreh_old_Matmul_SRAM.csv"
    header = ["M", "N", "K", "Cycles", "Time (ms)", "TFLOPS"]
    data = []
    for vec in test_vector_global:
        mt = int(vec[0] / 32)
        nt = int(vec[1] / 32)
        kt = int(vec[2] / 32)
        per_core_mt = int((mt - 1) / r) + 1
        per_core_nt = int((nt - 1) / c) + 1
        test_matmul_global(r, c, mt, nt, kt, per_core_mt, per_core_nt, 1, 1, 1, 4)
        cycle = profile_results()
        num_op = vec[0] * vec[1] * vec[2] * 2
        time = cycle / freq / 1000.0
        throughput = num_op / time / 1000.0 / 1000.0 / 1000.0
        data.append(vec + [cycle, time, throughput])
    for vec in test_vector_local:
        mt = int(vec[0] / 32)
        nt = int(vec[1] / 32)
        kt = int(vec[2] / 32)
        test_matmul_local(r, c, mt, nt, kt)
        cycle = profile_results()
        num_op = vec[0] * vec[1] * vec[2] * 2
        time = cycle / freq / 1000.0
        throughput = num_op / time / 1000.0 / 1000.0 / 1000.0
        data.append(vec + [cycle, time, throughput])
    generate_csv(file_name, header, data)
    return


@pytest.fixture(scope="function")
def create_moreh_microbenchmark_csv(request):
    microbenchmark_name = request.node.name.split("[")[0]

    file_name = PROFILER_LOGS_DIR / f"moreh_{microbenchmark_name}.csv"

    yield file_name


@pytest.fixture(scope="function")
def record_moreh_microbenchmark_csv(capsys, create_moreh_microbenchmark_csv):
    yield

    captured = capsys.readouterr()

    result_output = captured.out

    def get_entries(result_output, marker):
        line = capture_line_from_str_output(result_output, marker)
        return line.split(":")[1:]

    csv_microbenchmark_name = get_entries(result_output, "CSV_MICROBENCHMARK")[0]
    csv_inputs_and_values = get_entries(result_output, "CSV_INPUT")
    csv_outputs_and_values = get_entries(result_output, "CSV_OUTPUT")
    csv_result_and_value = get_entries(result_output, "CSV_RESULT")

    assert len(csv_result_and_value) == 2, f"CSV_RESULT needs to be a single name and value"
    assert len(csv_inputs_and_values) >= 2
    assert len(csv_outputs_and_values) >= 2

    def get_names(inputs_and_values):
        return list(toolz.itertoolz.take_nth(2, inputs_and_values))

    def get_values(inputs_and_values):
        return list(toolz.itertoolz.take_nth(2, inputs_and_values[1:]))

    csv_inputs_names = get_names(csv_inputs_and_values)
    csv_inputs_values = get_values(csv_inputs_and_values)

    csv_outputs_names = get_names(csv_outputs_and_values)
    csv_outputs_values = get_values(csv_outputs_and_values)

    csv_result_name = get_names(csv_result_and_value)[0]
    csv_result_value = get_values(csv_result_and_value)[0]

    headers = csv_inputs_names + csv_outputs_names + [csv_result_name]
    data = csv_inputs_values + csv_outputs_values + [csv_result_value]

    file_name = create_moreh_microbenchmark_csv

    file_path = Path(file_name)

    if not file_path.exists():
        with open(file_path, mode="w", newline="") as file:
            writer = csv.writer(file)
            writer.writerow(headers)

    assert file_path.is_file()
    with open(file_path, mode="a", newline="") as file:
        writer = csv.writer(file)
        writer.writerow(data)


@pytest.mark.parametrize(
    "r, c, num_tiles, tiles_per_transfer, noc_index, noc_direction, access_type, use_device_profiler",
    [(9, 12, 204800, 1, 0, 0, 0, 0), (9, 12, 204800, 1, 0, 0, 0, 0)],
)
def test_noc_adjacent(
    r,
    c,
    num_tiles,
    tiles_per_transfer,
    noc_index,
    noc_direction,
    access_type,
    use_device_profiler,
    record_moreh_microbenchmark_csv,
):
    command = (
        "./build/test/tt_metal/perf_microbenchmark/2_noc_adjacent/test_noc_adjacent"
        + " "
        + "--cores-r "
        + str(r)
        + " --cores-c "
        + str(c)
        + " --num-tiles "
        + str(num_tiles)
        + " --tiles-per-transfer"
        + str(tiles_per_transfer)
        + " --noc-index"
        + str(noc_index)
        + " --noc-direction "
        + str(noc_direction)
        + " --access-type "
        + str(access_type)
    )
    if use_device_profiler:
        command += " --use-device-profiler"
    result = run_moreh_single_test("test_noc_adjacent", command)
