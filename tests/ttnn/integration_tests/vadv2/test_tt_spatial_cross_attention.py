# SPDX-FileCopyrightText: Â© 2025 Tenstorrent AI ULC

# SPDX-License-Identifier: Apache-2.0

import pytest
import torch
from loguru import logger

import ttnn
from models.experimental.vadv2.reference import spatial_cross_attention
from models.experimental.vadv2.tt import tt_spatial_cross_attention
from models.experimental.vadv2.tt.model_preprocessing import (
    create_vadv2_model_parameters_sca,
)
from tests.ttnn.utils_for_testing import assert_with_pcc


@pytest.mark.parametrize("device_params", [{"l1_small_size": 32768}], indirect=True)
def test_vadv2_sca(
    device,
    reset_seeds,
    use_program_cache,
):
    weights_path = "models/experimental/vadv2/tt/vadv2_weights_1.pth"
    point_cloud_range = [-15.0, -30.0, -2.0, 15.0, 30.0, 2.0]
    batch_first = True
    torch_model = spatial_cross_attention.SpatialCrossAttention(
        embed_dims=256, pc_range=point_cloud_range, batch_first=batch_first
    )
    torch_dict = torch.load(weights_path)

    state_dict = {
        k: v
        for k, v in torch_dict.items()
        if (k.startswith("pts_bbox_head.transformer.encoder.layers.0.attentions.1."))
    }
    new_state_dict = dict(zip(torch_model.state_dict().keys(), state_dict.values()))
    torch_model.load_state_dict(new_state_dict)
    torch_model.eval()

    query = torch.randn(1, 10000, 256)
    key = torch.randn(6, 240, 1, 256)
    value = torch.randn(6, 240, 1, 256)
    reference_points = torch.randn(1, 4, 10000, 3)
    spatial_shapes = torch.tensor([[12, 20]])
    reference_points_cam = torch.randn(6, 1, 10000, 4, 2)
    bev_mask = torch.randn(6, 1, 10000, 4)
    level_start_index = torch.tensor([0])

    torch_output = torch_model(
        query,
        key,
        value,
        reference_points=reference_points,
        spatial_shapes=spatial_shapes,
        reference_points_cam=reference_points_cam,
        bev_mask=bev_mask,
        level_start_index=level_start_index,
    )

    tt_model = tt_spatial_cross_attention.TtSpatialCrossAttention(
        embed_dims=256, pc_range=point_cloud_range, batch_first=batch_first
    )

    parameter = create_vadv2_model_parameters_sca(
        torch_model,
        [query, key, value, reference_points, spatial_shapes, reference_points_cam, bev_mask, level_start_index],
        device,
    )
    query = ttnn.from_torch(query, device=device, dtype=ttnn.bfloat16)
    key = ttnn.from_torch(key, device=device, dtype=ttnn.bfloat16)
    value = ttnn.from_torch(value, device=device, dtype=ttnn.bfloat16)
    reference_points = ttnn.from_torch(reference_points, device=device, dtype=ttnn.bfloat16)
    reference_points_cam = ttnn.from_torch(reference_points_cam, device=device, dtype=ttnn.bfloat16)
    spatial_shapes = ttnn.from_torch(spatial_shapes, device=device, dtype=ttnn.bfloat16)
    bev_mask = ttnn.from_torch(bev_mask, device=device, dtype=ttnn.bfloat16)
    level_start_index = ttnn.from_torch(level_start_index, device=device, dtype=ttnn.bfloat16)

    tt_output = tt_model(
        query,
        key,
        value,
        reference_points=reference_points,
        spatial_shapes=spatial_shapes,
        reference_points_cam=reference_points_cam,
        bev_mask=bev_mask,
        level_start_index=level_start_index,
    )
