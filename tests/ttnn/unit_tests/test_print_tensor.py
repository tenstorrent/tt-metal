# SPDX-FileCopyrightText: Â© 2023 Tenstorrent Inc.

# SPDX-License-Identifier: Apache-2.0

import pytest

import torch

import ttnn
from tests.ttnn.utils_for_testing import tt_dtype_to_torch_dtype


GOLDEN_TENSOR_STRINGS = {
    (
        ttnn.uint16,
        ttnn.ROW_MAJOR_LAYOUT,
    ): "ttnn.Tensor([[[[  684,   559,  ...,   777,   916],\n               [  115,   976,  ...,   459,   882],\n               ...,\n               [  649,   773,  ...,   778,   555],\n               [  955,   414,  ...,   389,   378]],\n\n              [[  856,   273,  ...,   632,     2],\n               [  785,   143,  ...,   358,   404],\n               ...,\n               [  738,   150,  ...,   423,   609],\n               [  105,   687,  ...,   580,   862]],\n\n              ...,\n\n              [[  409,   607,  ...,   290,   816],\n               [  375,   306,  ...,   954,   218],\n               ...,\n               [  204,   718,  ...,   130,   890],\n               [  653,   250,  ...,   282,   825]],\n\n              [[  707,   273,  ...,   437,   848],\n               [  591,    14,  ...,   882,   546],\n               ...,\n               [  670,   571,  ...,   178,    24],\n               [    0,  1017,  ...,   664,   815]]],\n\n             [[[   27,     5,  ...,   401,   490],\n               [  136,   533,  ...,   688,   427],\n               ...,\n               [  827,  1018,  ...,   595,   431],\n               [  649,   238,  ...,   872,   741]],\n\n              [[  143,   142,  ...,   440,   812],\n               [  872,    76,  ...,   305,   892],\n               ...,\n               [  193,    83,  ...,   940,   404],\n               [  987,    69,  ...,   368,   413]],\n\n              ...,\n\n              [[  839,   704,  ...,   218,   229],\n               [  363,   605,  ...,   857,   928],\n               ...,\n               [  708,   781,  ...,   231,   277],\n               [   72,   148,  ...,   781,  1009]],\n\n              [[  369,   372,  ...,   786,   868],\n               [  874,   957,  ...,   158,   258],\n               ...,\n               [  660,   839,  ...,   592,   448],\n               [  276,   587,  ...,   880,   695]]]], shape=Shape([2, 16, 64, 32]), dtype=DataType::UINT16, layout=Layout::ROW_MAJOR)",
    (
        ttnn.uint32,
        ttnn.ROW_MAJOR_LAYOUT,
    ): "ttnn.Tensor([[[[  684,   559,  ...,   777,   916],\n               [  115,   976,  ...,   459,   882],\n               ...,\n               [  649,   773,  ...,   778,   555],\n               [  955,   414,  ...,   389,   378]],\n\n              [[  856,   273,  ...,   632,     2],\n               [  785,   143,  ...,   358,   404],\n               ...,\n               [  738,   150,  ...,   423,   609],\n               [  105,   687,  ...,   580,   862]],\n\n              ...,\n\n              [[  409,   607,  ...,   290,   816],\n               [  375,   306,  ...,   954,   218],\n               ...,\n               [  204,   718,  ...,   130,   890],\n               [  653,   250,  ...,   282,   825]],\n\n              [[  707,   273,  ...,   437,   848],\n               [  591,    14,  ...,   882,   546],\n               ...,\n               [  670,   571,  ...,   178,    24],\n               [    0,  1017,  ...,   664,   815]]],\n\n             [[[   27,     5,  ...,   401,   490],\n               [  136,   533,  ...,   688,   427],\n               ...,\n               [  827,  1018,  ...,   595,   431],\n               [  649,   238,  ...,   872,   741]],\n\n              [[  143,   142,  ...,   440,   812],\n               [  872,    76,  ...,   305,   892],\n               ...,\n               [  193,    83,  ...,   940,   404],\n               [  987,    69,  ...,   368,   413]],\n\n              ...,\n\n              [[  839,   704,  ...,   218,   229],\n               [  363,   605,  ...,   857,   928],\n               ...,\n               [  708,   781,  ...,   231,   277],\n               [   72,   148,  ...,   781,  1009]],\n\n              [[  369,   372,  ...,   786,   868],\n               [  874,   957,  ...,   158,   258],\n               ...,\n               [  660,   839,  ...,   592,   448],\n               [  276,   587,  ...,   880,   695]]]], shape=Shape([2, 16, 64, 32]), dtype=DataType::UINT32, layout=Layout::ROW_MAJOR)",
    (
        ttnn.float32,
        ttnn.ROW_MAJOR_LAYOUT,
    ): "ttnn.Tensor([[[[ 4.9626e-01,  7.6822e-01,  ...,  3.0510e-01,  9.3200e-01],\n               [ 1.7591e-01,  2.6983e-01,  ...,  2.0382e-01,  6.5105e-01],\n               ...,\n               [ 7.6926e-01,  4.2571e-01,  ...,  8.4923e-01,  5.6027e-01],\n               [ 4.4989e-01,  8.1796e-01,  ...,  8.2632e-01,  2.9092e-01]],\n\n              [[ 2.3870e-01,  3.5561e-01,  ...,  6.0709e-01,  2.6819e-01],\n               [ 3.0522e-01,  1.6529e-01,  ...,  5.8980e-01,  3.6324e-01],\n               ...,\n               [ 2.3448e-01,  4.4381e-02,  ...,  7.9019e-01,  7.9197e-01],\n               [ 4.0821e-01,  7.7287e-01,  ...,  6.1930e-01,  6.3589e-02]],\n\n              ...,\n\n              [[ 8.3083e-01,  2.5181e-01,  ...,  5.7106e-01,  5.8434e-01],\n               [ 3.6629e-01,  8.2161e-01,  ...,  5.9307e-01,  3.0592e-02],\n               ...,\n               [ 1.9764e-01,  2.9350e-01,  ...,  5.7648e-01,  8.4179e-01],\n               [ 6.3157e-01,  6.1360e-01,  ...,  6.1183e-01,  7.3247e-01]],\n\n              [[ 1.4732e-01,  7.1010e-01,  ...,  2.3446e-01,  6.6704e-01],\n               [ 8.0021e-01,  1.8268e-01,  ...,  8.0993e-01,  1.0013e-01],\n               ...,\n               [ 3.4751e-01,  7.9996e-01,  ...,  5.2534e-01,  6.8817e-01],\n               [ 5.8313e-01,  4.8791e-01,  ...,  2.5724e-01,  2.4742e-01]]],\n\n             [[[ 6.6742e-01,  2.4011e-01,  ...,  7.6113e-01,  6.9809e-01],\n               [ 6.4527e-01,  3.7637e-01,  ...,  8.8212e-01,  5.9121e-01],\n               ...,\n               [ 4.6611e-01,  9.4733e-01,  ...,  3.1224e-02,  8.6672e-01],\n               [ 1.9755e-01,  8.4151e-01,  ...,  1.7895e-01,  6.5135e-01]],\n\n              [[ 8.4791e-01,  2.0442e-01,  ...,  1.1282e-01,  2.5896e-01],\n               [ 7.9491e-01,  2.9383e-01,  ...,  4.4655e-01,  8.9416e-01],\n               ...,\n               [ 1.5174e-01,  3.2483e-01,  ...,  5.7135e-01,  1.2307e-01],\n               [ 1.2457e-01,  1.9291e-02,  ...,  7.9574e-01,  1.2551e-01]],\n\n              ...,\n\n              [[ 3.0748e-01,  6.9975e-01,  ...,  7.2877e-01,  3.0830e-01],\n               [ 1.6573e-01,  4.5456e-01,  ...,  9.4799e-01,  3.6468e-01],\n               ...,\n               [ 9.4468e-01,  9.3938e-01,  ...,  9.1499e-01,  9.0715e-02],\n               [ 5.7001e-01,  4.8939e-01,  ...,  7.1654e-01,  7.8021e-01]],\n\n              [[ 4.6043e-02,  3.5653e-01,  ...,  9.0001e-01,  4.5373e-01],\n               [ 9.0872e-02,  6.4209e-01,  ...,  9.7529e-01,  1.6585e-01],\n               ...,\n               [ 2.9423e-01,  2.8798e-02,  ...,  9.5983e-02,  2.4148e-01],\n               [ 2.9158e-01,  8.2738e-02,  ...,  4.3615e-01,  7.1519e-01]]]], shape=Shape([2, 16, 64, 32]), dtype=DataType::FLOAT32, layout=Layout::ROW_MAJOR)",
    (
        ttnn.bfloat16,
        ttnn.ROW_MAJOR_LAYOUT,
    ): "ttnn.Tensor([[[[ 0.6719,  0.1836,  ...,  0.0352,  0.5781],\n               [ 0.4492,  0.8125,  ...,  0.7930,  0.4453],\n               ...,\n               [ 0.5352,  0.0195,  ...,  0.0391,  0.1680],\n               [ 0.7305,  0.6172,  ...,  0.5195,  0.4766]],\n\n              [[ 0.3438,  0.0664,  ...,  0.4688,  0.0078],\n               [ 0.0664,  0.5586,  ...,  0.3984,  0.5781],\n               ...,\n               [ 0.8828,  0.5859,  ...,  0.6523,  0.3789],\n               [ 0.4102,  0.6836,  ...,  0.2656,  0.3672]],\n\n              ...,\n\n              [[ 0.5977,  0.3711,  ...,  0.1328,  0.1875],\n               [ 0.4648,  0.1953,  ...,  0.7266,  0.8516],\n               ...,\n               [ 0.7969,  0.8047,  ...,  0.5078,  0.4766],\n               [ 0.5508,  0.9766,  ...,  0.1016,  0.2227]],\n\n              [[ 0.7617,  0.0664,  ...,  0.7070,  0.3125],\n               [ 0.3086,  0.0547,  ...,  0.4453,  0.1328],\n               ...,\n               [ 0.6172,  0.2305,  ...,  0.6953,  0.0938],\n               [ 0.0000,  0.9727,  ...,  0.5938,  0.1836]]],\n\n             [[[ 0.1055,  0.0195,  ...,  0.5664,  0.9141],\n               [ 0.5312,  0.0820,  ...,  0.6875,  0.6680],\n               ...,\n               [ 0.2305,  0.9766,  ...,  0.3242,  0.6836],\n               [ 0.5352,  0.9297,  ...,  0.4062,  0.8945]],\n\n              [[ 0.5586,  0.5547,  ...,  0.7188,  0.1719],\n               [ 0.4062,  0.2969,  ...,  0.1914,  0.4844],\n               ...,\n               [ 0.7539,  0.3242,  ...,  0.6719,  0.5781],\n               [ 0.8555,  0.2695,  ...,  0.4375,  0.6133]],\n\n              ...,\n\n              [[ 0.2773,  0.7500,  ...,  0.8516,  0.8945],\n               [ 0.4180,  0.3633,  ...,  0.3477,  0.6250],\n               ...,\n               [ 0.7656,  0.0508,  ...,  0.9023,  0.0820],\n               [ 0.2812,  0.5781,  ...,  0.0508,  0.9414]],\n\n              [[ 0.4414,  0.4531,  ...,  0.0703,  0.3906],\n               [ 0.4141,  0.7383,  ...,  0.6172,  0.0078],\n               ...,\n               [ 0.5781,  0.2773,  ...,  0.3125,  0.7500],\n               [ 0.0781,  0.2930,  ...,  0.4375,  0.7148]]]], shape=Shape([2, 16, 64, 32]), dtype=DataType::BFLOAT16, layout=Layout::ROW_MAJOR)",
    (
        ttnn.uint16,
        ttnn.TILE_LAYOUT,
    ): "ttnn.Tensor([[[[  684,   559,  ...,   777,   916],\n               [  115,   976,  ...,   459,   882],\n               ...,\n               [  649,   773,  ...,   778,   555],\n               [  955,   414,  ...,   389,   378]],\n\n              [[  856,   273,  ...,   632,     2],\n               [  785,   143,  ...,   358,   404],\n               ...,\n               [  738,   150,  ...,   423,   609],\n               [  105,   687,  ...,   580,   862]],\n\n              ...,\n\n              [[  409,   607,  ...,   290,   816],\n               [  375,   306,  ...,   954,   218],\n               ...,\n               [  204,   718,  ...,   130,   890],\n               [  653,   250,  ...,   282,   825]],\n\n              [[  707,   273,  ...,   437,   848],\n               [  591,    14,  ...,   882,   546],\n               ...,\n               [  670,   571,  ...,   178,    24],\n               [    0,  1017,  ...,   664,   815]]],\n\n             [[[   27,     5,  ...,   401,   490],\n               [  136,   533,  ...,   688,   427],\n               ...,\n               [  827,  1018,  ...,   595,   431],\n               [  649,   238,  ...,   872,   741]],\n\n              [[  143,   142,  ...,   440,   812],\n               [  872,    76,  ...,   305,   892],\n               ...,\n               [  193,    83,  ...,   940,   404],\n               [  987,    69,  ...,   368,   413]],\n\n              ...,\n\n              [[  839,   704,  ...,   218,   229],\n               [  363,   605,  ...,   857,   928],\n               ...,\n               [  708,   781,  ...,   231,   277],\n               [   72,   148,  ...,   781,  1009]],\n\n              [[  369,   372,  ...,   786,   868],\n               [  874,   957,  ...,   158,   258],\n               ...,\n               [  660,   839,  ...,   592,   448],\n               [  276,   587,  ...,   880,   695]]]], shape=Shape([2, 16, 64, 32]), dtype=DataType::UINT16, layout=Layout::TILE)",
    (
        ttnn.uint32,
        ttnn.TILE_LAYOUT,
    ): "ttnn.Tensor([[[[  684,   559,  ...,   777,   916],\n               [  115,   976,  ...,   459,   882],\n               ...,\n               [  649,   773,  ...,   778,   555],\n               [  955,   414,  ...,   389,   378]],\n\n              [[  856,   273,  ...,   632,     2],\n               [  785,   143,  ...,   358,   404],\n               ...,\n               [  738,   150,  ...,   423,   609],\n               [  105,   687,  ...,   580,   862]],\n\n              ...,\n\n              [[  409,   607,  ...,   290,   816],\n               [  375,   306,  ...,   954,   218],\n               ...,\n               [  204,   718,  ...,   130,   890],\n               [  653,   250,  ...,   282,   825]],\n\n              [[  707,   273,  ...,   437,   848],\n               [  591,    14,  ...,   882,   546],\n               ...,\n               [  670,   571,  ...,   178,    24],\n               [    0,  1017,  ...,   664,   815]]],\n\n             [[[   27,     5,  ...,   401,   490],\n               [  136,   533,  ...,   688,   427],\n               ...,\n               [  827,  1018,  ...,   595,   431],\n               [  649,   238,  ...,   872,   741]],\n\n              [[  143,   142,  ...,   440,   812],\n               [  872,    76,  ...,   305,   892],\n               ...,\n               [  193,    83,  ...,   940,   404],\n               [  987,    69,  ...,   368,   413]],\n\n              ...,\n\n              [[  839,   704,  ...,   218,   229],\n               [  363,   605,  ...,   857,   928],\n               ...,\n               [  708,   781,  ...,   231,   277],\n               [   72,   148,  ...,   781,  1009]],\n\n              [[  369,   372,  ...,   786,   868],\n               [  874,   957,  ...,   158,   258],\n               ...,\n               [  660,   839,  ...,   592,   448],\n               [  276,   587,  ...,   880,   695]]]], shape=Shape([2, 16, 64, 32]), dtype=DataType::UINT32, layout=Layout::TILE)",
    (
        ttnn.float32,
        ttnn.TILE_LAYOUT,
    ): "ttnn.Tensor([[[[ 4.9626e-01,  7.6822e-01,  ...,  3.0510e-01,  9.3200e-01],\n               [ 1.7591e-01,  2.6983e-01,  ...,  2.0382e-01,  6.5105e-01],\n               ...,\n               [ 7.6926e-01,  4.2571e-01,  ...,  8.4923e-01,  5.6027e-01],\n               [ 4.4989e-01,  8.1796e-01,  ...,  8.2632e-01,  2.9092e-01]],\n\n              [[ 2.3870e-01,  3.5561e-01,  ...,  6.0709e-01,  2.6819e-01],\n               [ 3.0522e-01,  1.6529e-01,  ...,  5.8980e-01,  3.6324e-01],\n               ...,\n               [ 2.3448e-01,  4.4381e-02,  ...,  7.9019e-01,  7.9197e-01],\n               [ 4.0821e-01,  7.7287e-01,  ...,  6.1930e-01,  6.3589e-02]],\n\n              ...,\n\n              [[ 8.3083e-01,  2.5181e-01,  ...,  5.7106e-01,  5.8434e-01],\n               [ 3.6629e-01,  8.2161e-01,  ...,  5.9307e-01,  3.0592e-02],\n               ...,\n               [ 1.9764e-01,  2.9350e-01,  ...,  5.7648e-01,  8.4179e-01],\n               [ 6.3157e-01,  6.1360e-01,  ...,  6.1183e-01,  7.3247e-01]],\n\n              [[ 1.4732e-01,  7.1010e-01,  ...,  2.3446e-01,  6.6704e-01],\n               [ 8.0021e-01,  1.8268e-01,  ...,  8.0993e-01,  1.0013e-01],\n               ...,\n               [ 3.4751e-01,  7.9996e-01,  ...,  5.2534e-01,  6.8817e-01],\n               [ 5.8313e-01,  4.8791e-01,  ...,  2.5724e-01,  2.4742e-01]]],\n\n             [[[ 6.6742e-01,  2.4011e-01,  ...,  7.6113e-01,  6.9809e-01],\n               [ 6.4527e-01,  3.7637e-01,  ...,  8.8212e-01,  5.9121e-01],\n               ...,\n               [ 4.6611e-01,  9.4733e-01,  ...,  3.1224e-02,  8.6672e-01],\n               [ 1.9755e-01,  8.4151e-01,  ...,  1.7895e-01,  6.5135e-01]],\n\n              [[ 8.4791e-01,  2.0442e-01,  ...,  1.1282e-01,  2.5896e-01],\n               [ 7.9491e-01,  2.9383e-01,  ...,  4.4655e-01,  8.9416e-01],\n               ...,\n               [ 1.5174e-01,  3.2483e-01,  ...,  5.7135e-01,  1.2307e-01],\n               [ 1.2457e-01,  1.9291e-02,  ...,  7.9574e-01,  1.2551e-01]],\n\n              ...,\n\n              [[ 3.0748e-01,  6.9975e-01,  ...,  7.2877e-01,  3.0830e-01],\n               [ 1.6573e-01,  4.5456e-01,  ...,  9.4799e-01,  3.6468e-01],\n               ...,\n               [ 9.4468e-01,  9.3938e-01,  ...,  9.1499e-01,  9.0715e-02],\n               [ 5.7001e-01,  4.8939e-01,  ...,  7.1654e-01,  7.8021e-01]],\n\n              [[ 4.6043e-02,  3.5653e-01,  ...,  9.0001e-01,  4.5373e-01],\n               [ 9.0872e-02,  6.4209e-01,  ...,  9.7529e-01,  1.6585e-01],\n               ...,\n               [ 2.9423e-01,  2.8798e-02,  ...,  9.5983e-02,  2.4148e-01],\n               [ 2.9158e-01,  8.2738e-02,  ...,  4.3615e-01,  7.1519e-01]]]], shape=Shape([2, 16, 64, 32]), dtype=DataType::FLOAT32, layout=Layout::TILE)",
    (
        ttnn.bfloat16,
        ttnn.TILE_LAYOUT,
    ): "ttnn.Tensor([[[[ 0.6719,  0.1836,  ...,  0.0352,  0.5781],\n               [ 0.4492,  0.8125,  ...,  0.7930,  0.4453],\n               ...,\n               [ 0.5352,  0.0195,  ...,  0.0391,  0.1680],\n               [ 0.7305,  0.6172,  ...,  0.5195,  0.4766]],\n\n              [[ 0.3438,  0.0664,  ...,  0.4688,  0.0078],\n               [ 0.0664,  0.5586,  ...,  0.3984,  0.5781],\n               ...,\n               [ 0.8828,  0.5859,  ...,  0.6523,  0.3789],\n               [ 0.4102,  0.6836,  ...,  0.2656,  0.3672]],\n\n              ...,\n\n              [[ 0.5977,  0.3711,  ...,  0.1328,  0.1875],\n               [ 0.4648,  0.1953,  ...,  0.7266,  0.8516],\n               ...,\n               [ 0.7969,  0.8047,  ...,  0.5078,  0.4766],\n               [ 0.5508,  0.9766,  ...,  0.1016,  0.2227]],\n\n              [[ 0.7617,  0.0664,  ...,  0.7070,  0.3125],\n               [ 0.3086,  0.0547,  ...,  0.4453,  0.1328],\n               ...,\n               [ 0.6172,  0.2305,  ...,  0.6953,  0.0938],\n               [ 0.0000,  0.9727,  ...,  0.5938,  0.1836]]],\n\n             [[[ 0.1055,  0.0195,  ...,  0.5664,  0.9141],\n               [ 0.5312,  0.0820,  ...,  0.6875,  0.6680],\n               ...,\n               [ 0.2305,  0.9766,  ...,  0.3242,  0.6836],\n               [ 0.5352,  0.9297,  ...,  0.4062,  0.8945]],\n\n              [[ 0.5586,  0.5547,  ...,  0.7188,  0.1719],\n               [ 0.4062,  0.2969,  ...,  0.1914,  0.4844],\n               ...,\n               [ 0.7539,  0.3242,  ...,  0.6719,  0.5781],\n               [ 0.8555,  0.2695,  ...,  0.4375,  0.6133]],\n\n              ...,\n\n              [[ 0.2773,  0.7500,  ...,  0.8516,  0.8945],\n               [ 0.4180,  0.3633,  ...,  0.3477,  0.6250],\n               ...,\n               [ 0.7656,  0.0508,  ...,  0.9023,  0.0820],\n               [ 0.2812,  0.5781,  ...,  0.0508,  0.9414]],\n\n              [[ 0.4414,  0.4531,  ...,  0.0703,  0.3906],\n               [ 0.4141,  0.7383,  ...,  0.6172,  0.0078],\n               ...,\n               [ 0.5781,  0.2773,  ...,  0.3125,  0.7500],\n               [ 0.0781,  0.2930,  ...,  0.4375,  0.7148]]]], shape=Shape([2, 16, 64, 32]), dtype=DataType::BFLOAT16, layout=Layout::TILE)",
    (
        ttnn.bfloat8_b,
        ttnn.TILE_LAYOUT,
    ): "ttnn.Tensor([[[[ 0.5000,  0.7656,  ...,  0.3047,  0.9297],\n               [ 0.1797,  0.2734,  ...,  0.2031,  0.6484],\n               ...,\n               [ 0.7656,  0.4219,  ...,  0.8516,  0.5625],\n               [ 0.4531,  0.8203,  ...,  0.8281,  0.2891]],\n\n              [[ 0.2422,  0.3594,  ...,  0.6094,  0.2656],\n               [ 0.3047,  0.1641,  ...,  0.5859,  0.3594],\n               ...,\n               [ 0.2344,  0.0469,  ...,  0.7891,  0.7891],\n               [ 0.4062,  0.7734,  ...,  0.6172,  0.0625]],\n\n              ...,\n\n              [[ 0.8281,  0.2500,  ...,  0.5703,  0.5859],\n               [ 0.3672,  0.8203,  ...,  0.5938,  0.0312],\n               ...,\n               [ 0.1953,  0.2969,  ...,  0.5781,  0.8438],\n               [ 0.6328,  0.6172,  ...,  0.6094,  0.7344]],\n\n              [[ 0.1484,  0.7109,  ...,  0.2344,  0.6641],\n               [ 0.7969,  0.1797,  ...,  0.8125,  0.1016],\n               ...,\n               [ 0.3438,  0.7969,  ...,  0.5234,  0.6875],\n               [ 0.5859,  0.4844,  ...,  0.2578,  0.2500]]],\n\n             [[[ 0.6641,  0.2422,  ...,  0.7578,  0.6953],\n               [ 0.6484,  0.3750,  ...,  0.8828,  0.5938],\n               ...,\n               [ 0.4688,  0.9453,  ...,  0.0312,  0.8672],\n               [ 0.1953,  0.8438,  ...,  0.1797,  0.6484]],\n\n              [[ 0.8516,  0.2031,  ...,  0.1094,  0.2578],\n               [ 0.7969,  0.2969,  ...,  0.4453,  0.8906],\n               ...,\n               [ 0.1484,  0.3281,  ...,  0.5703,  0.1250],\n               [ 0.1250,  0.0156,  ...,  0.7969,  0.1250]],\n\n              ...,\n\n              [[ 0.3047,  0.7031,  ...,  0.7266,  0.3047],\n               [ 0.1641,  0.4531,  ...,  0.9453,  0.3672],\n               ...,\n               [ 0.9453,  0.9375,  ...,  0.9141,  0.0938],\n               [ 0.5703,  0.4922,  ...,  0.7188,  0.7812]],\n\n              [[ 0.0469,  0.3594,  ...,  0.8984,  0.4531],\n               [ 0.0938,  0.6406,  ...,  0.9766,  0.1641],\n               ...,\n               [ 0.2969,  0.0312,  ...,  0.0938,  0.2422],\n               [ 0.2891,  0.0859,  ...,  0.4375,  0.7188]]]], shape=Shape([2, 16, 64, 32]), dtype=DataType::BFLOAT8_B, layout=Layout::TILE)",
}


@pytest.mark.parametrize(
    "dtype",
    [
        ttnn.uint16,
        ttnn.uint32,
        ttnn.float32,
        ttnn.bfloat16,
        ttnn.bfloat8_b,
    ],
)
@pytest.mark.parametrize("layout", [ttnn.ROW_MAJOR_LAYOUT, ttnn.TILE_LAYOUT])
@pytest.mark.parametrize("profile", ["empty", "short"])
@pytest.mark.parametrize("deallocate", [False, True])
def test_print(device, dtype, layout, profile, deallocate):
    if layout == ttnn.ROW_MAJOR_LAYOUT and dtype == ttnn.bfloat8_b:
        pytest.skip("This combination is not valid")

    torch.manual_seed(0)

    ttnn.set_printoptions(profile=profile)

    torch_dtype = tt_dtype_to_torch_dtype[dtype]
    shape = (2, 16, 64, 32)

    if torch_dtype in {torch.int16, torch.int32}:
        torch_tensor = torch.randint(0, 1024, shape, dtype=torch_dtype)
    else:
        torch_tensor = torch.rand(shape, dtype=torch_dtype)

    tensor = ttnn.from_torch(torch_tensor, layout=layout, dtype=dtype, device=device)
    if deallocate:
        ttnn.deallocate(tensor)

    tensor_as_string = str(tensor)

    if deallocate:
        assert (
            tensor_as_string
            == f"ttnn.Tensor(<buffer is not allocated>, shape=Shape({list(shape)}), dtype=DataType::{dtype.name}, layout=Layout::{layout.name})"
        )
    elif profile == "empty":
        assert (
            tensor_as_string
            == f"ttnn.Tensor(..., shape=Shape({list(shape)}), dtype=DataType::{dtype.name}, layout=Layout::{layout.name})"
        )
    else:
        # To generate golden output, use the following line
        # print("\\n".join(str(tensor).split("\n")))

        assert tensor_as_string == GOLDEN_TENSOR_STRINGS[(dtype, layout)]


def test_print_0d(device):
    torch_tensor = torch.ones((), dtype=torch.bfloat16)
    tensor = ttnn.from_torch(torch_tensor, layout=ttnn.TILE_LAYOUT, dtype=ttnn.bfloat16, device=device)
    assert str(tensor) == "ttnn.Tensor( 1.0000, shape=Shape([]), dtype=DataType::BFLOAT16, layout=Layout::TILE)"


def test_print_short_profile_limit(device):
    ttnn.set_printoptions(profile="short")  # This is the default profile
    torch_tensor = torch.arange(16, dtype=torch.bfloat16).reshape(4, 4)
    tensor = ttnn.from_torch(torch_tensor, layout=ttnn.TILE_LAYOUT, dtype=ttnn.bfloat16, device=device)

    tensor_as_string = str(tensor)

    # Check that ellipsis is NOT used for dimensions of size 4 with short profile
    assert "..." not in tensor_as_string

    # Check the full string representation
    expected_string = (
        "ttnn.Tensor([[ 0.0000,  1.0000,  2.0000,  3.0000],\n"
        "             [ 4.0000,  5.0000,  6.0000,  7.0000],\n"
        "             [ 8.0000,  9.0000, 10.0000, 11.0000],\n"
        "             [12.0000, 13.0000, 14.0000, 15.0000]], shape=Shape([4, 4]), dtype=DataType::BFLOAT16, layout=Layout::TILE)"
    )
    assert tensor_as_string == expected_string


ADVANCED_GOLDEN_TENSOR_STRINGS = {
    (
        "short",
        True,
        2,
    ): """ttnn.Tensor([[ 1.46e+00,  2.91e-01,  ...,  1.57e+00, -6.72e-01],
             [-1.11e-01,  8.95e-01,  ..., -8.75e-01,  3.24e-01],
             [ 1.37e+00,  5.93e-02,  ...,  5.62e-01,  2.00e-01],
             [-6.99e-01,  2.83e-01,  ..., -4.43e-01, -4.49e-01]], shape=Shape([4, 5]), dtype=DataType::BFLOAT16, layout=Layout::TILE)""",
    (
        "short",
        True,
        4,
    ): """ttnn.Tensor([[ 1.4609e+00,  2.9102e-01,  ...,  1.5703e+00, -6.7188e-01],
             [-1.1084e-01,  8.9453e-01,  ..., -8.7500e-01,  3.2422e-01],
             [ 1.3672e+00,  5.9326e-02,  ...,  5.6250e-01,  2.0020e-01],
             [-6.9922e-01,  2.8320e-01,  ..., -4.4336e-01, -4.4922e-01]], shape=Shape([4, 5]), dtype=DataType::BFLOAT16, layout=Layout::TILE)""",
    (
        "short",
        False,
        2,
    ): """ttnn.Tensor([[ 1.46,  0.29,  ...,  1.57, -0.67],
             [-0.11,  0.89,  ..., -0.88,  0.32],
             [ 1.37,  0.06,  ...,  0.56,  0.20],
             [-0.70,  0.28,  ..., -0.44, -0.45]], shape=Shape([4, 5]), dtype=DataType::BFLOAT16, layout=Layout::TILE)""",
    (
        "short",
        False,
        4,
    ): """ttnn.Tensor([[ 1.4609,  0.2910,  ...,  1.5703, -0.6719],
             [-0.1108,  0.8945,  ..., -0.8750,  0.3242],
             [ 1.3672,  0.0593,  ...,  0.5625,  0.2002],
             [-0.6992,  0.2832,  ..., -0.4434, -0.4492]], shape=Shape([4, 5]), dtype=DataType::BFLOAT16, layout=Layout::TILE)""",
    (
        "full",
        True,
        2,
    ): """ttnn.Tensor([[ 1.46e+00,  2.91e-01,  9.61e-01,  1.57e+00, -6.72e-01],
             [-1.11e-01,  8.95e-01, -1.34e+00, -8.75e-01,  3.24e-01],
             [ 1.37e+00,  5.93e-02,  2.03e+00,  5.62e-01,  2.00e-01],
             [-6.99e-01,  2.83e-01, -8.09e-01, -4.43e-01, -4.49e-01]], shape=Shape([4, 5]), dtype=DataType::BFLOAT16, layout=Layout::TILE)""",
    (
        "full",
        True,
        4,
    ): """ttnn.Tensor([[ 1.4609e+00,  2.9102e-01,  9.6094e-01,  1.5703e+00, -6.7188e-01],
             [-1.1084e-01,  8.9453e-01, -1.3359e+00, -8.7500e-01,  3.2422e-01],
             [ 1.3672e+00,  5.9326e-02,  2.0312e+00,  5.6250e-01,  2.0020e-01],
             [-6.9922e-01,  2.8320e-01, -8.0859e-01, -4.4336e-01, -4.4922e-01]], shape=Shape([4, 5]), dtype=DataType::BFLOAT16, layout=Layout::TILE)""",
    (
        "full",
        False,
        2,
    ): """ttnn.Tensor([[ 1.46,  0.29,  0.96,  1.57, -0.67],
             [-0.11,  0.89, -1.34, -0.88,  0.32],
             [ 1.37,  0.06,  2.03,  0.56,  0.20],
             [-0.70,  0.28, -0.81, -0.44, -0.45]], shape=Shape([4, 5]), dtype=DataType::BFLOAT16, layout=Layout::TILE)""",
    (
        "full",
        False,
        4,
    ): """ttnn.Tensor([[ 1.4609,  0.2910,  0.9609,  1.5703, -0.6719],
             [-0.1108,  0.8945, -1.3359, -0.8750,  0.3242],
             [ 1.3672,  0.0593,  2.0312,  0.5625,  0.2002],
             [-0.6992,  0.2832, -0.8086, -0.4434, -0.4492]], shape=Shape([4, 5]), dtype=DataType::BFLOAT16, layout=Layout::TILE)""",
}


@pytest.mark.parametrize("profile", ["short", "full"])
@pytest.mark.parametrize("sci_mode", [True, False])
@pytest.mark.parametrize("precision", [2, 4])
def test_advanced_print_options(device, profile, sci_mode, precision):
    ttnn.set_printoptions(profile=profile, sci_mode=sci_mode, precision=precision)

    torch.manual_seed(0)
    torch_tensor = torch.randn((4, 5), dtype=torch.bfloat16)
    tensor = ttnn.from_torch(torch_tensor, layout=ttnn.TILE_LAYOUT, dtype=ttnn.bfloat16, device=device)

    tensor_as_string = str(tensor)

    assert tensor_as_string == ADVANCED_GOLDEN_TENSOR_STRINGS[(profile, sci_mode, precision)]
