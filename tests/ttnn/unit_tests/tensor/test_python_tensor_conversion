# SPDX-FileCopyrightText: Â© 2025 Tenstorrent Inc.


# SPDX-License-Identifier: Apache-2.0


import pathlib
import pytest


import torch


import ttnn


@pytest.mark.parametrize("size", [64])
@pytest.mark.parametrize("mode", [ttnn.graph.RunMode.NO_DISPATCH, ttnn.graph.RunMode.NORMAL])
@pytest.mark.parametrize("dtype", [torch.int32, torch.float, torch.bfloat16, torch.uint8])
def test_convert_python_tensor(device, size, mode, dtype):
    torch.manual_seed(0)

    # weird hack necessary for pytorch typechecking...
    test = torch.tensor([1], dtype=dtype)
    if torch.is_floating_point(test):
        torch_input_tensor = torch.rand((size,), dtype=dtype)
    else:
        torch_input_tensor = torch.randint(0, 256, (size,), dtype=dtype)

    input_tensor = ttnn.from_torch(torch_input_tensor, layout=ttnn.TILE_LAYOUT, device=device)
    output_tensor = ttnn.to_torch(input_tensor, torch_rank=1)

    assert torch.equal(output_tensor, torch_input_tensor)


@pytest.mark.parametrize("size", [64])
@pytest.mark.parametrize("mode", [ttnn.graph.RunMode.NO_DISPATCH, ttnn.graph.RunMode.NORMAL])
@pytest.mark.parametrize("dtype", [ttnn.bfloat4_b, ttnn.bfloat8_b])
def test_convert_python_tensor_bfp_b(device, size, mode, dtype):
    torch.manual_seed(0)

    torch_input_tensor = torch.rand((size,), dtype=torch.float)
    input_tensor = ttnn.from_torch(torch_input_tensor, layout=ttnn.TILE_LAYOUT, device=device, dtype=(dtype))
    output_tensor = ttnn.to_torch(input_tensor, torch_rank=1)
    # assert torch.equal(output_tensor,torch_input_tensor)
