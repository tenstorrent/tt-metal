# SPDX-FileCopyrightText: Â© 2023 Tenstorrent Inc.

# SPDX-License-Identifier: Apache-2.0

import pytest
from loguru import logger

import torch
import torchvision

import ttnn
from ttnn.model_preprocessing import (
    preprocess_model_parameters,
    fold_batch_norm2d_into_conv2d,
    convert_torch_model_to_ttnn_model,
)

from tests.ttnn.utils_for_testing import assert_with_pcc
from models.utility_functions import (
    pad_and_fold_conv_filters_for_unity_stride,
    enable_memory_reports,
    skip_for_grayskull,
    is_wormhole_b0,
)

from models.demos.ttnn_resnet.tests.resnet50_test_infra import load_resnet50_model
from models.demos.ttnn_resnet.tt.ttnn_functional_resnet50_xxlarge_new_conv_api import resnet50


def preprocess_conv_parameter(parameter, *, dtype):
    parameter = ttnn.from_torch(parameter, dtype=dtype, layout=ttnn.TILE_LAYOUT)
    return parameter


def custom_preprocessor(model, name, ttnn_module_args, convert_to_ttnn):
    parameters = {}
    if isinstance(model, torchvision.models.resnet.Bottleneck):
        conv1_weight, conv1_bias = fold_batch_norm2d_into_conv2d(model.conv1, model.bn1)
        conv2_weight, conv2_bias = fold_batch_norm2d_into_conv2d(model.conv2, model.bn2)
        conv3_weight, conv3_bias = fold_batch_norm2d_into_conv2d(model.conv3, model.bn3)
        parameters["conv1"] = {}
        parameters["conv2"] = {}
        parameters["conv3"] = {}
        parameters["conv1"]["weight"] = ttnn.from_torch(conv1_weight)
        parameters["conv2"]["weight"] = ttnn.from_torch(conv2_weight)
        parameters["conv3"]["weight"] = ttnn.from_torch(conv3_weight)
        parameters["conv1"]["bias"] = ttnn.from_torch(torch.reshape(conv1_bias, (1, 1, 1, -1)))
        parameters["conv2"]["bias"] = ttnn.from_torch(torch.reshape(conv2_bias, (1, 1, 1, -1)))
        parameters["conv3"]["bias"] = ttnn.from_torch(torch.reshape(conv3_bias, (1, 1, 1, -1)))
        if model.downsample is not None:
            downsample_weight, downsample_bias = fold_batch_norm2d_into_conv2d(model.downsample[0], model.downsample[1])
            parameters["downsample"] = {}
            parameters["downsample"]["weight"] = ttnn.from_torch(downsample_weight)
            parameters["downsample"]["bias"] = ttnn.from_torch(torch.reshape(downsample_bias, (1, 1, 1, -1)))
    elif isinstance(model, torchvision.models.resnet.ResNet):
        conv1_weight, conv1_bias = fold_batch_norm2d_into_conv2d(model.conv1, model.bn1)
        conv1_weight = pad_and_fold_conv_filters_for_unity_stride(conv1_weight, 2, 2)
        parameters["conv1"] = {}
        parameters["conv1"]["weight"] = ttnn.from_torch(conv1_weight)
        parameters["conv1"]["bias"] = ttnn.from_torch(torch.reshape(conv1_bias, (1, 1, 1, -1)))
        named_parameters = tuple((name, parameter) for name, parameter in model.named_parameters() if "." not in name)
        for child_name, child in tuple(model.named_children()) + named_parameters:
            if child_name in {"conv1", "bn1"}:
                continue
            parameters[child_name] = convert_torch_model_to_ttnn_model(
                child,
                name=name,
                custom_preprocessor=custom_preprocessor,
                convert_to_ttnn=convert_to_ttnn,
                ttnn_module_args=ttnn_module_args,
            )
    return parameters


## copied from ttlib version test:
# golden pcc is ordered fidelity, weight dtype, activation dtype
golden_pcc = {
    8: {
        (
            ttnn.MathFidelity.HiFi4,
            ttnn.bfloat16,
            ttnn.bfloat16,
        ): 0.983301,  # PCC: 0.9833017469734239             TODO: NEED DEBUGGING WHY THIS IS SLIGHTLY LOWER THAN TTLIB
        # ): 0.990804,  # Max ATOL Delta: 1.607335090637207, Max RTOL Delta: 115.62200164794922, PCC: 0.9908042840544742
        (
            ttnn.MathFidelity.HiFi4,
            ttnn.bfloat8_b,
            ttnn.bfloat16,
        ): 0.986301,  # Max ATOL Delta: 1.5697126388549805, Max RTOL Delta: 21.3042049407959, PCC: 0.9863013351442654
        (
            ttnn.MathFidelity.HiFi4,
            ttnn.bfloat16,
            ttnn.bfloat8_b,
        ): 0.973763,  # Max ATOL Delta: 2.455164909362793, Max RTOL Delta: inf, PCC: 0.9737631427307492
        (
            ttnn.MathFidelity.HiFi4,
            ttnn.bfloat8_b,
            ttnn.bfloat8_b,
        ): 0.978099,  # Max ATOL Delta: 1.955164909362793, Max RTOL Delta: inf, PCC: 0.9780993165966628
        (
            ttnn.MathFidelity.HiFi2,
            ttnn.bfloat16,
            ttnn.bfloat16,
        ): 0.983400,  # Max ATOL Delta: 1.7310011386871338, Max RTOL Delta: 369.5689392089844, PCC: 0.9834004200555363
        (
            ttnn.MathFidelity.HiFi2,
            ttnn.bfloat8_b,
            ttnn.bfloat16,
        ): 0.984828,  # Max ATOL Delta: 1.6054553985595703, Max RTOL Delta: 59.124324798583984, PCC: 0.9848281996919587
        (
            ttnn.MathFidelity.HiFi2,
            ttnn.bfloat16,
            ttnn.bfloat8_b,
        ): 0.934073,  # Max ATOL Delta: 4.330164909362793, Max RTOL Delta: inf, PCC: 0.9340735819578696
        (
            ttnn.MathFidelity.HiFi2,
            ttnn.bfloat8_b,
            ttnn.bfloat8_b,
        ): 0.944435,  # Max ATOL Delta: 4.705164909362793, Max RTOL Delta: inf, PCC: 0.9444350983635019
        (
            ttnn.MathFidelity.LoFi,
            ttnn.bfloat16,
            ttnn.bfloat16,
        ): 0.938909,  # Max ATOL Delta: 3.861414909362793, Max RTOL Delta: 240.63145446777344, PCC: 0.9389092547575272
        (
            ttnn.MathFidelity.LoFi,
            ttnn.bfloat8_b,
            ttnn.bfloat16,
        ): 0.959609,  # Max ATOL Delta: 3.205164909362793, Max RTOL Delta: 141.7057342529297, PCC: 0.9596095155046113
        (
            ttnn.MathFidelity.LoFi,
            ttnn.bfloat16,
            ttnn.bfloat8_b,
        ): 0.854903,  # Max ATOL Delta: 7.830164909362793, Max RTOL Delta: inf, PCC: 0.8549035869182201
        (
            ttnn.MathFidelity.LoFi,
            ttnn.bfloat8_b,
            ttnn.bfloat8_b,
        ): 0.884609,  # Max ATOL Delta: 6.455164909362793, Max RTOL Delta: inf, PCC: 0.8846098380419433
    },
    16: {
        (
            ttnn.MathFidelity.HiFi4,
            ttnn.bfloat8_b,
            ttnn.bfloat8_b,
        ): 0.978099,  # Max ATOL Delta: 1.955164909362793, Max RTOL Delta: inf, PCC: 0.9780993165966632
        (
            ttnn.MathFidelity.HiFi2,
            ttnn.bfloat8_b,
            ttnn.bfloat8_b,
        ): 0.941,  # PCC: 0.9414369437627494               TODO: NEED DEBUGGING WHY THIS IS SLIGHTLY LOWER THAN TTLIB
        # ): 0.944435,  # Max ATOL Delta: 4.705164909362793, Max RTOL Delta: inf, PCC: 0.9444350983635021
        (
            ttnn.MathFidelity.LoFi,
            ttnn.bfloat8_b,
            ttnn.bfloat8_b,
        ): 0.884609,  # Max ATOL Delta: 6.455164909362793, Max RTOL Delta: inf, PCC: 0.8846098380419435
    },
    20: {
        (
            ttnn.MathFidelity.HiFi4,
            ttnn.bfloat8_b,
            ttnn.bfloat8_b,
        ): 0.978099,  # Max ATOL Delta: 1.955164909362793, Max RTOL Delta: inf, PCC: 0.9780993165966628
        (
            ttnn.MathFidelity.HiFi2,
            ttnn.bfloat8_b,
            ttnn.bfloat8_b,
        ): 0.941,  #   PCC: 0.9419975597174123             TODO: NEED DEBUGGING WHY THIS IS SLIGHTLY LOWER THAN TTLIB
        # ): 0.944435,  # Max ATOL Delta: 4.705164909362793, Max RTOL Delta: inf, PCC: 0.9444350983635021
        (
            ttnn.MathFidelity.LoFi,
            ttnn.bfloat8_b,
            ttnn.bfloat8_b,
        ): 0.884609,  # Max ATOL Delta: 6.455164909362793, Max RTOL Delta: inf, PCC: 0.8846098380419433
    },
}


class ResNet50TestInfra:
    def __init__(self, device, batch_size, act_dtype, weight_dtype, math_fidelity, model_location_generator=None):
        super().__init__()
        torch.manual_seed(0)
        self.pcc_passed = False
        self.pcc_message = "Did you forget to call validate()?"
        self.device = device
        self.batch_size = batch_size
        self.act_dtype = act_dtype
        self.weight_dtype = weight_dtype
        self.math_fidelity = math_fidelity

        torch_model = load_resnet50_model(model_location_generator).eval()

        model_config = {
            "MATH_FIDELITY": math_fidelity,
            "WEIGHTS_DTYPE": weight_dtype,
            "ACTIVATIONS_DTYPE": act_dtype,
        }

        input_shape = (1, 3, 1024, 1024)

        self.torch_input_tensor = torch.rand(input_shape, dtype=torch.float32)

        parameters = preprocess_model_parameters(
            initialize_model=lambda: torch_model, custom_preprocessor=custom_preprocessor, device=None
        )

        torch_model.to(torch.bfloat16)
        self.torch_input_tensor = self.torch_input_tensor.to(torch.bfloat16)

        ## golden

        print(f"Running golden model")
        self.torch_output_tensor = torch_model(self.torch_input_tensor)
        print(f"Golden model run complete")

        ## ttnn

        self.ttnn_resnet50_model = resnet50(
            device=device, parameters=parameters, batch_size=batch_size, model_config=model_config
        )
        self.ops_parallel_config = {}

    def preprocess_torch_input(self, torch_input_tensor=None):
        torch_input_tensor = self.torch_input_tensor if torch_input_tensor is None else torch_input_tensor
        self.input_tensor = self.ttnn_resnet50_model.preprocessing(torch_input_tensor)

    def run(self, torch_input_tensor=None):
        # Note: currently not including the time to flip from torch to ttnn tensors.
        # self.preprocess_torch_input(torch_input_tensor)
        self.output_tensor = self.ttnn_resnet50_model(
            self.input_tensor, self.device, self.batch_size, self.ops_parallel_config
        )
        return self.output_tensor

    def validate(self, output_tensor=None):
        output_tensor = self.output_tensor if output_tensor is None else output_tensor
        output_tensor = ttnn.to_torch(output_tensor)
        output_tensor = torch.reshape(output_tensor, (self.batch_size, 1000))

        valid_pcc = 1.0
        if self.batch_size >= 8:
            valid_pcc = golden_pcc[self.batch_size][(self.math_fidelity, self.weight_dtype, self.act_dtype)]
        else:
            if self.act_dtype == ttnn.bfloat8_b:
                if self.math_fidelity == ttnn.MathFidelity.LoFi:
                    valid_pcc = 0.87
                else:
                    valid_pcc = 0.94
            else:
                if self.math_fidelity == ttnn.MathFidelity.LoFi:
                    valid_pcc = 0.93
                else:
                    valid_pcc = 0.982

        self.pcc_passed, self.pcc_message = assert_with_pcc(self.torch_output_tensor, output_tensor, pcc=valid_pcc)

        logger.info(
            f"ResNet50 batch_size={self.batch_size}, act_dtype={self.act_dtype}, weight_dtype={self.weight_dtype}, math_fidelity={self.math_fidelity}, PCC={self.pcc_message}"
        )


def create_test_infra(device, batch_size, act_dtype, weight_dtype, math_fidelity, model_location_generator):
    return ResNet50TestInfra(
        device, batch_size, act_dtype, weight_dtype, math_fidelity, model_location_generator=model_location_generator
    )


@pytest.mark.timeout(600)
@skip_for_grayskull("Only works for Wormhole")
@pytest.mark.parametrize("device_params", [{"l1_small_size": 24576}], indirect=True)
@pytest.mark.parametrize(
    "batch_size, act_dtype, weight_dtype, math_fidelity",
    ((1, ttnn.bfloat8_b, ttnn.bfloat8_b, ttnn.MathFidelity.LoFi),),
)
def test_resnet_50(device, batch_size, act_dtype, weight_dtype, math_fidelity, model_location_generator):
    test_infra = create_test_infra(
        device, batch_size, act_dtype, weight_dtype, math_fidelity, model_location_generator=model_location_generator
    )
    enable_memory_reports()
    test_infra.preprocess_torch_input()
    # First run configures convs JIT
    test_infra.run()
    # # Optimized run
    test_infra.run()
    # # More optimized run with caching
    test_infra.run()
    test_infra.validate()
