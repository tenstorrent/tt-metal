#!/usr/bin/env python3
"""
Migrate compute_kernel_api from tt_metal/include to tt_metal/hw/inc/api/compute.

This script:
1. Uses JSON data from find_device_side_includes.py and map_headers_to_include_dirs.py
   to find ALL include styles (relative, full-path, dot, dotdot)
2. Moves all files from tt_metal/include/* to tt_metal/hw/inc/api/compute/
3. Updates all #include directives using the exact strings found in source files
4. Updates path references in docs/config files

Usage:
    # First, generate the JSON data (if not already done):
    python3 include_scripts/find_device_side_includes.py > include_scripts/device_includes.json
    python3 include_scripts/map_headers_to_include_dirs.py include_scripts/device_includes.json > include_scripts/headers_to_include_dirs.json

    # Then run the migration:
    python3 include_scripts/migrate_compute_kernel_api.py [--dry-run]
"""

import argparse
import json
import os
import re
import shutil
import sys
from pathlib import Path


def load_json_data(repo_root: Path) -> tuple[list, dict]:
    """
    Load the JSON data files generated by the analysis scripts.
    Returns (device_includes, headers_to_dirs).
    """
    device_includes_path = repo_root / "include_scripts/device_includes.json"
    headers_to_dirs_path = repo_root / "include_scripts/headers_to_include_dirs.json"

    if not device_includes_path.exists():
        print(f"ERROR: {device_includes_path} not found.", file=sys.stderr)
        print(
            "Run: python3 include_scripts/find_device_side_includes.py > include_scripts/device_includes.json",
            file=sys.stderr,
        )
        sys.exit(1)

    if not headers_to_dirs_path.exists():
        print(f"ERROR: {headers_to_dirs_path} not found.", file=sys.stderr)
        print(
            "Run: python3 include_scripts/map_headers_to_include_dirs.py include_scripts/device_includes.json > include_scripts/headers_to_include_dirs.json",
            file=sys.stderr,
        )
        sys.exit(1)

    with open(device_includes_path) as f:
        device_includes = json.load(f)

    with open(headers_to_dirs_path) as f:
        headers_to_dirs = json.load(f)

    return device_includes, headers_to_dirs


def find_headers_to_migrate(repo_root: Path) -> set[str]:
    """
    Find all header files in tt_metal/include/ that will be migrated.
    Returns set of relative paths from tt_metal/include/ (e.g., "compute_kernel_api/x.h").
    """
    src_dir = repo_root / "tt_metal/include"
    if not src_dir.exists():
        return set()

    headers = set()
    for item in src_dir.rglob("*"):
        if item.is_file():
            rel_path = item.relative_to(src_dir)
            headers.add(str(rel_path))

    return headers


def build_include_mapping(headers_to_migrate: set[str], device_includes: list, headers_to_dirs: dict) -> dict[str, str]:
    """
    Build a mapping of old include strings -> new include strings.

    Uses the JSON data to find ALL ways each header is included:
    - Via tt_metal/include (-I): "compute_kernel_api/x.h"
    - Via root (-I .): "tt_metal/include/compute_kernel_api/x.h"
    - Via dot (-I .): relative paths from source dir
    - Via dotdot (-I ..): relative paths from parent dir
    """
    mapping = {}

    # Helper to compute new include path
    def new_path_for(old_rel_path: str) -> str:
        """Convert old path relative to tt_metal/include/ to new path."""
        parts = Path(old_rel_path).parts
        if parts[0] == "compute_kernel_api":
            # Strip compute_kernel_api prefix: compute_kernel_api/x.h -> x.h
            new_rel = Path(*parts[1:]) if len(parts) > 1 else Path(parts[0])
        else:
            new_rel = Path(old_rel_path)
        return f"api/compute/{new_rel}"

    # 1. Headers resolved via tt_metal/include (-I tt_metal/include)
    #    Include string: "compute_kernel_api/x.h"
    tt_metal_include_headers = headers_to_dirs.get("headers_by_directory", {}).get("tt_metal/include", [])
    for header in tt_metal_include_headers:
        if header in headers_to_migrate or any(
            header.startswith(h.rsplit("/", 1)[0] + "/") for h in headers_to_migrate if "/" in h
        ):
            # Check if this header is one we're migrating
            if header in headers_to_migrate:
                mapping[header] = new_path_for(header)

    # 2. Headers resolved via root (-I .)
    #    Include string: "tt_metal/include/compute_kernel_api/x.h"
    root_headers = headers_to_dirs.get("headers_by_directory", {}).get("(root)", [])
    for header in root_headers:
        if header.startswith("tt_metal/include/"):
            rel_to_include = header[len("tt_metal/include/") :]
            if rel_to_include in headers_to_migrate:
                mapping[header] = new_path_for(rel_to_include)

    # 3. Scan device_includes.json for actual include strings used
    #    This catches any patterns we might have missed
    for entry in device_includes:
        for inc in entry["includes"]:
            # Skip if already mapped
            if inc in mapping:
                continue

            # Check if it's a full path to tt_metal/include/
            if inc.startswith("tt_metal/include/"):
                rel_to_include = inc[len("tt_metal/include/") :]
                if rel_to_include in headers_to_migrate:
                    mapping[inc] = new_path_for(rel_to_include)
                continue

            # Check if it matches a header we're migrating (relative path style)
            if inc in headers_to_migrate:
                mapping[inc] = new_path_for(inc)
                continue

            # Check compute_kernel_api/ prefix variants
            if inc.startswith("compute_kernel_api/"):
                full_rel = inc
                if full_rel in headers_to_migrate:
                    mapping[inc] = new_path_for(full_rel)

    # 4. Also add common patterns that might not be in the JSON
    #    (e.g., if JSON was generated before some files were added)
    for header in headers_to_migrate:
        # Relative style: compute_kernel_api/x.h
        if header not in mapping:
            mapping[header] = new_path_for(header)

        # Full path style: tt_metal/include/compute_kernel_api/x.h
        full_path = f"tt_metal/include/{header}"
        if full_path not in mapping:
            mapping[full_path] = new_path_for(header)

    return mapping


def move_files(repo_root: Path, dry_run: bool = False) -> set[str]:
    """
    Move files from tt_metal/include to tt_metal/hw/inc/api/compute.
    Returns set of headers that were moved (relative to tt_metal/include/).
    """
    src_dir = repo_root / "tt_metal/include"
    dst_dir = repo_root / "tt_metal/hw/inc/api/compute"

    moved = set()

    if not src_dir.exists():
        print(f"ERROR: Source directory not found: {src_dir}", file=sys.stderr)
        return moved

    for item in src_dir.rglob("*"):
        if item.is_file():
            rel_path = item.relative_to(src_dir)

            # Compute destination path (strip compute_kernel_api/ prefix)
            rel_parts = rel_path.parts
            if rel_parts[0] == "compute_kernel_api":
                new_rel_path = Path(*rel_parts[1:]) if len(rel_parts) > 1 else rel_path
            else:
                new_rel_path = rel_path

            new_path = dst_dir / new_rel_path

            if dry_run:
                print(f"WOULD MOVE: {item} -> {new_path}")
            else:
                new_path.parent.mkdir(parents=True, exist_ok=True)
                shutil.move(str(item), str(new_path))
                print(f"Moved: {rel_path} -> api/compute/{new_rel_path}")

            moved.add(str(rel_path))

    return moved


def update_includes_in_file(filepath: Path, include_mapping: dict, dry_run: bool = False) -> int:
    """
    Update #include directives in a file.
    Returns number of changes made.
    """
    try:
        content = filepath.read_text(encoding="utf-8", errors="replace")
    except Exception as e:
        print(f"Warning: Could not read {filepath}: {e}", file=sys.stderr)
        return 0

    original_content = content
    changes = 0

    # Sort by length (longest first) to avoid partial replacements
    sorted_mappings = sorted(include_mapping.items(), key=lambda x: -len(x[0]))

    for old_path, new_path in sorted_mappings:
        # Match both angle brackets and quotes
        pattern1 = f"#include\\s*<{re.escape(old_path)}>"
        pattern2 = f'#include\\s*"{re.escape(old_path)}"'

        replacement1 = f"#include <{new_path}>"
        replacement2 = f'#include "{new_path}"'

        new_content = re.sub(pattern1, replacement1, content)
        if new_content != content:
            changes += len(re.findall(pattern1, content))
            content = new_content

        new_content = re.sub(pattern2, replacement2, content)
        if new_content != content:
            changes += len(re.findall(pattern2, content))
            content = new_content

    if content != original_content:
        if dry_run:
            print(f"WOULD UPDATE: {filepath} ({changes} includes)")
        else:
            filepath.write_text(content, encoding="utf-8")
            print(f"Updated: {filepath} ({changes} includes)")
        return changes

    return 0


def update_all_includes(repo_root: Path, include_mapping: dict, dry_run: bool = False):
    """
    Update all #include directives in the repository.
    """
    exclude_dirs = ["build_", ".git", "__pycache__"]
    total_files = 0
    total_changes = 0

    print("\nUpdating #include directives...", file=sys.stderr)

    for dirpath, dirnames, filenames in os.walk(repo_root):
        # Skip excluded directories
        dirnames[:] = [d for d in dirnames if not any(excl in d for excl in exclude_dirs)]

        for filename in filenames:
            if not (filename.endswith((".cpp", ".cc", ".h", ".hpp"))):
                continue

            filepath = Path(dirpath) / filename
            changes = update_includes_in_file(filepath, include_mapping, dry_run)
            if changes > 0:
                total_files += 1
                total_changes += changes

    print(f"\nSummary: Updated {total_changes} includes in {total_files} files", file=sys.stderr)


def update_path_references(repo_root: Path, dry_run: bool = False):
    """
    Update path references in non-source files (docs, CODEOWNERS, etc.).
    These are plain path strings, not #include directives.
    """
    # Path mappings for non-include references
    # ORDER MATTERS: more specific patterns must come first to avoid partial matches
    path_mappings = [
        # Top-level header MUST come before directory pattern without slash
        ("tt_metal/include/compute_kernel_api.h", "tt_metal/hw/inc/api/compute/compute_kernel_api.h"),
        # Directory with trailing slash
        ("tt_metal/include/compute_kernel_api/", "tt_metal/hw/inc/api/compute/"),
        # Directory without trailing slash (least specific, must be last)
        ("tt_metal/include/compute_kernel_api", "tt_metal/hw/inc/api/compute"),
    ]

    # Files to update
    files_to_check = [
        repo_root / "docs/Doxyfile",
        repo_root / ".github/CODEOWNERS",
    ]

    # Also find .rst files in docs
    docs_dir = repo_root / "docs"
    if docs_dir.exists():
        files_to_check.extend(docs_dir.rglob("*.rst"))

    total_files = 0
    print("\nUpdating path references in docs/config files...", file=sys.stderr)

    for filepath in files_to_check:
        if not filepath.exists():
            continue

        try:
            content = filepath.read_text(encoding="utf-8", errors="replace")
        except Exception as e:
            print(f"Warning: Could not read {filepath}: {e}", file=sys.stderr)
            continue

        original_content = content

        for old_path, new_path in path_mappings:
            content = content.replace(old_path, new_path)

        if content != original_content:
            if dry_run:
                print(f"WOULD UPDATE: {filepath}")
            else:
                filepath.write_text(content, encoding="utf-8")
                print(f"Updated: {filepath}")
            total_files += 1

    print(f"\nSummary: Updated {total_files} config/doc files", file=sys.stderr)


def main():
    parser = argparse.ArgumentParser(description=__doc__, formatter_class=argparse.RawDescriptionHelpFormatter)
    parser.add_argument("--dry-run", action="store_true", help="Show what would be done without making changes")
    parser.add_argument("repo_root", nargs="?", help="Repository root directory (default: parent of script directory)")
    args = parser.parse_args()

    # Determine repo root
    if args.repo_root:
        repo_root = Path(args.repo_root).resolve()
    else:
        repo_root = Path(__file__).parent.parent.resolve()

    print(f"Repository root: {repo_root}", file=sys.stderr)
    print(f"Dry run: {args.dry_run}", file=sys.stderr)

    # Step 0: Load JSON data
    print("\n=== Step 0: Loading JSON data ===", file=sys.stderr)
    device_includes, headers_to_dirs = load_json_data(repo_root)
    print(f"Loaded {len(device_includes)} source files from device_includes.json", file=sys.stderr)

    # Step 1: Find headers to migrate
    print("\n=== Step 1: Finding headers to migrate ===", file=sys.stderr)
    headers_to_migrate = find_headers_to_migrate(repo_root)
    if not headers_to_migrate:
        print("ERROR: No headers found in tt_metal/include/. Already migrated?", file=sys.stderr)
        sys.exit(1)
    print(f"Found {len(headers_to_migrate)} headers to migrate", file=sys.stderr)

    # Step 2: Build include mapping using JSON data
    print("\n=== Step 2: Building include mapping ===", file=sys.stderr)
    include_mapping = build_include_mapping(headers_to_migrate, device_includes, headers_to_dirs)
    print(f"Built mapping for {len(include_mapping)} include patterns", file=sys.stderr)

    # Show some examples
    examples = list(include_mapping.items())[:5]
    for old, new in examples:
        print(f"  {old} -> {new}", file=sys.stderr)
    if len(include_mapping) > 5:
        print(f"  ... and {len(include_mapping) - 5} more", file=sys.stderr)

    # Step 3: Move files
    print("\n=== Step 3: Moving files ===", file=sys.stderr)
    moved = move_files(repo_root, args.dry_run)
    print(f"Moved {len(moved)} files", file=sys.stderr)

    # Step 4: Update all includes
    print("\n=== Step 4: Updating includes ===", file=sys.stderr)
    update_all_includes(repo_root, include_mapping, args.dry_run)

    # Step 5: Update path references in docs/config files
    print("\n=== Step 5: Updating docs/config files ===", file=sys.stderr)
    update_path_references(repo_root, args.dry_run)

    if args.dry_run:
        print("\n=== DRY RUN COMPLETE ===", file=sys.stderr)
        print("Run without --dry-run to apply changes", file=sys.stderr)
    else:
        print("\n=== MIGRATION COMPLETE ===", file=sys.stderr)
        print("Next step: Remove 'root_ + \"tt_metal/include\"' from build.cpp", file=sys.stderr)


if __name__ == "__main__":
    main()
