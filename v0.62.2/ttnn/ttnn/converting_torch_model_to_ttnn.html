<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Converting PyTorch Model to TT-NN &mdash; TT-NN  documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/tt_theme.css" type="text/css" />
    <link rel="shortcut icon" href="../_static/favicon.png"/>
    <link rel="canonical" href="/tt-metal/latest/ttnn/ttnn/converting_torch_model_to_ttnn.html" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js?v=b3ba4146"></script>
        <script src="../_static/doctools.js?v=888ff710"></script>
        <script src="../_static/sphinx_highlight.js?v=4825356b"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Adding New TT-NN Operation" href="adding_new_ttnn_operation.html" />
    <link rel="prev" title="Onboarding New Functionality" href="onboarding.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >



<a href="https://docs.tenstorrent.com/">
    <img src="../_static/tt_logo.svg" class="logo" alt="Logo"/>
</a>

<a href="../index.html">
    TT-NN
</a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">TTNN</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="about.html">What is TT-NN?</a></li>
<li class="toctree-l1"><a class="reference internal" href="get_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="installing.html">Install</a></li>
<li class="toctree-l1"><a class="reference internal" href="usage.html">Using TT-NN</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor.html">Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials.html">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="onboarding.html">Onboarding New Functionality</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Converting PyTorch Model to TT-NN</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#step-1-rewriting-the-model">Step 1 - Rewriting the Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="#step-2-switching-to-ttnn-operations">Step 2 - Switching to ttnn Operations</a></li>
<li class="toctree-l2"><a class="reference internal" href="#step-3-optimizing-the-model">Step 3 - Optimizing the Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="#more-examples">More examples</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="adding_new_ttnn_operation.html">Adding New TT-NN Operation</a></li>
<li class="toctree-l1"><a class="reference internal" href="profiling_ttnn_operations.html">Profiling TT-NN Operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="demos.html">Building and Uplifting Demos</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Resources</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../resources/support.html">Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../resources/contributing.html">Contributing as a developer</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">TT-NN</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Converting PyTorch Model to TT-NN</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/ttnn/converting_torch_model_to_ttnn.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="converting-pytorch-model-to-tt-nn">
<h1>Converting PyTorch Model to TT-NN<a class="headerlink" href="#converting-pytorch-model-to-tt-nn" title="Permalink to this heading"></a>
</h1>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This particular example only works on Grayskull.</p>
<p>Not all converted models may be functional on all Tenstorrent hardware
(Grayskull, Wormhole, or others). Functionality is on a case-by-case basis.</p>
</div>
<p>There are many ways to convert a torch model to ttnn.</p>
<dl class="simple">
<dt>This is the recommend approach:</dt>
<dd>
<ol class="arabic simple">
<li><p>Re-writing torch model using functional torch APIs</p></li>
<li><p>Converting operations of the functional torch model to ttnn operations</p></li>
<li><p>Optimizing functional ttnn model</p></li>
</ol>
</dd>
</dl>
<section id="step-1-rewriting-the-model">
<h2>Step 1 - Rewriting the Model<a class="headerlink" href="#step-1-rewriting-the-model" title="Permalink to this heading"></a>
</h2>
<p>Given a torch model, it can be rewritten using functional torch APIs.</p>
<p>For example, given the following torch model:</p>
<div class="highlight-python notranslate">
<div class="highlight"><pre><span></span><span class="c1"># From transformers.models.bert.modeling_bert.BertIntermediate</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="k">class</span><span class="w"> </span><span class="nc">BertIntermediate</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dense</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">intermediate_size</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_states</span><span class="p">):</span>
        <span class="n">hidden_states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>
        <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">gelu</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">hidden_states</span>
</pre></div>
</div>
<p>Following TDD, the first step is to write a test for the model:</p>
<div class="highlight-python notranslate">
<div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">transformers</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">ttnn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch_bert</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">models.utility_functions</span><span class="w"> </span><span class="kn">import</span> <span class="n">torch_random</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tests.ttnn.utils_for_testing</span><span class="w"> </span><span class="kn">import</span> <span class="n">assert_with_pcc</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">parametrize</span><span class="p">(</span><span class="s2">"model_name"</span><span class="p">,</span> <span class="p">[</span><span class="s2">"phiyodr/bert-large-finetuned-squad2"</span><span class="p">])</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">parametrize</span><span class="p">(</span><span class="s2">"batch_size"</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">parametrize</span><span class="p">(</span><span class="s2">"sequence_size"</span><span class="p">,</span> <span class="p">[</span><span class="mi">384</span><span class="p">])</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_bert_intermediate</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">sequence_size</span><span class="p">):</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">config</span> <span class="o">=</span> <span class="n">transformers</span><span class="o">.</span><span class="n">BertConfig</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">bert</span><span class="o">.</span><span class="n">modeling_bert</span><span class="o">.</span><span class="n">BertIntermediate</span><span class="p">(</span><span class="n">config</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="n">torch_hidden_states</span> <span class="o">=</span> <span class="n">torch_random</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">sequence_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">),</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">torch_output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">torch_hidden_states</span><span class="p">)</span> <span class="c1"># Golden output</span>

    <span class="n">parameters</span> <span class="o">=</span> <span class="n">preprocess_model_parameters</span><span class="p">(</span>
        <span class="n">initialize_model</span><span class="o">=</span><span class="k">lambda</span><span class="p">:</span> <span class="n">model</span><span class="p">,</span> <span class="c1"># Function to initialize the model</span>
        <span class="n">convert_to_ttnn</span><span class="o">=</span><span class="k">lambda</span> <span class="o">*</span><span class="n">_</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span> <span class="c1"># Keep the weights as torch tensors</span>
    <span class="p">)</span>

    <span class="n">output</span> <span class="o">=</span> <span class="n">torch_bert</span><span class="o">.</span><span class="n">bert_intermediate</span><span class="p">(</span>
        <span class="n">torch_hidden_states</span><span class="p">,</span>
        <span class="n">parameters</span><span class="o">=</span><span class="n">parameters</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">assert_with_pcc</span><span class="p">(</span><span class="n">torch_output</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="mf">0.9999</span><span class="p">)</span>
</pre></div>
</div>
<p>And finally, the model can be rewritten using functional torch APIs to make the test pass:</p>
<div class="highlight-python notranslate">
<div class="highlight"><pre><span></span><span class="c1"># torch_bert.py</span>

<span class="k">def</span><span class="w"> </span><span class="nf">bert_intermediate</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">parameters</span><span class="p">):</span>
    <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">hidden_states</span> <span class="o">@</span> <span class="n">parameters</span><span class="o">.</span><span class="n">dense</span><span class="o">.</span><span class="n">weight</span>
    <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">hidden_states</span> <span class="o">+</span> <span class="n">parameters</span><span class="o">.</span><span class="n">dense</span><span class="o">.</span><span class="n">bias</span>
    <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">gelu</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">hidden_states</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">parameters</span></code> is a dictionary which sets its keys as its attributes, so both <code class="docutils literal notranslate"><span class="pre">parameters["dense"]["weight"]</span></code> and <code class="docutils literal notranslate"><span class="pre">parameters.dense.weight</span></code> are valid.</p>
<p>The structure of <code class="docutils literal notranslate"><span class="pre">parameters</span></code> follows the structure of the model class.
In this case, <code class="docutils literal notranslate"><span class="pre">BertIntermediate</span></code> has a single attribute <code class="docutils literal notranslate"><span class="pre">dense</span></code>, so <code class="docutils literal notranslate"><span class="pre">parameters</span></code> has a single attribute <code class="docutils literal notranslate"><span class="pre">dense</span></code>.
And <code class="docutils literal notranslate"><span class="pre">dense</span></code> is a <code class="docutils literal notranslate"><span class="pre">torch.nn.Linear</span></code> object, so it in turn has two attributes <code class="docutils literal notranslate"><span class="pre">weight</span></code> and <code class="docutils literal notranslate"><span class="pre">bias</span></code>.</p>
</div>
</section>
<section id="step-2-switching-to-ttnn-operations">
<h2>Step 2 - Switching to ttnn Operations<a class="headerlink" href="#step-2-switching-to-ttnn-operations" title="Permalink to this heading"></a>
</h2>
<p>Starting off with the test:</p>
<div class="highlight-python notranslate">
<div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">transformers</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">ttnn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">ttnn_bert</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">models.utility_functions</span><span class="w"> </span><span class="kn">import</span> <span class="n">torch_random</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tests.ttnn.utils_for_testing</span><span class="w"> </span><span class="kn">import</span> <span class="n">assert_with_pcc</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">parametrize</span><span class="p">(</span><span class="s2">"model_name"</span><span class="p">,</span> <span class="p">[</span><span class="s2">"phiyodr/bert-large-finetuned-squad2"</span><span class="p">])</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">parametrize</span><span class="p">(</span><span class="s2">"batch_size"</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">parametrize</span><span class="p">(</span><span class="s2">"sequence_size"</span><span class="p">,</span> <span class="p">[</span><span class="mi">384</span><span class="p">])</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_bert_intermediate</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">sequence_size</span><span class="p">):</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">config</span> <span class="o">=</span> <span class="n">transformers</span><span class="o">.</span><span class="n">BertConfig</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">bert</span><span class="o">.</span><span class="n">modeling_bert</span><span class="o">.</span><span class="n">BertIntermediate</span><span class="p">(</span><span class="n">config</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="n">torch_hidden_states</span> <span class="o">=</span> <span class="n">torch_random</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">sequence_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">),</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
    <span class="n">torch_output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">torch_hidden_states</span><span class="p">)</span>

    <span class="n">parameters</span> <span class="o">=</span> <span class="n">preprocess_model_parameters</span><span class="p">(</span>
        <span class="n">initialize_model</span><span class="o">=</span><span class="k">lambda</span><span class="p">:</span> <span class="n">model</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="c1"># Device to put the parameters on</span>
    <span class="p">)</span>

    <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">from_torch</span><span class="p">(</span><span class="n">torch_hidden_states</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">TILE_LAYOUT</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">ttnn_bert</span><span class="o">.</span><span class="n">bert_intermediate</span><span class="p">(</span>
        <span class="n">hidden_states</span><span class="p">,</span>
        <span class="n">parameters</span><span class="o">=</span><span class="n">parameters</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">to_torch</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

    <span class="n">assert_with_pcc</span><span class="p">(</span><span class="n">torch_output</span><span class="p">,</span> <span class="n">output</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch_output</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="mf">0.999</span><span class="p">)</span>
</pre></div>
</div>
<p>Then implementing the function using ttnn operations:</p>
<div class="highlight-python notranslate">
<div class="highlight"><pre><span></span><span class="c1"># ttnn_bert.py</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">ttnn</span>

<span class="k">def</span><span class="w"> </span><span class="nf">bert_intermediate</span><span class="p">(</span>
    <span class="n">hidden_states</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">parameters</span><span class="p">,</span>
<span class="p">):</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">hidden_states</span> <span class="o">@</span> <span class="n">parameters</span><span class="o">.</span><span class="n">dense</span><span class="o">.</span><span class="n">weight</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">output</span> <span class="o">+</span> <span class="n">parameters</span><span class="o">.</span><span class="n">dense</span><span class="o">.</span><span class="n">bias</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">gelu</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">output</span>
</pre></div>
</div>
</section>
<section id="step-3-optimizing-the-model">
<h2>Step 3 - Optimizing the Model<a class="headerlink" href="#step-3-optimizing-the-model" title="Permalink to this heading"></a>
</h2>
<p>Starting off with the test:</p>
<div class="highlight-python notranslate">
<div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">transformers</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">ttnn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">ttnn_bert</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">models.utility_functions</span><span class="w"> </span><span class="kn">import</span> <span class="n">torch_random</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tests.ttnn.utils_for_testing</span><span class="w"> </span><span class="kn">import</span> <span class="n">assert_with_pcc</span>

<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">parametrize</span><span class="p">(</span><span class="s2">"model_name"</span><span class="p">,</span> <span class="p">[</span><span class="s2">"phiyodr/bert-large-finetuned-squad2"</span><span class="p">])</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">parametrize</span><span class="p">(</span><span class="s2">"batch_size"</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">parametrize</span><span class="p">(</span><span class="s2">"sequence_size"</span><span class="p">,</span> <span class="p">[</span><span class="mi">384</span><span class="p">])</span>
<span class="k">def</span><span class="w"> </span><span class="nf">test_bert_intermediate</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">sequence_size</span><span class="p">):</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">config</span> <span class="o">=</span> <span class="n">transformers</span><span class="o">.</span><span class="n">BertConfig</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">bert</span><span class="o">.</span><span class="n">modeling_bert</span><span class="o">.</span><span class="n">BertIntermediate</span><span class="p">(</span><span class="n">config</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="n">torch_hidden_states</span> <span class="o">=</span> <span class="n">torch_random</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">sequence_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">),</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
    <span class="n">torch_output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">torch_hidden_states</span><span class="p">)</span>

    <span class="n">parameters</span> <span class="o">=</span> <span class="n">preprocess_model_parameters</span><span class="p">(</span>
        <span class="n">initialize_model</span><span class="o">=</span><span class="k">lambda</span><span class="p">:</span> <span class="n">model</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="c1"># Device to put the parameters on</span>
        <span class="n">custom_preprocessor</span><span class="o">=</span><span class="n">ttnn_bert</span><span class="o">.</span><span class="n">custom_preprocessor</span><span class="p">,</span> <span class="c1"># Use custom_preprocessor to set ttnn.bfloat8_b data type for the weights and biases</span>
    <span class="p">)</span>

    <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">from_torch</span><span class="p">(</span><span class="n">torch_hidden_states</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">TILE_LAYOUT</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">ttnn_bert</span><span class="o">.</span><span class="n">bert_intermediate</span><span class="p">(</span>
        <span class="n">hidden_states</span><span class="p">,</span>
        <span class="n">parameters</span><span class="o">=</span><span class="n">parameters</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">to_torch</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>

    <span class="n">assert_with_pcc</span><span class="p">(</span><span class="n">torch_output</span><span class="p">,</span> <span class="n">output</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch_output</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="mf">0.999</span><span class="p">)</span>
</pre></div>
</div>
<p>And the optimized model can be something like this:</p>
<div class="highlight-python notranslate">
<div class="highlight"><pre><span></span><span class="c1"># ttnn_optimized_bert.py</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">ttnn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">transformers</span>

<span class="k">def</span><span class="w"> </span><span class="nf">custom_preprocessor</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>

    <span class="n">parameters</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">transformers</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">bert</span><span class="o">.</span><span class="n">modeling_bert</span><span class="o">.</span><span class="n">BertIntermediate</span><span class="p">):</span>
        <span class="n">parameters</span><span class="p">[</span><span class="s2">"weight"</span><span class="p">]</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">model_preprocessing</span><span class="o">.</span><span class="n">preprocess_linear_weight</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">bfloat8_b</span><span class="p">)</span>
        <span class="n">parameters</span><span class="p">[</span><span class="s2">"bias"</span><span class="p">]</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">model_preprocessing</span><span class="o">.</span><span class="n">preprocess_linear_bias</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">bfloat8_b</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">parameters</span>

<span class="k">def</span><span class="w"> </span><span class="nf">bert_intermediate</span><span class="p">(</span>
    <span class="n">hidden_states</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">parameters</span><span class="p">,</span>
    <span class="n">num_cores_x</span><span class="p">,</span>
<span class="p">):</span>
    <span class="n">batch_size</span><span class="p">,</span> <span class="o">*</span><span class="n">_</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="o">.</span><span class="n">shape</span>

    <span class="n">num_cores_x</span> <span class="o">=</span> <span class="mi">12</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span>
        <span class="n">hidden_states</span><span class="p">,</span>
        <span class="n">ff1_weight</span><span class="p">,</span>
        <span class="n">bias</span><span class="o">=</span><span class="n">ff1_bias</span><span class="p">,</span>
        <span class="n">memory_config</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">L1_MEMORY_CONFIG</span><span class="p">,</span> <span class="c1"># Put the output into local core memory</span>
        <span class="n">core_grid</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_cores_x</span><span class="p">),</span> <span class="c1"># Specify manual core grid to get the best possible performance</span>
        <span class="n">activation</span><span class="o">=</span><span class="s2">"gelu"</span><span class="p">,</span> <span class="c1"># Fuse Gelu</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="kc">True</span>
</pre></div>
</div>
</section>
<section id="more-examples">
<h2>More examples<a class="headerlink" href="#more-examples" title="Permalink to this heading"></a>
</h2>
<p>Additional examples can be found in <a class="reference external" href="https://github.com/tenstorrent/tt-metal/tree/main/tests/ttnn/integration_tests">the integration tests</a>.</p>
</section>
</section>



           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="onboarding.html" class="btn btn-neutral float-left" title="Onboarding New Functionality" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="adding_new_ttnn_operation.html" class="btn btn-neutral float-right" title="Adding New TT-NN Operation" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright Tenstorrent.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
        Version: <span id="current-version">latest</span>
        <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
        <dl id="version-list">
            <dt>Versions</dt>
        </dl>
        <br>
        </dl>
    </div>
</div>

<script>
const VERSIONS_URL = 'https://raw.githubusercontent.com/tenstorrent/tt-metal/refs/heads/main/docs/published_versions.json';

async function loadVersions() {
    try {
        const response = await fetch(VERSIONS_URL);
        const data = await response.json();
        const versionList = document.getElementById('version-list');
        const projectCode = location.pathname.split('/')[3];

        data.versions.forEach(version => {
            const dd = document.createElement('dd');
            const link = document.createElement('a');
            link.href = `https://docs.tenstorrent.com/tt-metal/${version}/${projectCode}/index.html`;
            link.textContent = version;
            dd.appendChild(link);
            versionList.appendChild(dd);
        });
    } catch (error) {
        console.error('Error loading versions:', error);
    }
}

loadVersions();

function getCurrentVersion() {
    return window.location.pathname.split('/')[2];
}
document.getElementById('current-version').textContent = getCurrentVersion();

const versionEl = document.createElement("span");
versionEl.innerText = getCurrentVersion();
versionEl.className = "project-versions";
const wySideSearchEl = document.getElementsByClassName("wy-side-nav-search").item(0);
if (wySideSearchEl) {
    const projectNameEl = wySideSearchEl.children.item(1);
    if (projectNameEl) projectNameEl.appendChild(versionEl);
}

</script><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>