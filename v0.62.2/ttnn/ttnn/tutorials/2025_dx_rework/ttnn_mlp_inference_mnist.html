<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>MLP Inference &mdash; TT-NN  documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/tt_theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/nbsphinx-code-cells.css" type="text/css" />
    <link rel="shortcut icon" href="../../../_static/favicon.png"/>
    <link rel="canonical" href="/tt-metal/latest/ttnn/ttnn/tutorials/2025_dx_rework/ttnn_mlp_inference_mnist.html" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js?v=b3ba4146"></script>
        <script src="../../../_static/doctools.js?v=888ff710"></script>
        <script src="../../../_static/sphinx_highlight.js?v=4825356b"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Multi-Head Attention" href="ttnn_multihead_attention.html" />
    <link rel="prev" title="More Basic Tensor Operations" href="ttnn_basic_operations.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >



<a href="https://docs.tenstorrent.com/">
    <img src="../../../_static/tt_logo.svg" class="logo" alt="Logo"/>
</a>

<a href="../../../index.html">
    TT-NN
</a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">TTNN</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../about.html">What is TT-NN?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../get_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../installing.html">Install</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../usage.html">Using TT-NN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tensor.html">Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api.html">APIs</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../tutorials.html">Tutorials</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="ttnn_add_tensors.html">Add Tensors</a></li>
<li class="toctree-l2"><a class="reference internal" href="ttnn_basic_operations.html">More Basic Tensor Operations</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">MLP Inference</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Import-the-necessary-libraries">Import the necessary libraries</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Open-Tenstorrent-device">Open Tenstorrent device</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Load-MNIST-Test-Data">Load MNIST Test Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Load-Pretrained-MLP-Weights">Load Pretrained MLP Weights</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Basic-accuracy-tracking,-inference,-loop,-and-image-flattening">Basic accuracy tracking, inference, loop, and image flattening</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Close-The-Device">Close The Device</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Full-example-and-output">Full example and output</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="ttnn_multihead_attention.html">Multi-Head Attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="ttnn_basic_conv.html">Basic Convolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="ttnn_simplecnn_inference.html">Running a Simple CNN Inference on CIFAR-10</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../onboarding.html">Onboarding New Functionality</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../converting_torch_model_to_ttnn.html">Converting PyTorch Model to TT-NN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../adding_new_ttnn_operation.html">Adding New TT-NN Operation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../profiling_ttnn_operations.html">Profiling TT-NN Operations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../demos.html">Building and Uplifting Demos</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Resources</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../resources/support.html">Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../resources/contributing.html">Contributing as a developer</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">TT-NN</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../tutorials.html">Tutorials</a></li>
      <li class="breadcrumb-item active">MLP Inference</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/ttnn/tutorials/2025_dx_rework/ttnn_mlp_inference_mnist.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="MLP-Inference">
<h1>MLP Inference<a class="headerlink" href="#MLP-Inference" title="Permalink to this heading"></a>
</h1>
<p>In this example we will combine insight from the previous examples, and use TT-NN with PyTorch to perform a simple MLP inference task. This will demonstrate how to use TT-NN for tensor operations and model inference.</p>
<p>Lets create the example file, <code class="docutils literal notranslate"><span class="pre">ttnn_mlp_inference_mnist.py</span></code></p>
<section id="Import-the-necessary-libraries">
<h2>Import the necessary libraries<a class="headerlink" href="#Import-the-necessary-libraries" title="Permalink to this heading"></a>
</h2>
<p>In this script, a set of essential libraries are imported to perform inference on the MNIST digit classification task using a multi-layer perceptron (MLP) accelerated by Tenstorrent hardware. The torch library provides utilities for loading and manipulating data, while torchvision and its transforms submodule are used to download the MNIST dataset and apply normalization and tensor conversion to the image inputs. The ttnn library is the core interface for compiling and running neural network
operations on Tenstorrent devices, including tensor creation, data layout transformation, and layer computation (e.g., linear, relu). The os module is used to check for the existence of a pretrained weights file on disk. Finally, loguru is used to provide clear and structured logging throughout the script, including loading status, prediction results, and final accuracy reporting. These imports collectively enable a pipeline that loads data, runs inference on a custom backend, and logs the
outcome efficiently.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate">
<div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate">
<div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torchvision</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torchvision.transforms</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">transforms</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">ttnn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">loguru</span><span class="w"> </span><span class="kn">import</span> <span class="n">logger</span>
</pre></div>
</div>
</div>
</section>
<section id="Open-Tenstorrent-device">
<h2>Open Tenstorrent device<a class="headerlink" href="#Open-Tenstorrent-device" title="Permalink to this heading"></a>
</h2>
<p>Create necessary device on which we will run our program.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate">
<div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate">
<div class="highlight"><pre><span></span><span class="c1"># Open Tenstorrent device</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">open_device</span><span class="p">(</span><span class="n">device_id</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Load-MNIST-Test-Data">
<h2>Load MNIST Test Data<a class="headerlink" href="#Load-MNIST-Test-Data" title="Permalink to this heading"></a>
</h2>
<p>Load and convert the MNIST 28x28 grayscale images to tensors and normalize them. Subsequently, lets create a DataLoader to iterate through the dataset. This will allow us to perform inference on each image in the dataset.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate">
<div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate">
<div class="highlight"><pre><span></span><span class="c1"># Load MNIST data</span>
<span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.5</span><span class="p">,),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,))])</span>
<span class="n">testset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s2">"./data"</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
<span class="n">testloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">testset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Load-Pretrained-MLP-Weights">
<h2>Load Pretrained MLP Weights<a class="headerlink" href="#Load-Pretrained-MLP-Weights" title="Permalink to this heading"></a>
</h2>
<p>Load the pretrained MLP weights from a file. You can run the provided <code class="docutils literal notranslate"><span class="pre">train_and_export_mlp.py</span></code> script to generate the weights to a file named <code class="docutils literal notranslate"><span class="pre">mlp_mnist_weights.pt</span></code>. Alternatively, if weights file is not found, random weights values will be generated to test functionality, but expect poor prediction results there.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate">
<div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate">
<div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="s2">"mlp_mnist_weights.pt"</span><span class="p">):</span>
    <span class="c1"># Pretrained weights</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">"mlp_mnist_weights.pt"</span><span class="p">)</span>
    <span class="n">W1</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">from_torch</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="s2">"W1"</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">TILE_LAYOUT</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">b1</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">from_torch</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="s2">"b1"</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">TILE_LAYOUT</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">W2</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">from_torch</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="s2">"W2"</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">TILE_LAYOUT</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">b2</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">from_torch</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="s2">"b2"</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">TILE_LAYOUT</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">W3</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">from_torch</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="s2">"W3"</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">TILE_LAYOUT</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">b3</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">from_torch</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="s2">"b3"</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">TILE_LAYOUT</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"Loaded pretrained weights from mlp_mnist_weights.pt"</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="c1"># Random weights for MLP - will not predict correctly</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">"mlp_mnist_weights.pt not found, using random weights"</span><span class="p">)</span>
    <span class="n">W1</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">128</span><span class="p">,</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">TILE_LAYOUT</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">b1</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">128</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">TILE_LAYOUT</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">W2</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">TILE_LAYOUT</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">b2</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">64</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">TILE_LAYOUT</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">W3</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">TILE_LAYOUT</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">b3</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">rand</span><span class="p">((</span><span class="mi">10</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">TILE_LAYOUT</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Basic-accuracy-tracking,-inference,-loop,-and-image-flattening">
<h2>Basic accuracy tracking, inference, loop, and image flattening<a class="headerlink" href="#Basic-accuracy-tracking,-inference,-loop,-and-image-flattening" title="Permalink to this heading"></a>
</h2>
<p>This code snippet performs inference on the first five test samples from the MNIST dataset using a multi-layer perceptron (MLP) executed on Tenstorrent hardware via the TT-NN API. It initializes counters for tracking the number of correct predictions. For each sample, the input image is flattened into a 1D vector and converted from a PyTorch tensor to a TT-NN tensor with bfloat16 precision and TILE_LAYOUT for efficient execution. The tensor is then passed sequentially through three fully
connected layers: each of the first two layers applies a linear transformation followed by a ReLU activation, while the final layer produces raw logits for the 10 output classes (digits 0–9). For each layer, the weights are transposed and the biases are reshaped to match TT-NN’s expected input dimensions. After computing the final output, it is converted back to a PyTorch tensor, and the class with the highest activation is selected as the predicted label. The prediction is compared with the
true label to update the accuracy counters, and the result is logged. Once all five samples are processed, the script logs the overall prediction accuracy.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate">
<div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate">
<div class="highlight"><pre><span></span><span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">testloader</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="mi">5</span><span class="p">:</span>
        <span class="k">break</span>

    <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="c1"># Convert to TT-NN Tensor</span>
    <span class="c1"># Convert the PyTorch tensor to TT-NN format with bfloat16 data type and</span>
    <span class="c1"># TILE\_LAYOUT. This is necessary for efficient computation on the</span>
    <span class="c1"># Tenstorrent device.</span>
    <span class="n">image_tt</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">from_torch</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">ttnn</span><span class="o">.</span><span class="n">TILE_LAYOUT</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># Layer 1</span>
    <span class="c1"># Transposed weights are used to match TT-NN's expected shape. Bias</span>
    <span class="c1"># reshaped to 1x128 for broadcasting, and compute output 1.</span>
    <span class="n">W1_final</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">W1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">b1_final</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">b1</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">out1</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">image_tt</span><span class="p">,</span> <span class="n">W1_final</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">b1_final</span><span class="p">)</span>
    <span class="n">out1</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out1</span><span class="p">)</span>

    <span class="c1"># Layer 2</span>
    <span class="c1"># Same pattern as Layer 1, but with different weights and biases.</span>
    <span class="n">W2_final</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">W2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">b2_final</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">b2</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">out2</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">out1</span><span class="p">,</span> <span class="n">W2_final</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">b2_final</span><span class="p">)</span>
    <span class="n">out2</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">out2</span><span class="p">)</span>

    <span class="c1"># Layer 3</span>
    <span class="c1"># Final layer with 10 output (for digits 0-9). No ReLU activation here, as</span>
    <span class="c1"># this is the output layer.</span>
    <span class="n">W3_final</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">W3</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">b3_final</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">b3</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">out3</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">out2</span><span class="p">,</span> <span class="n">W3_final</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">b3_final</span><span class="p">)</span>

    <span class="c1"># Convert result back to torch</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="n">ttnn</span><span class="o">.</span><span class="n">to_torch</span><span class="p">(</span><span class="n">out3</span><span class="p">)</span>
    <span class="n">predicted_label</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="n">correct</span> <span class="o">+=</span> <span class="n">predicted_label</span> <span class="o">==</span> <span class="n">label</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="n">total</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Sample </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">: Predicted=</span><span class="si">{</span><span class="n">predicted_label</span><span class="si">}</span><span class="s2">, Actual=</span><span class="si">{</span><span class="n">label</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">TT-NN MLP Inference Accuracy: </span><span class="si">{</span><span class="n">correct</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">total</span><span class="si">}</span><span class="s2"> = </span><span class="si">{</span><span class="mf">100.0</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">correct</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">total</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Close-The-Device">
<h2>Close The Device<a class="headerlink" href="#Close-The-Device" title="Permalink to this heading"></a>
</h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate">
<div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-python notranslate">
<div class="highlight"><pre><span></span><span class="n">ttnn</span><span class="o">.</span><span class="n">close_device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Full-example-and-output">
<h2>Full example and output<a class="headerlink" href="#Full-example-and-output" title="Permalink to this heading"></a>
</h2>
<p>Lets put everything together in a complete example that can be run directly.</p>
<p><a class="reference external" href="https://github.com/tenstorrent/tt-metal/tree/main/ttnn/tutorials/basic_python/ttnn_mlp_inference_mnist.py">ttnn_mlp_inference_mnist.py</a></p>
<p>Running this script will generate output the as shown below:</p>
<div class="highlight-console notranslate">
<div class="highlight"><pre><span></span><span class="gp">$ </span>python3<span class="w"> </span><span class="nv">$TT_METAL_HOME</span>/ttnn/tutorials/basic_python/ttnn_mlp_inference_mnist.py
<span class="go">2025-07-07 13:03:41.990 | info     |   SiliconDriver | Opened PCI device 7; KMD version: 1.34.0; API: 1; IOMMU: disabled (pci_device.cpp:198)</span>
<span class="go">2025-07-07 13:03:41.992 | info     |   SiliconDriver | Opened PCI device 7; KMD version: 1.34.0; API: 1; IOMMU: disabled (pci_device.cpp:198)</span>
<span class="go">2025-07-07 13:03:41.998 | info     |          Device | Opening user mode device driver (tt_cluster.cpp:190)</span>
<span class="go">2025-07-07 13:03:41.998 | info     |   SiliconDriver | Opened PCI device 7; KMD version: 1.34.0; API: 1; IOMMU: disabled (pci_device.cpp:198)</span>
<span class="go">2025-07-07 13:03:41.999 | info     |   SiliconDriver | Opened PCI device 7; KMD version: 1.34.0; API: 1; IOMMU: disabled (pci_device.cpp:198)</span>
<span class="go">2025-07-07 13:03:42.006 | info     |   SiliconDriver | Opened PCI device 7; KMD version: 1.34.0; API: 1; IOMMU: disabled (pci_device.cpp:198)</span>
<span class="go">2025-07-07 13:03:42.007 | info     |   SiliconDriver | Opened PCI device 7; KMD version: 1.34.0; API: 1; IOMMU: disabled (pci_device.cpp:198)</span>
<span class="go">2025-07-07 13:03:42.013 | info     |   SiliconDriver | Harvesting mask for chip 0 is 0x100 (NOC0: 0x100, simulated harvesting mask: 0x0). (cluster.cpp:282)</span>
<span class="go">2025-07-07 13:03:42.110 | info     |   SiliconDriver | Opened PCI device 7; KMD version: 1.34.0; API: 1; IOMMU: disabled (pci_device.cpp:198)</span>
<span class="go">2025-07-07 13:03:42.172 | info     |   SiliconDriver | Opening local chip ids/pci ids: {0}/[7] and remote chip ids {} (cluster.cpp:147)</span>
<span class="go">2025-07-07 13:03:42.182 | info     |   SiliconDriver | Software version 6.0.0, Ethernet FW version 6.14.0 (Device 0) (cluster.cpp:1039)</span>
<span class="go">2025-07-07 13:03:42.268 | info     |           Metal | AI CLK for device 0 is:   1000 MHz (metal_context.cpp:128)</span>
<span class="go">2025-07-07 13:03:42.886 | info     |           Metal | Initializing device 0. Program cache is enabled (device.cpp:428)</span>
<span class="go">2025-07-07 13:03:42.888 | warning  |           Metal | Unable to bind worker thread to CPU Core. May see performance degradation. Error Code: 22 (hardware_command_queue.cpp:74)</span>
<span class="go">2025-07-07 13:03:44.852 | INFO     | __main__:main:32 - Loaded pretrained weights from mlp_mnist_weights.pt</span>
<span class="go">2025-07-07 13:03:48.677 | INFO     | __main__:main:87 - Sample 1: Predicted=7, Actual=7</span>
<span class="go">2025-07-07 13:03:48.682 | INFO     | __main__:main:87 - Sample 2: Predicted=2, Actual=2</span>
<span class="go">2025-07-07 13:03:48.686 | INFO     | __main__:main:87 - Sample 3: Predicted=1, Actual=1</span>
<span class="go">2025-07-07 13:03:48.690 | INFO     | __main__:main:87 - Sample 4: Predicted=0, Actual=0</span>
<span class="go">2025-07-07 13:03:48.695 | INFO     | __main__:main:87 - Sample 5: Predicted=4, Actual=4</span>
<span class="go">2025-07-07 13:03:48.695 | INFO     | __main__:main:89 -</span>
<span class="go">TT-NN MLP Inference Accuracy: 5/5 = 100.00%</span>
<span class="go">2025-07-07 13:03:48.695 | info     |           Metal | Closing mesh device 1 (mesh_device.cpp:488)</span>
<span class="go">2025-07-07 13:03:48.696 | info     |           Metal | Closing mesh device 0 (mesh_device.cpp:488)</span>
<span class="go">2025-07-07 13:03:48.696 | info     |           Metal | Closing device 0 (device.cpp:468)</span>
<span class="go">2025-07-07 13:03:48.696 | info     |           Metal | Disabling and clearing program cache on device 0 (device.cpp:783)</span>
<span class="go">2025-07-07 13:03:48.697 | info     |           Metal | Closing mesh device 1 (mesh_device.cpp:488)</span>
</pre></div>
</div>
</section>
</section>



           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="ttnn_basic_operations.html" class="btn btn-neutral float-left" title="More Basic Tensor Operations" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="ttnn_multihead_attention.html" class="btn btn-neutral float-right" title="Multi-Head Attention" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright Tenstorrent.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
        Version: <span id="current-version">latest</span>
        <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
        <dl id="version-list">
            <dt>Versions</dt>
        </dl>
        <br>
        </dl>
    </div>
</div>

<script>
const VERSIONS_URL = 'https://raw.githubusercontent.com/tenstorrent/tt-metal/refs/heads/main/docs/published_versions.json';

async function loadVersions() {
    try {
        const response = await fetch(VERSIONS_URL);
        const data = await response.json();
        const versionList = document.getElementById('version-list');
        const projectCode = location.pathname.split('/')[3];

        data.versions.forEach(version => {
            const dd = document.createElement('dd');
            const link = document.createElement('a');
            link.href = `https://docs.tenstorrent.com/tt-metal/${version}/${projectCode}/index.html`;
            link.textContent = version;
            dd.appendChild(link);
            versionList.appendChild(dd);
        });
    } catch (error) {
        console.error('Error loading versions:', error);
    }
}

loadVersions();

function getCurrentVersion() {
    return window.location.pathname.split('/')[2];
}
document.getElementById('current-version').textContent = getCurrentVersion();

const versionEl = document.createElement("span");
versionEl.innerText = getCurrentVersion();
versionEl.className = "project-versions";
const wySideSearchEl = document.getElementsByClassName("wy-side-nav-search").item(0);
if (wySideSearchEl) {
    const projectNameEl = wySideSearchEl.children.item(1);
    if (projectNameEl) projectNameEl.appendChild(versionEl);
}

</script><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>